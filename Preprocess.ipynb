{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import [BigQuery](https://cloud.google.com/bigquery) to use as your data warehouse.\n",
    "- Initialize the client to start interacting with the data warehouse, send SQL and retrieve data into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client=bigquery.Client.from_service_account_json(\"qlora-finetuning-cce64209d0bb.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Overflow Public Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_ALL = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts_answers\n",
      "users\n",
      "posts_orphaned_tag_wiki\n",
      "posts_tag_wiki\n",
      "stackoverflow_posts\n",
      "posts_questions\n",
      "comments\n",
      "posts_tag_wiki_excerpt\n",
      "posts_wiki_placeholder\n",
      "posts_privilege_wiki\n",
      "post_history\n",
      "badges\n",
      "post_links\n",
      "tags\n",
      "votes\n",
      "posts_moderator_nomination\n"
     ]
    }
   ],
   "source": [
    "for row in query_job:\n",
    "    for value in row.values():\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is too large to load into memory. 403 Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors; reason: responseTooLarge, message: Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n",
      "\n",
      "Location: US\n",
      "Job ID: 8ab0684b-9e80-47de-8e84-b48ca95401c9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    stack_overflow_df = query_job\\\n",
    "    .result()\\\n",
    "    .to_arrow()\\\n",
    "    .to_pandas()\n",
    "except Exception as e:\n",
    "    print('The DataFrame is too large to load into memory.', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Tables and Query Optimization\n",
    "\n",
    "- Select questions as `input_text` (column 1), answers as `output_text` (column 2).\n",
    "- Take the questions from `posts_questions` and answers from `posts_answers`.\n",
    "- Join the questions and their corresponding accepted answers based on their same `unique ID`.\n",
    "- Making sure the question is about `Python`, and that it `has an answer`. And the date the question was posted is on or after `2020-01-01`\n",
    "- Limit as 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT\n",
    "    CONCAT(q.title, q.body) as input_text,\n",
    "    a.body AS output_text\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "JOIN\n",
    "    `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "ON\n",
    "    q.accepted_answer_id = a.id\n",
    "WHERE\n",
    "    q.accepted_answer_id IS NOT NULL AND\n",
    "    REGEXP_CONTAINS(q.tags, \"python\") AND\n",
    "    a.creation_date >= \"2020-01-01\"\n",
    "LIMIT\n",
    "    10000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajdipingale/miniforge3/envs/ml_env/lib/python3.8/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECS task only able to pick one message from SQ...</td>\n",
       "      <td>&lt;p&gt;I forgot to give an answer to that question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When saving a list of LabelEncoders the classe...</td>\n",
       "      <td>&lt;p&gt;I suggest to avoid memory &lt;code&gt;id()&lt;/code&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  ECS task only able to pick one message from SQ...   \n",
       "1  When saving a list of LabelEncoders the classe...   \n",
       "\n",
       "                                         output_text  \n",
       "0  <p>I forgot to give an answer to that question...  \n",
       "1  <p>I suggest to avoid memory <code>id()</code>...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df = query_job.result()\\\n",
    "                        .to_arrow()\\\n",
    "                        .to_pandas()\n",
    "\n",
    "stack_overflow_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Instructions\n",
    "\n",
    "- Instructions for LLMs have been shown to improve\n",
    "model performance and generalization to unseen tasks.\n",
    "- Wihtout the instruction, it is only question and answer. Model might not understand what to do.\n",
    "- With the instructions, the model gets a guideline as to what task to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
    "Please answer the following Stackoverflow question on Python. \\\n",
    "Answer it like you are a developer answering Stackoverflow questions.\n",
    "\n",
    "Stackoverflow question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_df['input_text_instruct'] = INSTRUCTION_TEMPLATE + ' '\\\n",
    "    + stack_overflow_df['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, evaluation = train_test_split(\n",
    "    stack_overflow_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['input_text_instruct','output_text']\n",
    "tune_jsonl = train[cols].to_json(orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versioning data\n",
    "training_data_filename = f\"tune_data_stack_overflow_\\\n",
    "                            python_qa-{date}.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_data_filename, \"w\") as f:\n",
    "    f.write(tune_jsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data as required by Lamma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete! Transformed dataset saved to 'transformed_data1.json'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'tune_data_stack_overflow_                            python_qa-12:19:01:2025 copy.jsonl'\n",
    "\n",
    "output_file_path = 'transformed_data1.json'\n",
    "\n",
    "# Function to transform JSON to LLaMA 2 format\n",
    "def transform_to_llama_format(example):\n",
    "    input_text = example['input_text_instruct']\n",
    "    output_text = example['output_text']\n",
    "    \n",
    "    transformed_text = f'<s>[INST] {input_text.strip()} [/INST] {output_text.strip()} </s>'\n",
    "    return {'text': transformed_text}\n",
    "\n",
    "transformed_data = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            example = json.loads(line)\n",
    "            transformed_data.append(transform_to_llama_format(example))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Skipping invalid line: {line.strip()} - Error: {e}\")\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(transformed_data, output_file, indent=4)\n",
    "\n",
    "print(f\"Transformation complete! Transformed dataset saved to '{output_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
